{"version":3,"file":"bundle.js","mappings":";0BAKA,MAAM,MAACA,GAAS,EAAQ,KAClBC,EAAQ,EAAQ,MAChB,SAACC,GAAY,EAAQ,KA0X3BC,EAAOC,QAzWP,cAdA,QAeCC,YAAYC,GAEXC,QAEAC,KAAKF,YAAcA,EAMnBE,KAAKC,OAAS,GAcdD,KAAKE,OAAS,EAkBdF,KAAKG,YAAa,EAGnBC,OACC,OAAO,EAGRC,QAAQC,IAIRC,QACCP,KAAKQ,KAAK,GAGXA,KAAKN,GACJF,KAAKS,WACLT,KAAKE,MAAQF,KAAKU,gBAAgBR,GAGnCS,IAAIT,GAEH,OADAF,KAAKS,WACET,KAAKC,OAAOC,GAGpBU,UACC,IAAIC,GAAe,EAcnB,GATEA,EAJEb,KAAKE,OAAS,IACbF,KAAKG,WAGOH,KAAKE,MAAQF,KAAKC,OAAOa,OAAS,EAGlCd,KAAKE,MAAQF,KAAKC,OAAOa,SAMrCD,GAAgBb,KAAKe,GAAG,KAAOvB,EAAMwB,IACzC,KAAM,qBAEHhB,KAAKiB,KAAKjB,KAAKE,MAAQ,KAC1BF,KAAKE,MAAQF,KAAKU,gBAAgBV,KAAKE,MAAQ,IAWjDe,KAAKC,GACJ,MAAMC,EAAID,EAAIlB,KAAKC,OAAOa,OAAS,EACnC,QAAIK,EAAI,IACSnB,KAAKoB,MAAMD,IACTA,EAUpBC,MAAMD,GACL,GAAInB,KAAKG,WACR,OAAO,EAER,IAAK,IAAIe,EAAI,EAAGA,EAAIC,EAAGD,IAAK,CAC3B,MAAMG,EAAIrB,KAAKF,YAAYwB,YAG3B,GAFAD,EAAEE,WAAavB,KAAKC,OAAOa,OAC3Bd,KAAKC,OAAOuB,KAAKH,GACbA,EAAEI,OAASjC,EAAMwB,IAEpB,OADAhB,KAAKG,YAAa,EACXe,EAAI,EAGb,OAAOC,EAIRO,UAAUC,EAAOC,EAAMC,GAItB,QAHcC,IAAVD,IACHA,EAAQ,MAELF,EAAQ,GAAKC,EAAO,EACvB,OAAO,KAER5B,KAAKS,WACL,MAAMsB,EAAS,GACXH,GAAQ5B,KAAKC,OAAOa,SACvBc,EAAO5B,KAAKC,OAAOa,OAAS,GAE7B,IAAK,IAAII,EAAIS,EAAOT,EAAIU,EAAMV,IAAK,CAClC,MAAMG,EAAIrB,KAAKC,OAAOiB,GACtB,GAAIG,EAAEI,OAASjC,EAAMwB,IACpB,OAEa,OAAVa,GAAkBA,EAAMG,SAASX,EAAEI,QACtCM,EAAOP,KAAKH,GAGd,OAAOU,EAGRhB,GAAGG,GACF,OAAOlB,KAAKiC,GAAGf,GAAGO,KAGnBS,GAAGC,GACF,OAAInC,KAAKE,MAAQiC,EAAI,EACb,KAEDnC,KAAKC,OAAOD,KAAKE,MAAQiC,GAGjCF,GAAGE,GAEF,GADAnC,KAAKS,WACK,IAAN0B,EACH,OAAO,KAER,GAAIA,EAAI,EACP,OAAOnC,KAAKkC,IAAIC,GAEjB,MAAMjB,EAAIlB,KAAKE,MAAQiC,EAAI,EAE3B,OADAnC,KAAKiB,KAAKC,GACNA,GAAKlB,KAAKC,OAAOa,OAEbd,KAAKC,OAAOD,KAAKC,OAAOa,OAAS,GAElCd,KAAKC,OAAOiB,GAiBpBR,gBAAgBQ,GACf,OAAOA,EAGRT,YACqB,IAAhBT,KAAKE,OACRF,KAAKoC,QAIPA,QACCpC,KAAKiB,KAAK,GACVjB,KAAKE,MAAQF,KAAKU,gBAAgB,GAInC2B,eAAevC,GACdE,KAAKF,YAAcA,EACnBE,KAAKC,OAAS,GACdD,KAAKE,OAAS,EACdF,KAAKG,YAAa,EAQnBmC,mBAAmBpB,EAAGqB,GAErB,GADAvC,KAAKiB,KAAKC,GACNA,GAAKlB,KAAKC,OAAOa,OACpB,OAAQ,EAET,IAAI0B,EAAQxC,KAAKC,OAAOiB,GACxB,KAAOsB,EAAMD,UAAYvC,KAAKuC,SAAS,CACtC,GAAIC,EAAMf,OAASjC,EAAMwB,IACxB,OAAQ,EAETE,GAAK,EACLlB,KAAKiB,KAAKC,GACVsB,EAAQxC,KAAKC,OAAOiB,GAErB,OAAOA,EAQRuB,uBAAuBvB,EAAGqB,GACzB,KAAOrB,GAAK,GAAKlB,KAAKC,OAAOiB,GAAGqB,UAAYA,GAC3CrB,GAAK,EAEN,OAAOA,EAQRwB,uBAAuBnB,EACrBgB,GAKD,QAJgBT,IAAZS,IACHA,GAAW,GAEZvC,KAAKS,WACDc,EAAa,GAAKA,GAAcvB,KAAKC,OAAOa,OAC/C,MAAWS,EAAa,cAAgBvB,KAAKC,OAAOa,OAAS,EAE9D,MAAM6B,EAAgB3C,KAAKsC,mBAAmBf,EAAa,EAAG9B,EAAMmD,uBAC9DC,EAAQtB,EAAa,EAErBuB,GAAwB,IAAnBH,EAAuB3C,KAAKC,OAAOa,OAAS,EAAI6B,EAC3D,OAAO3C,KAAK+C,iBAAiBF,EAAOC,EAAIP,GAQzCS,sBAAsBzB,EACpBgB,GAKD,QAJgBT,IAAZS,IACHA,GAAW,GAEZvC,KAAKS,WACDc,EAAa,GAAKA,GAAcvB,KAAKC,OAAOa,OAC/C,MAAWS,EAAa,cAAgBvB,KAAKC,OAAOa,OAAS,EAE9D,MAAMmC,EAAgBjD,KAAKyC,uBAAuBlB,EAAa,EAAG9B,EAAMmD,uBACxE,GAAIK,IAAkB1B,EAAa,EAClC,OAAO,KAGR,MAAMsB,EAAQI,EAAgB,EACxBH,EAAKvB,EAAa,EACxB,OAAOvB,KAAK+C,iBAAiBF,EAAOC,EAAIP,GAGzCQ,iBAAiBG,EAAMC,EAAOZ,GAC7B,MAAMa,EAAS,GACf,IAAK,IAAIlC,EAAIgC,EAAMhC,EAAIiC,EAAQ,EAAGjC,IAAK,CACtC,MAAMG,EAAIrB,KAAKC,OAAOiB,IACL,IAAbqB,EACClB,EAAEkB,UAAY9C,EAAMmD,uBACvBQ,EAAO5B,KAAKH,GAEHA,EAAEkB,UAAYA,GACxBa,EAAO5B,KAAKH,GAGd,OAAsB,IAAlB+B,EAAOtC,OACH,KAEDsC,EAGRC,gBACC,OAAOrD,KAAKF,YAAYuD,gBAIzBC,QAAQC,GACPvD,KAAKS,WACLT,KAAKwD,OACDD,MAAAA,IACHA,EAAW,IAAI7D,EAAS,EAAGM,KAAKC,OAAOa,OAAS,IAEjD,IAAIa,EAAQ4B,EAAS5B,MACjBA,aAAiBnC,IACpBmC,EAAQA,EAAMJ,YAEf,IAAIK,EAAO2B,EAAS3B,KAIpB,GAHIA,aAAgBpC,IACnBoC,EAAOA,EAAKL,YAEC,OAAVI,GAA2B,OAATC,GAAiBD,EAAQ,GAAKC,EAAO,EAC1D,MAAO,GAEJA,GAAQ5B,KAAKC,OAAOa,SACvBc,EAAO5B,KAAKC,OAAOa,OAAS,GAE7B,IAAI2C,EAAI,GACR,IAAK,IAAIvC,EAAIS,EAAOT,EAAIU,EAAO,EAAGV,IAAK,CACtC,MAAMG,EAAIrB,KAAKC,OAAOiB,GACtB,GAAIG,EAAEI,OAASjC,EAAMwB,IACpB,MAEDyC,GAAQpC,EAAEqC,KAEX,OAAOD,EAIRD,OAEC,IADAxD,KAAKS,WACuB,MAArBT,KAAKoB,MAAM,yBCrXpB,MAAMuC,EAAc,EAAQ,KACtBC,EAAK,EAAQ,KASbC,EAAc,CAElBC,WAAY,SAASC,GACnB,OAAO,IAAIJ,EAAYI,GAAK,IAW9BC,SAAU,SAASC,EAAMC,EAAUC,EAAQC,GACzC,MAAMC,EAAS,IAAIC,OAAOC,WAC1BF,EAAOG,OAAS,SAASC,GACvB,MAAMC,EAAK,IAAIf,EAAYc,EAAEE,OAAOC,QAAQ,GAC5CT,EAAOO,IAETL,EAAOQ,QAAUT,EACjBC,EAAOS,WAAWb,EAAMC,IAQ1Ba,WAAY,SAASC,EAAQd,GAC3B,OAAO,IAAIP,EAAYqB,EAAOC,SAASf,IAAW,IASpDgB,SAAU,SAASC,EAAMjB,EAAUkB,GACjCxB,EAAGyB,SAASF,EAAMjB,GAAU,SAASoB,EAAKC,GACxC,IAAIb,EAAK,KACI,OAATa,IACFb,EAAK,IAAIf,EAAY4B,GAAM,IAE7BH,EAASE,EAAKZ,OASlBc,aAAc,SAASL,EAAMjB,GAC3B,MAAMqB,EAAO3B,EAAG6B,aAAaN,EAAMjB,GACnC,OAAO,IAAIP,EAAY4B,GAAM,KAIjC5F,EAAOC,QAAUiE,gBCtEjB,MAAM6B,EAAc,mBAQpB,MAAMC,UANN,QAOI9F,YAAY+F,GACR7F,QAgBAC,KAAK4F,cAAsB9D,IAAX8D,GAA+BA,EAGnDC,OAAOC,EAAQrE,EAAMiC,EAAMnB,EAASZ,EAAOC,EAAMmE,EAAMC,GACnD,MAAM3E,EAAI,IAAIqE,EAAYI,EAAQrE,EAAMc,EAASZ,EAAOC,GAQxD,OAPAP,EAAE0E,KAAOA,EACT1E,EAAE2E,OAASA,EACC,OAARtC,EACArC,EAAEqC,KAAOA,EACF1D,KAAK4F,UAAyB,OAAbE,EAAO,KAC/BzE,EAAEqC,KAAOoC,EAAO,GAAGxC,QAAQ3B,EAAMC,IAE9BP,EAGX4E,WAAWxE,EAAMiC,GACb,MAAMrC,EAAI,IAAIqE,EAAY,KAAMjE,GAEhC,OADAJ,EAAEqC,KAAOA,EACFrC,GAWfsE,EAAmBO,QAAU,IAAIP,EAEjChG,EAAOC,QAAU+F,iBCxDjB,MAAMnG,EAAQ,aACR2G,EAAsB,EAAQ,IA4FpCxG,EAAOC,QAlEP,cAAgCuG,EAC5BtG,YAAYuG,EAAO7D,GACfxC,MAAMqG,GACNpG,KAAKuC,aAAoBT,IAAVS,EAAsB/C,EAAM6G,gBAAkB9D,EAGjE7B,gBAAgBQ,GACZ,OAAOlB,KAAKsC,mBAAmBpB,EAAGlB,KAAKuC,SAG3CL,GAAGC,GACC,GAAQ,IAAJA,GAASnC,KAAKE,MAAMiC,EAAE,EACtB,OAAO,KAEX,IAAIjB,EAAIlB,KAAKE,MACTiB,EAAI,EAER,KAAOA,GAAKgB,GAERjB,EAAIlB,KAAKyC,uBAAuBvB,EAAI,EAAGlB,KAAKuC,SAC5CpB,GAAK,EAET,OAAID,EAAI,EACG,KAEJlB,KAAKC,OAAOiB,GAGvBe,GAAGE,GAEC,GADAnC,KAAKS,WACK,IAAN0B,EACA,OAAO,KAEX,GAAIA,EAAI,EACJ,OAAOnC,KAAKkC,IAAIC,GAEpB,IAAIjB,EAAIlB,KAAKE,MACTiB,EAAI,EAER,KAAOA,EAAIgB,GAEHnC,KAAKiB,KAAKC,EAAI,KACdA,EAAIlB,KAAKsC,mBAAmBpB,EAAI,EAAGlB,KAAKuC,UAE5CpB,GAAK,EAET,OAAOnB,KAAKC,OAAOiB,GAIvBoF,6BACI,IAAInF,EAAI,EACRnB,KAAKwD,OACL,IAAK,IAAItC,EAAG,EAAGA,EAAGlB,KAAKC,OAAOa,OAAOI,IAAK,CACtC,MAAMG,EAAIrB,KAAKC,OAAOiB,GAItB,GAHIG,EAAEkB,UAAUvC,KAAKuC,UACjBpB,GAAK,GAELE,EAAEI,OAAOjC,EAAMwB,IACf,MAGR,OAAOG,mBC1Ff,MAAMwC,EAAc,EAAQ,KACtBC,EAAK,EAAQ,KAcnBjE,EAAOC,QARP,cAAyB+D,EACxB9D,YAAY0G,EAAUC,GAErBzG,MADa6D,EAAG6B,aAAac,EAAU,QAC3BC,GACZxG,KAAKuG,SAAWA,mBCXlB,MAAM,MAAC/G,GAAS,EAAQ,KACxB,EAAQ,KACR,EAAQ,KA2HRG,EAAOC,QAlHP,MACCC,YAAY0F,EAAMiB,GAOjB,GANAxG,KAAKyG,KAAO,UACZzG,KAAK0G,QAAUnB,EACfvF,KAAKwG,0BAA4BA,IAA6B,EAE9DxG,KAAK2G,OAAS,EACd3G,KAAKuF,KAAO,GACRvF,KAAKwG,0BACR,IAAK,IAAItF,EAAI,EAAGA,EAAIlB,KAAK0G,QAAQ5F,QAAU,CAC1C,MAAM8F,EAAY5G,KAAK0G,QAAQG,YAAY3F,GAC3ClB,KAAKuF,KAAK/D,KAAKoF,GACf1F,GAAK0F,GAAa,MAAS,EAAI,MAE1B,CACN5G,KAAKuF,KAAO,IAAIuB,MAAM9G,KAAK0G,QAAQ5F,QACnC,IAAK,IAAII,EAAI,EAAGA,EAAIlB,KAAK0G,QAAQ5F,OAAQI,IAAK,CAC7C,MAAM6F,EAAW/G,KAAK0G,QAAQM,WAAW9F,GACzClB,KAAKuF,KAAKrE,GAAK6F,GAGjB/G,KAAKiH,MAAQjH,KAAKuF,KAAKzE,OAQxBP,QACCP,KAAK2G,OAAS,EAGf/F,UACC,GAAIZ,KAAK2G,QAAU3G,KAAKiH,MAEvB,KAAM,qBAEPjH,KAAK2G,QAAU,EAGhB5F,GAAGmG,GACF,GAAe,IAAXA,EACH,OAAO,EAEJA,EAAS,IACZA,GAAU,GAEX,MAAMC,EAAMnH,KAAK2G,OAASO,EAAS,EACnC,OAAIC,EAAM,GAAKA,GAAOnH,KAAKiH,MACnBzH,EAAMwB,IAEPhB,KAAKuF,KAAK4B,GAGlBlF,GAAGiF,GACF,OAAOlH,KAAKe,GAAGmG,GAIhB9G,OACC,OAAQ,EAGTC,QAAQC,IAORE,KAAKmG,GACAA,GAAU3G,KAAK2G,OAClB3G,KAAK2G,OAASA,EAKf3G,KAAK2G,OAASS,KAAKC,IAAIV,EAAQ3G,KAAKiH,OAGrC3D,QAAQ3B,EAAOC,GAId,GAHIA,GAAQ5B,KAAKiH,QAChBrF,EAAO5B,KAAKiH,MAAQ,GAEjBtF,GAAS3B,KAAKiH,MACjB,MAAO,GAEP,GAAIjH,KAAKwG,0BAA2B,CACnC,IAAI5B,EAAS,GACb,IAAK,IAAI1D,EAAIS,EAAOT,GAAKU,EAAMV,IAC9B0D,GAAU0C,OAAOC,cAAcvH,KAAKuF,KAAKrE,IAE1C,OAAO0D,EAEP,OAAO5E,KAAK0G,QAAQc,MAAM7F,EAAOC,EAAO,GAK3CqD,WACC,OAAOjF,KAAK0G,QAGTxG,YACH,OAAOF,KAAK2G,OAGTc,WACH,OAAOzH,KAAKiH,uBCxHd,MAAM,MAACzH,GAAS,EAAQ,KAGxB,MAAME,EAELG,YAAY8B,EAAOC,GAClB5B,KAAK2B,MAAQA,EACb3B,KAAK4B,KAAOA,EAGb8F,QACC,OAAO,IAAIhI,EAASM,KAAK2B,MAAO3B,KAAK4B,MAGtCI,SAAS2F,GACR,OAAOA,GAAQ3H,KAAK2B,OAASgG,EAAO3H,KAAK4B,KAG1CqD,WACC,OAAGjF,KAAK2B,QAAQ3B,KAAK4B,KAAK,EAClB5B,KAAK2B,MAAMsD,WAEXjF,KAAK2B,MAAMsD,WAAa,MAAQjF,KAAK4B,KAAK,GAAGqD,WAIlDnE,aACH,OAAOd,KAAK4B,KAAO5B,KAAK2B,OAK1B,MAAMiG,EACL/H,cACCG,KAAK6H,UAAY,KACjB7H,KAAK8H,UAAW,EAGjBC,MAAMC,GACL,OAAuB,OAAnBhI,KAAK6H,WAA8C,IAAxB7H,KAAK6H,UAAU/G,OACtCtB,EAAMyI,aAENjI,KAAK6H,UAAU,GAAGlG,MAI3BuG,OAAOF,GACNhI,KAAKmI,YAAY,IAAIzI,EAASsI,EAAGA,EAAI,IAGtCI,SAASC,EAAGC,GACXtI,KAAKmI,YAAY,IAAIzI,EAAS2I,EAAGC,EAAI,IAGtCH,YAAYI,GACX,GAAuB,OAAnBvI,KAAK6H,UACR7H,KAAK6H,UAAY,GACjB7H,KAAK6H,UAAUrG,KAAK+G,EAAMb,aACpB,CAEN,IAAK,IAAIP,EAAM,EAAGA,EAAMnH,KAAK6H,UAAU/G,OAAQqG,IAAO,CACrD,MAAMqB,EAAWxI,KAAK6H,UAAUV,GAEhC,GAAIoB,EAAM3G,KAAO4G,EAAS7G,MAEzB,YADA3B,KAAK6H,UAAUY,OAAOtB,EAAK,EAAGoB,GAI1B,GAAIA,EAAM3G,OAAS4G,EAAS7G,MAEhC,YADA3B,KAAK6H,UAAUV,GAAO,IAAIzH,EAAS6I,EAAM5G,MAAO6G,EAAS5G,OAIrD,GAAI2G,EAAM5G,OAAS6G,EAAS5G,KAGhC,OAFA5B,KAAK6H,UAAUV,GAAO,IAAIzH,EAAS0H,KAAKC,IAAImB,EAAS7G,MAAO4G,EAAM5G,OAAQyF,KAAKsB,IAAIF,EAAS5G,KAAM2G,EAAM3G,YACxG5B,KAAK2I,OAAOxB,GAKdnH,KAAK6H,UAAUrG,KAAK+G,EAAMb,UAI5BkB,OAAOC,GAIN,OAHwB,OAApBA,EAAMhB,WACTgB,EAAMhB,UAAUiB,SAASP,GAASvI,KAAKmI,YAAYI,IAAQvI,MAErDA,KAGR2I,OAAOxB,GAEN,GAAIA,EAAMnH,KAAK6H,UAAU/G,OAAS,EAAG,CACpC,MAAMiI,EAAU/I,KAAK6H,UAAUV,GACzB6B,EAAOhJ,KAAK6H,UAAUV,EAAM,GAE9B4B,EAAQnH,MAAQoH,EAAKpH,MACxB5B,KAAK6H,UAAUY,OAAOtB,EAAM,EAAG,GAC/BnH,KAAK2I,OAAOxB,IACF4B,EAAQnH,MAAQoH,EAAKrH,QAC/B3B,KAAK6H,UAAUV,GAAO,IAAIzH,EAASqJ,EAAQpH,MAAOqH,EAAKpH,MACvD5B,KAAK6H,UAAUY,OAAOtB,EAAM,EAAG,KAKlC8B,WAAWtH,EAAOC,GACjB,MAAMgD,EAAS,IAAIgD,EAInB,OAHAhD,EAAOuD,YAAY,IAAIzI,EAASiC,EAAOC,EAAO,IACxB,OAAnB5B,KAAK6H,WACP7H,KAAK6H,UAAUiB,SAAQI,GAAYtE,EAAOuE,YAAYD,KAChDtE,EAGR5C,SAAS2F,GACR,GAAuB,OAAnB3H,KAAK6H,UACR,OAAO,EAEP,IAAK,IAAI1F,EAAI,EAAGA,EAAInC,KAAK6H,UAAU/G,OAAQqB,IAC1C,GAAGnC,KAAK6H,UAAU1F,GAAGH,SAAS2F,GAC7B,OAAO,EAGT,OAAO,EAITwB,YAAYD,GACX,GAAGA,EAASvH,QAAQuH,EAAStH,KAAK,EACjC5B,KAAKoJ,UAAUF,EAASvH,YAClB,GAAuB,OAAnB3B,KAAK6H,UAAoB,CACnC,IAAIV,EAAM,EACV,IAAI,IAAIhG,EAAE,EAAGA,EAAEnB,KAAK6H,UAAU/G,OAAQK,IAAK,CAC1C,MAAMqH,EAAWxI,KAAK6H,UAAUV,GAEhC,GAAI+B,EAAStH,MAAM4G,EAAS7G,MAC3B,OAGI,GAAGuH,EAASvH,MAAM6G,EAAS7G,OAASuH,EAAStH,KAAK4G,EAAS5G,KAAM,CACrE5B,KAAK6H,UAAUV,GAAO,IAAIzH,EAAS8I,EAAS7G,MAAOuH,EAASvH,OAC5D,MAAM0H,EAAI,IAAI3J,EAASwJ,EAAStH,KAAM4G,EAAS5G,MAE/C,YADA5B,KAAK6H,UAAUY,OAAOtB,EAAK,EAAGkC,GAIvBH,EAASvH,OAAO6G,EAAS7G,OAASuH,EAAStH,MAAM4G,EAAS5G,MACjE5B,KAAK6H,UAAUY,OAAOtB,EAAK,GAC3BA,GAAY,GAGL+B,EAASvH,MAAM6G,EAAS5G,KAC/B5B,KAAK6H,UAAUV,GAAO,IAAIzH,EAAS8I,EAAS7G,MAAOuH,EAASvH,OAGrDuH,EAAStH,KAAK4G,EAAS5G,OAC9B5B,KAAK6H,UAAUV,GAAO,IAAIzH,EAASwJ,EAAStH,KAAM4G,EAAS5G,OAE5DuF,GAAO,IAKViC,UAAUE,GACT,GAAuB,OAAnBtJ,KAAK6H,UACR,IAAK,IAAI3G,EAAI,EAAGA,EAAIlB,KAAK6H,UAAU/G,OAAQI,IAAK,CAC/C,MAAMsH,EAAWxI,KAAK6H,UAAU3G,GAEhC,GAAIoI,EAAQd,EAAS7G,MACpB,OAGI,GAAI2H,IAAUd,EAAS7G,OAAS2H,IAAUd,EAAS5G,KAAO,EAE9D,YADA5B,KAAK6H,UAAUY,OAAOvH,EAAG,GAIrB,GAAIoI,IAAUd,EAAS7G,MAE3B,YADA3B,KAAK6H,UAAU3G,GAAK,IAAIxB,EAAS8I,EAAS7G,MAAQ,EAAG6G,EAAS5G,OAI1D,GAAI0H,IAAUd,EAAS5G,KAAO,EAElC,YADA5B,KAAK6H,UAAU3G,GAAK,IAAIxB,EAAS8I,EAAS7G,MAAO6G,EAAS5G,KAAO,IAI7D,GAAI0H,EAAQd,EAAS5G,KAAO,EAAG,CACnC,MAAM2H,EAAU,IAAI7J,EAAS8I,EAAS7G,MAAO2H,GAG7C,OAFAd,EAAS7G,MAAQ2H,EAAQ,OACzBtJ,KAAK6H,UAAUY,OAAOvH,EAAG,EAAGqI,KAOhCtE,SAASuE,EAAcC,EAAeC,GAIrC,OAHAF,EAAeA,GAAgB,KAC/BC,EAAgBA,GAAiB,KACjCC,EAAeA,IAAgB,EACR,OAAnB1J,KAAK6H,UACD,KACiB,OAAf2B,GAAuC,OAAhBC,EACzBzJ,KAAK2J,cAAcH,EAAcC,GAC/BC,EACF1J,KAAK4J,eAEL5J,KAAK6J,gBAIdD,eACC,MAAME,EAAQ,GACd,IAAK,IAAI5I,EAAI,EAAGA,EAAIlB,KAAK6H,UAAU/G,OAAQI,IAAK,CAC/C,MAAMsH,EAAWxI,KAAK6H,UAAU3G,GAC7BsH,EAAS5G,OAAO4G,EAAS7G,MAAM,EAC5B6G,EAAS7G,QAAQnC,EAAMwB,IAC3B8I,EAAMtI,KAAK,SAEXsI,EAAMtI,KAAK,IAAM8F,OAAOyC,aAAavB,EAAS7G,OAAS,KAGxDmI,EAAMtI,KAAK,IAAM8F,OAAOyC,aAAavB,EAAS7G,OAAS,OAAS2F,OAAOyC,aAAavB,EAAS5G,KAAK,GAAK,KAGzG,OAAIkI,EAAMhJ,OAAS,EACX,IAAMgJ,EAAME,KAAK,MAAQ,IAEzBF,EAAM,GAIfD,gBACC,MAAMC,EAAQ,GACd,IAAK,IAAI5I,EAAI,EAAGA,EAAIlB,KAAK6H,UAAU/G,OAAQI,IAAK,CAC/C,MAAMsH,EAAWxI,KAAK6H,UAAU3G,GAC7BsH,EAAS5G,OAAO4G,EAAS7G,MAAM,EAC5B6G,EAAS7G,QAAQnC,EAAMwB,IAC3B8I,EAAMtI,KAAK,SAEXsI,EAAMtI,KAAKgH,EAAS7G,MAAMsD,YAG3B6E,EAAMtI,KAAKgH,EAAS7G,MAAMsD,WAAa,MAAQuD,EAAS5G,KAAK,GAAGqD,YAGlE,OAAI6E,EAAMhJ,OAAS,EACX,IAAMgJ,EAAME,KAAK,MAAQ,IAEzBF,EAAM,GAIfH,cAAcH,EAAcC,GAC3B,MAAMK,EAAQ,GACd,IAAK,IAAI5I,EAAI,EAAGA,EAAIlB,KAAK6H,UAAU/G,OAAQI,IAAK,CAC/C,MAAMsH,EAAWxI,KAAK6H,UAAU3G,GAChC,IAAK,IAAI+I,EAAIzB,EAAS7G,MAAOsI,EAAIzB,EAAS5G,KAAMqI,IAC/CH,EAAMtI,KAAKxB,KAAKkK,YAAYV,EAAcC,EAAeQ,IAG3D,OAAIH,EAAMhJ,OAAS,EACX,IAAMgJ,EAAME,KAAK,MAAQ,IAEzBF,EAAM,GAIfI,YAAYV,EAAcC,EAAejH,GACxC,OAAIA,IAAUhD,EAAMwB,IACZ,QACGwB,IAAUhD,EAAM2K,QACnB,YAEAX,EAAahH,IAAUiH,EAAcjH,GAI1C1B,aACH,OAAOd,KAAK6H,UAAUuC,KAAK7G,GAAYA,EAASzC,SAAS6H,QAAO,CAAC0B,EAAKC,IAAQD,EAAMC,KAItF3K,EAAOC,QAAU,CAChBF,SAAAA,EACAkI,YAAAA,kBC/RD,MAAM,IAAC2C,EAAG,OAAEC,GAAU,EAAQ,MACxB,MAAChL,GAAS,EAAQ,MAClB,UAACiL,GAAa,EAAQ,MACtB,YAAC7C,GAAe,EAAQ,MACxB,cAAC8C,GAAiB,EAAQ,MAC1B,eAACC,EAAc,iBAAEC,EAAgB,mBAAEC,EAAkB,4BAAEC,GAA+B,EAAQ,KAC9F,iCAACC,EAAgC,kBAAEC,EAAiB,2BAAEC,GAA8B,EAAQ,KAElG,MAAMC,EACFrL,YAAYsL,GACRnL,KAAKmL,IAAMA,EAafC,qBAAqB3H,GACjB,GAAU,OAANA,EACA,OAAO,KAEX,MAAM4H,EAAQ5H,EAAE6H,YAAYxK,OACtByK,EAAO,GACb,IAAI,IAAIC,EAAI,EAAGA,EAAKH,EAAOG,IAAO,CAC9BD,EAAKC,GAAO,IAAI5D,EAChB,MAAM6D,EAAW,IAAIlB,EACfmB,GAAe,EACrB1L,KAAK2L,MAAMlI,EAAEmI,WAAWJ,GAAK7G,OAAQ,KAAMqG,EAAkBa,MACvDN,EAAKC,GAAMC,EAAU,IAAIjB,EAAUkB,GAAc,IAGhC,IAAnBH,EAAKC,GAAK1K,QAAcyK,EAAKC,GAAKxJ,SAASkJ,EAAYY,aACvDP,EAAKC,GAAO,MAGpB,OAAOD,EAqBXQ,KAAKtI,EAAGuI,EAAWC,GACf,MAAMC,EAAI,IAAItE,EAGRuE,EAAoB,QAD1BF,EAAMA,GAAO,MACoBlB,EAAiCtH,EAAE0H,IAAKc,GAAO,KAEhF,OADAjM,KAAK2L,MAAMlI,EAAGuI,EAAWG,EAAaD,EAAG,IAAI3B,EAAO,IAAIC,GAHnC,GAG2D,GACzE0B,EAiCXP,MAAMlI,EAAGuI,EAAYC,EAAKV,EAAME,EAAUW,EAAiBV,EAAcW,GACrE,MAAMC,EAAI,IAAI7B,EAAU,CAAC8B,MAAM9I,EAAG+H,IAAI,EAAGgB,QAASP,GAAM,MACxD,IAAIR,EAASzJ,SAASsK,GAAtB,CAIA,GADAb,EAASgB,IAAIH,GACT7I,IAAMuI,EAAW,CACjB,GAAW,OAAPC,EAEA,YADAV,EAAKrD,OAAO1I,EAAM2K,SAEf,GAAI8B,EAAIS,WAAaL,EAExB,YADAd,EAAKrD,OAAO1I,EAAMwB,KAI1B,GAAIyC,aAAaiH,EAAgB,CAC7B,GAAW,OAAPuB,EAEA,YADAV,EAAKrD,OAAO1I,EAAM2K,SAEf,GAAI8B,EAAIS,WAAaL,EAExB,YADAd,EAAKrD,OAAO1I,EAAMwB,KAGtB,GAAIiL,IAAQjB,EAAkBa,MAAO,CACjC,MAAMc,EAAUP,EAAgBpK,SAASyB,EAAEmJ,WAC3C,IACIR,EAAgBS,OAAOpJ,EAAEmJ,WAEzB,IAAK,IAAI1L,EAAI,EAAGA,EAAI+K,EAAInL,OAAQI,IAAK,CACjC,MAAM4L,EAAc9M,KAAKmL,IAAI4B,OAAOd,EAAIe,eAAe9L,IACvDlB,KAAK2L,MAAMmB,EAAad,EAAWC,EAAIgB,UAAU/L,GAAIqK,EAAME,EAAUW,EAAiBV,EAAcW,IAE3G,QACOM,GACAP,EAAgBK,IAAIhJ,EAAEmJ,WAG9B,QAGR,IAAI,IAAI3C,EAAE,EAAGA,EAAExG,EAAE6H,YAAYxK,OAAQmJ,IAAK,CACtC,MAAM5I,EAAIoC,EAAE6H,YAAYrB,GACxB,GAAI5I,EAAExB,cAAgB8K,EAAgB,CAClC,GAAIyB,EAAgBpK,SAASX,EAAEsD,OAAOiI,WAClC,SAEJ,MAAMM,EAAajC,EAA2BpF,OAAOoG,EAAK5K,EAAE8L,YAAYC,aACxE,IACIhB,EAAgBK,IAAIpL,EAAEsD,OAAOiI,WAC7B5M,KAAK2L,MAAMtK,EAAEsD,OAAQqH,EAAWkB,EAAY3B,EAAME,EAAUW,EAAiBV,EAAcW,GAC7F,QACED,EAAgBS,OAAOxL,EAAEsD,OAAOiI,iBAEjC,GAAIvL,aAAayJ,EAChBY,EACA1L,KAAK2L,MAAMtK,EAAEsD,OAAQqH,EAAWC,EAAKV,EAAME,EAAUW,EAAiBV,EAAcW,GAEpFd,EAAKrD,OAAOgD,EAAYY,eAEzB,GAAIzK,EAAEgM,UACTrN,KAAK2L,MAAMtK,EAAEsD,OAAQqH,EAAWC,EAAKV,EAAME,EAAUW,EAAiBV,EAAcW,QACjF,GAAIhL,EAAExB,cAAgBgL,EACzBU,EAAKnD,SAAU5I,EAAM8N,oBAAqBtN,KAAKmL,IAAIoC,kBAChD,CACH,IAAIC,EAAMnM,EAAEoM,MACA,OAARD,IACInM,aAAauJ,IACb4C,EAAMA,EAAIvE,WAAWzJ,EAAM8N,oBAAqBtN,KAAKmL,IAAIoC,eAE7DhC,EAAK3C,OAAO4E,QAWhCtC,EAAYY,SAAWtM,EAAMyI,aAE7BtI,EAAOC,QAAUsL,iBCvLjB,MAAM,MAAC1L,GAAS,EAAQ,KAClBkO,EAAa,EAAQ,KACrB/H,EAAqB,EAAQ,KAC7B,qBAACgI,GAAwB,EAAQ,MACjC,0BAACC,GAA6B,EAAQ,KAS5C,MAAMnO,UAAciO,EACnB7N,YAAYgO,GACX9N,QACAC,KAAK8N,OAASD,EACd7N,KAAK+N,SAAWpI,EAAmBO,QACnClG,KAAKgO,wBAA0B,CAAEhO,KAAM6N,GAEvC7N,KAAKiO,QAAU,KAWfjO,KAAKkO,OAAS,KAOdlO,KAAKmO,sBAAwB,EAG7BnO,KAAKoO,iBAAmB,EAGxBpO,KAAKqO,mBAAqB,EAI1BrO,KAAKsO,SAAU,EAGftO,KAAKuO,SAAW/O,EAAM6G,gBAGtBrG,KAAKwO,MAAQhP,EAAMyI,aAEnBjI,KAAKyO,WAAa,GAClBzO,KAAK0O,MAAQjP,EAAMkP,aAMnB3O,KAAK4O,MAAQ,KAGdrO,QAEqB,OAAhBP,KAAK8N,QACR9N,KAAK8N,OAAOtN,KAAK,GAElBR,KAAKkO,OAAS,KACdlO,KAAKwO,MAAQhP,EAAMyI,aACnBjI,KAAKuO,SAAW/O,EAAM6G,gBACtBrG,KAAKmO,sBAAwB,EAC7BnO,KAAKqO,mBAAqB,EAC1BrO,KAAKoO,iBAAmB,EACxBpO,KAAK4O,MAAQ,KAEb5O,KAAKsO,SAAU,EACftO,KAAK0O,MAAQjP,EAAMkP,aACnB3O,KAAKyO,WAAa,GAElBzO,KAAKiO,QAAQ1N,QAIde,YACC,GAAoB,OAAhBtB,KAAK8N,OACR,KAAM,8CAOP,MAAMe,EAAmB7O,KAAK8N,OAAO1N,OACrC,IACC,OAAa,CACZ,GAAIJ,KAAKsO,QAER,OADAtO,KAAK8O,UACE9O,KAAKkO,OAEblO,KAAKkO,OAAS,KACdlO,KAAKuO,SAAW/O,EAAM6G,gBACtBrG,KAAKmO,qBAAuBnO,KAAK8N,OAAO5N,MACxCF,KAAKqO,kBAAoBrO,KAAKiO,QAAQjI,OACtChG,KAAKoO,gBAAkBpO,KAAKiO,QAAQlI,KACpC/F,KAAK4O,MAAQ,KACb,IAAIG,GAAgB,EACpB,OAAa,CACZ/O,KAAKwO,MAAQhP,EAAMyI,aACnB,IAAI+G,EAAQvP,EAAMwP,KAClB,IACCD,EAAQhP,KAAKiO,QAAQiB,MAAMlP,KAAK8N,OAAQ9N,KAAK0O,OAC5C,MAAOjK,GACR,KAAGA,aAAakJ,GAKf,MADAwB,QAAQC,IAAI3K,EAAE4K,OACR5K,EAJNzE,KAAKsP,gBAAgB7K,GACrBzE,KAAKuP,QAAQ9K,GAYf,GANIzE,KAAK8N,OAAO/M,GAAG,KAAOvB,EAAMwB,MAC/BhB,KAAKsO,SAAU,GAEZtO,KAAKwO,QAAUhP,EAAMyI,eACxBjI,KAAKwO,MAAQQ,GAEVhP,KAAKwO,QAAU/O,EAAMwP,KAAM,CAC9BF,GAAgB,EAChB,MAED,GAAI/O,KAAKwO,QAAU/O,EAAM+P,KACxB,MAGF,IAAIT,EAMJ,OAHoB,OAAhB/O,KAAKkO,QACRlO,KAAKyP,OAECzP,KAAKkO,QAEZ,QAGDlO,KAAK8N,OAAOzN,QAAQwO,IAWtBa,OACC1P,KAAKwO,MAAQ/O,EAAMwP,KAGpBU,OACC3P,KAAKwO,MAAQ/O,EAAM+P,KAGpBI,KAAKC,GACJ7P,KAAK0O,MAAQmB,EAGdC,SAASD,GACJ7P,KAAKiO,QAAQ8B,OAChBZ,QAAQC,IAAI,YAAcS,GAE3B7P,KAAKyO,WAAWjN,KAAKxB,KAAK0O,OAC1B1O,KAAK4P,KAAKC,GAGXG,UACC,GAA+B,IAA3BhQ,KAAKyO,WAAW3N,OACnB,KAAM,cAMP,OAJId,KAAKiO,QAAQ8B,OAChBZ,QAAQC,IAAI,mBAAqBpP,KAAKyO,WAAWjH,MAAM,GAAI,IAE5DxH,KAAK4P,KAAK5P,KAAKyO,WAAWwB,OACnBjQ,KAAK0O,MASbwB,UAAU1N,GACTxC,KAAKkO,OAAS1L,EAUfiN,OACC,MAAMpO,EAAIrB,KAAK+N,SAASlI,OAAO7F,KAAKgO,wBAAyBhO,KAAKwO,MAChExO,KAAK4O,MAAO5O,KAAKuO,SAAUvO,KAAKmO,qBAAsBnO,KACnDmQ,eAAiB,EAAGnQ,KAAKoO,gBAC5BpO,KAAKqO,mBAEP,OADArO,KAAKkQ,UAAU7O,GACRA,EAGRyN,UACC,MAAMsB,EAAOpQ,KAAKgG,OACZqK,EAAOrQ,KAAK+F,KACZuK,EAAMtQ,KAAK+N,SAASlI,OAAO7F,KAAKgO,wBAAyBxO,EAAMwB,IACnE,KAAMxB,EAAM6G,gBAAiBrG,KAAK8N,OAAO5N,MACzCF,KAAK8N,OAAO5N,MAAQ,EAAGmQ,EAAMD,GAE/B,OADApQ,KAAKkQ,UAAUI,GACRA,EAIRH,eACC,OAAOnQ,KAAK8N,OAAO5N,MAOpBqQ,eACC,MAAMtQ,EAAS,GACf,IAAIoB,EAAIrB,KAAKsB,YACb,KAAOD,EAAEI,OAASjC,EAAMwB,KACvBf,EAAOuB,KAAKH,GACZA,EAAIrB,KAAKsB,YAEV,OAAOrB,EAGRqP,gBAAgB7K,GACf,MAAM9C,EAAQ3B,KAAKmO,qBACbvM,EAAO5B,KAAK8N,OAAO5N,MACnBwD,EAAO1D,KAAK8N,OAAOxK,QAAQ3B,EAAOC,GAClC4O,EAAM,gCAAkCxQ,KAAKyQ,gBAAgB/M,GAAQ,IAC1D1D,KAAK0Q,2BACbC,YAAY3Q,KAAM,KAAMA,KAAKoO,gBACpCpO,KAAKqO,kBAAmBmC,EAAK/L,GAGhCgM,gBAAgBhN,GACf,MAAMmN,EAAI,GACV,IAAK,IAAI1P,EAAI,EAAGA,EAAIuC,EAAE3C,OAAQI,IAC7B0P,EAAEpP,KAAKiC,EAAEvC,IAEV,OAAO0P,EAAE5G,KAAK,IAGf6G,uBAAuBvE,GACtB,OAAIA,EAAEtF,WAAW,KAAOxH,EAAMwB,IACtB,QACS,OAANsL,EACH,MACS,OAANA,EACH,MACS,OAANA,EACH,MAEAA,EAITwE,oBAAoBxE,GACnB,MAAO,IAAMtM,KAAK6Q,uBAAuBvE,GAAK,IAS/CiD,QAAQwB,GACH/Q,KAAK8N,OAAO/M,GAAG,KAAOvB,EAAMwB,MAC3B+P,aAAcnD,EAEjB5N,KAAKiO,QAAQrN,QAAQZ,KAAK8N,QAG1B9N,KAAK8N,OAAOlN,WAKXoQ,kBACH,OAAOhR,KAAK8N,OAGTkD,gBAAYnD,GACf7N,KAAK8N,OAAS,KACd9N,KAAKgO,wBAA0B,CAAEhO,KAAMA,KAAK8N,QAC5C9N,KAAKO,QACLP,KAAK8N,OAASD,EACd7N,KAAKgO,wBAA0B,CAAEhO,KAAMA,KAAK8N,QAGzCmD,iBACH,OAAOjR,KAAK8N,OAAOmD,WAGhBxP,WACH,OAAOzB,KAAKwO,MAGT/M,SAAKA,GACRzB,KAAKwO,MAAQ/M,EAGVsE,WACH,OAAO/F,KAAKiO,QAAQlI,KAGjBA,SAAKA,GACR/F,KAAKiO,QAAQlI,KAAOA,EAGjBC,aACH,OAAOhG,KAAKiO,QAAQjI,OAGjBA,WAAOA,GACVhG,KAAKiO,QAAQjI,OAASA,EAGnBtC,WACH,OAAmB,OAAf1D,KAAK4O,MACD5O,KAAK4O,MAEL5O,KAAKiO,QAAQ3K,QAAQtD,KAAK8N,QAI/BpK,SAAKA,GACR1D,KAAK4O,MAAQlL,GAOfjE,EAAMkP,aAAe,EACrBlP,EAAM+P,MAAQ,EACd/P,EAAMwP,MAAQ,EAEdxP,EAAMmD,sBAAwBpD,EAAM6G,gBACpC5G,EAAMyR,OAAS1R,EAAM2R,eACrB1R,EAAM2R,eAAiB,EACvB3R,EAAM4R,eAAiB,QAKvB1R,EAAOC,QAAUH,gBChXjB,MAAM,MAACD,GAAS,EAAQ,MAClB,kBAAC8R,EAAiB,aAAEC,EAAY,UAAEC,GAAa,EAAQ,KACvD9D,EAAa,EAAQ,MACrB,qBAAC+D,GAAwB,EAAQ,KACjCC,EAAkB,EAAQ,KAC1BC,EAA4B,EAAQ,KACpClS,EAAQ,EAAQ,KAEtB,MAAMmS,UAAsBN,EAC3BzR,YAAYgS,GACX9R,QACAC,KAAK6R,OAASA,EAGfC,eAAe7F,GACdkD,QAAQC,IAAI,WAAapP,KAAK6R,OAAOE,UAAU9F,EAAIW,WAAa,WAAa5M,KAAK6R,OAAO/D,OAAO7L,GAAG,GAAGyB,MAGvGsO,cAAcC,GACb9C,QAAQC,IAAI,WAAa6C,EAAKC,OAAS,SAAWlS,KAAK6R,OAAOE,UAAU/R,KAAK6R,OAAOM,KAAKvF,YAG1FwF,cAAcnG,GACbkD,QAAQC,IAAI,WAAapP,KAAK6R,OAAOE,UAAU9F,EAAIW,WAAa,WAAa5M,KAAK6R,OAAO/D,OAAO7L,GAAG,GAAGyB,OAIxG,MAAM2O,UAAe3E,EAKpB7N,YAAYgO,GACX9N,QAEAC,KAAK8N,OAAS,KAKd9N,KAAKsS,YAAc,IAAIb,EACvBzR,KAAKuS,iBAAmB,GACxBvS,KAAKuS,iBAAiB/Q,KAAK,GAK3BxB,KAAKmS,KAAO,KAKZnS,KAAKwS,iBAAkB,EAQvBxS,KAAKyS,QAAU,KAKfzS,KAAK0S,gBAAkB,KAKvB1S,KAAK2S,cAAgB,EACrB3S,KAAK4S,eAAe/E,GAIrBtN,QACqB,OAAhBP,KAAK8N,QACR9N,KAAK8N,OAAOtN,KAAK,GAElBR,KAAKsS,YAAY/R,MAAMP,MACvBA,KAAKmS,KAAO,KACZnS,KAAK2S,cAAgB,EACrB3S,KAAK6S,UAAS,GACd7S,KAAKuS,iBAAmB,GACxBvS,KAAKuS,iBAAiB/Q,KAAK,GACN,OAAjBxB,KAAKiO,SACRjO,KAAKiO,QAAQ1N,QAsBf2O,MAAMF,GACL,IAAI3N,EAAIrB,KAAK8S,kBAab,OAZIzR,EAAEI,OAASuN,GACdhP,KAAKsS,YAAYS,YAAY/S,MAC7BA,KAAKY,YAELS,EAAIrB,KAAKsS,YAAYU,cAAchT,MAC/BA,KAAKwS,kBAAqC,IAAlBnR,EAAEE,YAI7BvB,KAAKmS,KAAKc,aAAa5R,IAGlBA,EAoBR6R,gBACC,IAAI7R,EAAIrB,KAAK8S,kBAab,OAZIzR,EAAEI,KAAO,GACZzB,KAAKsS,YAAYS,YAAY/S,MAC7BA,KAAKY,YAELS,EAAIrB,KAAKsS,YAAYU,cAAchT,MAC/BA,KAAKmT,mBAAsC,IAAlB9R,EAAEE,YAI9BvB,KAAKmS,KAAKc,aAAa5R,IAGlBA,EAGR+R,oBACC,OAAOpT,KAAK0S,iBAAmB,GAgChCW,iBAAiBC,GAChB,GAAiB,OAAbA,EACH,KAAM,WAEsB,OAAzBtT,KAAK0S,kBACR1S,KAAK0S,gBAAkB,IAExB1S,KAAK0S,gBAAgBlR,KAAK8R,GAU3BC,oBAAoBD,GACnB,GAA6B,OAAzBtT,KAAK0S,gBAA0B,CAClC,MAAMc,EAAMxT,KAAK0S,gBAAgBe,QAAQH,GACrCE,GAAO,GACVxT,KAAK0S,gBAAgBjK,OAAO+K,EAAK,GAEE,IAAhCxT,KAAK0S,gBAAgB5R,SACxBd,KAAK0S,gBAAkB,OAM1BgB,uBACC1T,KAAK0S,gBAAkB,KAIxBiB,wBACC,GAA6B,OAAzB3T,KAAK0S,gBAA0B,CAClC,MAAMzG,EAAMjM,KAAKmS,KACjBnS,KAAK0S,gBAAgB5J,SAAQ,SAASwK,GACrCA,EAASxB,eAAe7F,GACxBA,EAAI2H,UAAUN,OASjBO,uBACC,GAA6B,OAAzB7T,KAAK0S,gBAA0B,CAElC,MAAMzG,EAAMjM,KAAKmS,KACjBnS,KAAK0S,gBAAgBlL,MAAM,GAAGsM,UAAUhL,SAAQ,SAASwK,GACxDrH,EAAI8H,SAAST,GACbA,EAASlB,cAAcnG,OAK1B+H,kBACC,OAAOhU,KAAK8N,OAAOhO,YAAYiO,SAIhCkG,gBAAgBC,GACflU,KAAK8N,OAAOhO,YAAYiO,SAAWmG,EAUpCC,uBACC,MAAMC,EAAgBpU,KAAKqU,mBAC3B,GAAsB,OAAlBD,EACH,KAAM,uEAEP,IAAIxP,EAAS5E,KAAKsU,mBAAmBF,GACrC,GAAe,OAAXxP,EAAiB,CACpB,MAAM2P,EAAyB,IAAI5C,EACnC4C,EAAuBC,+BAAgC,EACvD5P,EAAS,IAAI8M,EAAgB6C,GAC1BE,YAAYL,GACfpU,KAAKsU,mBAAmBF,GAAiBxP,EAE1C,OAAOA,EAeR8P,wBAAwBC,EAASC,EAAkBxO,GAElD,GAAc,QADdA,EAAQA,GAAS,OAEc,OAA1BpG,KAAK6U,iBAA2B,CACnC,MAAM/U,EAAcE,KAAK6U,iBAAiB/U,YACtCA,aAAuBL,IAC1B2G,EAAQtG,GAIX,GAAc,OAAVsG,EACH,KAAM,uCAGP,OADU,IAAI0O,wBAAwB1O,EAAOpG,MACpC+U,QAAQJ,EAASC,GAG3BI,iBACC,OAAOhV,KAAK6U,iBAGbjC,eAAe/E,GACd7N,KAAKiV,eAAepH,GAGrBgH,iBACC,OAAO7U,KAAK8N,OAIbmH,eAAepH,GACd7N,KAAK8N,OAAS,KACd9N,KAAKO,QACLP,KAAK8N,OAASD,EAOfiF,kBACC,OAAO9S,KAAK8N,OAAO7L,GAAG,GAGvBiT,qBAAqB1E,EAAK2E,EAAgB7P,GAEzCA,EAAMA,GAAO,KACU,QAFvB6P,EAAiBA,GAAkB,QAGlCA,EAAiBnV,KAAK8S,mBAEvB9S,KAAK2S,eAAiB,EACtB,MAAM5M,EAAOoP,EAAepP,KACtBC,EAASmP,EAAenP,OACbhG,KAAK0Q,2BACbC,YAAY3Q,KAAMmV,EAAgBpP,EAAMC,EAAQwK,EAAKlL,GAwB/D1E,UACC,MAAMwU,EAAIpV,KAAK8S,kBACXsC,EAAE3T,OAASjC,EAAMwB,KACpBhB,KAAKgV,iBAAiBpU,UAEvB,MAAMyU,EAAuC,OAAzBrV,KAAK0S,iBAA4B1S,KAAK0S,gBAAgB5R,OAAS,EACnF,GAAId,KAAKwS,iBAAmB6C,EAAa,CACxC,IAAIpD,EAEHA,EADGjS,KAAKsS,YAAYgD,oBAAoBtV,MACjCA,KAAKmS,KAAKc,aAAamC,GAEvBpV,KAAKmS,KAAKoD,aAAaH,GAE/BnD,EAAKuD,cAAgBxV,KAAKuM,MACtB8I,GACHrV,KAAK0S,gBAAgB5J,SAAQ,SAASwK,GACjCrB,aAAgBT,QAAmC1P,IAArBmQ,EAAKwD,aAA6BxD,EAAKwD,cACxEnC,EAASoC,eAAezD,GACdA,aAAgBV,GAC1B+B,EAAStB,cAAcC,MAK3B,OAAOmD,EAGRO,wBAE6B,OAAxB3V,KAAKmS,KAAKyD,WACb5V,KAAKmS,KAAKyD,UAAUC,SAAS7V,KAAKmS,MAQpCyB,UAAUkC,EAAUvJ,EAAOK,GAC1B5M,KAAKuM,MAAQA,EACbvM,KAAKmS,KAAO2D,EACZ9V,KAAKmS,KAAKxQ,MAAQ3B,KAAK8N,OAAO7L,GAAG,GAC7BjC,KAAKwS,iBACRxS,KAAK2V,wBAEN3V,KAAK2T,wBAGNI,WACC/T,KAAKmS,KAAKvQ,KAAO5B,KAAK8N,OAAO7L,IAAI,GAEjCjC,KAAK6T,uBACL7T,KAAKuM,MAAQvM,KAAKmS,KAAKqD,cACvBxV,KAAKmS,KAAOnS,KAAKmS,KAAKyD,UAGvBG,cAAcD,EAAUE,GACvBF,EAASG,aAAaD,GAGlBhW,KAAKwS,iBAAmBxS,KAAKmS,OAAS2D,GACb,OAAxB9V,KAAKmS,KAAKyD,YACb5V,KAAKmS,KAAKyD,UAAUM,kBACpBlW,KAAKmS,KAAKyD,UAAUC,SAASC,IAG/B9V,KAAKmS,KAAO2D,EASbK,gBACC,OAAqC,IAAjCnW,KAAKuS,iBAAiBzR,QACjB,EAEDd,KAAKuS,iBAAiBvS,KAAKuS,iBAAiBzR,OAAO,GAI5DsV,mBAAmBN,EAAUvJ,EAAOK,EAAWyJ,GAC5CrW,KAAKuM,MAAQA,EACbvM,KAAKuS,iBAAiB/Q,KAAK6U,GAC3BrW,KAAKmS,KAAO2D,EACZ9V,KAAKmS,KAAKxQ,MAAQ3B,KAAK8N,OAAO7L,GAAG,GACjCjC,KAAK2T,wBAIR2C,wBAAwBR,EAAUvJ,EAAOK,GACxC,MAAM2J,EAAWvW,KAAKmS,KACtBoE,EAASX,UAAYE,EACrBS,EAASf,cAAgBjJ,EACzBgK,EAAS3U,KAAO5B,KAAK8N,OAAO7L,IAAI,GAEhCjC,KAAKmS,KAAO2D,EACZ9V,KAAKmS,KAAKxQ,MAAQ4U,EAAS5U,MACvB3B,KAAKwS,iBACRxS,KAAKmS,KAAK0D,SAASU,GAEpBvW,KAAK2T,wBAGN6C,wBAAwBZ,GACvB5V,KAAKuS,iBAAiBtC,MACtBjQ,KAAKmS,KAAKvQ,KAAO5B,KAAK8N,OAAO7L,IAAI,GACjC,MAAMwU,EAASzW,KAAKmS,KAEduE,EAAiB1W,KAAKoT,oBAC5B,GAAuB,OAAnBsD,GAA2BA,EAAe5V,OAAS,EACtD,KAAOd,KAAKmS,OAASyD,GACpB5V,KAAK6T,uBACL7T,KAAKmS,KAAOnS,KAAKmS,KAAKyD,eAGvB5V,KAAKmS,KAAOyD,EAGba,EAAOb,UAAYA,EACf5V,KAAKwS,iBAAiC,OAAdoD,GAE3BA,EAAUC,SAASY,GAIrBE,mBAAmB/J,GAClB,IAAIX,EAAMjM,KAAKmS,KACf,KAAe,OAARlG,GAAc,CACpB,GAAIA,EAAIW,YAAcA,EACrB,OAAOX,EAERA,EAAMA,EAAI2J,UAEX,OAAO,KAGRgB,SAASd,EAAUO,GAClB,OAAOA,GAAcrW,KAAKuS,iBAAiBvS,KAAKuS,iBAAiBzR,OAAO,GAGzE+V,UAAUrK,GAET,OAAO,EAiBRsK,gBAAgB5E,GACf,MAAM/G,EAAMnL,KAAKiO,QAAQ9C,IACzB,IAAIc,EAAMjM,KAAKmS,KACf,MAAM1O,EAAI0H,EAAI4B,OAAO/M,KAAKuM,OAC1B,IAAIwK,EAAY5L,EAAI6L,WAAWvT,GAC/B,GAAIsT,EAAU/U,SAASkQ,GACtB,OAAO,EAER,IAAK6E,EAAU/U,SAASxC,EAAM2K,SAC7B,OAAO,EAER,KAAe,OAAR8B,GAAgBA,EAAIuJ,eAAiB,GAAKuB,EAAU/U,SAASxC,EAAM2K,UAAU,CACnF,MACM8M,EADgB9L,EAAI4B,OAAOd,EAAIuJ,eACZlK,YAAY,GAErC,GADAyL,EAAY5L,EAAI6L,WAAWC,EAAG9J,aAC1B4J,EAAU/U,SAASkQ,GACtB,OAAO,EAERjG,EAAMA,EAAI2J,UAEX,SAAImB,EAAU/U,SAASxC,EAAM2K,UAAY+H,IAAW1S,EAAMwB,KAc3DkW,oBACC,OAAOlX,KAAKiO,QAAQ9C,IAAI+L,kBAAkBlX,KAAKuM,MAAOvM,KAAKmS,MAG5DgF,qCACC,MAAMhM,EAAMnL,KAAKiO,QAAQ9C,IACnB1H,EAAI0H,EAAI4B,OAAO/M,KAAKuM,OAC1B,OAAOpB,EAAI6L,WAAWvT,GAIvB2T,aAAaC,GACZ,MAAMzK,EAAY5M,KAAKsX,kBAAkBD,GACzC,OAAkB,OAAdzK,EACIA,GAEC,EAYV2K,uBAAuBC,GAEZ,QADVA,EAAIA,GAAK,QAERA,EAAIxX,KAAKmS,MAEV,MAAM9C,EAAQ,GACd,KAAa,OAANmI,GAAY,CAElB,MAAM5K,EAAY4K,EAAE5K,UAChBA,EAAY,EACfyC,EAAM7N,KAAK,OAEX6N,EAAM7N,KAAKxB,KAAK+R,UAAUnF,IAE3B4K,EAAIA,EAAE5B,UAEP,OAAOvG,EAIRoI,gBACC,OAAOzX,KAAKiO,QAAQyJ,cAAczS,WAInC0S,UACC,IAAIC,GAAU,EACd,IAAK,IAAI1W,EAAI,EAAGA,EAAIlB,KAAKiO,QAAQyJ,cAAc5W,OAAQI,IAAK,CAC3D,MAAM2W,EAAM7X,KAAKiO,QAAQyJ,cAAcxW,GACnC2W,EAAI9K,OAAOjM,OAAS,IACnB8W,GACHzI,QAAQC,MAETpP,KAAK8X,QAAQC,QAAQ,YAAcF,EAAIG,SAAW,KAClDhY,KAAK8X,QAAQG,MAAMJ,EAAI5S,SAASjF,KAAKwJ,aAAcxJ,KAAKyJ,gBACxDmO,GAAU,IAWbvU,gBACC,OAAOrD,KAAK8N,OAAOmD,WAOpB4B,SAASqF,GACHA,GAIiB,OAAjBlY,KAAKyS,SACRzS,KAAKuT,oBAAoBvT,KAAKyS,SAE/BzS,KAAKyS,QAAU,IAAIb,EAAc5R,MACjCA,KAAKqT,iBAAiBrT,KAAKyS,WAP3BzS,KAAKuT,oBAAoBvT,KAAKyS,SAC9BzS,KAAKyS,QAAU,OAkBlBJ,EAAOiC,mBAAqB,GAE5B3U,EAAOC,QAAUyS,iBCnqBjB,MAAM8F,EAAc,EAAQ,KACtBC,EAAO,EAAQ,KACfC,EAAmBD,EAAKC,iBACxB9G,EAAe6G,EAAK7G,aACpB+G,EAAmBF,EAAKE,iBACxBC,EAAgBH,EAAKG,cACrB7Y,EAAW,gBA0BjB,MAAM8Y,UAA0BL,EAC/BtY,YAAY4Y,EAAQC,GAGnB3Y,MAFA0Y,EAASA,GAAU,KACnBC,EAAsBA,GAAuB,MAE7C1Y,KAAK4M,WAAa,EAQlB5M,KAAK2Y,SAAW,KAChB3Y,KAAK2B,MAAQ,KACb3B,KAAK4B,KAAO,KAKZ5B,KAAK4Y,UAAY,KAIlBC,SAAS5M,GAERjM,KAAK4V,UAAY3J,EAAI2J,UACrB5V,KAAKwV,cAAgBvJ,EAAIuJ,cACzBxV,KAAK2Y,SAAW,KAChB3Y,KAAK2B,MAAQsK,EAAItK,MACjB3B,KAAK4B,KAAOqK,EAAIrK,KAEbqK,EAAI0M,WACN3Y,KAAK2Y,SAAW,GAEhB1M,EAAI0M,SAASvO,KAAI,SAAS0O,GACrBA,aAAiBP,IACpBvY,KAAK2Y,SAASnX,KAAKsX,GACnBA,EAAMlD,UAAY5V,QAEjBA,OAKL4T,UAAUN,IAGVS,SAAST,IAITuC,SAASiD,GAKR,OAJsB,OAAlB9Y,KAAK2Y,WACR3Y,KAAK2Y,SAAW,IAEjB3Y,KAAK2Y,SAASnX,KAAKsX,GACZA,EAOR5C,kBACuB,OAAlBlW,KAAK2Y,UACR3Y,KAAK2Y,SAAS1I,MAIhBsF,aAAa/S,GACZ,MAAMyP,EAAO,IAAIqG,EAAiB9V,GAGlC,OAFAxC,KAAK6V,SAAS5D,GACdA,EAAK2D,UAAY5V,KACViS,EAGRgB,aAAa8F,GACZ,MAAM9G,EAAO,IAAIsG,EAAcQ,GAG/B,OAFA/Y,KAAK6V,SAAS5D,GACdA,EAAK2D,UAAY5V,KACViS,EAGR+G,SAAS9X,EAAGO,GAEX,GADAA,EAAOA,GAAQ,KACO,OAAlBzB,KAAK2Y,UAAqBzX,EAAI,GAAKA,GAAKlB,KAAK2Y,SAAS7X,OACzD,OAAO,KAER,GAAa,OAATW,EACH,OAAOzB,KAAK2Y,SAASzX,GAErB,IAAI,IAAI+I,EAAE,EAAGA,EAAEjK,KAAK2Y,SAAS7X,OAAQmJ,IAAK,CACzC,MAAM6O,EAAQ9Y,KAAK2Y,SAAS1O,GAC5B,GAAG6O,aAAiBrX,EAAM,CACzB,GAAO,IAAJP,EACF,OAAO4X,EAEP5X,GAAK,GAIR,OAAO,KAIT+X,SAASjK,EAAO9N,GACf,GAAsB,OAAlBlB,KAAK2Y,UAAqBzX,EAAI,GAAKA,GAAKlB,KAAK2Y,SAAS7X,OACzD,OAAO,KAER,IAAI,IAAImJ,EAAE,EAAGA,EAAEjK,KAAK2Y,SAAS7X,OAAQmJ,IAAK,CACzC,MAAM6O,EAAQ9Y,KAAK2Y,SAAS1O,GAC5B,GAAI6O,aAAiBvH,GAChBuH,EAAM5G,OAAOzQ,OAASuN,EAAO,CAChC,GAAO,IAAJ9N,EACF,OAAO4X,EAEP5X,GAAK,GAKT,OAAO,KAGRQ,UAAUsN,GACT,GAAqB,OAAjBhP,KAAK2Y,SACR,MAAO,GACD,CACN,MAAM1Y,EAAS,GACf,IAAI,IAAIgK,EAAE,EAAGA,EAAEjK,KAAK2Y,SAAS7X,OAAQmJ,IAAK,CACzC,MAAM6O,EAAQ9Y,KAAK2Y,SAAS1O,GACxB6O,aAAiBvH,GAChBuH,EAAM5G,OAAOzQ,OAASuN,GACzB/O,EAAOuB,KAAKsX,GAIf,OAAO7Y,GAITiZ,oBAAoBC,EAASjY,GAC5B,OAAOlB,KAAKgZ,SAAS9X,EAAGiY,GAGzBC,qBAAqBD,GACpB,GAAqB,OAAjBnZ,KAAK2Y,SACR,MAAO,GACD,CACN,MAAMU,EAAW,GACjB,IAAI,IAAIpP,EAAE,EAAGA,EAAEjK,KAAK2Y,SAAS7X,OAAQmJ,IAAK,CACzC,MAAM6O,EAAQ9Y,KAAK2Y,SAAS1O,GACxB6O,aAAiBK,GACpBE,EAAS7X,KAAKsX,GAGhB,OAAOO,GAITC,gBACC,OAAqB,OAAjBtZ,KAAK2Y,SACD,EAEA3Y,KAAK2Y,SAAS7X,OAIvByY,oBACC,OAAmB,OAAfvZ,KAAK2B,OAAgC,OAAd3B,KAAK4B,KACxByW,EAEA,IAAI3Y,EAASM,KAAK2B,MAAMJ,WAAYvB,KAAK4B,KAAKL,aAKxD4W,EAAYtM,MAAQ,IAAI2M,EASxB7Y,EAAOC,QAAU4Y,iBC3NjB,MAAML,EAAc,EAAQ,MACtB,KAACqB,EAAI,IAAEC,EAAG,YAAEC,GAAe,EAAQ,KAEzC,MAAM1O,EAELnL,YAAY8Z,GACX3Z,KAAK2Z,eAAiBA,EA6BvBjN,UACC,OAAO1M,OAASgL,EAAkBa,MAGnC+N,eACC,OAAO5Z,KAAKgN,eAAehN,KAAKc,OAAS,KAAOkK,EAAkB6O,mBAGnEC,WACC,OAAO9Z,KAAK2Z,eAGbI,eAAeC,GACdA,EAAKC,OAAOja,KAAK2Z,iBAQnB3O,EAAkBa,MAAQ,KAO1Bb,EAAkB6O,mBAAqB,WAEvC7O,EAAkBkP,gBAAkB,EACpClP,EAAkBmP,GAAKnP,EAAkBkP,gBA+CzC,MAAMjP,UAAmCD,EAExCnL,YAAY4Y,EAAQ3L,GACnB,IAAIgN,EAAW,EACf,MAAME,EAAO,IAAIR,EACH,OAAXf,EACFuB,EAAKC,OAAOxB,EAAQ3L,GAEpBkN,EAAKC,OAAO,GAEbH,EAAWE,EAAKI,SAChBra,MAAM+Z,GACN9Z,KAAK4V,UAAY6C,EACjBzY,KAAK8M,YAAcA,EAGpBG,UAAU/M,GACT,OAAOF,KAAK4V,UAGb5I,eAAe9M,GACd,OAAOF,KAAK8M,YAGbuN,OAAOxR,GACN,OAAI7I,OAAS6I,GAEAA,aAAiBoC,GAEnBjL,KAAK8Z,aAAejR,EAAMiR,YAGjC9Z,KAAK8M,cAAgBjE,EAAMiE,cAEN,MAAhB9M,KAAK4V,UACY,MAAjB/M,EAAM+M,UAEN5V,KAAK4V,UAAUyE,OAAOxR,EAAM+M,YAItC3Q,WACC,MAAMqV,EAAwB,OAAnBta,KAAK4V,UAAqB,GAAK5V,KAAK4V,UAAU3Q,WACzD,OAAkB,IAAdqV,EAAGxZ,OACFd,KAAK8M,cAAgB9B,EAAkB6O,mBACnC,IAEA,GAAK7Z,KAAK8M,YAGN9M,KAAK8M,YAAc,IAAMwN,EAInCxZ,aACH,OAAO,EAGRyZ,cAAc9B,EAAQ3L,GACrB,OAAIA,IAAgB9B,EAAkB6O,oBAAiC,OAAXpB,EAEpDzN,EAAkBa,MAElB,IAAIZ,EAA2BwN,EAAQ3L,IAKjD,MAAM0N,UAA+BvP,EAEpCpL,cACCE,MAAM,KAAMiL,EAAkB6O,oBAG/BnN,UACC,OAAO,EAGRO,UAAU/M,GACT,OAAO,KAGR8M,eAAe9M,GACd,OAAOF,KAAK8M,YAGbuN,OAAOxR,GACN,OAAO7I,OAAS6I,EAGjB5D,WACC,MAAO,KAKT+F,EAAkBa,MAAQ,IAAI2O,EAE9B,MAAMC,UAA+BzP,EAEpCnL,YAAY6a,EAASC,GAOpB,MAAMrS,EAAI,IAAIkR,EAMd,OALAlR,EAAE2R,OAAOS,EAASC,GAElB5a,MADiBuI,EAAE8R,UAEnBpa,KAAK0a,QAAUA,EACf1a,KAAK2a,aAAeA,EACb3a,KAGR0M,UAGC,OAAO1M,KAAK2a,aAAa,KAAO3P,EAAkB6O,mBAGnD5M,UAAU/M,GACT,OAAOF,KAAK0a,QAAQxa,GAGrB8M,eAAe9M,GACd,OAAOF,KAAK2a,aAAaza,GAG1Bma,OAAOxR,GACN,OAAI7I,OAAS6I,GAEAA,aAAiB4R,GAEnBza,KAAK8Z,aAAejR,EAAMiR,YAG7BJ,EAAY1Z,KAAK2a,aAAc9R,EAAM8R,eAC3CjB,EAAY1Z,KAAK0a,QAAS7R,EAAM6R,SAInCzV,WACC,GAAIjF,KAAK0M,UACR,MAAO,KACD,CACN,IAAIjJ,EAAI,IACR,IAAK,IAAIvC,EAAI,EAAGA,EAAIlB,KAAK2a,aAAa7Z,OAAQI,IACzCA,EAAI,IACPuC,GAAQ,MAELzD,KAAK2a,aAAazZ,KAAO8J,EAAkB6O,oBAI/CpW,GAAQzD,KAAK2a,aAAazZ,GACF,OAApBlB,KAAK0a,QAAQxZ,GAChBuC,EAAIA,EAAI,IAAMzD,KAAK0a,QAAQxZ,GAE3BuC,GAAQ,QAPRA,GAAQ,IAUV,OAAOA,EAAI,KAIT3C,aACH,OAAOd,KAAK2a,aAAa7Z,QA+b3BnB,EAAOC,QAAU,CAChBgb,MA5ZD,SAASA,EAAMC,EAAGC,EAAGC,EAAgBC,GAEpC,GAAIH,IAAMC,EACT,OAAOD,EAER,GAAIA,aAAa5P,GAA8B6P,aAAa7P,EAC3D,OAqDF,SAAyB4P,EAAGC,EAAGC,EAAgBC,GAC9C,GAAmB,OAAfA,EAAqB,CACxB,IAAIzE,EAAWyE,EAAWra,IAAIka,EAAGC,GACjC,GAAiB,OAAbvE,EACH,OAAOA,EAGR,GADAA,EAAWyE,EAAWra,IAAIma,EAAGD,GACZ,OAAbtE,EACH,OAAOA,EAIT,MAAM0E,EAwGP,SAAmBJ,EAAGC,EAAGC,GACxB,GAAIA,EAAgB,CACnB,GAAIF,IAAM7P,EAAkBa,MAC3B,OAAOb,EAAkBa,MAE1B,GAAIiP,IAAM9P,EAAkBa,MAC3B,OAAOb,EAAkBa,UAEpB,CACN,GAAIgP,IAAM7P,EAAkBa,OAASiP,IAAM9P,EAAkBa,MAC5D,OAAOb,EAAkBa,MACnB,GAAIgP,IAAM7P,EAAkBa,MAAO,CACzC,MAAMqP,EAAW,CAAEJ,EAAEhO,YACnB9B,EAAkB6O,oBACda,EAAU,CAAEI,EAAElF,UAAW,MAC/B,OAAO,IAAI6E,EAAuBC,EAASQ,GACrC,GAAIJ,IAAM9P,EAAkBa,MAAO,CACzC,MAAMqP,EAAW,CAAEL,EAAE/N,YAAa9B,EAAkB6O,oBAC9Ca,EAAU,CAAEG,EAAEjF,UAAW,MAC/B,OAAO,IAAI6E,EAAuBC,EAASQ,IAG7C,OAAO,KA9HWC,CAAUN,EAAGC,EAAGC,GAClC,GAAkB,OAAdE,EAIH,OAHmB,OAAfD,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGG,GAEfA,EAER,GAAIJ,EAAE/N,cAAgBgO,EAAEhO,YAAa,CACpC,MAAM2L,EAASmC,EAAMC,EAAEjF,UAAWkF,EAAElF,UAAWmF,EAAgBC,GAG/D,GAAIvC,IAAWoC,EAAEjF,UAChB,OAAOiF,EAER,GAAIpC,IAAWqC,EAAElF,UAChB,OAAOkF,EAMR,MAAMM,EAAMnQ,EAA2BpF,OAAO4S,EAAQoC,EAAE/N,aAIxD,OAHmB,OAAfkO,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGM,GAEfA,EACD,CAEN,IAAIC,EAAe,KAMnB,IALIR,IAAMC,GAAsB,OAAhBD,EAAEjF,WAAsBiF,EAAEjF,YAAckF,EAAElF,aAGzDyF,EAAeR,EAAEjF,WAEG,OAAjByF,EAAuB,CAE1B,MAAMH,EAAW,CAAEL,EAAE/N,YAAagO,EAAEhO,aAChC+N,EAAE/N,YAAcgO,EAAEhO,cACrBoO,EAAS,GAAKJ,EAAEhO,YAChBoO,EAAS,GAAKL,EAAE/N,aAEjB,MACMwO,EAAM,IAAIb,EADA,CAAEY,EAAcA,GACgBH,GAIhD,OAHmB,OAAfF,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGQ,GAEfA,EAKR,MAAMJ,EAAW,CAAEL,EAAE/N,YAAagO,EAAEhO,aACpC,IAAI4N,EAAU,CAAEG,EAAEjF,UAAWkF,EAAElF,WAC3BiF,EAAE/N,YAAcgO,EAAEhO,cACrBoO,EAAS,GAAKJ,EAAEhO,YAChBoO,EAAS,GAAKL,EAAE/N,YAChB4N,EAAU,CAAEI,EAAElF,UAAWiF,EAAEjF,YAE5B,MAAM2F,EAAK,IAAId,EAAuBC,EAASQ,GAI/C,OAHmB,OAAfF,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGS,GAEfA,GA/HAC,CAAgBX,EAAGC,EAAGC,EAAgBC,GAI9C,GAAID,EAAgB,CACnB,GAAIF,aAAaL,EAChB,OAAOK,EAER,GAAIC,aAAaN,EAChB,OAAOM,EAUT,OANID,aAAa5P,IAChB4P,EAAI,IAAIJ,EAAuB,CAACI,EAAE5N,aAAc,CAAC4N,EAAE/N,eAEhDgO,aAAa7P,IAChB6P,EAAI,IAAIL,EAAuB,CAACK,EAAE7N,aAAc,CAAC6N,EAAEhO,eAqMrD,SAAqB+N,EAAGC,EAAGC,EAAgBC,GAC1C,GAAmB,OAAfA,EAAqB,CACxB,IAAIzE,EAAWyE,EAAWra,IAAIka,EAAGC,GACjC,GAAiB,OAAbvE,EACH,OAAOA,EAGR,GADAA,EAAWyE,EAAWra,IAAIma,EAAGD,GACZ,OAAbtE,EACH,OAAOA,EAIT,IAAIrV,EAAI,EACJ+I,EAAI,EACJ9H,EAAI,EAEJsZ,EAAqB,GACrBC,EAAgB,GAEpB,KAAOxa,EAAI2Z,EAAEF,aAAa7Z,QAAUmJ,EAAI6Q,EAAEH,aAAa7Z,QAAQ,CAC9D,MAAM6a,EAAWd,EAAEH,QAAQxZ,GACrB0a,EAAWd,EAAEJ,QAAQzQ,GAC3B,GAAI4Q,EAAEF,aAAazZ,KAAO4Z,EAAEH,aAAa1Q,GAAI,CAE5C,MAAM4R,EAAUhB,EAAEF,aAAazZ,GAIzB4a,EAAsB,OAAbH,GAAkC,OAAbC,GAAqBD,IAAaC,EAFlDC,IAAY7Q,EAAkB6O,oBACnC,OAAb8B,GAAkC,OAAbC,GAIJE,GAClBJ,EAAcvZ,GAAKwZ,EACnBF,EAAmBtZ,GAAK0Z,IAExBH,EAAcvZ,GAAKyY,EAAMe,EAAUC,EAAUb,EAAgBC,GAC7DS,EAAmBtZ,GAAK0Z,GAEzB3a,GAAK,EACL+I,GAAK,OACK4Q,EAAEF,aAAazZ,GAAK4Z,EAAEH,aAAa1Q,IAC7CyR,EAAcvZ,GAAKwZ,EACnBF,EAAmBtZ,GAAK0Y,EAAEF,aAAazZ,GACvCA,GAAK,IAELwa,EAAcvZ,GAAKyZ,EACnBH,EAAmBtZ,GAAK2Y,EAAEH,aAAa1Q,GACvCA,GAAK,GAEN9H,GAAK,EAGN,GAAIjB,EAAI2Z,EAAEF,aAAa7Z,OACtB,IAAK,IAAI0W,EAAItW,EAAGsW,EAAIqD,EAAEF,aAAa7Z,OAAQ0W,IAC1CkE,EAAcvZ,GAAK0Y,EAAEH,QAAQlD,GAC7BiE,EAAmBtZ,GAAK0Y,EAAEF,aAAanD,GACvCrV,GAAK,OAGN,IAAK,IAAIqV,EAAIvN,EAAGuN,EAAIsD,EAAEH,aAAa7Z,OAAQ0W,IAC1CkE,EAAcvZ,GAAK2Y,EAAEJ,QAAQlD,GAC7BiE,EAAmBtZ,GAAK2Y,EAAEH,aAAanD,GACvCrV,GAAK,EAIP,GAAIA,EAAIuZ,EAAc5a,OAAQ,CAC7B,GAAU,IAANqB,EAAS,CACZ,MAAMoZ,EAAKtQ,EAA2BpF,OAAO6V,EAAc,GACzDD,EAAmB,IAIrB,OAHmB,OAAfT,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGS,GAEfA,EAERG,EAAgBA,EAAclU,MAAM,EAAGrF,GACvCsZ,EAAqBA,EAAmBjU,MAAM,EAAGrF,GAGlD,MAAM4Z,EAAI,IAAItB,EAAuBiB,EAAeD,GAIpD,OAAIM,IAAMlB,GACU,OAAfG,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGD,GAEfA,GAEJkB,IAAMjB,GACU,OAAfE,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGA,GAEfA,IAcT,SAA8BJ,GAC7B,MAAMsB,EAAgB,IAAIvC,EAE1B,IAAK,IAAIjC,EAAI,EAAGA,EAAIkD,EAAQ5Z,OAAQ0W,IAAK,CACxC,MAAMiB,EAASiC,EAAQlD,GACjBwE,EAAcC,YAAYxD,IAC/BuD,EAAcE,IAAIzD,EAAQA,GAG5B,IAAK,IAAI0D,EAAI,EAAGA,EAAIzB,EAAQ5Z,OAAQqb,IACnCzB,EAAQyB,GAAKH,EAAcrb,IAAI+Z,EAAQyB,IAtBxCC,CAAqBV,GAEF,OAAfV,GACHA,EAAWxN,IAAIqN,EAAGC,EAAGiB,GAEfA,GAvSAM,CAAYxB,EAAGC,EAAGC,EAAgBC,IAoYzChQ,kBAAAA,EACAsR,uBA3oBD,MAECzc,cACCG,KAAKuc,MAAQ,IAAI9C,EAQlBhN,IAAIR,GACH,GAAIA,IAAQjB,EAAkBa,MAC7B,OAAOb,EAAkBa,MAE1B,MAAMrD,EAAWxI,KAAKuc,MAAM5b,IAAIsL,IAAQ,KACxC,OAAiB,OAAbzD,EACIA,GAERxI,KAAKuc,MAAML,IAAIjQ,EAAKA,GACbA,GAGRtL,IAAIsL,GACH,OAAOjM,KAAKuc,MAAM5b,IAAIsL,IAAQ,KAG3BnL,aACH,OAAOd,KAAKuc,MAAMzb,SAgnBnBmK,2BAAAA,EACAF,iCA3bD,SAASA,EAAiCI,EAAKqR,GAM9C,GALIA,MAAAA,IACHA,EAAerE,EAAYtM,OAIG,OAA3B2Q,EAAa5G,WAAsB4G,IAAiBrE,EAAYtM,MACnE,OAAOb,EAAkBa,MAG1B,MAAM4M,EAAS1N,EAAiCI,EAAKqR,EAAa5G,WAE5DhK,EADQT,EAAI4B,OAAOyP,EAAahH,eACblK,YAAY,GACrC,OAAOL,EAA2BpF,OAAO4S,EAAQ7M,EAAWuB,YAAYC,cA+axEqP,2BA5ED,SAASA,EAA2BjQ,EAASkQ,EAAcC,GAC1D,GAAInQ,EAAQE,UACX,OAAOF,EAER,IAAIhE,EAAWmU,EAAQhc,IAAI6L,IAAY,KACvC,GAAiB,OAAbhE,EACH,OAAOA,EAGR,GADAA,EAAWkU,EAAa/b,IAAI6L,GACX,OAAbhE,EAEH,OADAmU,EAAQT,IAAI1P,EAAShE,GACdA,EAER,IAAIoU,GAAU,EACVlC,EAAU,GACd,IAAK,IAAIxZ,EAAI,EAAGA,EAAIwZ,EAAQ5Z,OAAQI,IAAK,CACxC,MAAMuX,EAASgE,EAA2BjQ,EAAQS,UAAU/L,GAAIwb,EAAcC,GAC9E,GAAIC,GAAWnE,IAAWjM,EAAQS,UAAU/L,GAAI,CAC/C,IAAK0b,EAAS,CACblC,EAAU,GACV,IAAK,IAAIzQ,EAAI,EAAGA,EAAIuC,EAAQ1L,OAAQmJ,IACnCyQ,EAAQzQ,GAAKuC,EAAQS,UAAUhD,GAEhC2S,GAAU,EAEXlC,EAAQxZ,GAAKuX,GAGf,IAAKmE,EAGJ,OAFAF,EAAajQ,IAAID,GACjBmQ,EAAQT,IAAI1P,EAASA,GACdA,EAER,IAAIqQ,EAAU,KAad,OAXCA,EADsB,IAAnBnC,EAAQ5Z,OACDkK,EAAkBa,MACC,IAAnB6O,EAAQ5Z,OACRmK,EAA2BpF,OAAO6U,EAAQ,GAAIlO,EACrDQ,eAAe,IAER,IAAIyN,EAAuBC,EAASlO,EAAQmO,cAEvD+B,EAAajQ,IAAIoQ,GACjBF,EAAQT,IAAIW,EAASA,GACrBF,EAAQT,IAAI1P,EAASqQ,GAEdA,mBChsBR,MAAM,MAACrd,GAAS,EAAQ,MAClB,qBAACsd,GAAwB,EAAQ,MACjC,mBAACC,GAAsB,EAAQ,KAErC,MAAMrP,EACF7N,cACIG,KAAKgd,WAAa,CAAEF,EAAqBG,UACzCjd,KAAKiO,QAAU,KACfjO,KAAKkd,cAAgB,EAGzBC,aAAaC,GACc,UACFA,GACjBjO,QAAQC,IAAI,8DAA2EgO,GAI/FC,iBAAiB/J,GACbtT,KAAKgd,WAAWxb,KAAK8R,GAGzBgK,uBACItd,KAAKgd,WAAa,GAGtBO,kBACI,OAAOC,OAAOC,eAAezd,MAAMH,YAAY2J,cAAgB,GAGnEkU,mBACI,OAAOF,OAAOC,eAAezd,MAAMH,YAAY4J,eAAiB,GAGpEkU,gBACI,IAAI3d,KAAK4d,WAAY,CACjB,MAAMpU,EAAexJ,KAAKud,kBACpB9T,EAAgBzJ,KAAK0d,mBACrB5c,EAAS0I,EAAa1I,OAAS2I,EAAc3I,OAAS0I,EAAa1I,OAAS2I,EAAc3I,OAChGd,KAAK4d,WAAa,GAClB,IAAI,IAAI1c,EAAE,EAAGA,EAAEJ,EAAQI,IACnBlB,KAAK4d,WAAW1c,GAAKsI,EAAatI,IAAMuI,EAAcvI,IAAM,WAGpE,OAAOlB,KAAK4d,WAGhBC,kBACI,MAAMD,EAAa5d,KAAK2d,gBACxB,GAAiB,OAAbC,EACA,KAAK,iEAET,IAAIhZ,EAAS5E,KAAK8d,kBAAkBF,GAMpC,YALY9b,IAAT8C,IACCA,EAASgZ,EAAWjV,QAAO,SAASyM,EAAGjT,EAAGjB,GAAKkU,EAAEjT,GAAKjB,KACtD0D,EAAO5D,IAAMxB,EAAMwB,IACnBhB,KAAK8d,kBAAkBF,GAAchZ,GAElCA,EAOX0S,kBACI,MAAMvF,EAAY/R,KAAK+R,UACvB,GAAgB,OAAZA,EACA,KAAK,gEAET,IAAInN,EAAS5E,KAAK+d,kBAAkBhM,GAKpC,YAJYjQ,IAAT8C,IACCA,EAASmN,EAAUpJ,QAAO,SAASyM,EAAGjT,EAAGjB,GAAKkU,EAAEjT,GAAKjB,KACrDlB,KAAK+d,kBAAkBhM,GAAanN,GAEjCA,EAGXoZ,aAAaC,GACT,MAAMjP,EAAQhP,KAAK6d,kBAAkBI,GACrC,YAAanc,IAATkN,EACOA,EAEAxP,EAAMyI,aAKrBiW,eAAezZ,GAGX,MAAO,QAFMA,EAAE0Z,oBAAoBpY,KAEX,IADTtB,EAAE0Z,oBAAoBnY,OAiBzCoY,qBAAqB/c,GACjB,GAAQ,OAAJA,EACA,MAAO,aAEX,IAAIoC,EAAIpC,EAAEqC,KASV,OARQ,OAAJD,IAEIA,EADApC,EAAEI,OAAOjC,EAAMwB,IACX,QAEA,IAAMK,EAAEI,KAAO,KAG3BgC,EAAIA,EAAE8F,QAAQ,KAAK,OAAOA,QAAQ,KAAK,OAAOA,QAAQ,KAAK,OACpD,IAAM9F,EAAI,IAGrBiN,2BACI,OAAO,IAAIqM,EAAmB/c,KAAKgd,YAOvCqB,QAAQvI,EAAUlJ,EAAW0R,GACzB,OAAO,EAGX1H,SAASd,EAAWO,GAChB,OAAO,EAGP9J,YACA,OAAOvM,KAAKkd,aAGZ3Q,UAAMA,GACNvM,KAAKkd,aAAe3Q,GAI5BmB,EAAWoQ,kBAAoB,GAC/BpQ,EAAWqQ,kBAAoB,GAE/Bpe,EAAOC,QAAU8N,iBCvJjB,MAAM,SAAC6Q,GAAY,EAAQ,MACrB,iBAAClG,GAAoB,EAAQ,KAC7BmG,EAAQ,EAAQ,IAwJtB7e,EAAOC,QAtJP,cAA0B2e,EAqBzB1e,YAAY4Y,EAAQjD,GAEnBzV,QACAC,KAAK4V,UAAY6C,GAAU,KAM3BzY,KAAKwV,cAAgBA,IAAkB,EAGxCiJ,QACC,IAAItd,EAAI,EACJqW,EAAIxX,KACR,KAAa,OAANwX,GACNA,EAAIA,EAAE5B,UACNzU,GAAK,EAEN,OAAOA,EAORuL,UACC,OAA+B,IAAxB1M,KAAKwV,cAIb+D,oBACC,OAAOlB,EAGRqG,iBACC,OAAO1e,KAGR2e,aACC,OAAO3e,KAWRsD,UACC,OAA6B,IAAzBtD,KAAKsZ,gBACD,GAEAtZ,KAAK2Y,SAASvO,KAAI,SAAS0O,GACjC,OAAOA,EAAMxV,aACX0G,KAAK,IAYV4U,eAEI,OAAO,EAUX3I,aAAa4I,IAEb7F,SAAS9X,GACR,OAAO,KAGRoY,gBACC,OAAO,EAGRwF,OAAOC,GACN,OAAOA,EAAQC,cAAchf,MAO9Bif,aAAalN,EAAWmN,GACvB,OAAOV,EAAMS,aAAajf,KAAM+R,EAAWmN,GAG5Cja,SAAS8M,EAAWnQ,GACnBmQ,EAAYA,GAAa,KACzBnQ,EAAOA,GAAQ,KACf,IAAI4V,EAAIxX,KACJyD,EAAI,IACR,KAAa,OAAN+T,GAAcA,IAAM5V,GAAM,CAChC,GAAkB,OAAdmQ,EACEyF,EAAE9K,YACNjJ,GAAK+T,EAAEhC,mBAEF,CACN,MAAM2J,EAAK3H,EAAE5K,UAGbnJ,GAFkB0b,GAAM,GAAKA,EAAKpN,EAAUjR,OAAUiR,EAAUoN,GAC5D,GAAKA,EAGU,OAAhB3H,EAAE5B,WAAqC,OAAd7D,GAAuByF,EAAE5B,UAAUlJ,YAC/DjJ,GAAK,KAEN+T,EAAIA,EAAE5B,UAGP,OADAnS,GAAK,IACEA,aCjJT,MAAMjE,EACLK,cACCG,KAAK8F,OAAS,KACd9F,KAAKyB,KAAO,KACZzB,KAAKuC,QAAU,KACfvC,KAAK2B,MAAQ,KACb3B,KAAK4B,KAAO,KACZ5B,KAAKuB,WAAa,KAClBvB,KAAK+F,KAAO,KACZ/F,KAAKgG,OAAS,KACdhG,KAAK4O,MAAQ,KAGdwQ,iBACC,OAAOpf,KAAK8F,OAAO,GAGpBkP,iBACC,OAAOhV,KAAK8F,OAAO,GAGhBpC,WACH,OAAO1D,KAAK4O,MAGTlL,SAAKA,GACR1D,KAAK4O,MAAQlL,GAIflE,EAAMyI,aAAe,EAMrBzI,EAAM2K,SAAW,EAEjB3K,EAAM8N,oBAAsB,EAE5B9N,EAAMwB,KAAO,EAObxB,EAAM6G,gBAAkB,EAMxB7G,EAAM2R,eAAiB,EAGvB,MAAMzL,UAAoBlG,EACzBK,YAAYiG,EAAQrE,EAAMc,EAASZ,EAAOC,GACzC7B,QACAC,KAAK8F,YAAoBhE,IAAXgE,EAAuBA,EAASJ,EAAY2Z,aAC1Drf,KAAKyB,UAAgBK,IAATL,EAAqBA,EAAO,KACxCzB,KAAKuC,aAAsBT,IAAZS,EAAwBA,EAAU/C,EAAM6G,gBACvDrG,KAAK2B,WAAkBG,IAAVH,EAAsBA,GAAS,EAC5C3B,KAAK4B,UAAgBE,IAATF,EAAqBA,GAAQ,EACzC5B,KAAKuB,YAAc,EACI,OAAnBvB,KAAK8F,OAAO,IACf9F,KAAK+F,KAAOD,EAAO,GAAGC,KACtB/F,KAAKgG,OAASF,EAAO,GAAGE,QAExBhG,KAAKgG,QAAU,EAiBjB0B,QACC,MAAMrG,EAAI,IAAIqE,EAAY1F,KAAK8F,OAAQ9F,KAAKyB,KAAMzB,KAAKuC,QAASvC,KAAK2B,MAAO3B,KAAK4B,MAKjF,OAJAP,EAAEE,WAAavB,KAAKuB,WACpBF,EAAE0E,KAAO/F,KAAK+F,KACd1E,EAAE2E,OAAShG,KAAKgG,OAChB3E,EAAEqC,KAAO1D,KAAK0D,KACPrC,EAGR4D,WACC,IAAIqa,EAAMtf,KAAK0D,KAMf,OAJC4b,EADW,OAARA,EACGA,EAAI/V,QAAQ,MAAO,OAAOA,QAAQ,MAAO,OAAOA,QAAQ,MAAO,OAE/D,YAEA,KAAOvJ,KAAKuB,WAAa,IAAMvB,KAAK2B,MAAQ,IAAM3B,KAAK4B,KAAO,KACnE0d,EAAM,MAAQtf,KAAKyB,KAAO,KACzBzB,KAAKuC,QAAU,EAAI,YAAcvC,KAAKuC,QAAU,IAAM,IACvDvC,KAAK+F,KAAO,IAAM/F,KAAKgG,OAAS,IAG/BtC,WACH,GAAmB,OAAf1D,KAAK4O,MACR,OAAO5O,KAAK4O,MAEb,MAAMf,EAAQ7N,KAAKgV,iBACnB,GAAc,OAAVnH,EACH,OAAO,KAER,MAAM1M,EAAI0M,EAAMpG,KAChB,OAAIzH,KAAK2B,MAAQR,GAAKnB,KAAK4B,KAAOT,EAC1B0M,EAAMvK,QAAQtD,KAAK2B,MAAO3B,KAAK4B,MAE/B,QAIL8B,SAAKA,GACR1D,KAAK4O,MAAQlL,GAQfgC,EAAY2Z,aAAe,CAAE,KAAM,MAEnC1f,EAAOC,QAAU,CAChBJ,MAAAA,EACAkG,YAAAA,YC9ID,SAAS6Z,EAAcvX,GACnB,OAAa,OAANA,EAAa,OAASA,EAGjC,SAASwX,EAAc3E,GACnB,OAAO/T,MAAM2Y,QAAQ5E,GAAM,IAAMA,EAAEzQ,IAAImV,GAAevV,KAAK,MAAQ,IAAO,OA6D9E,SAAS0V,EAAuB7E,EAAGC,GAC/B,OAAOD,EAAIA,EAAER,OAAOS,GAAKD,GAAGC,EAGhC,SAAS6E,EAAyB9E,GAC9B,OAAOA,EAAIA,EAAEf,YAAc,EA/D/BxS,OAAOsY,UAAUC,KAAOvY,OAAOsY,UAAUC,MAAQzY,KAAK0Y,MAAM1Y,KAAK2Y,SAAW3Y,KAAK4Y,IAAI,EAAG,KAExF1Y,OAAOsY,UAAU9F,SAAW,WACxB,MAAMmG,EAAMjgB,KAAKiF,WACjB,IAAIib,EAAKC,EAET,MAAMC,EAAyB,EAAbH,EAAInf,OAChBuf,EAAQJ,EAAInf,OAASsf,EAC3B,IAAIE,EAAKhZ,OAAOsY,UAAUC,KAC1B,MAAMU,EAAK,WACLC,EAAK,UACX,IAAItf,EAAI,EAER,KAAOA,EAAImf,GACPF,EAC0B,IAApBF,EAAIjZ,WAAW9F,IACO,IAAtB+e,EAAIjZ,aAAa9F,KAAc,GACT,IAAtB+e,EAAIjZ,aAAa9F,KAAc,IACT,IAAtB+e,EAAIjZ,aAAa9F,KAAc,KACnCA,EAEFif,GAAc,MAALA,GAAeI,KAAUJ,IAAO,IAAMI,EAAM,QAAW,IAAQ,WACxEJ,EAAMA,GAAM,GAAOA,IAAO,GAC1BA,GAAc,MAALA,GAAeK,KAAUL,IAAO,IAAMK,EAAM,QAAW,IAAQ,WAExEF,GAAMH,EACNG,EAAMA,GAAM,GAAOA,IAAO,GAC1BJ,EAAyB,GAAV,MAALI,KAAqC,GAAbA,IAAO,IAAW,QAAW,IAAQ,WACvEA,EAAwB,OAAV,MAANJ,KAA4C,OAAdA,IAAQ,IAAgB,QAAW,IAK7E,OAFAC,EAAK,EAEGC,GACJ,KAAK,EACDD,IAA+B,IAAxBF,EAAIjZ,WAAW9F,EAAI,KAAc,GAC5C,KAAK,EACDif,IAA+B,IAAxBF,EAAIjZ,WAAW9F,EAAI,KAAc,EAC5C,KAAK,EACDif,GAA2B,IAApBF,EAAIjZ,WAAW9F,GAEtBif,GAAa,MAALA,GAAeI,KAAUJ,IAAO,IAAMI,EAAM,QAAW,IAAO,WACtEJ,EAAMA,GAAM,GAAOA,IAAO,GAC1BA,GAAa,MAALA,GAAeK,KAAUL,IAAO,IAAMK,EAAM,QAAW,IAAO,WACtEF,GAAMH,EAWd,OARAG,GAAML,EAAInf,OAEVwf,GAAMA,IAAO,GACbA,EAAuB,YAAV,MAALA,KAA8C,YAAbA,IAAO,IAAoB,QAAW,IAAO,WACtFA,GAAMA,IAAO,GACbA,EAAwB,YAAV,MAALA,KAA8C,YAAbA,IAAO,IAAoB,QAAW,IAAQ,WACxFA,GAAMA,IAAO,GAENA,IAAO,GAgFlB,MAAM9V,EACF3K,cACIG,KAAKuF,KAAO,GAGhBkH,IAAInD,GACAtJ,KAAKuF,KAAK+D,IAAS,EAGvBmX,GAAGjT,GACC,MAAMkT,EAAO1gB,KACbwd,OAAOmD,KAAKnT,EAAIjI,MAAM6E,KAAI,SAAUoB,GAChCkV,EAAKjU,IAAIjB,MAIjBqB,OAAOvD,UACItJ,KAAKuF,KAAK+D,GAGrBtH,SAASsH,GACL,OAA4B,IAArBtJ,KAAKuF,KAAK+D,GAGrBsX,SACI,OAAOpD,OAAOmD,KAAK3gB,KAAKuF,MAG5Bsb,WACI,OAAOzZ,KAAKC,IAAIyZ,MAAM,KAAM9gB,KAAK4gB,UAGrC9G,WACI,MAAME,EAAO,IAAIR,EAEjB,OADAQ,EAAKC,OAAOja,KAAK4gB,UACV5G,EAAKI,SAGhBC,OAAOxR,GACH,OAAMA,aAAiB2B,GAGhBxK,KAAK8Z,aAAejR,EAAMiR,WAGrC7U,WACI,MAAO,IAAMjF,KAAK4gB,SAAS5W,KAAK,MAAQ,IAGxClJ,aACA,OAAOd,KAAK4gB,SAAS9f,QAK7B,MAAM2Y,EACF5Z,YAAYkhB,EAAcC,GACtBhhB,KAAKuF,KAAO,GACZvF,KAAK+gB,aAAeA,GAAgBpB,EACpC3f,KAAKghB,eAAiBA,GAAkBtB,EAG5CxD,IAAI+D,EAAK3W,GACL,MAAM2X,EAAU,QAAUjhB,KAAK+gB,aAAad,GAC5C,GAAIgB,KAAWjhB,KAAKuF,KAAM,CACtB,MAAM2b,EAAUlhB,KAAKuF,KAAK0b,GAC1B,IAAK,IAAI/f,EAAI,EAAGA,EAAIggB,EAAQpgB,OAAQI,IAAK,CACrC,MAAMigB,EAAQD,EAAQhgB,GACtB,GAAIlB,KAAKghB,eAAef,EAAKkB,EAAMlB,KAAM,CACrC,MAAMmB,EAAWD,EAAM7X,MAEvB,OADA6X,EAAM7X,MAAQA,EACP8X,GAIf,OADAF,EAAQ1f,KAAK,CAACye,IAAIA,EAAK3W,MAAMA,IACtBA,EAGP,OADAtJ,KAAKuF,KAAK0b,GAAW,CAAC,CAAChB,IAAIA,EAAK3W,MAAMA,IAC/BA,EAIf2S,YAAYgE,GACR,MAAMgB,EAAU,QAAUjhB,KAAK+gB,aAAad,GAC5C,GAAGgB,KAAWjhB,KAAKuF,KAAM,CACrB,MAAM2b,EAAUlhB,KAAKuF,KAAK0b,GAC1B,IAAK,IAAI/f,EAAI,EAAGA,EAAIggB,EAAQpgB,OAAQI,IAAK,CACrC,MAAMigB,EAAQD,EAAQhgB,GACtB,GAAIlB,KAAKghB,eAAef,EAAKkB,EAAMlB,KAC/B,OAAO,GAGnB,OAAO,EAGXtf,IAAIsf,GACA,MAAMgB,EAAU,QAAUjhB,KAAK+gB,aAAad,GAC5C,GAAGgB,KAAWjhB,KAAKuF,KAAM,CACrB,MAAM2b,EAAUlhB,KAAKuF,KAAK0b,GAC1B,IAAK,IAAI/f,EAAI,EAAGA,EAAIggB,EAAQpgB,OAAQI,IAAK,CACrC,MAAMigB,EAAQD,EAAQhgB,GACtB,GAAIlB,KAAKghB,eAAef,EAAKkB,EAAMlB,KAC/B,OAAOkB,EAAM7X,OAGzB,OAAO,KAGX4X,UACI,IAAI7Y,EAAI,GACR,IAAK,MAAM4X,KAAOjgB,KAAKuF,KACU,IAAzB0a,EAAIxM,QAAQ,WACZpL,EAAIA,EAAEgZ,OAAOrhB,KAAKuF,KAAK0a,KAG/B,OAAO5X,EAGXiZ,UACI,OAAOthB,KAAKkhB,UAAU9W,KAAI,SAAS3F,GAC/B,OAAOA,EAAEwb,OAIjBsB,YACI,OAAOvhB,KAAKkhB,UAAU9W,KAAI,SAAS3F,GAC3B,OAAOA,EAAE6E,SAIrBrE,WAII,MAAO,IAHIjF,KAAKkhB,UAAU9W,KAAI,SAAS+W,GACnC,MAAO,IAAMA,EAAMlB,IAAM,IAAMkB,EAAM7X,MAAQ,OAEjCU,KAAK,MAAQ,IAG7BlJ,aACA,IAAIuH,EAAI,EACR,IAAK,MAAM4Y,KAAWjhB,KAAKuF,KACU,IAA7B0b,EAAQxN,QAAQ,WAChBpL,GAAQrI,KAAKuF,KAAK0b,GAASngB,QAGnC,OAAOuH,GAuDf,MAAMmR,EACF3Z,cACIG,KAAKqL,MAAQ,EACbrL,KAAKga,KAAO,EAGhBC,SACI,IAAI,IAAI/Y,EAAE,EAAEA,EAAEsgB,UAAU1gB,OAAOI,IAAK,CAChC,MAAMoI,EAAQkY,UAAUtgB,GACxB,GAAa,MAAToI,EAEJ,GAAGxC,MAAM2Y,QAAQnW,GACbtJ,KAAKia,OAAO6G,MAAM9gB,KAAMsJ,OACvB,CACD,IAAInH,EAAI,EACR,cAAc,GACV,IAAK,YACL,IAAK,WACD,SACJ,IAAK,SACL,IAAK,UACDA,EAAImH,EACJ,MACJ,IAAK,SACDnH,EAAImH,EAAMwQ,WACV,MACJ,QACOxQ,EAAMyQ,eACLzQ,EAAMyQ,eAAe/Z,MAErBmP,QAAQC,IAAI,yBAA2B9F,EAAMrE,YACjD,SAER9C,GAAQ,WACRA,EAAKA,GAAK,GAAOA,IAAM,GACvBA,GAAQ,UACRnC,KAAKqL,MAAQrL,KAAKqL,MAAQ,EAC1B,IAAI2O,EAAOha,KAAKga,KAAO7X,EACvB6X,EAAQA,GAAQ,GAAOA,IAAS,GAChCA,EAAc,EAAPA,EAAW,WAClBha,KAAKga,KAAOA,IAKxBI,SACI,IAAIJ,EAAOha,KAAKga,KAAqB,EAAbha,KAAKqL,MAM7B,OALA2O,GAAeA,IAAS,GACxBA,GAAc,WACdA,GAAeA,IAAS,GACxBA,GAAc,WACdA,GAAeA,IAAS,GACjBA,GA2Cfra,EAAOC,QAAU,CACb4Z,KAAAA,EACAjP,IA7WJ,MACI1K,YAAYkhB,EAAcC,GACtBhhB,KAAKuF,KAAO,GACZvF,KAAK+gB,aAAeA,GAAgBpB,EACpC3f,KAAKghB,eAAiBA,GAAkBtB,EAG5CjT,IAAInD,GACA,MACM2W,EAAM,QADCjgB,KAAK+gB,aAAazX,GAE/B,GAAI2W,KAAOjgB,KAAKuF,KAAM,CAClB,MAAMqb,EAAS5gB,KAAKuF,KAAK0a,GACzB,IAAK,IAAI/e,EAAI,EAAGA,EAAI0f,EAAO9f,OAAQI,IAC/B,GAAIlB,KAAKghB,eAAe1X,EAAOsX,EAAO1f,IAClC,OAAO0f,EAAO1f,GAItB,OADA0f,EAAOpf,KAAK8H,GACLA,EAGP,OADAtJ,KAAKuF,KAAK0a,GAAO,CAAC3W,GACXA,EAIftH,SAASsH,GACL,OAA0B,MAAnBtJ,KAAKW,IAAI2I,GAGpB3I,IAAI2I,GACA,MACM2W,EAAM,QADCjgB,KAAK+gB,aAAazX,GAE/B,GAAI2W,KAAOjgB,KAAKuF,KAAM,CAClB,MAAMqb,EAAS5gB,KAAKuF,KAAK0a,GACzB,IAAK,IAAI/e,EAAI,EAAGA,EAAI0f,EAAO9f,OAAQI,IAC/B,GAAIlB,KAAKghB,eAAe1X,EAAOsX,EAAO1f,IAClC,OAAO0f,EAAO1f,GAI1B,OAAO,KAGX0f,SACI,IAAIvY,EAAI,GACR,IAAK,MAAM4X,KAAOjgB,KAAKuF,KACU,IAAzB0a,EAAIxM,QAAQ,WACZpL,EAAIA,EAAEgZ,OAAOrhB,KAAKuF,KAAK0a,KAG/B,OAAO5X,EAGXpD,WACI,OAAOua,EAAcxf,KAAK4gB,UAG1B9f,aACA,IAAIuH,EAAI,EACR,IAAK,MAAM4X,KAAOjgB,KAAKuF,KACU,IAAzB0a,EAAIxM,QAAQ,WACZpL,GAAQrI,KAAKuF,KAAK0a,GAAKnf,QAG/B,OAAOuH,IA8SXoR,IAAAA,EACAjP,OAAAA,EACAiX,QAtJJ,MACI5hB,cACIG,KAAKuF,KAAO,GAGhB5E,IAAIsf,GAEA,OADAA,EAAM,KAAOA,KACFjgB,KAAKuF,KACLvF,KAAKuF,KAAK0a,GAEV,KAIf/D,IAAI+D,EAAK3W,GACL2W,EAAM,KAAOA,EACbjgB,KAAKuF,KAAK0a,GAAO3W,EAGrBsX,SACI,MAAMrb,EAAOvF,KAAKuF,KAElB,OADaiY,OAAOmD,KAAK3gB,KAAKuF,MAClB6E,KAAI,SAAU6V,GACtB,OAAO1a,EAAK0a,QAgIpByB,WA1HJ,MACI7hB,YAAY8hB,GACR3hB,KAAK2hB,eAAiBA,GAAkBlI,EACxCzZ,KAAK4hB,SAAW,IAAI5hB,KAAK2hB,eAG7BhhB,IAAIka,EAAGC,GACH,MAAMlK,EAAI5Q,KAAK4hB,SAASjhB,IAAIka,IAAM,KAClC,OAAa,OAANjK,EAAa,KAAQA,EAAEjQ,IAAIma,IAAM,KAG5CtN,IAAIqN,EAAGC,EAAG1F,GACN,IAAIxE,EAAI5Q,KAAK4hB,SAASjhB,IAAIka,IAAM,KACtB,OAANjK,IACAA,EAAI,IAAI5Q,KAAK2hB,eACb3hB,KAAK4hB,SAAS1F,IAAIrB,EAAGjK,IAEzBA,EAAEsL,IAAIpB,EAAG1F,KA0GbyM,UA9CJ,WACI,MAAM7H,EAAO,IAAIR,EAEjB,OADAQ,EAAKC,OAAO6G,MAAM9G,EAAMwH,WACjBxH,EAAKI,UA4CZ0H,iBAxCJ,SAA0Bre,EAAGse,GAOzB,OANAte,EAAIA,EAAE8F,QAAQ,MAAO,OACfA,QAAQ,MAAO,OACfA,QAAQ,MAAO,OACjBwY,IACAte,EAAIA,EAAE8F,QAAQ,KAAM,MAEjB9F,GAkCP+b,cAAAA,EACAwC,UAhCJ,SAAmBje,GACf,OAAOA,EAAIwF,QAAQ,UAAU,SAAU+V,GACnC,OAAOA,EAAI2C,OAAO,GAAGC,cAAgB5C,EAAI6C,OAAO,OA+BpDzI,YA3BJ,SAAqBmB,EAAGC,GACpB,IAAKhU,MAAM2Y,QAAQ5E,KAAO/T,MAAM2Y,QAAQ3E,GACpC,OAAO,EACX,GAAID,IAAMC,EACN,OAAO,EACX,GAAID,EAAE/Z,SAAWga,EAAEha,OACf,OAAO,EACX,IAAK,IAAII,EAAI,EAAGA,EAAI2Z,EAAE/Z,OAAQI,IAC1B,KAAI2Z,EAAE3Z,KAAO4Z,EAAE5Z,IAEV2Z,EAAE3Z,GAAGmZ,QAAWQ,EAAE3Z,GAAGmZ,OAAOS,EAAE5Z,KAC/B,OAAO,EAEf,OAAO,mBClbX,MAAMgK,EAAc,EAAQ,MACtB,YAACtD,GAAe,EAAQ,MACxB,MAACpI,GAAS,EAAQ,KAExB,MAAM4iB,EAEFviB,YAAYwiB,EAAc9U,GAKtBvN,KAAKqiB,YAAcA,EAEnBriB,KAAKuN,aAAeA,EACpBvN,KAAK+M,OAAS,GAMd/M,KAAKsiB,gBAAkB,GAEvBtiB,KAAKuiB,iBAAmB,GAExBviB,KAAKwiB,gBAAkB,KACvBxiB,KAAKyiB,qBAAuB,GAO5BziB,KAAK0iB,gBAAkB,KAKvB1iB,KAAK2iB,aAAe,KACpB3iB,KAAK4iB,iBAAmB,GAS5BC,oBAAoBpf,EAAGwI,GAEnB,OADa,IAAIf,EAAYlL,MACjB+L,KAAKtI,EAAG,KAAMwI,GAQ9B6W,oBAAoBrf,GAChB,OAA8B,OAA1BA,EAAEsf,sBAGNtf,EAAEsf,oBAAsB/iB,KAAK6iB,oBAAoBpf,EAAG,MACpDA,EAAEsf,oBAAoBjb,UAAW,GAHtBrE,EAAEsf,oBAOjB/L,WAAWvT,EAAGwI,GACV,YAAWnK,IAANmK,EACMjM,KAAK8iB,oBAAoBrf,GAEzBzD,KAAK6iB,oBAAoBpf,EAAGwI,GAI3C+W,SAASzW,GACU,OAAVA,IACDA,EAAMpB,IAAMnL,KACZuM,EAAMa,YAAcpN,KAAK+M,OAAOjM,QAEpCd,KAAK+M,OAAOvL,KAAK+K,GAGrB0W,YAAY1W,GACRvM,KAAK+M,OAAOR,EAAMa,aAAe,KAGrC8V,oBAAoBzf,GAGhB,OAFAzD,KAAKsiB,gBAAgB9gB,KAAKiC,GAC1BA,EAAEuU,SAAWhY,KAAKsiB,gBAAgBxhB,OAAO,EAClC2C,EAAEuU,SAGbmL,iBAAiBnL,GACb,OAAkC,IAA9BhY,KAAKsiB,gBAAgBxhB,OACd,KAEAd,KAAKsiB,gBAAgBtK,GAyBpCd,kBAAkB9J,EAAanB,GAC3B,GAAKmB,EAAc,GAAKA,GAAepN,KAAK+M,OAAOjM,OAC/C,KAAK,wBAET,MAAM2C,EAAIzD,KAAK+M,OAAOK,GACtB,IAAI2J,EAAY/W,KAAKgX,WAAWvT,GAChC,IAAKsT,EAAU/U,SAASxC,EAAM2K,SAC1B,OAAO4M,EAEX,MAAMqM,EAAW,IAAIxb,EAGrB,IAFAwb,EAASxa,OAAOmO,GAChBqM,EAASha,UAAU5J,EAAM2K,SACV,OAAR8B,GAAgBA,EAAIuJ,eAAiB,GAAKuB,EAAU/U,SAASxC,EAAM2K,UAAU,CAChF,MACM8M,EADgBjX,KAAK+M,OAAOd,EAAIuJ,eACblK,YAAY,GACrCyL,EAAY/W,KAAKgX,WAAWC,EAAG9J,aAC/BiW,EAASxa,OAAOmO,GAChBqM,EAASha,UAAU5J,EAAM2K,SACzB8B,EAAMA,EAAI2J,UAKd,OAHImB,EAAU/U,SAASxC,EAAM2K,UACzBiZ,EAASlb,OAAO1I,EAAMwB,KAEnBoiB,GAIfhB,EAAIiB,mBAAqB,EAEzB1jB,EAAOC,QAAUwiB,iBCtJjB,MAAM,cAACkB,GAAiB,EAAQ,MAC1B,gBAACC,GAAmB,EAAQ,MAC5B,KAAC/J,GAAQ,EAAQ,KAGvB,SAASgK,EAAYC,EAAQC,GAC5B,GAAY,OAATD,EAAe,CACjB,MAAM7e,EAAS,CAAE2H,MAAM,KAAMf,IAAI,KAAMgB,QAAQ,KAAMmX,gBAAgB,MAIrE,OAHGD,IACF9e,EAAOgf,wBAA0B,GAE3Bhf,EACD,CACN,MAAMif,EAAQ,GASd,OARAA,EAAMtX,MAAQkX,EAAOlX,OAAS,KAC9BsX,EAAMrY,SAAsB1J,IAAf2hB,EAAOjY,IAAqB,KAAOiY,EAAOjY,IACvDqY,EAAMrX,QAAUiX,EAAOjX,SAAW,KAClCqX,EAAMF,gBAAkBF,EAAOE,iBAAmB,KAC/CD,IACFG,EAAMD,wBAA0BH,EAAOG,yBAA2B,EAClEC,EAAMC,2BAA6BL,EAAOK,6BAA8B,GAElED,GAIT,MAAMpZ,EASF5K,YAAY4jB,EAAQM,GAChB/jB,KAAKgkB,aAAaP,EAAQM,GAC1BN,EAASD,EAAYC,GACrBM,EAASP,EAAYO,GAAQ,GAE7B/jB,KAAKuM,MAAuB,OAAfkX,EAAOlX,MAAekX,EAAOlX,MAAQwX,EAAOxX,MAEzDvM,KAAKwL,IAAmB,OAAbiY,EAAOjY,IAAaiY,EAAOjY,IAAMuY,EAAOvY,IAMnDxL,KAAKwM,QAA2B,OAAjBiX,EAAOjX,QAAiBiX,EAAOjX,QAAUuX,EAAOvX,QAC/DxM,KAAK2jB,gBAA2C,OAAzBF,EAAOE,gBAAyBF,EAAOE,gBAChC,OAAzBI,EAAOJ,gBAAyBI,EAAOJ,gBAAkBJ,EAAgBU,KAY9EjkB,KAAK4jB,wBAA0BG,EAAOH,wBACtC5jB,KAAK8jB,2BAA6BC,EAAOD,2BAG7CE,aAAaP,EAAQM,GACI,OAAjBN,EAAOjX,cAAmC1K,IAAjB2hB,EAAOjX,SAClB,OAATuX,GAAkC,OAAjBA,EAAOvX,cAAmC1K,IAAjBiiB,EAAOvX,UACtDxM,KAAKwM,QAAU,MAIvBsN,WACI,MAAME,EAAO,IAAIR,EAEjB,OADAxZ,KAAK+Z,eAAeC,GACbA,EAAKI,SAGhBL,eAAeC,GACXA,EAAKC,OAAOja,KAAKuM,MAAMa,YAAapN,KAAKwL,IAAKxL,KAAKwM,QAASxM,KAAK2jB,iBAQrEtJ,OAAOxR,GACH,OAAI7I,OAAS6I,GAECA,aAAiB4B,GAGpBzK,KAAKuM,MAAMa,cAAcvE,EAAM0D,MAAMa,aACxCpN,KAAKwL,MAAM3C,EAAM2C,MACD,OAAfxL,KAAKwM,QAAiC,OAAhB3D,EAAM2D,QAAiBxM,KAAKwM,QAAQ6N,OAAOxR,EAAM2D,WACxExM,KAAK2jB,gBAAgBtJ,OAAOxR,EAAM8a,kBAClC3jB,KAAK8jB,6BAA6Bjb,EAAMib,2BAIpDI,uBACI,MAAMlK,EAAO,IAAIR,EAEjB,OADAQ,EAAKC,OAAOja,KAAKuM,MAAMa,YAAapN,KAAKwL,IAAKxL,KAAK2jB,iBAC5C3J,EAAKI,SAGhB+J,mBAAmBtb,GACf,OAAI7I,OAAS6I,GAECA,aAAiB4B,GAGpBzK,KAAKuM,MAAMa,cAAcvE,EAAM0D,MAAMa,aACxCpN,KAAKwL,MAAM3C,EAAM2C,KACjBxL,KAAK2jB,gBAAgBtJ,OAAOxR,EAAM8a,iBAI9C1e,WACI,MAAO,IAAMjF,KAAKuM,MAAQ,IAAMvM,KAAKwL,KACjB,OAAfxL,KAAKwM,QAAiB,KAAOxM,KAAKwM,QAAQvH,WAAa,IAAM,KAC7DjF,KAAK2jB,kBAAoBJ,EAAgBU,KACjC,IAAMjkB,KAAK2jB,gBAAgB1e,WAC1B,KACTjF,KAAK4jB,wBAAwB,EACrB,OAAS5jB,KAAK4jB,wBACb,IAAM,KAK5B,MAAMQ,UAAuB3Z,EACzB5K,YAAY4jB,EAAQM,GAChBhkB,MAAM0jB,EAAQM,GAGd,MAAMM,EAAsBZ,EAAOY,qBAAuB,KAK1D,OAJArkB,KAAKqkB,oBAAsBA,IAAiC,OAATN,EAAgBA,EAAOM,oBAAsB,MAChGrkB,KAAKskB,+BAA0C,OAATP,GAAgB/jB,KAAKukB,uBAAuBR,EAAQ/jB,KAAKuM,OAC/FvM,KAAKkkB,qBAAuBE,EAAexE,UAAU9F,SACrD9Z,KAAKmkB,mBAAqBC,EAAexE,UAAUvF,OAC5Cra,KAGX+Z,eAAeC,GACXA,EAAKC,OAAOja,KAAKuM,MAAMa,YAAapN,KAAKwL,IAAKxL,KAAKwM,QAASxM,KAAK2jB,gBAAiB3jB,KAAKskB,+BAAgCtkB,KAAKqkB,qBAGhIhK,OAAOxR,GACH,OAAO7I,OAAS6I,GACPA,aAAiBub,GAClBpkB,KAAKskB,iCAAmCzb,EAAMyb,iCAC7CtkB,KAAKqkB,oBAAsBrkB,KAAKqkB,oBAAoBhK,OAAOxR,EAAMwb,sBAAwBxb,EAAMwb,sBAChGtkB,MAAMsa,OAAOxR,GAGzB0b,uBAAuBze,EAAQnB,GAC3B,OAAOmB,EAAOwe,gCACT3f,aAAkB2e,GAAkB3e,EAAO6f,WAKxD7kB,EAAOC,QAAQ6K,UAAYA,EAC3B9K,EAAOC,QAAQwkB,eAAiBA,gBCtKhC,MAAMhC,EAAM,EAAQ,KACdqC,EAAQ,EAAQ,MAChB,gBAAClB,GAAmB,EAAQ,MAC5B,MAAC3I,GAAS,EAAQ,KAExB,SAAS8J,EAAcpY,GACtB,OAAOA,EAAE4X,uBAGV,SAASS,EAAgB9J,EAAGC,GAC3B,OAAKD,IAAIC,GAEO,OAAJD,GAAgB,OAAJC,GAGXD,EAAEsJ,mBAAmBrJ,GAQnC,MAAM8J,EACL/kB,YAAYglB,GAaX7kB,KAAK8kB,aAAe,IAAIL,EAAMla,IAAIma,EAAeC,GAMjD3kB,KAAK6kB,aAAsB/iB,IAAZ+iB,GAA+BA,EAQ9C7kB,KAAK8H,UAAW,EAEhB9H,KAAK+kB,QAAU,GAMf/kB,KAAKglB,UAAY,EACjBhlB,KAAKilB,gBAAkB,KAMvBjlB,KAAKklB,oBAAqB,EAC1BllB,KAAKmlB,sBAAuB,EAE5BnlB,KAAK2Z,gBAAkB,EAaxBlN,IAAIsX,EAAQ/I,GAIX,QAHmBlZ,IAAfkZ,IACHA,EAAa,MAEVhb,KAAK8H,SACR,KAAM,uBAEHic,EAAOJ,kBAAoBJ,EAAgBU,OAC9CjkB,KAAKklB,oBAAqB,GAEvBnB,EAAOH,wBAA0B,IACpC5jB,KAAKmlB,sBAAuB,GAE7B,MAAM3c,EAAWxI,KAAK8kB,aAAarY,IAAIsX,GACvC,GAAIvb,IAAaub,EAGhB,OAFA/jB,KAAK2Z,gBAAkB,EACvB3Z,KAAK+kB,QAAQvjB,KAAKuiB,IACX,EAGR,MAAMhJ,GAAkB/a,KAAK6kB,QACvBO,EAASxK,EAAMpS,EAASgE,QAASuX,EAAOvX,QAASuO,EAAgBC,GAYvE,OANAxS,EAASob,wBAA0Bxc,KAAKsB,IAAKF,EAASob,wBAAyBG,EAAOH,yBAElFG,EAAOD,6BACVtb,EAASsb,4BAA6B,GAEvCtb,EAASgE,QAAU4Y,GACZ,EAGRC,YACC,MAAMtY,EAAS,IAAI0X,EAAMla,IACzB,IAAK,IAAIrJ,EAAI,EAAGA,EAAIlB,KAAK+kB,QAAQjkB,OAAQI,IACxC6L,EAAON,IAAIzM,KAAK+kB,QAAQ7jB,GAAGqL,OAE5B,OAAOQ,EAGRuY,gBACC,MAAMC,EAAQ,GACd,IAAK,IAAIrkB,EAAI,EAAGA,EAAIlB,KAAK+kB,QAAQjkB,OAAQI,IAAK,CAC7C,MAAMoL,EAAItM,KAAK+kB,QAAQ7jB,GAAGyiB,gBACtBrX,IAAMiX,EAAgBU,MACzBsB,EAAM/jB,KAAK8K,EAAEqX,iBAGf,OAAO4B,EAGRC,gBAAgBC,GACf,GAAIzlB,KAAK8H,SACR,KAAM,uBAEP,GAAiC,IAA7B9H,KAAK8kB,aAAahkB,OAGtB,IAAK,IAAII,EAAI,EAAGA,EAAIlB,KAAK+kB,QAAQjkB,OAAQI,IAAK,CAC7C,MAAM6iB,EAAS/jB,KAAK+kB,QAAQ7jB,GAC5B6iB,EAAOvX,QAAUiZ,EAAYC,iBAAiB3B,EAAOvX,UAIvDmZ,OAAOC,GACN,IAAK,IAAI1kB,EAAI,EAAGA,EAAI0kB,EAAK9kB,OAAQI,IAChClB,KAAKyM,IAAImZ,EAAK1kB,IAEf,OAAO,EAGRmZ,OAAOxR,GACN,OAAO7I,OAAS6I,GACdA,aAAiB+b,GAClBH,EAAM/K,YAAY1Z,KAAK+kB,QAASlc,EAAMkc,UACtC/kB,KAAK6kB,UAAYhc,EAAMgc,SACvB7kB,KAAKglB,YAAcnc,EAAMmc,WACzBhlB,KAAKilB,kBAAoBpc,EAAMoc,iBAC/BjlB,KAAKklB,qBAAuBrc,EAAMqc,oBAClCllB,KAAKmlB,uBAAyBtc,EAAMsc,qBAGtCrL,WACC,MAAME,EAAO,IAAIyK,EAAMjL,KAEvB,OADAQ,EAAKC,OAAOja,KAAK+kB,SACV/K,EAAKI,SAGbL,eAAeC,GACVha,KAAK8H,WACqB,IAAzB9H,KAAK2Z,iBACR3Z,KAAK2Z,eAAiB3Z,KAAK8Z,YAE5BE,EAAKC,OAAOja,KAAK2Z,iBAEjBK,EAAKC,OAAOja,KAAK8Z,YAInBpN,UACC,OAA+B,IAAxB1M,KAAK+kB,QAAQjkB,OAGrBkB,SAAS2F,GACR,GAA0B,OAAtB3H,KAAK8kB,aACR,KAAM,oDAEP,OAAO9kB,KAAK8kB,aAAa9iB,SAAS2F,GAGnCke,aAAale,GACZ,GAA0B,OAAtB3H,KAAK8kB,aACR,KAAM,oDAEP,OAAO9kB,KAAK8kB,aAAae,aAAale,GAGvCme,QACC,GAAI9lB,KAAK8H,SACR,KAAM,uBAEP9H,KAAK+kB,QAAU,GACf/kB,KAAK2Z,gBAAkB,EACvB3Z,KAAK8kB,aAAe,IAAIL,EAAMla,IAG/Bwb,YAAYje,GACX9H,KAAK8H,SAAWA,EACZA,IACH9H,KAAK8kB,aAAe,MAItB7f,WACC,OAAOwf,EAAMjF,cAAcxf,KAAK+kB,UAC9B/kB,KAAKklB,mBAAqB,uBAAyBllB,KAAKklB,mBAAqB,KAC7EllB,KAAKglB,YAAc5C,EAAIiB,mBAAqB,cAAgBrjB,KAAKglB,UAAY,KACpD,OAAzBhlB,KAAKilB,gBAA2B,oBAAsBjlB,KAAKilB,gBAAkB,KAC7EjlB,KAAKmlB,qBAAuB,wBAA0B,IAGrDa,YACH,OAAOhmB,KAAK+kB,QAGTjkB,aACH,OAAOd,KAAK+kB,QAAQjkB,QAYtBnB,EAAOC,QAAU,CAChBglB,aAAAA,EACAqB,oBATD,cAAkCrB,EACjC/kB,cACCE,QACAC,KAAK8kB,aAAe,IAAIL,EAAMla,gBChPhC,MAAMoH,EACL9R,YAAYgZ,QACG/W,IAAX+W,IACFA,EAAW,MAEZ7Y,KAAK8H,UAAW,EAChB9H,KAAKkmB,UAAuB,OAAXrN,GAAyBA,EAASqN,UACnDlmB,KAAKwU,8BAA2C,OAAXqE,GAA0BA,EAASrE,+BAI1E7C,EAA0BwU,eAAiB,IAAIxU,EAC/CA,EAA0BwU,eAAere,UAAW,EAOpDnI,EAAOC,QAAU+R,iBCnBjB,MAAM,MAACnS,GAAS,EAAQ,KAClB4iB,EAAM,EAAQ,KACdgE,EAAU,EAAQ,MAElB,SACFC,EAAQ,WACRC,EAAU,cACVhD,EAAa,gBACbiD,EAAe,cACfC,EAAa,aACbC,EAAY,eACZC,EAAc,cACdhc,EAAa,iBACbic,EAAgB,kBAChBC,EAAiB,kBACjBC,EAAiB,mBACjBC,EAAkB,oBAClBC,EAAmB,oBACnBC,EAAmB,qBACnBC,GACA,EAAQ,MAEN,WACFC,EAAU,eACVC,EAAc,cACdC,EAAa,iBACbxc,EAAgB,eAChBD,EAAc,gBACd0c,EAAe,iBACfC,EAAgB,kBAChBC,EAAiB,mBACjB1c,EAAkB,oBAClB2c,EAAmB,8BACnBC,GACA,EAAQ,KAEN,YAAC7f,GAAe,EAAQ,KACxB+J,EAA4B,EAAQ,MAEpC,gBACF+V,EAAe,gBACfC,EAAe,mBACfC,EAAkB,kBAClBC,EAAiB,gBACjBC,EAAe,gBACfC,EAAe,oBACfC,EAAmB,mBACnBC,EAAkB,gBAClBC,GACA,EAAQ,KAWNC,EAAoB,uCAIpBC,EAAkB,CAXK,uCAWmBD,GAOhD,SAASE,EAAWvnB,EAAQwI,GAC3B,MAAMgf,EAAM,GAEZ,OADAA,EAAIxnB,EAAO,GAAKwI,EACTgf,EAAIle,KAAI,SAASlJ,GAAI,OAAOoI,KAwlBpC,MAAMif,EARN,WACC,MAAMC,EAAM,GACZ,IAAK,IAAItnB,EAAI,EAAGA,EAAI,IAAKA,IACxBsnB,EAAItnB,IAAMA,EAAI,KAAO+D,SAAS,IAAIkd,OAAO,GAAGD,cAE7C,OAAOsG,EAGUC,GAGlB9oB,EAAOC,QAxlBP,MACIC,YAAY6oB,GAEHA,MAAAA,IACDA,EAAU/W,EAA0BwU,gBAExCnmB,KAAKuU,uBAAyBmU,EAC9B1oB,KAAK2oB,eAAiB,KACtB3oB,KAAK4oB,gBAAkB,KAgB3BC,mBAAmBC,EAASC,GACxB,MAAMC,EAAOZ,EAAgB3U,QAAQqV,GACrC,QAAIE,EAAK,IAGIZ,EAAgB3U,QAAQsV,IACtBC,EAGnBvU,YAAYlP,GACRvF,KAAKO,MAAMgF,GACXvF,KAAKmd,eACLnd,KAAKipB,YACL,MAAM9d,EAAMnL,KAAKkpB,UACjBlpB,KAAKmpB,WAAWhe,GAChBnL,KAAKopB,UAAUje,GACfnL,KAAKqpB,UAAUle,GACf,MAAMme,EAAO,GAkBb,OAhBAtpB,KAAKupB,SAASpe,EAAKme,EAAMtpB,KAAKwpB,QAAQC,KAAKzpB,OAGvCA,KAAK6oB,mBAAmBV,EAAmBnoB,KAAK0pB,OAChD1pB,KAAKupB,SAASpe,EAAKme,EAAMtpB,KAAK2pB,UAAUF,KAAKzpB,OAEjDA,KAAK4pB,UAAUze,EAAKme,GACpBtpB,KAAK6pB,cAAc1e,GACnBnL,KAAK8pB,iBAAiB3e,GACtBnL,KAAK+pB,wBAAwB5e,GAC7BnL,KAAKkmB,UAAU/a,GACXnL,KAAKuU,uBAAuBC,+BAAiCrJ,EAAIkX,cAAgB+D,EAAQ4D,SACzFhqB,KAAKwU,8BAA8BrJ,GAEnCnL,KAAKkmB,UAAU/a,IAEZA,EAGX5K,MAAMgF,GACF,MAIM0kB,EAAO1kB,EAAK2kB,MAAM,IAAI9f,KAJb,SAASkC,GACpB,MAAMtE,EAAIsE,EAAEtF,WAAW,GACvB,OAAOgB,EAAE,EAAKA,EAAE,EAAIA,EAAI,SAI5BiiB,EAAK,GAAK1kB,EAAKyB,WAAW,GAC1BhH,KAAKuF,KAAO0kB,EACZjqB,KAAKmH,IAAM,EAGfgW,eACI,MAAMgN,EAAUnqB,KAAKwpB,UACrB,GAvFmB,IAuFdW,EACD,KAAO,0CAA4CA,EAA7C,iBAIdlB,YACI,MAAMS,EAAO1pB,KAAKoqB,WAClB,GAAIhC,EAAgB3U,QAAQiW,GAAM,EAC9B,KA5FYvB,uCA+FhBnoB,KAAK0pB,KAAOA,EAGhBR,UACI,MAAM7G,EAAcriB,KAAKwpB,UACnBjc,EAAevN,KAAKwpB,UAC1B,OAAO,IAAIpH,EAAIC,EAAa9U,GAGhC4b,WAAWhe,GACP,IAAIlB,EAAGogB,EAAMjd,EACb,MAAOkd,EAAuB,GACvBC,EAAkB,GAClBC,EAAUxqB,KAAKwpB,UACtB,IAAI,IAAItoB,EAAE,EAAGA,EAAEspB,EAAStpB,IAAK,CACzB,MAAOupB,EAAQzqB,KAAKwpB,UAEpB,GAAIiB,IAAQpE,EAASpe,aAAc,CAC/BkD,EAAI6X,SAAS,MACb,SAEJ,IAAIpW,EAAY5M,KAAKwpB,UACH,QAAd5c,IACAA,GAAa,GAEjB,MAAOnJ,EAAIzD,KAAK0qB,aAAaD,EAAO7d,GACpC,GAAI6d,IAAUpE,EAASsE,SAAU,CAC7B,MAAOC,EAAsB5qB,KAAKwpB,UAClCc,EAAqB9oB,KAAK,CAACiC,EAAGmnB,SAC3B,GAAGnnB,aAAa8iB,EAAiB,CACpC,MAAOsE,EAAiB7qB,KAAKwpB,UAC7Be,EAAgB/oB,KAAK,CAACiC,EAAGonB,IAE7B1f,EAAI6X,SAASvf,GAIjB,IAAKwG,EAAE,EAAGA,EAAEqgB,EAAqBxpB,OAAQmJ,IACrCogB,EAAOC,EAAqBrgB,GAC5BogB,EAAK,GAAGS,cAAgB3f,EAAI4B,OAAOsd,EAAK,IAG5C,IAAKpgB,EAAE,EAAGA,EAAEsgB,EAAgBzpB,OAAQmJ,IAChCogB,EAAOE,EAAgBtgB,GACvBogB,EAAK,GAAGU,SAAW5f,EAAI4B,OAAOsd,EAAK,IAGvC,IAAIW,EAAqBhrB,KAAKwpB,UAC9B,IAAKvf,EAAE,EAAGA,EAAE+gB,EAAoB/gB,IAC5BmD,EAAcpN,KAAKwpB,UACnBre,EAAI4B,OAAOK,GAAaoX,WAAY,EAGxC,IAAIyG,EAAsBjrB,KAAKwpB,UAC/B,IAAKvf,EAAE,EAAGA,EAAEghB,EAAqBhhB,IAC7BmD,EAAcpN,KAAKwpB,UACnBre,EAAI4B,OAAOK,GAAa8d,kBAAmB,EAInD9B,UAAUje,GACN,IAAIjK,EACJ,MAAMiqB,EAASnrB,KAAKwpB,UAKpB,IAJIre,EAAIkX,cAAgB+D,EAAQgF,QAC5BjgB,EAAIuX,gBAAkB2F,EAAU8C,EAAQ,IAE5ChgB,EAAIoX,iBAAmB8F,EAAU8C,EAAQ,GACpCjqB,EAAE,EAAGA,EAAEiqB,EAAQjqB,IAAK,CACrB,MAAMuC,EAAIzD,KAAKwpB,UAEf,GADAre,EAAIoX,iBAAiBrhB,GAAKiK,EAAI4B,OAAOtJ,GAChC0H,EAAIkX,cAAgB+D,EAAQgF,MAAQ,CACrC,IAAIC,EAAYrrB,KAAKwpB,UACH,QAAd6B,IACAA,EAAY7rB,EAAMwB,KAEtBmK,EAAIuX,gBAAgBxhB,GAAKmqB,GAIjC,IADAlgB,EAAIqX,gBAAkB6F,EAAU8C,EAAQ,GACnCjqB,EAAE,EAAGA,EAAEiK,EAAI4B,OAAOjM,OAAQI,IAAK,CAChC,MAAMqL,EAAQpB,EAAI4B,OAAO7L,GACnBqL,aAAiB7B,IAGvBS,EAAIqX,gBAAgBjW,EAAMK,WAAaL,EACvCpB,EAAIoX,iBAAiBhW,EAAMK,WAAWZ,UAAYO,IAI1D8c,UAAUle,GACN,MAAMmgB,EAAStrB,KAAKwpB,UACpB,IAAK,IAAItoB,EAAE,EAAGA,EAAEoqB,EAAQpqB,IAAK,CACzB,IAAIuC,EAAIzD,KAAKwpB,UACbre,EAAIyX,iBAAiBphB,KAAK2J,EAAI4B,OAAOtJ,KAI7C8lB,SAASpe,EAAKme,EAAMiC,GAChB,MAAM1b,EAAI7P,KAAKwpB,UACf,IAAK,IAAItoB,EAAE,EAAGA,EAAE2O,EAAG3O,IAAK,CACpB,MAAMsqB,EAAO,IAAI5jB,EACjB0hB,EAAK9nB,KAAKgqB,GACV,MAAMrqB,EAAInB,KAAKwpB,UAEG,IADExpB,KAAKwpB,WAErBgC,EAAKtjB,QAAQ,GAEjB,IAAK,IAAI+B,EAAE,EAAGA,EAAE9I,EAAG8I,IAAK,CACpB,MAAMwhB,EAAKF,IACLG,EAAKH,IACXC,EAAKpjB,SAASqjB,EAAIC,KAK9B9B,UAAUze,EAAKme,GACX,IAAIpoB,EAAG+I,EAAGsC,EAAOof,EAAOhnB,EACxB,MAAMinB,EAAS5rB,KAAKwpB,UACpB,IAAKtoB,EAAE,EAAGA,EAAE0qB,EAAQ1qB,IAAK,CACrB,MAAM2qB,EAAM7rB,KAAKwpB,UACXsC,EAAM9rB,KAAKwpB,UACXxa,EAAQhP,KAAKwpB,UACbuC,EAAO/rB,KAAKwpB,UACZwC,EAAOhsB,KAAKwpB,UACZyC,EAAOjsB,KAAKwpB,UAClBmC,EAAQ3rB,KAAKksB,YAAY/gB,EAAK6D,EAAO6c,EAAKC,EAAKC,EAAMC,EAAMC,EAAM3C,GAChDne,EAAI4B,OAAO8e,GACnBM,cAAcR,GAG3B,IAAKzqB,EAAE,EAAGA,EAAEiK,EAAI4B,OAAOjM,OAAQI,IAE3B,IADAqL,EAAQpB,EAAI4B,OAAO7L,GACd+I,EAAE,EAAGA,EAAEsC,EAAMjB,YAAYxK,OAAQmJ,IAAK,CACvC,MAAM5I,EAAIkL,EAAMjB,YAAYrB,GAC5B,KAAM5I,aAAasJ,GACf,SAEJ,IAAIyhB,GAA6B,EAC7BjhB,EAAIoX,iBAAiBlhB,EAAEsD,OAAOiI,WAAWse,kBACpB,IAAjB7pB,EAAEgV,aACF+V,EAA4B/qB,EAAEsD,OAAOiI,WAI7C+e,EAAQ,IAAIpE,EAAkBlmB,EAAE8L,YAAaif,GAC7CjhB,EAAIqX,gBAAgBnhB,EAAEsD,OAAOiI,WAAWuf,cAAcR,GAI9D,IAAKzqB,EAAE,EAAGA,EAAEiK,EAAI4B,OAAOjM,OAAQI,IAAK,CAEhC,GADAqL,EAAQpB,EAAI4B,OAAO7L,GACfqL,aAAiBga,EAAiB,CAElC,GAAuB,OAAnBha,EAAMwe,SACN,KAAM,eAIV,GAAmC,OAA9Bxe,EAAMwe,SAASsB,WAChB,KAAM,eAEV9f,EAAMwe,SAASsB,WAAa9f,EAEhC,GAAIA,aAAiBqa,EACjB,IAAK3c,EAAE,EAAGA,EAAEsC,EAAMjB,YAAYxK,OAAQmJ,IAClCtF,EAAS4H,EAAMjB,YAAYrB,GAAGtF,OAC1BA,aAAkBoiB,IAClBpiB,EAAOmmB,cAAgBve,QAG5B,GAAIA,aAAiBsa,EACxB,IAAK5c,EAAE,EAAGA,EAAEsC,EAAMjB,YAAYxK,OAAQmJ,IAClCtF,EAAS4H,EAAMjB,YAAYrB,GAAGtF,OAC1BA,aAAkBmiB,IAClBniB,EAAOmmB,cAAgBve,IAO3Csd,cAAc1e,GACV,MAAMmhB,EAAatsB,KAAKwpB,UACxB,IAAK,IAAItoB,EAAE,EAAGA,EAAEorB,EAAYprB,IAAK,CAC7B,MAAMuC,EAAIzD,KAAKwpB,UACT+C,EAAWphB,EAAI4B,OAAOtJ,GAC5B0H,EAAImX,gBAAgB9gB,KAAK+qB,GACzBA,EAASvU,SAAW9W,GAI5B4oB,iBAAiB3e,GACb,GAAIA,EAAIkX,cAAgB+D,EAAQgF,MAAO,CACnC,MAAM/f,EAAQrL,KAAKwpB,UACnBre,EAAIwX,aAAe0F,EAAUhd,EAAO,MACpC,IAAK,IAAInK,EAAE,EAAGA,EAAEmK,EAAOnK,IAAK,CACxB,MAAMsrB,EAAaxsB,KAAKwpB,UACxB,IAAIiD,EAAQzsB,KAAKwpB,UACH,QAAViD,IACAA,GAAS,GAEb,IAAIC,EAAQ1sB,KAAKwpB,UACH,QAAVkD,IACAA,GAAS,GAGbvhB,EAAIwX,aAAazhB,GAAKlB,KAAK2sB,mBAAmBH,EAAYC,EAAOC,KAK7ElY,8BAA8BrJ,GAC1B,IAAIjK,EACJ,MAAMmK,EAAQF,EAAIoX,iBAAiBzhB,OACnC,IAAII,EAAE,EAAGA,EAAEmK,EAAOnK,IACdiK,EAAIuX,gBAAgBxhB,GAAKiK,EAAIoC,aAAerM,EAAI,EAEpD,IAAIA,EAAE,EAAGA,EAAEmK,EAAOnK,IACdlB,KAAK4sB,6BAA6BzhB,EAAKjK,GAI/C0rB,6BAA6BzhB,EAAKqI,GAC9B,IAAItS,EAAGqL,EACP,MAAMsgB,EAAc,IAAI5F,EACxB4F,EAAYjgB,UAAY4G,EACxBrI,EAAI6X,SAAS6J,GAEb,MAAMC,EAAa,IAAItG,EACvBsG,EAAWlgB,UAAY4G,EACvBrI,EAAI6X,SAAS8J,GAEbD,EAAY9B,SAAW+B,EACvB3hB,EAAI+X,oBAAoB2J,GAExBC,EAAWT,WAAaQ,EAExB,IAAIE,EAAoB,KACpBhC,EAAW,KAEf,GAAI5f,EAAIoX,iBAAiB/O,GAAK0X,iBAAkB,CAG5C,IADAH,EAAW,KACP7pB,EAAE,EAAGA,EAAEiK,EAAI4B,OAAOjM,OAAQI,IAE1B,GADAqL,EAAQpB,EAAI4B,OAAO7L,GACflB,KAAKgtB,mBAAmBzgB,EAAOiH,GAAM,CACrCuX,EAAWxe,EACXwgB,EAAoBxgB,EAAMue,cAAcxf,YAAY,GACpD,MAGR,GAA0B,OAAtByhB,EACA,KAAM,4EAGVhC,EAAW5f,EAAIqX,gBAAgBhP,GAKnC,IAAItS,EAAE,EAAGA,EAAEiK,EAAI4B,OAAOjM,OAAQI,IAAK,CAC/BqL,EAAQpB,EAAI4B,OAAO7L,GACnB,IAAI,IAAI+I,EAAE,EAAGA,EAAEsC,EAAMjB,YAAYxK,OAAQmJ,IAAK,CAC1C,MAAM2B,EAAaW,EAAMjB,YAAYrB,GACjC2B,IAAemhB,GAGfnhB,EAAWjH,SAAWomB,IACtBnf,EAAWjH,OAASmoB,IAOhC,MAAMvK,EAAmBpX,EAAIoX,iBAAiB/O,GACxCnI,EAAQkX,EAAiBjX,YAAYxK,OAC3C,KAAQuK,EAAQ,GACZwhB,EAAYV,cAAc5J,EAAiBjX,YAAYD,EAAM,IAC7DkX,EAAiBjX,YAAciX,EAAiBjX,YAAY9D,OAAO,GAGvE2D,EAAIoX,iBAAiB/O,GAAK2Y,cAAc,IAAI5E,EAAkBsF,IAC9DC,EAAWX,cAAc,IAAI5E,EAAkBwD,IAE/C,MAAMkC,EAAa,IAAI3G,EACvBnb,EAAI6X,SAASiK,GACbA,EAAWd,cAAc,IAAIhF,EAAe2F,EAAY3hB,EAAIuX,gBAAgBlP,KAC5EqZ,EAAYV,cAAc,IAAI5E,EAAkB0F,IAGpDD,mBAAmBzgB,EAAOiH,GACtB,GAAKjH,EAAMK,YAAc4G,EACrB,OAAO,KAEX,KAAOjH,aAAiBua,GACpB,OAAO,KAEX,MAAMoG,EAAoB3gB,EAAMjB,YAAYiB,EAAMjB,YAAYxK,OAAS,GAAG6D,OAC1E,OAAOuoB,aAA6BzG,GAGhCyG,EAAkBC,wBACjBD,EAAkB5hB,YAAY,GAAG3G,kBAAkB+F,EAC7C6B,EAJA,KAgBfwd,wBAAwB5e,GACpB,IAAI,IAAIjK,EAAE,EAAGA,EAAEiK,EAAI4B,OAAOjM,OAAQI,IAAK,CACnC,MAAMqL,EAAQpB,EAAI4B,OAAO7L,GACzB,GAAOqL,aAAiBua,GAMnB3b,EAAIoX,iBAAiBhW,EAAMK,WAAWse,iBAAkB,CACzD,MAAMgC,EAAoB3gB,EAAMjB,YAAYiB,EAAMjB,YAAYxK,OAAS,GAAG6D,OACtEuoB,aAA6BzG,GACxByG,EAAkBC,wBACdD,EAAkB5hB,YAAY,GAAG3G,kBAAkB+F,IACxD6B,EAAM6gB,sBAAuB,KAOjDlH,UAAU/a,GACN,GAAKnL,KAAKuU,uBAAuB2R,UAIjC,IAAI,IAAIhlB,EAAE,EAAGA,EAAEiK,EAAI4B,OAAOjM,OAAQI,IAAK,CACnC,MAAMqL,EAAQpB,EAAI4B,OAAO7L,GACzB,GAAc,OAAVqL,EAIJ,GADAvM,KAAKqtB,eAAe9gB,EAAM4gB,wBAA0B5gB,EAAMjB,YAAYxK,QAAU,GAC5EyL,aAAiBwa,EACjB/mB,KAAKqtB,eAAuC,OAAxB9gB,EAAMue,oBACtB,GAAIve,aAAiBua,EAGzB,GAFA9mB,KAAKqtB,eAAuC,OAAxB9gB,EAAMue,eAC1B9qB,KAAKqtB,eAA4C,IAA7B9gB,EAAMjB,YAAYxK,QAClCyL,EAAMjB,YAAY,GAAG3G,kBAAkBqiB,EACvChnB,KAAKqtB,eAAe9gB,EAAMjB,YAAY,GAAG3G,kBAAkB8hB,GAC3DzmB,KAAKqtB,gBAAgB9gB,EAAMiY,eACxB,MAAIjY,EAAMjB,YAAY,GAAG3G,kBAAkB8hB,GAI9C,KAAK,eAHLzmB,KAAKqtB,eAAe9gB,EAAMjB,YAAY,GAAG3G,kBAAkBqiB,GAC3DhnB,KAAKqtB,eAAe9gB,EAAMiY,gBAIvBjY,aAAiBsa,GACxB7mB,KAAKqtB,eAA4C,IAA7B9gB,EAAMjB,YAAYxK,QACtCd,KAAKqtB,eAAe9gB,EAAMjB,YAAY,GAAG3G,kBAAkBmiB,IACpDva,aAAiBka,EACxBzmB,KAAKqtB,eAAuC,OAAxB9gB,EAAMue,eACnBve,aAAiBma,EACxB1mB,KAAKqtB,eAAmC,OAApB9gB,EAAMP,WACnBO,aAAiBga,EACxBvmB,KAAKqtB,eAAkC,OAAnB9gB,EAAMwe,UACnBxe,aAAiBia,EACxBxmB,KAAKqtB,eAAoC,OAArB9gB,EAAM8f,YACnB9f,aAAiB+W,EACxBtjB,KAAKqtB,eAAe9gB,EAAMjB,YAAYxK,QAAU,GAAKyL,EAAMyL,UAAY,GAEvEhY,KAAKqtB,eAAe9gB,EAAMjB,YAAYxK,QAAU,GAAMyL,aAAiB7B,IAKnF2iB,eAAeC,EAAWC,GACtB,IAAKD,EAID,MAHIC,MAAAA,IACAA,EAAU,gBAER,EAId/D,UACI,OAAOxpB,KAAKuF,KAAKvF,KAAKmH,OAG1BwiB,YAGI,OAFY3pB,KAAKwpB,UACJxpB,KAAKwpB,WACI,GAG1BgE,WAGI,OAAc,WAFFxtB,KAAK2pB,YACJ3pB,KAAK2pB,aAC2B,GAGjDS,WACI,MAAMqD,EAAK,GACX,IAAI,IAAIvsB,EAAE,EAAEA,GAAG,EAAEA,IAAK,CAClB,MAAMwsB,EAAM1tB,KAAKwpB,UAEjBiE,EAAI,EAAEvsB,EAAG,GAAW,IAANwsB,EACdD,EAAG,EAAEvsB,GAAMwsB,GAAO,EAAK,IAE3B,OAAOnF,EAAUkF,EAAG,IAAMlF,EAAUkF,EAAG,IACvClF,EAAUkF,EAAG,IAAMlF,EAAUkF,EAAG,IAAM,IACtClF,EAAUkF,EAAG,IAAMlF,EAAUkF,EAAG,IAAM,IACtClF,EAAUkF,EAAG,IAAMlF,EAAUkF,EAAG,IAAM,IACtClF,EAAUkF,EAAG,IAAMlF,EAAUkF,EAAG,IAAM,IACtClF,EAAUkF,EAAG,KAAOlF,EAAUkF,EAAG,KACjClF,EAAUkF,EAAG,KAAOlF,EAAUkF,EAAG,KACjClF,EAAUkF,EAAG,KAAOlF,EAAUkF,EAAG,KAGrCvB,YAAY/gB,EAAK1J,EAAMoqB,EAAKC,EAAKC,EAAMC,EAAMC,EAAM3C,GAC/C,MAAM3kB,EAASwG,EAAI4B,OAAO+e,GAC1B,OAAOrqB,GACP,KAAKylB,EAAW/c,QACZ,OAAO,IAAIod,EAAkB5iB,GACjC,KAAKuiB,EAAWyG,MACZ,OAAoB,IAAItG,EAAgB1iB,EAAxB,IAATsnB,EAAyCzsB,EAAMwB,IAAyC+qB,EAApCC,GAC/D,KAAK9E,EAAW0G,KACZ,OAAO,IAAIjjB,EAAeQ,EAAI4B,OAAOgf,GAAOC,EAAMC,EAAMtnB,GAC5D,KAAKuiB,EAAW2G,UACZ,OAAO,IAAIrG,EAAoB7iB,EAAQonB,EAAMC,EAAe,IAATC,GACvD,KAAK/E,EAAW4G,WACZ,OAAO,IAAIrG,EAA8B9iB,EAAQonB,GACrD,KAAK7E,EAAW6G,KACZ,OAAoB,IAAI5G,EAAexiB,EAAvB,IAATsnB,EAAwCzsB,EAAMwB,IAAkC+qB,GAC3F,KAAK7E,EAAW8G,OACZ,OAAO,IAAI1G,EAAiB3iB,EAAQonB,EAAMC,EAAe,IAATC,GACpD,KAAK/E,EAAW+G,IACZ,OAAO,IAAI7G,EAAcziB,EAAQ2kB,EAAKyC,IAC1C,KAAK7E,EAAWgH,QACZ,OAAO,IAAItjB,EAAiBjG,EAAQ2kB,EAAKyC,IAC7C,KAAK7E,EAAWiH,SACZ,OAAO,IAAItjB,EAAmBlG,GAClC,QACI,KAAM,kCAAoClD,EAAO,kBAIzDipB,aAAajpB,EAAMmL,GACf,GAA4B,OAAxB5M,KAAK2oB,eAAyB,CAC9B,MAAMyF,EAAK,GACXA,EAAG/H,EAASpe,cAAgB,KAC5BmmB,EAAG/H,EAASgI,OAAS,IAAM,IAAI/H,EAC/B8H,EAAG/H,EAASiI,YAAc,IAAM,IAAI5H,EACpC0H,EAAG/H,EAASkI,aAAe,IAAM,IAAItH,EACrCmH,EAAG/H,EAASmI,kBAAoB,IAAM,IAAIzH,EAC1CqH,EAAG/H,EAASoI,kBAAoB,IAAM,IAAIzH,EAC1CoH,EAAG/H,EAASqI,aAAe,IAAM,IAAI/H,EACrCyH,EAAG/H,EAASsI,WAAa,IAAM,IAAIjkB,EACnC0jB,EAAG/H,EAASuI,WAAa,IAAM,IAAIpI,EACnC4H,EAAG/H,EAASwI,gBAAkB,IAAM,IAAIhI,EACxCuH,EAAG/H,EAASyI,iBAAmB,IAAM,IAAIhI,EACzCsH,EAAG/H,EAAS0I,gBAAkB,IAAM,IAAInI,EACxCwH,EAAG/H,EAASsE,UAAY,IAAM,IAAIlE,EAClCzmB,KAAK2oB,eAAiByF,EAE1B,GAAI3sB,EAAKzB,KAAK2oB,eAAe7nB,QAAwC,OAA9Bd,KAAK2oB,eAAelnB,GACvD,KAAM,4BAA8BA,EAAO,iBACxC,CACH,MAAMgC,EAAIzD,KAAK2oB,eAAelnB,KAC9B,GAAQ,OAAJgC,EAEA,OADAA,EAAEmJ,UAAYA,EACPnJ,GAKnBkpB,mBAAmBlrB,EAAMgrB,EAAOC,GAC5B,GAA6B,OAAzB1sB,KAAK4oB,gBAA0B,CAC/B,MAAMoG,EAAK,GACXA,EAAGtH,EAAgBuH,SAAW,CAACxC,EAAOC,IAAU,IAAI9E,EAAmB6E,GACvEuC,EAAGtH,EAAgBwH,QAAU,CAACzC,EAAOC,IAAU,IAAI7E,EAAkB4E,EAAOC,GAC5EsC,EAAGtH,EAAgByH,MAAQ,CAAC1C,EAAOC,IAAU,IAAIxE,EAAgBuE,GACjEuC,EAAGtH,EAAgBlY,MAAQ,CAACid,EAAOC,IAAU5E,EAAgB7K,SAC7D+R,EAAGtH,EAAgB0H,UAAY,CAAC3C,EAAOC,IAAUzE,EAAmBhL,SACpE+R,EAAGtH,EAAgB2H,WAAa,CAAC5C,EAAOC,IAAU,IAAI1E,EAAoByE,GAC1EuC,EAAGtH,EAAgBzY,MAAQ,CAACwd,EAAOC,IAAU/E,EAAgB1K,SAC7D+R,EAAGtH,EAAgB4H,MAAQ,CAAC7C,EAAOC,IAAU,IAAI3E,EAAgB0E,GACjEzsB,KAAK4oB,gBAAkBoG,EAE3B,GAAIvtB,EAAKzB,KAAK4oB,gBAAgB9nB,QAAyC,OAA/Bd,KAAK4oB,gBAAgBnnB,GACzD,KAAM,mCAAqCA,EAAO,iBAElD,OAAOzB,KAAK4oB,gBAAgBnnB,GAAMgrB,EAAOC,oBCrpBrD,MAAM,SAAC6C,GAAY,EAAQ,MACrB,aAAC3K,GAAgB,EAAQ,KACzB,2BAACnI,GAA8B,EAAQ,MACvC,IAAChD,GAAO,EAAQ,KAEtB,MAAM+V,EACF3vB,YAAYsL,EAAKskB,GAwBb,OAFAzvB,KAAKmL,IAAMA,EACXnL,KAAKyvB,mBAAqBA,EACnBzvB,KAGX0lB,iBAAiBlZ,GACb,GAA+B,OAA3BxM,KAAKyvB,mBACL,OAAOjjB,EAEX,MAAMmQ,EAAU,IAAIlD,EACpB,OAAOgD,EAA2BjQ,EAASxM,KAAKyvB,mBAAoB9S,IAK5E6S,EAAaE,MAAQ,IAAIH,EAAS,WAAY,IAAI3K,GAGlDjlB,EAAOC,QAAU4vB,WCgBjB,MAAMnJ,EACFxmB,cAEIG,KAAKmL,IAAM,KACXnL,KAAKoN,YAAciZ,EAASsJ,qBAC5B3vB,KAAK4vB,UAAY,KACjB5vB,KAAK4M,UAAY,EACjB5M,KAAKmtB,wBAAyB,EAE9BntB,KAAKsL,YAAc,GAEnBtL,KAAK+iB,oBAAsB,KAG/B9d,WACI,OAAOjF,KAAKoN,YAGhBiN,OAAOxR,GACH,OAAIA,aAAiBwd,GACVrmB,KAAKoN,cAAcvE,EAAMuE,YAMxCyiB,uBACI,OAAO,EAGX1D,cAAcR,EAAOzrB,QACN4B,IAAR5B,IACCA,GAAS,GAEiB,IAA1BF,KAAKsL,YAAYxK,OACjBd,KAAKmtB,uBAAyBxB,EAAMte,UAC9BrN,KAAKmtB,yBAA2BxB,EAAMte,YAC5CrN,KAAKmtB,wBAAyB,IAErB,IAATjtB,EACAF,KAAKsL,YAAY9J,KAAKmqB,GAEtB3rB,KAAKsL,YAAY7C,OAAOvI,EAAO,EAAGyrB,IAM9CtF,EAASpe,aAAe,EACxBoe,EAASgI,MAAQ,EACjBhI,EAASiI,WAAa,EACtBjI,EAASkI,YAAc,EACvBlI,EAASmI,iBAAmB,EAC5BnI,EAASoI,iBAAmB,EAC5BpI,EAASqI,YAAc,EACvBrI,EAASsI,UAAY,EACrBtI,EAASuI,UAAY,EACrBvI,EAASwI,eAAiB,EAC1BxI,EAASyI,gBAAkB,GAC3BzI,EAAS0I,eAAiB,GAC1B1I,EAASsE,SAAW,GAEpBtE,EAASyJ,mBAAqB,CAClB,UACA,QACA,aACA,cACA,mBACA,mBACA,cACA,YACA,YACA,iBACA,kBACA,iBACA,YAEZzJ,EAASsJ,sBAAwB,EAUjC,MAAMrM,UAAsB+C,EACxBxmB,cAII,OAHAE,QACAC,KAAKgY,UAAY,EACjBhY,KAAKwkB,WAAY,EACVxkB,MAOf,MAAMumB,UAAwBjD,EAC1BzjB,cAGI,OAFAE,QACAC,KAAK+qB,SAAW,KACT/qB,MAgIfL,EAAOC,QAAU,CACbymB,SAAAA,EACAC,WAzJJ,cAAyBD,EACrBxmB,cACIE,QACAC,KAAK4vB,UAAYvJ,EAASgI,QAuJ9B/K,cAAAA,EACAiD,gBAAAA,EACAC,cAtHJ,cAA4BH,EACxBxmB,cAII,OAHAE,QACAC,KAAK4vB,UAAYvJ,EAASuI,UAC1B5uB,KAAKqsB,WAAa,KACXrsB,OAkHXymB,aA1BJ,cAA2BJ,EACvBxmB,cAII,OAHAE,QACAC,KAAK4vB,UAAYvJ,EAASsE,SAC1B3qB,KAAK8qB,cAAgB,KACd9qB,OAsBX0mB,eAjGJ,cAA6BL,EACzBxmB,cAKI,OAJAE,QACAC,KAAK4vB,UAAYvJ,EAASiI,WAC1BtuB,KAAKgM,UAAY,KACjBhM,KAAKkrB,kBAAmB,EACjBlrB,OA4FX0K,cA1GJ,cAA4B2b,EACxBxmB,cAGI,OAFAE,QACAC,KAAK4vB,UAAYvJ,EAASsI,UACnB3uB,OAuGX2mB,iBAjBJ,cAA+BrD,EAC3BzjB,cAGI,OAFAE,QACAC,KAAK4vB,UAAYvJ,EAASqI,YACnB1uB,OAcX4mB,kBAtFJ,cAAgCtD,EAC5BzjB,cAGI,OAFAE,QACAC,KAAK4vB,UAAYvJ,EAAS0I,eACnB/uB,OAmFX6mB,kBArDJ,cAAgCR,EAC5BxmB,cAGI,OAFAE,QACAC,KAAK4vB,UAAYvJ,EAASwI,eACnB7uB,OAkDX8mB,mBA9CJ,cAAiCxD,EAC7BzjB,cAMI,OALAE,QACAC,KAAK4vB,UAAYvJ,EAASyI,gBAC1B9uB,KAAK8qB,cAAgB,KAErB9qB,KAAKotB,qBAAuB,KACrBptB,OAwCX+mB,oBA3EJ,cAAkCR,EAC9B1mB,cAII,OAHAE,QACAC,KAAK4vB,UAAYvJ,EAASmI,iBAC1BxuB,KAAK8qB,cAAgB,KACd9qB,OAuEXgnB,oBAhEJ,cAAkCT,EAC9B1mB,cAGI,OAFAE,QACAC,KAAK4vB,UAAYvJ,EAASoI,iBACnBzuB,OA6DXinB,qBA3IJ,cAAmCV,EAC/B1mB,cAGI,OAFAE,QACAC,KAAK4vB,UAAYvJ,EAASkI,YACnBvuB,iBC1KfL,EAAOC,QAAU,CACbwrB,MAAO,EACPpB,OAAQ,kBCLZ,MAAM,MAACxqB,GAAS,EAAQ,KAClBC,EAAQ,EAAQ,KAChB2iB,EAAM,EAAQ,KACdoN,EAAe,EAAQ,MACvB,SAACD,GAAY,EAAQ,MACrB,oBAACtJ,GAAuB,EAAQ,KAChC,kBAACjb,GAAqB,EAAQ,MAC9B,2BAACC,GAA8B,EAAQ,MACvC,cAACP,GAAiB,EAAQ,MAC1B,eAAC0Z,GAAkB,EAAQ,MAC3B,WAAC8C,GAAc,EAAQ,IACvB6I,EAAsB,EAAQ,MAC9B,0BAACniB,GAA6B,EAAQ,KAE5C,SAASoiB,EAAcC,GACtBA,EAAI/vB,OAAS,EACb+vB,EAAIlqB,KAAO,EACXkqB,EAAIjqB,QAAU,EACdiqB,EAAIC,SAAW,KAGhB,MAAMC,EACLtwB,cACCmwB,EAAchwB,MAGfO,QACCyvB,EAAchwB,OAIhB,MAAMowB,UAA0BZ,EAiB/B3vB,YAAYqf,EAAO/T,EAAKuM,EAAe+X,GACtC1vB,MAAMoL,EAAKskB,GACXzvB,KAAK0X,cAAgBA,EACrB1X,KAAKkf,MAAQA,EAOblf,KAAKqwB,YAAc,EAEnBrwB,KAAK+F,KAAO,EAKZ/F,KAAKgG,OAAS,EACdhG,KAAK4P,KAAOnQ,EAAMkP,aAKlB3O,KAAKswB,WAAa,IAAIH,EAGvBI,UAAUC,GACTxwB,KAAKgG,OAASwqB,EAAUxqB,OACxBhG,KAAK+F,KAAOyqB,EAAUzqB,KACtB/F,KAAK4P,KAAO4gB,EAAU5gB,KACtB5P,KAAKqwB,WAAaG,EAAUH,WAG7BnhB,MAAMrB,EAAO+B,GACZ5P,KAAKywB,aAAe,EACpBzwB,KAAK4P,KAAOA,EACZ,MAAMxP,EAAOyN,EAAMzN,OACnB,IACCJ,KAAKqwB,WAAaxiB,EAAM3N,MACxBF,KAAKswB,WAAW/vB,QAChB,MAAMsX,EAAM7X,KAAK0X,cAAc9H,GAC/B,OAAe,OAAXiI,EAAI6Y,GACA1wB,KAAK2wB,SAAS9iB,GAEd7N,KAAK4wB,QAAQ/iB,EAAOgK,EAAI6Y,IAE/B,QACD7iB,EAAMxN,QAAQD,IAIhBG,QACCP,KAAKswB,WAAW/vB,QAChBP,KAAKqwB,YAAc,EACnBrwB,KAAK+F,KAAO,EACZ/F,KAAKgG,OAAS,EACdhG,KAAK4P,KAAOnQ,EAAMkP,aAGnBgiB,SAAS9iB,GACR,MAAMwe,EAAarsB,KAAKmL,IAAIyX,iBAAiB5iB,KAAK4P,MAE9CwgB,EAAkBrgB,OACrBZ,QAAQC,IAAI,iBAAmBpP,KAAK4P,KAAO,WAAayc,GAEzD,MAAMwE,EAAW7wB,KAAK4P,KAChBkhB,EAAa9wB,KAAK+wB,kBAAkBljB,EAAOwe,GAC3C2E,EAAeF,EAAW5L,mBAChC4L,EAAW5L,oBAAqB,EAEhC,MAAMlc,EAAOhJ,KAAKixB,YAAYH,GACzBE,IACJhxB,KAAK0X,cAAc1X,KAAK4P,MAAM8gB,GAAK1nB,GAGpC,MAAMkoB,EAAUlxB,KAAK4wB,QAAQ/iB,EAAO7E,GAKpC,OAHIonB,EAAkBrgB,OACrBZ,QAAQC,IAAI,uBAAyBpP,KAAK0X,cAAcmZ,GAAUM,iBAE5DD,EAGRN,QAAQ/iB,EAAOujB,GACVhB,EAAkBrgB,OACrBZ,QAAQC,IAAI,uBAAyBgiB,EAAIrM,SAEtCqM,EAAIC,eAEPrxB,KAAKsxB,gBAAgBtxB,KAAKswB,WAAYziB,EAAOujB,GAE9C,IAAI/vB,EAAIwM,EAAM9M,GAAG,GACb0C,EAAI2tB,EAER,OAAa,CACRhB,EAAkBrgB,OACrBZ,QAAQC,IAAI,kCAAoC3L,EAAEshB,SAuBnD,IAAIpgB,EAAS3E,KAAKuxB,uBAAuB9tB,EAAGpC,GAM5C,GAJe,OAAXsD,IACHA,EAAS3E,KAAKwxB,mBAAmB3jB,EAAOpK,EAAGpC,IAGxCsD,IAAW6qB,EAAaE,MAC3B,MASD,GAHIruB,IAAM7B,EAAMwB,KACfhB,KAAKY,QAAQiN,GAEVlJ,EAAO0sB,gBACVrxB,KAAKsxB,gBAAgBtxB,KAAKswB,WAAYziB,EAAOlJ,GACzCtD,IAAM7B,EAAMwB,KACf,MAGFK,EAAIwM,EAAM9M,GAAG,GACb0C,EAAIkB,EAEL,OAAO3E,KAAKyxB,aAAazxB,KAAKswB,WAAYziB,EAAOpK,EAAEshB,QAAS1jB,GAc7DkwB,uBAAuB9tB,EAAGpC,GACzB,GAAgB,OAAZoC,EAAEiuB,OAAkBrwB,EAAI+uB,EAAkBuB,cAAgBtwB,EAAI+uB,EAAkBwB,aACnF,OAAO,KAGR,IAAIjtB,EAASlB,EAAEiuB,MAAMrwB,EAAI+uB,EAAkBuB,cAO3C,YANY7vB,IAAT6C,IACFA,EAAS,MAENyrB,EAAkBrgB,OAAoB,OAAXpL,GAC9BwK,QAAQC,IAAI,eAAiB3L,EAAE2J,YAAc,YAAczI,EAAOyI,aAE5DzI,EAeR6sB,mBAAmB3jB,EAAOpK,EAAGpC,GAC5B,MAAMwwB,EAAQ,IAAI5L,EAKlB,OAFAjmB,KAAK8xB,sBAAsBjkB,EAAOpK,EAAEshB,QAAS8M,EAAOxwB,GAEzB,IAAvBwwB,EAAM7L,MAAMllB,QACV+wB,EAAM3M,oBAGVllB,KAAK+xB,WAAWtuB,EAAGpC,EAAGmuB,EAAaE,OAG7BF,EAAaE,OAGd1vB,KAAK+xB,WAAWtuB,EAAGpC,EAAG,KAAMwwB,GAGpCJ,aAAanB,EAAYziB,EAAOgkB,EAAOxwB,GACtC,GAAiC,OAA7BrB,KAAKswB,WAAWJ,SAAmB,CACtC,MAAM7L,EAAsBiM,EAAWJ,SAAS7L,oBAGhD,OAFArkB,KAAK8e,OAAOjR,EAAOwW,EAAqBrkB,KAAKqwB,WAC3CC,EAAWpwB,MAAOowB,EAAWvqB,KAAMuqB,EAAWtqB,QACzCsqB,EAAWJ,SAAS8B,WAG3B,GAAI3wB,IAAM7B,EAAMwB,KAAO6M,EAAM3N,QAAUF,KAAKqwB,WAC3C,OAAO7wB,EAAMwB,IAEd,MAAM,IAAI4M,EAA0B5N,KAAKkf,MAAOrR,EAAO7N,KAAKqwB,WAAYwB,GAS1EC,sBAAsBjkB,EAAOokB,EAC3BJ,EAAOxwB,GAGR,IAAI6wB,EAAU9P,EAAIiB,mBAClB,IAAK,IAAIniB,EAAI,EAAGA,EAAI+wB,EAAQjM,MAAMllB,OAAQI,IAAK,CAC9C,MAAMixB,EAAMF,EAAQjM,MAAM9kB,GACpBkxB,EAAgCD,EAAI3mB,MAAQ0mB,EAClD,IAAIE,IAAgCD,EAAI7N,+BAAxC,CAGI8L,EAAkBrgB,OACrBZ,QAAQC,IAAI,qBAAsBpP,KAAKqyB,aAAahxB,GAAI8wB,EACrDltB,SAASjF,KAAKkf,OAAO,IAEzB,IAAK,IAAIjV,EAAI,EAAGA,EAAIkoB,EAAI5lB,MAAMjB,YAAYxK,OAAQmJ,IAAK,CACtD,MAAM0hB,EAAQwG,EAAI5lB,MAAMjB,YAAYrB,GAC9BtF,EAAS3E,KAAKsyB,mBAAmB3G,EAAOtqB,GAC9C,GAAe,OAAXsD,EAAiB,CACpB,IAAI0f,EAAsB8N,EAAI9N,oBACF,OAAxBA,IACHA,EAAsBA,EAAoBkO,qBAAqB1kB,EAAM3N,MAAQF,KAAKqwB,aAEnF,MAAMmC,EAAqBnxB,IAAM7B,EAAMwB,IACjC+iB,EAAS,IAAIK,EAAe,CAAC7X,MAAM5H,EAAQ0f,oBAAoBA,GAAsB8N,GACvFnyB,KAAKiyB,QAAQpkB,EAAOkW,EAAQ8N,EAC9BO,GAA8B,EAAMI,KAGrCN,EAAUC,EAAI3mB,SAOnBsT,OAAOjR,EAAOwW,EACTgM,EAAYnwB,EAAO6F,EAAM0sB,GACtBrC,EAAkBrgB,OACrBZ,QAAQC,IAAI,cAAeiV,GAG5BxW,EAAMrN,KAAKN,GACXF,KAAK+F,KAAOA,EACZ/F,KAAKgG,OAASysB,EACc,OAAxBpO,GAA+C,OAAfrkB,KAAKkf,OACxCmF,EAAoBqO,QAAQ1yB,KAAKkf,MAAOrR,EAAOwiB,GAIpDiC,mBAAmB3G,EAAOtqB,GACzB,OAAIsqB,EAAMgH,QAAQtxB,EAAG,EAAG5B,EAAM4R,gBACtBsa,EAAMhnB,OAEN,KAITosB,kBAAkBljB,EAAO2J,GACxB,MAAMob,EAAiB5nB,EAAkBa,MACnCkZ,EAAU,IAAIkB,EACpB,IAAK,IAAI/kB,EAAI,EAAGA,EAAIsW,EAAElM,YAAYxK,OAAQI,IAAK,CAC9C,MAAMyD,EAAS6S,EAAElM,YAAYpK,GAAGyD,OAC1BwtB,EAAM,IAAI/N,EAAe,CAAC7X,MAAM5H,EAAQ6G,IAAItK,EAAE,EAAGsL,QAAQomB,GAAiB,MAChF5yB,KAAKiyB,QAAQpkB,EAAOskB,EAAKpN,GAAS,GAAO,GAAO,GAEjD,OAAOA,EAaRkN,QAAQpkB,EAAOkW,EAAQgB,EACrBqN,EAA8BS,EAAaL,GAC5C,IAAIL,EAAM,KAIV,GAHI/B,EAAkBrgB,OACrBZ,QAAQC,IAAI,WAAa2U,EAAO9e,SAASjF,KAAKkf,OAAO,GAAQ,KAE1D6E,EAAOxX,iBAAiB7B,EAAe,CAQ1C,GAPI0lB,EAAkBrgB,QACF,OAAf/P,KAAKkf,MACR/P,QAAQC,IAAI,+BAAgCpP,KAAKkf,MAAMnN,UAAUgS,EAAOxX,MAAMK,WAAYmX,GAE1F5U,QAAQC,IAAI,4BAA6B2U,IAGpB,OAAnBA,EAAOvX,SAAoBuX,EAAOvX,QAAQoN,eAAgB,CAC7D,GAAuB,OAAnBmK,EAAOvX,SAAoBuX,EAAOvX,QAAQE,UAE7C,OADAqY,EAAQtY,IAAIsX,IACL,EAEPgB,EAAQtY,IAAI,IAAI2X,EAAe,CAAE7X,MAAMwX,EAAOxX,MAAOC,QAAQxB,EAAkBa,OAAQkY,IACvFqO,GAA+B,EAGjC,GAAuB,OAAnBrO,EAAOvX,UAAqBuX,EAAOvX,QAAQE,UAC9C,IAAK,IAAIxL,EAAI,EAAGA,EAAI6iB,EAAOvX,QAAQ1L,OAAQI,IAC1C,GAAI6iB,EAAOvX,QAAQQ,eAAe9L,KAAO8J,EAAkB6O,mBAAoB,CAC9E,MAAM3M,EAAa6W,EAAOvX,QAAQS,UAAU/L,GACtC4L,EAAc9M,KAAKmL,IAAI4B,OAAOgX,EAAOvX,QAAQQ,eAAe9L,IAClEixB,EAAM,IAAI/N,EAAe,CAAE7X,MAAMO,EAAaN,QAAQU,GAAc6W,GACpEqO,EAA+BpyB,KAAKiyB,QAAQpkB,EAAOskB,EACjDpN,EAASqN,EAA8BS,EACvCL,GAIL,OAAOJ,EAGHrO,EAAOxX,MAAM4gB,wBACZiF,GAAiCrO,EAAOO,gCAC5CS,EAAQtY,IAAIsX,GAGd,IAAK,IAAI9Z,EAAI,EAAGA,EAAI8Z,EAAOxX,MAAMjB,YAAYxK,OAAQmJ,IAAK,CACzD,MAAM0hB,EAAQ5H,EAAOxX,MAAMjB,YAAYrB,GACvCkoB,EAAMnyB,KAAK8yB,iBAAiBjlB,EAAOkW,EAAQ4H,EAAO5G,EAAS8N,EAAaL,GAC5D,OAARL,IACHC,EAA+BpyB,KAAKiyB,QAAQpkB,EAAOskB,EAAKpN,EACtDqN,EAA8BS,EAAaL,IAG/C,OAAOJ,EAIRU,iBAAiBjlB,EAAOkW,EAAQ4H,EAC9B5G,EAAS8N,EAAaL,GACvB,IAAIL,EAAM,KACV,GAAIxG,EAAMoH,oBAAsB7L,EAAW0G,KAAM,CAChD,MAAM1gB,EAAajC,EAA2BpF,OAAOke,EAAOvX,QAASmf,EAAMxe,YAAYC,aACvF+kB,EAAM,IAAI/N,EAAgB,CAAE7X,MAAMof,EAAMhnB,OAAQ6H,QAAQU,GAAa6W,OAC/D,IAAI4H,EAAMoH,oBAAsB7L,EAAW4G,WACjD,KAAM,qDACA,GAAInC,EAAMoH,oBAAsB7L,EAAW2G,UAmB7CuC,EAAkBrgB,OACrBZ,QAAQC,IAAI,aAAeuc,EAAM/e,UAAY,IAAM+e,EAAMqH,WAE1DjO,EAAQG,oBAAqB,EACzBllB,KAAKizB,kBAAkBplB,EAAO8d,EAAM/e,UAAW+e,EAAMqH,UAAWH,KACnEV,EAAM,IAAI/N,EAAe,CAAE7X,MAAMof,EAAMhnB,QAASof,SAE3C,GAAI4H,EAAMoH,oBAAsB7L,EAAW8G,OACjD,GAAuB,OAAnBjK,EAAOvX,SAAoBuX,EAAOvX,QAAQoN,eAAgB,CAa7D,MAAMyK,EAAsB0L,EAAoBmD,OAAOnP,EAAOM,oBAC5DrkB,KAAKmL,IAAIwX,aAAagJ,EAAMrN,cAC9B6T,EAAM,IAAI/N,EAAe,CAAE7X,MAAMof,EAAMhnB,OAAQ0f,oBAAoBA,GAAuBN,QAG1FoO,EAAM,IAAI/N,EAAgB,CAAE7X,MAAMof,EAAMhnB,QAASof,QAExC4H,EAAMoH,oBAAsB7L,EAAW/c,QACjDgoB,EAAM,IAAI/N,EAAe,CAAE7X,MAAMof,EAAMhnB,QAASof,GACtC4H,EAAMoH,oBAAsB7L,EAAW6G,MAC/CpC,EAAMoH,oBAAsB7L,EAAWyG,OACvChC,EAAMoH,oBAAsB7L,EAAW+G,KACrCuE,GACC7G,EAAMgH,QAAQnzB,EAAMwB,IAAK,EAAGvB,EAAM4R,kBACrC8gB,EAAM,IAAI/N,EAAgB,CAAE7X,MAAMof,EAAMhnB,QAAUof,IAIrD,OAAOoO,EAwBRc,kBAAkBplB,EAAOjB,EACvBomB,EAAWH,GAEZ,GAAmB,OAAf7yB,KAAKkf,MACR,OAAO,EAER,IAAK2T,EACJ,OAAO7yB,KAAKkf,MAAMb,QAAQ,KAAMzR,EAAWomB,GAE5C,MAAMG,EAAcnzB,KAAKgG,OACnBotB,EAAYpzB,KAAK+F,KACjB7F,EAAQ2N,EAAM3N,MACdI,EAASuN,EAAMzN,OACrB,IAEC,OADAJ,KAAKY,QAAQiN,GACN7N,KAAKkf,MAAMb,QAAQ,KAAMzR,EAAWomB,GAC1C,QACDhzB,KAAKgG,OAASmtB,EACdnzB,KAAK+F,KAAOqtB,EACZvlB,EAAMrN,KAAKN,GACX2N,EAAMxN,QAAQC,IAIhBgxB,gBAAgB+B,EAAUxlB,EAAOqiB,GAChCmD,EAASnzB,MAAQ2N,EAAM3N,MACvBmzB,EAASttB,KAAO/F,KAAK+F,KACrBstB,EAASrtB,OAAShG,KAAKgG,OACvBqtB,EAASnD,SAAWA,EAGrB6B,WAAWlvB,EAAOywB,EAAIxwB,EAAIywB,GAOzB,QANWzxB,IAAPgB,IACHA,EAAK,WAEOhB,IAATyxB,IACHA,EAAO,MAEG,OAAPzwB,GAAwB,OAATywB,EAAe,CAYjC,MAAMvC,EAAeuC,EAAKrO,mBAK1B,GAJAqO,EAAKrO,oBAAqB,EAE1BpiB,EAAK9C,KAAKixB,YAAYsC,GAElBvC,EACH,OAAOluB,EAIT,OAAIwwB,EAAKlD,EAAkBuB,cAAgB2B,EAAKlD,EAAkBwB,eAI9DxB,EAAkBrgB,OACrBZ,QAAQC,IAAI,QAAUvM,EAAQ,OAASC,EAAK,SAAWwwB,GAEpC,OAAhBzwB,EAAM6uB,QAET7uB,EAAM6uB,MAAQ,IAEf7uB,EAAM6uB,MAAM4B,EAAKlD,EAAkBuB,cAAgB7uB,GAT3CA,EAoBTmuB,YAAYlM,GACX,MAAMyO,EAAW,IAAIjE,EAAS,KAAMxK,GACpC,IAAI0O,EAA+B,KACnC,IAAK,IAAIvyB,EAAI,EAAGA,EAAI6jB,EAAQiB,MAAMllB,OAAQI,IAAK,CAC9C,MAAMixB,EAAMpN,EAAQiB,MAAM9kB,GAC1B,GAAIixB,EAAI5lB,iBAAiB7B,EAAe,CACvC+oB,EAA+BtB,EAC/B,OAGmC,OAAjCsB,IACHD,EAASnC,eAAgB,EACzBmC,EAASnP,oBAAsBoP,EAA6BpP,oBAC5DmP,EAASxB,WAAahyB,KAAKmL,IAAIuX,gBAAgB+Q,EAA6BlnB,MAAMK,YAEnF,MAAMiL,EAAM7X,KAAK0X,cAAc1X,KAAK4P,MAC9BpH,EAAWqP,EAAI9K,OAAOpM,IAAI6yB,GAChC,GAAe,OAAXhrB,EACH,OAAOA,EAER,MAAMkrB,EAAWF,EAKjB,OAJAE,EAAStmB,YAAcyK,EAAI9K,OAAOjM,OAClCikB,EAAQgB,aAAY,GACpB2N,EAAS3O,QAAUA,EACnBlN,EAAI9K,OAAON,IAAIinB,GACRA,EAGRC,OAAO/jB,GACN,OAAO5P,KAAK0X,cAAc9H,GAI3BtM,QAAQuK,GAEP,OAAOA,EAAMvK,QAAQtD,KAAKqwB,WAAYxiB,EAAM3N,MAAQ,GAGrDU,QAAQiN,GACSA,EAAM9M,GAAG,KACT,KAAKiG,WAAW,IAC/BhH,KAAK+F,MAAQ,EACb/F,KAAKgG,OAAS,GAEdhG,KAAKgG,QAAU,EAEhB6H,EAAMjN,UAGPyxB,aAAauB,GACZ,OAAY,IAARA,EACI,MAEA,IAAMtsB,OAAOyC,aAAa6pB,GAAM,KAK1CxD,EAAkBrgB,OAAQ,EAC1BqgB,EAAkByD,WAAY,EAE9BzD,EAAkBuB,aAAe,EACjCvB,EAAkBwB,aAAe,IAEjCxB,EAAkBK,YAAc,EAEhC9wB,EAAOC,QAAUwwB,WCpoBjB,MAAM1I,EAAkB,CAEpBuH,QAAS,EAETC,OAAQ,EAERC,KAAM,EAEN3f,KAAM,EAEN4f,SAAU,EAEVC,UAAW,EAEXpgB,KAAM,EAENqgB,KAAM,GAGV,MAAMwE,EACFj0B,YAAYk0B,GACR/zB,KAAKwsB,WAAauH,EAClB/zB,KAAKg0B,qBAAsB,EAG/Bla,WACI,MAAME,EAAO,IAAIR,KAEjB,OADAxZ,KAAK+Z,eAAeC,GACbA,EAAKI,SAGhBL,eAAeC,GACXA,EAAKC,OAAOja,KAAKwsB,YAGrBnS,OAAOxR,GACH,OAAO7I,OAAS6I,GAWxB,MAAM8e,UAAwBmM,EAC1Bj0B,cACIE,MAAM2nB,EAAgBzY,MAG1ByjB,QAAQtsB,GACJA,EAAMsJ,OAGVzK,WACI,MAAO,QAKf0iB,EAAgB1K,SAAW,IAAI0K,EAM/B,MAAMI,UAAwB+L,EAC1Bj0B,YAAY4B,GACR1B,MAAM2nB,EAAgB4H,MACtBtvB,KAAKyB,KAAOA,EAGhBixB,QAAQtsB,GACJA,EAAM3E,KAAOzB,KAAKyB,KAGtBsY,eAAeC,GACXA,EAAKC,OAAOja,KAAKwsB,WAAYxsB,KAAKyB,MAGtC4Y,OAAOxR,GACH,OAAG7I,OAAS6I,GAEEA,aAAiBkf,GAGpB/nB,KAAKyB,OAASoH,EAAMpH,KAInCwD,WACI,MAAO,QAAUjF,KAAKyB,KAAO,KASrC,MAAMumB,UAA4B8L,EAC9Bj0B,YAAY+P,GACR7P,MAAM2nB,EAAgB2H,WACtBrvB,KAAK4P,KAAOA,EAOhB8iB,QAAQtsB,GACJA,EAAM0J,SAAS9P,KAAK4P,MAGxBmK,eAAeC,GACXA,EAAKC,OAAOja,KAAKwsB,WAAYxsB,KAAK4P,MAGtCyK,OAAOxR,GACH,OAAI7I,OAAS6I,GAECA,aAAiBmf,GAGpBhoB,KAAK4P,OAAS/G,EAAM+G,KAInC3K,WACI,MAAO,YAAcjF,KAAK4P,KAAO,KAUzC,MAAMqY,UAA2B6L,EAC7Bj0B,cACIE,MAAM2nB,EAAgB0H,UAM1BsD,QAAQtsB,GACJA,EAAM4J,UAGV/K,WACI,MAAO,WAIfgjB,EAAmBhL,SAAW,IAAIgL,EAQlC,MAAMH,UAAwBgM,EAC1Bj0B,cACIE,MAAM2nB,EAAgBlY,MAM1BkjB,QAAQtsB,GACJA,EAAMuJ,OAGV1K,WACI,MAAO,QAIf6iB,EAAgB7K,SAAW,IAAI6K,EAO/B,MAAMI,UAAwB4L,EAC1Bj0B,YAAY+P,GACR7P,MAAM2nB,EAAgByH,MACtBnvB,KAAK4P,KAAOA,EAOhB8iB,QAAQtsB,GACJA,EAAMwJ,KAAK5P,KAAK4P,MAGpBmK,eAAeC,GACXA,EAAKC,OAAOja,KAAKwsB,WAAYxsB,KAAK4P,MAGtCyK,OAAOxR,GACH,OAAI7I,OAAS6I,GAECA,aAAiBqf,GAGpBloB,KAAK4P,OAAS/G,EAAM+G,KAInC3K,WACI,MAAO,QAAUjF,KAAK4P,KAAO,KAcrC,MAAMiY,UAA0BiM,EAU5Bj0B,YAAY+M,EAAW0R,GACnBve,MAAM2nB,EAAgBwH,QACtBlvB,KAAK4M,UAAYA,EACjB5M,KAAKse,YAAcA,EACnBte,KAAKg0B,qBAAsB,EAO/BtB,QAAQtsB,GACJA,EAAM2tB,OAAO,KAAM/zB,KAAK4M,UAAW5M,KAAKse,aAG5CvE,eAAeC,GACXA,EAAKC,OAAOja,KAAKwsB,WAAYxsB,KAAK4M,UAAW5M,KAAKse,aAGtDjE,OAAOxR,GACH,OAAI7I,OAAS6I,GAECA,aAAiBgf,GAGpB7nB,KAAK4M,YAAc/D,EAAM+D,WAAa5M,KAAKse,cAAgBzV,EAAMyV,aAWpF,MAAMsJ,UAA2BkM,EAC7Bj0B,YAAY0C,GACRxC,MAAM2nB,EAAgBuH,SACtBjvB,KAAKuC,QAAUA,EAOnBmwB,QAAQtsB,GACJA,EAAMmI,SAAWvO,KAAKuC,QAG1BwX,eAAeC,GACXA,EAAKC,OAAOja,KAAKwsB,WAAYxsB,KAAKuC,SAGtC8X,OAAOxR,GACH,OAAI7I,OAAS6I,GAECA,aAAiB+e,GAGpB5nB,KAAKuC,UAAYsG,EAAMtG,QAItC0C,WACI,MAAO,WAAajF,KAAKuC,QAAU,KA2B3C,MAAM0xB,UAAiCH,EACnCj0B,YAAYqH,EAAQ6sB,GAChBh0B,MAAMg0B,EAAOvH,YACbxsB,KAAKkH,OAASA,EACdlH,KAAK+zB,OAASA,EACd/zB,KAAKg0B,qBAAsB,EAO/BtB,QAAQtsB,GAEJpG,KAAK+zB,OAAOrB,QAAQtsB,GAGxB2T,eAAeC,GACXA,EAAKC,OAAOja,KAAKwsB,WAAYxsB,KAAKkH,OAAQlH,KAAK+zB,QAGnD1Z,OAAOxR,GACH,OAAI7I,OAAS6I,GAECA,aAAiBorB,GAGpBj0B,KAAKkH,SAAW2B,EAAM3B,QAAUlH,KAAK+zB,SAAWlrB,EAAMkrB,QAKzEp0B,EAAOC,QAAU,CACb8nB,gBAAAA,EACAC,gBAAAA,EACAC,mBAAAA,EACAC,kBAAAA,EACAoM,yBAAAA,EACAnM,gBAAAA,EACAC,gBAAAA,EACAC,oBAAAA,EACAC,mBAAAA,EACAC,gBAAAA,kBCzXJ,MAAM,UAACrG,GAAa,EAAQ,MACtB,yBAACoS,GAA4B,EAAQ,KAE3C,MAAMlE,EASLlwB,YAAY8iB,GAQX,OAPA3iB,KAAK2iB,aAAgC,OAAjBA,EAAwB,GAAKA,EAKjD3iB,KAAK2Z,eAAiBkI,EAAUc,GAEzB3iB,KAgCRuyB,qBAAqBrrB,GACpB,IAAIgtB,EAAsB,KAC1B,IAAK,IAAIhzB,EAAI,EAAGA,EAAIlB,KAAK2iB,aAAa7hB,OAAQI,KACzClB,KAAK2iB,aAAazhB,GAAG8yB,qBACrBh0B,KAAK2iB,aAAazhB,aAAc+yB,IACP,OAAxBC,IACHA,EAAsBl0B,KAAK2iB,aAAatB,OAAO,KAEhD6S,EAAoBhzB,GAAK,IAAI+yB,EAAyB/sB,EACpDlH,KAAK2iB,aAAazhB,KAGtB,OAA4B,OAAxBgzB,EACIl0B,KAEA,IAAI+vB,EAAoBmE,GAuBjCxB,QAAQtsB,EAAOyH,EAAOwiB,GACrB,IAAI8D,GAAe,EACnB,MAAMC,EAAYvmB,EAAM3N,MACxB,IACC,IAAK,IAAIgB,EAAI,EAAGA,EAAIlB,KAAK2iB,aAAa7hB,OAAQI,IAAK,CAClD,IAAImzB,EAAcr0B,KAAK2iB,aAAazhB,GACpC,GAAImzB,aAAuBJ,EAA0B,CACpD,MAAM/sB,EAASmtB,EAAYntB,OAC3B2G,EAAMrN,KAAK6vB,EAAanpB,GACxBmtB,EAAcA,EAAYN,OAC1BI,EAAgB9D,EAAanpB,IAAYktB,OAC/BC,EAAYL,sBACtBnmB,EAAMrN,KAAK4zB,GACXD,GAAe,GAEhBE,EAAY3B,QAAQtsB,IAEpB,QACG+tB,GACHtmB,EAAMrN,KAAK4zB,IAKdta,WACC,OAAO9Z,KAAK2Z,eAGbI,eAAeC,GACdA,EAAKC,OAAOja,KAAK2Z,gBAGlBU,OAAOxR,GACN,GAAI7I,OAAS6I,EACZ,OAAO,EACD,GAAMA,aAAiBknB,EAEvB,IAAI/vB,KAAK2Z,gBAAkB9Q,EAAM8Q,eACvC,OAAO,EACD,GAAI3Z,KAAK2iB,aAAa7hB,QAAU+H,EAAM8Z,aAAa7hB,OACzD,OAAO,EACD,CACN,MAAMwzB,EAAat0B,KAAK2iB,aAAa7hB,OACrC,IAAK,IAAI0S,EAAM,EAAGA,EAAM8gB,IAAc9gB,EACrC,IAAKxT,KAAK2iB,aAAanP,GAAK6G,OAAOxR,EAAM8Z,aAAanP,IACrD,OAAO,EAGT,OAAO,GAZP,OAAO,EA+BT+G,cAAc8J,EAAqBgQ,GAClC,GAA4B,OAAxBhQ,EACH,OAAO,IAAI0L,EAAoB,CAAEsE,IAElC,MAAM1R,EAAe0B,EAAoB1B,aAAatB,OAAO,CAAEgT,IAC/D,OAAO,IAAItE,EAAoBpN,IAKjChjB,EAAOC,QAAUmwB,iBCvKjB,MAAMtL,EAAQ,EAAQ,MAChB,IAACla,EAAG,OAAEC,EAAM,WAAEkX,GAAc+C,EAE5BrC,EAAM,EAAQ,MACd,SAACiE,EAAQ,cAAE3b,GAAiB,EAAQ,MAEpC,UAACD,GAAa,EAAQ,MACtB,aAACma,GAAgB,EAAQ,KACzB,MAACplB,GAAS,EAAQ,MAClB,SAAC+vB,EAAQ,eAAEgF,GAAkB,EAAQ,KACrC/E,EAAe,EAAQ,KACvBgF,EAAiB,EAAQ,KACzBrc,EAAc,EAAQ,MAEtB,gBAACoL,IADmB,EAAQ,KACR,EAAQ,OAC5B,kBAACvY,GAAqB,EAAQ,MAC9B,SAACtL,GAAY,EAAQ,MACrB,WAACwnB,EAAU,cAAEE,EAAa,iBAAExc,EAAgB,eAAED,EAAc,iBAAE2c,GAAoB,EAAQ,KAC1F,qBAACmN,GAAwB,EAAQ,MACjC,2BAACxpB,EAA0B,iCAAEF,GAAoC,EAAQ,KA4pD/EpL,EAAOC,QAt7CP,cAAiC4vB,EAC7B3vB,YAAYgS,EAAQ1G,EAAKuM,EAAe+X,GACpC1vB,MAAMoL,EAAKskB,GACXzvB,KAAK6R,OAASA,EACd7R,KAAK0X,cAAgBA,EAErB1X,KAAK00B,eAAiBF,EAAeG,GAErC30B,KAAK8N,OAAS,KACd9N,KAAK40B,YAAc,EACnB50B,KAAK60B,cAAgB,KACrB70B,KAAK80B,KAAO,KAUZ90B,KAAKgb,WAAa,KAClBhb,KAAK+P,OAAQ,EACb/P,KAAK+0B,eAAgB,EACrB/0B,KAAKg1B,WAAY,EACjBh1B,KAAKi1B,0BAA2B,EAChCj1B,KAAK6zB,WAAY,EACjB7zB,KAAKk1B,aAAc,EAGvB30B,SAEA40B,gBAAgBtnB,EAAOmK,EAAUwE,IACzBxc,KAAK+P,OAAS/P,KAAKi1B,2BACnB9lB,QAAQC,IAAI,4BAA8B4I,EACnB,gBAAkBhY,KAAKo1B,iBAAiBvnB,GACxC,SAAWA,EAAM5L,GAAG,GAAG8D,KAAO,IAC9B8H,EAAM5L,GAAG,GAAG+D,QAEvChG,KAAK8N,OAASD,EACd7N,KAAK40B,YAAc/mB,EAAM3N,MACzBF,KAAK60B,cAAgBrY,EAErB,MAAM3E,EAAM7X,KAAK0X,cAAcM,GAC/BhY,KAAK80B,KAAOjd,EACZ,MAAMhI,EAAIhC,EAAMzN,OACVF,EAAQ2N,EAAM3N,MAIpB,IACI,IAAIwwB,EASJ,GALIA,EAHA7Y,EAAIwd,cAGCxd,EAAIyd,wBAAwBt1B,KAAK6R,OAAOsE,iBAGxC0B,EAAI6Y,GAEJ,OAALA,EAAW,CACQ,OAAflU,IACAA,EAAerE,EAAYtM,QAE3B7L,KAAK+P,OAAS/P,KAAKi1B,2BACnB9lB,QAAQC,IAAI,uBAAyByI,EAAIG,SACtB,gBAAkBhY,KAAKo1B,iBAAiBvnB,GACxC,kBAAoB2O,EAAavX,SAASjF,KAAK6R,OAAOE,YAG7E,MAAM8S,GAAU,EAChB,IAAIiM,EAAa9wB,KAAK+wB,kBAAkBlZ,EAAI0d,cAAepd,EAAYtM,MAAOgZ,GAE1EhN,EAAIwd,eAOJxd,EAAI6Y,GAAG3L,QAAU+L,EACjBA,EAAa9wB,KAAKw1B,sBAAsB1E,GACxCJ,EAAK1wB,KAAKixB,YAAYpZ,EAAK,IAAI0X,EAAS,KAAMuB,IAC9CjZ,EAAI4d,wBAAwBz1B,KAAK6R,OAAOsE,gBAAiBua,KAEzDA,EAAK1wB,KAAKixB,YAAYpZ,EAAK,IAAI0X,EAAS,KAAMuB,IAC9CjZ,EAAI6Y,GAAKA,GAGjB,MAAMllB,EAAMxL,KAAK4wB,QAAQ/Y,EAAK6Y,EAAI7iB,EAAO3N,EAAOsc,GAIhD,OAHIxc,KAAK+P,OACLZ,QAAQC,IAAI,yBAA2ByI,EAAI5S,SAASjF,KAAK6R,OAAOrI,aAAcxJ,KAAK6R,OAAOpI,gBAEvF+B,EACT,QACExL,KAAK80B,KAAO,KACZ90B,KAAKgb,WAAa,KAClBnN,EAAMrN,KAAKN,GACX2N,EAAMxN,QAAQwP,IAoCtB+gB,QAAQ/Y,EAAK6Y,EAAI7iB,EAAOwiB,EAAY7T,GAMhC,IAAIhR,GALAxL,KAAK+P,OAAS/P,KAAKi1B,2BACnB9lB,QAAQC,IAAI,oBAAsByI,EAAIG,SAC9B,gBAAkBhY,KAAKo1B,iBAAiBvnB,GACxC,SAAWA,EAAM5L,GAAG,GAAG8D,KAAO,IAAM8H,EAAM5L,GAAG,GAAG+D,QAG5D,IAAI0vB,EAAYhF,EAEZ1wB,KAAK+P,OACLZ,QAAQC,IAAI,QAAUshB,GAE1B,IAAIrvB,EAAIwM,EAAM9M,GAAG,GACjB,OAAY,CACR,IAAI40B,EAAI31B,KAAKuxB,uBAAuBmE,EAAWr0B,GAI/C,GAHO,OAAJs0B,IACCA,EAAI31B,KAAKwxB,mBAAmB3Z,EAAK6d,EAAWr0B,IAE7Cs0B,IAAInG,EAAaE,MAAO,CAUvB,MAAMjrB,EAAIzE,KAAK41B,YAAY/nB,EAAO2O,EAAckZ,EAAU3Q,QAASsL,GAGnE,GAFAxiB,EAAMrN,KAAK6vB,GACX7kB,EAAMxL,KAAK61B,wDAAwDH,EAAU3Q,QAASvI,GACnFhR,IAAM4W,EAAIiB,mBACT,OAAO7X,EAEP,MAAM/G,EAGd,GAAGkxB,EAAEG,qBAAuB91B,KAAK00B,iBAAmBF,EAAeuB,IAAK,CAEpE,IAAI9Q,EAAkB,KACtB,GAAmB,OAAf0Q,EAAEK,WAAmB,CACjBh2B,KAAK+P,OACLZ,QAAQC,IAAI,8CAEhB,MAAM6mB,EAAgBpoB,EAAM3N,MAK5B,GAJG+1B,IAAkB5F,GACjBxiB,EAAMrN,KAAK6vB,GAEfpL,EAAkBjlB,KAAKk2B,oBAAoBP,EAAEK,WAAYxZ,GAAc,GAC1C,IAAzByI,EAAgBnkB,OAIhB,OAHGd,KAAK+P,OACJZ,QAAQC,IAAI,mBAET6V,EAAgBpE,WAEvBoV,IAAkB5F,GAGlBxiB,EAAMrN,KAAKy1B,GAGfj2B,KAAK6zB,WACL1kB,QAAQC,IAAI,uBAAyBoN,EAAc,OAASmZ,GAEhE,MAAM9Q,GAAU,EACViM,EAAa9wB,KAAK+wB,kBAAkBlZ,EAAI0d,cAAe/Y,EAAcqI,GAG3E,OAFA7kB,KAAKm2B,4BAA4Bte,EAAKoN,EAAiB0Q,EAAE5Q,QAASsL,EAAYxiB,EAAM3N,OACpFsL,EAAMxL,KAAKo2B,uBAAuBve,EAAK8d,EAAG7E,EAAYjjB,EAAOwiB,EAAY7T,GAClEhR,EAEX,GAAImqB,EAAEtE,cAAe,CACjB,GAAmB,OAAfsE,EAAEK,WACF,OAAOL,EAAE3D,WAEb,MAAMoC,EAAYvmB,EAAM3N,MACxB2N,EAAMrN,KAAK6vB,GACX,MAAMgG,EAAOr2B,KAAKk2B,oBAAoBP,EAAEK,WAAYxZ,GAAc,GAClE,GAAkB,IAAd6Z,EAAKv1B,OACL,MAAMd,KAAK41B,YAAY/nB,EAAO2O,EAAcmZ,EAAE5Q,QAASsL,GACpD,OAAkB,IAAdgG,EAAKv1B,QAIZd,KAAKs2B,gBAAgBze,EAAK8d,EAAGtF,EAAY+D,GAAW,EAAOiC,EAAMV,EAAE5Q,SAH5DsR,EAAKxV,WAOpB6U,EAAYC,EAERt0B,IAAM7B,EAAMwB,MACZ6M,EAAMjN,UACNS,EAAIwM,EAAM9M,GAAG,KAgBzBwwB,uBAAuBmE,EAAWr0B,GAC9B,MAAMqwB,EAAQgE,EAAUhE,MACxB,OAAY,OAARA,EACO,KAEAA,EAAMrwB,EAAI,IAAM,KAgB/BmwB,mBAAmB3Z,EAAK6d,EAAWr0B,GAChC,MAAMwwB,EAAQ7xB,KAAKu2B,gBAAgBb,EAAU3Q,QAAS1jB,GAAG,GACxD,GAAW,OAARwwB,EAEC,OADA7xB,KAAK+xB,WAAWla,EAAK6d,EAAWr0B,EAAGmuB,EAAaE,OACzCF,EAAaE,MAGxB,IAAIiG,EAAI,IAAIpG,EAAS,KAAMsC,GAE3B,MAAM2E,EAAex2B,KAAKy2B,aAAa5E,GAEvC,GAAI7xB,KAAK+P,MAAO,CACZ,MAAM2mB,EAAalC,EAAemC,yBAAyB9E,GAC3D1iB,QAAQC,IAAI,kBAAoBqV,EAAMjF,cAAckX,GAExC,aAAe7E,EACf,aAAe2E,EACf,wBACAhC,EAAeoC,mBAAmBF,GAAc,qBAChD12B,KAAK62B,mBAAmBhF,IAuBxC,OArBI2E,IAAepU,EAAIiB,oBAEnBsS,EAAEtE,eAAgB,EAClBsE,EAAE5Q,QAAQC,UAAYwR,EACtBb,EAAE3D,WAAawE,GACRhC,EAAesC,oCAAoC92B,KAAK00B,eAAgB7C,KAE/E8D,EAAE5Q,QAAQE,gBAAkBjlB,KAAK62B,mBAAmBhF,GACpD8D,EAAEG,qBAAsB,EAExBH,EAAEtE,eAAgB,EAClBsE,EAAE3D,WAAa2D,EAAE5Q,QAAQE,gBAAgBpE,YAEzC8U,EAAEtE,eAAiBsE,EAAE5Q,QAAQG,qBAC7BllB,KAAK+2B,kBAAkBpB,EAAG31B,KAAKmL,IAAIgY,iBAAiBtL,EAAIG,WACrC,OAAf2d,EAAEK,aACFL,EAAE3D,WAAa5P,EAAIiB,qBAI3BsS,EAAI31B,KAAK+xB,WAAWla,EAAK6d,EAAWr0B,EAAGs0B,GAChCA,EAGXoB,kBAAkB7G,EAAU8G,GAGxB,MAAMC,EAAQD,EAAc1rB,YAAYxK,OAGlCo2B,EAAyBl3B,KAAKm3B,8BAA8BjH,EAASnL,SACrEqS,EAAYp3B,KAAKq3B,qBAAqBH,EAAwBhH,EAASnL,QAASkS,GACtE,OAAZG,GACAlH,EAAS8F,WAAah2B,KAAKs3B,wBAAwBJ,EAAwBE,GAC3ElH,EAAS8B,WAAa5P,EAAIiB,oBAK1B6M,EAAS8B,WAAakF,EAAuBrW,WAKrDuV,uBAAuBve,EAAK8d,EACSjF,EACA7iB,EACAwiB,EACA7T,IAC7Bxc,KAAK+P,OAAS/P,KAAKi1B,2BACnB9lB,QAAQC,IAAI,0BAA0BshB,GAG1C,IACImB,EADA0F,GAAkB,EAElBhhB,EAAWma,EACf7iB,EAAMrN,KAAK6vB,GACX,IAAIhvB,EAAIwM,EAAM9M,GAAG,GACby1B,GAAgB,EACpB,OAAa,CAET,GADA3E,EAAQ7xB,KAAKu2B,gBAAgBhgB,EAAUlV,GAR3B,GASA,OAARwwB,EAAc,CAUd,MAAMptB,EAAIzE,KAAK41B,YAAY/nB,EAAO2O,EAAcjG,EAAU8Z,GAC1DxiB,EAAMrN,KAAK6vB,GACX,MAAM7kB,EAAMxL,KAAK61B,wDAAwDtf,EAAUiG,GACnF,GAAGhR,IAAM4W,EAAIiB,mBACT,OAAO7X,EAEP,MAAM/G,EAGd,MAAMiyB,EAAalC,EAAemC,yBAAyB9E,GAQ3D,GAPG7xB,KAAK+P,OACJZ,QAAQC,IAAI,iBAAmBsnB,EAAa,aACtClC,EAAeiC,aAAaC,GAAc,gCAC1ClC,EAAegD,2BAA2Bd,IAEpD7E,EAAM7M,UAAYhlB,KAAKy2B,aAAa5E,GAEjCA,EAAM7M,YAAY5C,EAAIiB,mBAAoB,CACzCmT,EAAe3E,EAAM7M,UACrB,MACG,GAAIhlB,KAAK00B,iBAAmBF,EAAeiD,0BAE9C,GADAjB,EAAehC,EAAegD,2BAA2Bd,GACtDF,IAAiBpU,EAAIiB,mBACpB,WAKJ,GAAImR,EAAeoC,mBAAmBF,IAAelC,EAAekD,gBAAgBhB,GAAa,CAC7Fa,GAAkB,EAClBf,EAAehC,EAAemD,mBAAmBjB,GACjD,MAMRngB,EAAWsb,EACPxwB,IAAM7B,EAAMwB,MACZ6M,EAAMjN,UACNS,EAAIwM,EAAM9M,GAAG,IAMrB,OAAI8wB,EAAM7M,YAAc5C,EAAIiB,oBACxBrjB,KAAK43B,yBAAyB/f,EAAK2e,EAAc3E,EAAOxB,EAAYxiB,EAAM3N,OACnEs2B,IA6BXx2B,KAAKs2B,gBAAgBze,EAAK8d,EAAGtF,EAAYxiB,EAAM3N,MAAOq3B,EAAiB,KAAM1F,GAEtE2E,GAGXD,gBAAgBtE,EAAS5wB,EAAGwjB,GACpB7kB,KAAK+P,OACLZ,QAAQC,IAAI,yCAA2C6iB,GAErC,OAAlBjyB,KAAKgb,aACLhb,KAAKgb,WAAa,IAAI0G,GAE1B,MAAMmW,EAAe,IAAIjT,EAAaC,GAYtC,IAAIiT,EAAoB,KAGxB,IAAK,IAAI52B,EAAE,EAAGA,EAAE+wB,EAAQjM,MAAMllB,OAAOI,IAAK,CACtC,MAAMoL,EAAI2lB,EAAQjM,MAAM9kB,GAIxB,GAHGlB,KAAK+P,OACJZ,QAAQC,IAAI,WAAapP,KAAKqyB,aAAahxB,GAAK,OAASiL,GAEzDA,EAAEC,iBAAiB7B,GACfma,GAAWxjB,IAAM7B,EAAMwB,OACC,OAApB82B,IACAA,EAAoB,IAExBA,EAAkBt2B,KAAK8K,GACpBtM,KAAKg1B,WACJ7lB,QAAQC,IAAI,SAAW9C,EAAI,+BAKvC,IAAI,IAAIrC,EAAE,EAAEA,EAAEqC,EAAEC,MAAMjB,YAAYxK,OAAOmJ,IAAK,CAC1C,MAAM0hB,EAAQrf,EAAEC,MAAMjB,YAAYrB,GAC5BtF,EAAS3E,KAAKsyB,mBAAmB3G,EAAOtqB,GAC9C,GAAa,OAATsD,EAAe,CACf,MAAMwtB,EAAM,IAAI1nB,EAAU,CAAC8B,MAAM5H,GAAS2H,GAC1CurB,EAAaprB,IAAI0lB,EAAKnyB,KAAKgb,YACxBhb,KAAKg1B,WACJ7lB,QAAQC,IAAI,SAAW+iB,EAAM,sBAM7C,IAAIN,EAAQ,KA2BZ,GAhBwB,OAApBiG,GAA4Bz2B,IAAI7B,EAAMwB,MACN,IAA5B62B,EAAa7R,MAAMllB,QAMZd,KAAKy2B,aAAaoB,KAAgBzV,EAAIiB,sBAD7CwO,EAAQgG,GAUJ,OAARhG,EAAc,CACdA,EAAQ,IAAIjN,EAAaC,GACzB,MAAMkT,EAAc,IAAIxtB,EAClBioB,EAAoBnxB,IAAM7B,EAAMwB,IACtC,IAAK,IAAImB,EAAE,EAAGA,EAAE01B,EAAa7R,MAAMllB,OAAOqB,IACtCnC,KAAKiyB,QAAQ4F,EAAa7R,MAAM7jB,GAAI0vB,EAAOkG,GAAa,EAAOlT,EAAS2N,GA+BhF,GA5BInxB,IAAM7B,EAAMwB,MAkBZ6wB,EAAQ7xB,KAAKg4B,mCAAmCnG,EAAOA,IAAUgG,MAU7C,OAApBC,GAAiCjT,GAAe2P,EAAeyD,yBAAyBpG,IACxF,IAAK,IAAIxpB,EAAE,EAAGA,EAAEyvB,EAAkBh3B,OAAOuH,IACrCwpB,EAAMplB,IAAIqrB,EAAkBzvB,GAAIrI,KAAKgb,YAG7C,OAAyB,IAArB6W,EAAM7L,MAAMllB,OACL,KAEA+wB,EAwBfmG,mCAAmCjT,EAASmT,GACxC,GAAI1D,EAAe2D,2BAA2BpT,GAC1C,OAAOA,EAEX,MAAMngB,EAAS,IAAIggB,EAAaG,EAAQF,SACxC,IAAI,IAAI3jB,EAAE,EAAGA,EAAE6jB,EAAQiB,MAAMllB,OAAOI,IAAK,CACrC,MAAM6iB,EAASgB,EAAQiB,MAAM9kB,GAC7B,GAAI6iB,EAAOxX,iBAAiB7B,EACxB9F,EAAO6H,IAAIsX,EAAQ/jB,KAAKgb,iBAG5B,GAAIkd,GAAmBnU,EAAOxX,MAAM4gB,wBACbntB,KAAKmL,IAAI6L,WAAW+M,EAAOxX,OAC/BvK,SAASxC,EAAM2K,SAAU,CACpC,MAAMiuB,EAAiBp4B,KAAKmL,IAAIqX,gBAAgBuB,EAAOxX,MAAMK,WAC7DhI,EAAO6H,IAAI,IAAIhC,EAAU,CAAC8B,MAAM6rB,GAAiBrU,GAAS/jB,KAAKgb,aAI3E,OAAOpW,EAGXmsB,kBAAkBvZ,EAAGvL,EAAK4Y,GAEtB,MAAM+N,EAAiB7nB,EAAiC/K,KAAKmL,IAAKc,GAC5D8Y,EAAU,IAAIH,EAAaC,GACjC,IAAI,IAAI3jB,EAAE,EAAEA,EAAEsW,EAAElM,YAAYxK,OAAOI,IAAK,CACpC,MAAMyD,EAAS6S,EAAElM,YAAYpK,GAAGyD,OAC1B2H,EAAI,IAAI7B,EAAU,CAAE8B,MAAM5H,EAAQ6G,IAAItK,EAAE,EAAGsL,QAAQomB,GAAkB,MACrEmF,EAAc,IAAIxtB,EACxBvK,KAAKiyB,QAAQ3lB,EAAGyY,EAASgT,GAAa,EAAMlT,GAAS,GAEzD,OAAOE,EA2DXyQ,sBAAsBzQ,GAClB,IAAIhB,EACJ,MAAMsU,EAAiB,GACjBC,EAAY,IAAI1T,EAAaG,EAAQF,SAC3C,IAAI,IAAI3jB,EAAE,EAAGA,EAAE6jB,EAAQiB,MAAMllB,OAAQI,IAAK,CAGtC,GAFA6iB,EAASgB,EAAQiB,MAAM9kB,GAEJ,IAAf6iB,EAAOvY,IACP,SAEJ,MAAM+sB,EAAiBxU,EAAOJ,gBAAgB6U,eAAex4B,KAAK6R,OAAQ7R,KAAK60B,eAC1D,OAAjB0D,IAIJF,EAAetU,EAAOxX,MAAMa,aAAe2W,EAAOvX,QAC9C+rB,IAAmBxU,EAAOJ,gBAC1B2U,EAAU7rB,IAAI,IAAIhC,EAAU,CAACkZ,gBAAgB4U,GAAiBxU,GAAS/jB,KAAKgb,YAE5Esd,EAAU7rB,IAAIsX,EAAQ/jB,KAAKgb,aAGnC,IAAI,IAAI9Z,EAAE,EAAGA,EAAE6jB,EAAQiB,MAAMllB,OAAQI,IAEjC,GADA6iB,EAASgB,EAAQiB,MAAM9kB,GACJ,IAAf6iB,EAAOvY,IAAX,CAOA,IAAKuY,EAAOD,2BAA4B,CACpC,MAAMtX,EAAU6rB,EAAetU,EAAOxX,MAAMa,cAAgB,KAC5D,GAAc,OAAVZ,GAAkBA,EAAQ6N,OAAO0J,EAAOvX,SAExC,SAGR8rB,EAAU7rB,IAAIsX,EAAQ/jB,KAAKgb,YAE/B,OAAOsd,EAGXhG,mBAAmB3G,EAAO3c,GACtB,OAAI2c,EAAMgH,QAAQ3jB,EAAO,EAAGhP,KAAKmL,IAAIoC,cAC1Boe,EAAMhnB,OAEN,KAIf0yB,qBAAqBoB,EAAW1T,EAASkS,GAarC,IAAIG,EAAY,GAChB,IAAI,IAAIl2B,EAAE,EAAEA,EAAE6jB,EAAQiB,MAAMllB,OAAOI,IAAK,CACpC,MAAMoL,EAAIyY,EAAQiB,MAAM9kB,GACrBu3B,EAAUz2B,SAAUsK,EAAEd,OACrB4rB,EAAU9qB,EAAEd,KAAO+X,EAAgBmV,UAAUtB,EAAU9qB,EAAEd,MAAQ,KAAMc,EAAEqX,kBAGjF,IAAIgV,EAAY,EAChB,IAAK,IAAIz3B,EAAG,EAAEA,EAAG+1B,EAAM,EAAE/1B,IAAK,CAC1B,MAAM03B,EAAOxB,EAAUl2B,IAAM,KAClB,OAAP03B,EACAxB,EAAUl2B,GAAKqiB,EAAgBU,KACxB2U,IAASrV,EAAgBU,OAChC0U,GAAa,GAUrB,OANgB,IAAZA,IACAvB,EAAY,MAEZp3B,KAAK+P,OACLZ,QAAQC,IAAI,+BAAiCqV,EAAMjF,cAAc4X,IAE9DA,EAGXE,wBAAwBmB,EAAWrB,GAC/B,MAAMyB,EAAQ,GACd,IAAIC,GAAoB,EACxB,IAAK,IAAI53B,EAAE,EAAGA,EAAEk2B,EAAUt2B,OAAOI,IAAK,CAClC,MAAM03B,EAAOxB,EAAUl2B,GAEP,OAAZu3B,GAAoBA,EAAUz2B,SAAUd,IACxC23B,EAAMr3B,KAAK,IAAI+yB,EAAeqE,EAAM13B,IAEpC03B,IAASrV,EAAgBU,OACzB6U,GAAoB,GAG5B,OAAMA,EAGCD,EAFI,KAmDfhD,wDAAwD9Q,EAASvI,GAC7D,MAAM+W,EAAOvzB,KAAK+4B,iCAAiChU,EAASvI,GACtDwc,EAAkBzF,EAAK,GACvB0F,EAAoB1F,EAAK,GAC/B,IAAI/nB,EAAMxL,KAAKk5B,oCAAoCF,GACnD,OAAIxtB,IAAM4W,EAAIiB,oBAIV4V,EAAkBjT,MAAMllB,OAAO,IAC/B0K,EAAMxL,KAAKk5B,oCAAoCD,GAC3CztB,IAAM4W,EAAIiB,oBALP7X,EASJ4W,EAAIiB,mBAGf6V,oCAAoCnU,GAChC,MAAMsR,EAAO,GACb,IAAI,IAAIn1B,EAAE,EAAEA,EAAE6jB,EAAQiB,MAAMllB,OAAQI,IAAK,CACrC,MAAMoL,EAAIyY,EAAQiB,MAAM9kB,IACpBoL,EAAEsX,wBAAwB,GAAOtX,EAAEC,iBAAiB7B,GAAkB4B,EAAEE,QAAQoN,iBAC7Eyc,EAAK5iB,QAAQnH,EAAEd,KAAK,GACnB6qB,EAAK70B,KAAK8K,EAAEd,KAIxB,OAAkB,IAAd6qB,EAAKv1B,OACEshB,EAAIiB,mBAEJjc,KAAKC,IAAIyZ,MAAM,KAAMuV,GAapC0C,iCAAkChU,EAASvI,GACvC,MAAM2c,EAAY,IAAIvU,EAAaG,EAAQF,SACrCuU,EAAS,IAAIxU,EAAaG,EAAQF,SACxC,IAAI,IAAI3jB,EAAE,EAAEA,EAAE6jB,EAAQiB,MAAMllB,OAAQI,IAAK,CACrC,MAAMoL,EAAIyY,EAAQiB,MAAM9kB,GACpBoL,EAAEqX,kBAAoBJ,EAAgBU,KACJ3X,EAAEqX,gBAAgB0V,SAASr5B,KAAK6R,OAAQ2K,GAEtE2c,EAAU1sB,IAAIH,GAEd8sB,EAAO3sB,IAAIH,GAGf6sB,EAAU1sB,IAAIH,GAGtB,MAAO,CAAC6sB,EAAWC,GAUvBlD,oBAAoBoD,EAAiB9c,EAAc+c,GAC/C,MAAMC,EAAc,IAAIhvB,EACxB,IAAI,IAAItJ,EAAE,EAAEA,EAAEo4B,EAAgBx4B,OAAOI,IAAK,CACtC,MAAMmpB,EAAOiP,EAAgBp4B,GAC7B,GAAImpB,EAAKuO,OAASrV,EAAgBU,KAAM,CAEpC,GADAuV,EAAY/sB,IAAI4d,EAAK7e,MACf+tB,EACF,MAEJ,SAEJ,MAAME,EAA4BpP,EAAKuO,KAAKS,SAASr5B,KAAK6R,OAAQ2K,GAIlE,IAHIxc,KAAK+P,OAAS/P,KAAK6zB,YACnB1kB,QAAQC,IAAI,aAAeib,EAAO,IAAMoP,GAExCA,KACIz5B,KAAK+P,OAAS/P,KAAK6zB,YACnB1kB,QAAQC,IAAI,WAAaib,EAAK7e,KAElCguB,EAAY/sB,IAAI4d,EAAK7e,MACf+tB,GACF,MAIZ,OAAOC,EASXvH,QAAQlO,EAAQgB,EAASgT,EAAa2B,EAAmB7U,EAAS2N,GAE9DxyB,KAAK25B,yBAAyB5V,EAAQgB,EAASgT,EAAa2B,EACnC7U,EAFJ,EAE2B2N,GAGpDmH,yBAAyB5V,EAAQgB,EAASgT,EAAa2B,EAAmB7U,EAASpG,EAAO+T,GACtF,IAAIxyB,KAAK+P,OAAS/P,KAAK+0B,iBACnB5lB,QAAQC,IAAI,WAAa2U,EAAO9e,SAASjF,KAAK6R,QAAO,GAAQ,KAE1DkS,EAAOH,wBAAwB,IAC9B,KAAM,UAGd,GAAIG,EAAOxX,iBAAiB7B,EAAe,CAGvC,IAAMqZ,EAAOvX,QAAQE,UAAW,CAC5B,IAAK,IAAIxL,EAAG,EAAGA,EAAE6iB,EAAOvX,QAAQ1L,OAAQI,IAAK,CACzC,GAAI6iB,EAAOvX,QAAQQ,eAAe9L,KAAO8J,EAAkB6O,mBAAoB,CAC3E,GAAIgL,EAAS,CACTE,EAAQtY,IAAI,IAAIhC,EAAU,CAAC8B,MAAMwX,EAAOxX,MAAOC,QAAQxB,EAAkBa,OAAQkY,GAAS/jB,KAAKgb,YAC/F,SAGIhb,KAAK+P,OACLZ,QAAQC,IAAI,oBAAsBpP,KAAK45B,YAAY7V,EAAOxX,MAAMK,YAEpE5M,KAAK65B,SAAS9V,EAAQgB,EAASgT,EAAa2B,EACnC7U,EAASpG,EAAO+T,GAE7B,SAEJ,MAAM1lB,EAAc9M,KAAKmL,IAAI4B,OAAOgX,EAAOvX,QAAQQ,eAAe9L,IAC5DgM,EAAa6W,EAAOvX,QAAQS,UAAU/L,GACtC44B,EAAQ,CAACvtB,MAAMO,EAAatB,IAAIuY,EAAOvY,IAAKgB,QAAQU,EAAYyW,gBAAgBI,EAAOJ,iBACvFrX,EAAI,IAAI7B,EAAUqvB,EAAO,MAI/BxtB,EAAEsX,wBAA0BG,EAAOH,wBACnC5jB,KAAK25B,yBAAyBrtB,EAAGyY,EAASgT,EAAa2B,EAAmB7U,EAASpG,EAAQ,EAAG+T,GAElG,OACG,GAAI3N,EAGP,YADAE,EAAQtY,IAAIsX,EAAQ/jB,KAAKgb,YAIrBhb,KAAK+P,OACLZ,QAAQC,IAAI,oBAAsBpP,KAAK45B,YAAY7V,EAAOxX,MAAMK,YAI5E5M,KAAK65B,SAAS9V,EAAQgB,EAASgT,EAAa2B,EAAmB7U,EAASpG,EAAO+T,GAInFqH,SAAS9V,EAAQgB,EAASgT,EAAa2B,EAAmB7U,EAASpG,EAAO+T,GACtE,MAAMhb,EAAIuM,EAAOxX,MAEXiL,EAAE2V,wBACJpI,EAAQtY,IAAIsX,EAAQ/jB,KAAKgb,YAI7B,IAAI,IAAI9Z,EAAI,EAAEA,EAAEsW,EAAElM,YAAYxK,OAAQI,IAAK,CACvC,GAAS,IAANA,GAAWlB,KAAK+5B,wCAAwChW,GACvD,SAEJ,MAAM1iB,EAAImW,EAAElM,YAAYpK,GAClB84B,EAAqBN,KAAuBr4B,aAAaimB,GACzDhb,EAAItM,KAAK8yB,iBAAiB/O,EAAQ1iB,EAAG24B,EAA8B,IAAVvb,EAAaoG,EAAS2N,GACrF,GAAQ,OAAJlmB,EAAU,CACV,IAAI2tB,EAAWxb,EACf,GAAKsF,EAAOxX,iBAAiB7B,EAAe,CAaxC,GAPkB,OAAd1K,KAAK80B,MAAiB90B,KAAK80B,KAAKO,eAC5Bh0B,EAAE+qB,4BAA8BpsB,KAAK80B,KAAKS,cAAc3oB,YACxDN,EAAEwX,4BAA6B,GAIvCxX,EAAEsX,yBAA2B,EACzBmU,EAAYtrB,IAAIH,KAAKA,EAErB,SAEJyY,EAAQI,sBAAuB,EAC/B8U,GAAY,EACRj6B,KAAK+P,OACLZ,QAAQC,IAAI,wBAA0B9C,OAEvC,CACH,IAAKjL,EAAEgM,WAAa0qB,EAAYtrB,IAAIH,KAAKA,EAErC,SAEAjL,aAAasJ,GAETsvB,GAAY,IACZA,GAAY,GAIxBj6B,KAAK25B,yBAAyBrtB,EAAGyY,EAASgT,EAAaiC,EAAoBnV,EAASoV,EAAUzH,KAK1GuH,wCAAwChW,GAEpC,MAAMvM,EAAIuM,EAAOxX,MAMjB,GAAGiL,EAAEoY,YAAcvJ,EAASyI,gBACxB,OAAO,EACX,GAAGtX,EAAEoY,YAAcvJ,EAASyI,kBAAoBtX,EAAE4V,sBAC3CrJ,EAAOvX,QAAQE,WAAaqX,EAAOvX,QAAQoN,eAC9C,OAAO,EAGX,MAAMsgB,EAAUnW,EAAOvX,QAAQ1L,OAC/B,IAAI,IAAII,EAAE,EAAGA,EAAEg5B,EAASh5B,IAEpB,GADoBlB,KAAKmL,IAAI4B,OAAOgX,EAAOvX,QAAQQ,eAAe9L,IAClD0L,YAAc4K,EAAE5K,UAC5B,OAAO,EAGf,MACMutB,EADqB3iB,EAAElM,YAAY,GAAG3G,OACAomB,SAAS3d,YAC/CgtB,EAAgBp6B,KAAKmL,IAAI4B,OAAOotB,GAItC,IAAI,IAAIj5B,EAAE,EAAGA,EAAEg5B,EAASh5B,IAAK,CACzB,MAAMm5B,EAAoBtW,EAAOvX,QAAQQ,eAAe9L,GAClD4L,EAAc9M,KAAKmL,IAAI4B,OAAOstB,GAEpC,GAAuC,IAAnCvtB,EAAYxB,YAAYxK,SAAiBgM,EAAYxB,YAAY,GAAG+B,UACpE,OAAO,EAGX,MAAMitB,EAAoBxtB,EAAYxB,YAAY,GAAG3G,OACrD,KAAKmI,EAAY8iB,YAAcvJ,EAASuI,WAAa0L,IAAsB9iB,GAMtE1K,IAAgBstB,GAKhBE,IAAsBF,GAKvBE,EAAkB1K,YAAcvJ,EAASuI,WAAsD,IAAzC0L,EAAkBhvB,YAAYxK,QAC7Ew5B,EAAkBhvB,YAAY,GAAG+B,WAAaitB,EAAkBhvB,YAAY,GAAG3G,SAAW6S,GAIrG,OAAO,EAEX,OAAO,EAGXoiB,YAAY15B,GACR,OAAkB,OAAdF,KAAK6R,QAAiB3R,GAAO,EACtBF,KAAK6R,OAAOE,UAAU7R,GAEtB,SAAWA,EAAQ,IAIlC4yB,iBAAiB/O,EAAQ1iB,EAAGq4B,EAAmB7iB,EAAWgO,EAAS2N,GAC/D,OAAOnxB,EAAE0xB,mBACT,KAAK7L,EAAW0G,KACZ,OAAO5tB,KAAKu6B,eAAexW,EAAQ1iB,GACvC,KAAK6lB,EAAW4G,WACZ,OAAO9tB,KAAKw6B,qBAAqBzW,EAAQ1iB,EAAGq4B,EAAmB7iB,EAAWgO,GAC9E,KAAKqC,EAAW2G,UACZ,OAAO7tB,KAAKy6B,eAAe1W,EAAQ1iB,EAAGq4B,EAAmB7iB,EAAWgO,GACxE,KAAKqC,EAAW8G,OACZ,OAAOhuB,KAAK06B,iBAAiB3W,EAAQ1iB,GACzC,KAAK6lB,EAAW/c,QACZ,OAAO,IAAIM,EAAU,CAAC8B,MAAMlL,EAAEsD,QAASof,GAC3C,KAAKmD,EAAW6G,KAChB,KAAK7G,EAAWyG,MAChB,KAAKzG,EAAW+G,IAGZ,OAAIuE,GACInxB,EAAEsxB,QAAQnzB,EAAMwB,IAAK,EAAG,GACjB,IAAIyJ,EAAU,CAAC8B,MAAOlL,EAAEsD,QAASof,GAGzC,KACX,QACI,OAAO,MAIf2W,iBAAiB3W,EAAQ1iB,GACrB,GAAIrB,KAAK+P,MAAO,CACZ,MAAM7P,GAA2B,IAAnBmB,EAAEid,YAAqB,MAAQjd,EAAEid,YAC/CnP,QAAQC,IAAI,eAAiB/N,EAAEuL,UAAY,IAAM1M,GAErD,OAAO,IAAIuK,EAAU,CAAC8B,MAAMlL,EAAEsD,QAASof,GAG3CyW,qBAAqBzW,EAAQ4W,EAAIjB,EAAmB7iB,EAAWgO,GACvD7kB,KAAK+P,QACLZ,QAAQC,IAAI,2BAA6BsqB,EAAoB,KACrDiB,EAAGtkB,WAAa,4BACN,OAAdrW,KAAK6R,QACL1C,QAAQC,IAAI,+BAAiCqV,EAAMjF,cAAcxf,KAAK6R,OAAO0F,4BAGrF,IAAIjL,EAAI,KACR,GAAIotB,GAAqB7iB,EACrB,GAAIgO,EAAS,CAKT,MAAM+V,EAAkB56B,KAAK8N,OAAO5N,MACpCF,KAAK8N,OAAOtN,KAAKR,KAAK40B,aACtB,MAAMiG,EAAeF,EAAGG,eAAezB,SAASr5B,KAAK6R,OAAQ7R,KAAK60B,eAClE70B,KAAK8N,OAAOtN,KAAKo6B,GACbC,IACAvuB,EAAI,IAAI7B,EAAU,CAAC8B,MAAMouB,EAAGh2B,QAASof,QAEtC,CACH,MAAMgX,EAAYxX,EAAgByX,WAAWjX,EAAOJ,gBAAiBgX,EAAGG,gBACxExuB,EAAI,IAAI7B,EAAU,CAAC8B,MAAMouB,EAAGh2B,OAAQgf,gBAAgBoX,GAAYhX,QAGpEzX,EAAI,IAAI7B,EAAU,CAAC8B,MAAMouB,EAAGh2B,QAASof,GAKzC,OAHI/jB,KAAK+P,OACLZ,QAAQC,IAAI,+BAAiC9C,GAE1CA,EAGXmuB,eAAe1W,EAAQ4W,EAAIjB,EAAmB7iB,EAAWgO,GACjD7kB,KAAK+P,QACLZ,QAAQC,IAAI,2BAA6BsqB,EAAoB,KAAOiB,EAAG/tB,UAC/D,IAAM+tB,EAAG3H,UAAY,mBAAqB2H,EAAGM,gBACnC,OAAdj7B,KAAK6R,QACL1C,QAAQC,IAAI,+BAAiCqV,EAAMjF,cAAcxf,KAAK6R,OAAO0F,4BAGrF,IAAIjL,EAAI,KACR,GAAIotB,IAAuBiB,EAAGM,gBAAkBpkB,IAAgB8jB,EAAGM,gBAC/D,GAAIpW,EAAS,CAKT,MAAM+V,EAAkB56B,KAAK8N,OAAO5N,MACpCF,KAAK8N,OAAOtN,KAAKR,KAAK40B,aACtB,MAAMiG,EAAeF,EAAGG,eAAezB,SAASr5B,KAAK6R,OAAQ7R,KAAK60B,eAClE70B,KAAK8N,OAAOtN,KAAKo6B,GACbC,IACAvuB,EAAI,IAAI7B,EAAU,CAAC8B,MAAMouB,EAAGh2B,QAASof,QAEtC,CACH,MAAMgX,EAAYxX,EAAgByX,WAAWjX,EAAOJ,gBAAiBgX,EAAGG,gBACxExuB,EAAI,IAAI7B,EAAU,CAAC8B,MAAMouB,EAAGh2B,OAAQgf,gBAAgBoX,GAAYhX,QAGpEzX,EAAI,IAAI7B,EAAU,CAAC8B,MAAMouB,EAAGh2B,QAASof,GAKzC,OAHI/jB,KAAK+P,OACLZ,QAAQC,IAAI,+BAAiC9C,GAE1CA,EAGXiuB,eAAexW,EAAQ1iB,GACfrB,KAAK+P,OACLZ,QAAQC,IAAI,aAAepP,KAAK45B,YAAYv4B,EAAEsD,OAAOiI,WAAa,SAAWmX,EAAOvX,SAExF,MAAMM,EAAczL,EAAE8L,YAChBD,EAAajC,EAA2BpF,OAAOke,EAAOvX,QAASM,EAAYM,aACjF,OAAO,IAAI3C,EAAU,CAAC8B,MAAMlL,EAAEsD,OAAQ6H,QAAQU,GAAa6W,GAG/D8S,mBAAmB9R,GACf,MAAMmW,EAAU1G,EAAemC,yBAAyB5R,GACxD,OAAOyP,EAAe2G,QAAQD,GAuClC/D,8BAA8BpS,GAC1B,IAAIE,EAAkB,KAOtB,OANIF,EAAQC,YAAa5C,EAAIiB,oBACzB4B,EAAkB,IAAIza,EACtBya,EAAgBxY,IAAIsY,EAAQC,YAE5BC,EAAkBF,EAAQE,gBAEvBA,EAGXoN,aAAahxB,GACT,GAAIA,IAAI7B,EAAMwB,IACV,MAAO,MAEX,GAAkB,OAAdhB,KAAK6R,QAA4C,OAA3B7R,KAAK6R,OAAOrI,aAAqB,CACvD,KAAInI,GAAKrB,KAAK6R,OAAOrI,aAAa1I,QAAUO,GAAKrB,KAAK6R,OAAOpI,cAAc3I,QAKvE,OADad,KAAK6R,OAAOrI,aAAanI,IAAMrB,KAAK6R,OAAOpI,cAAcpI,IACxD,IAAMA,EAAI,IAJxB8N,QAAQC,IAAS/N,EAAI,wBAA0BrB,KAAK6R,OAAOrI,cAC3D2F,QAAQC,IAAI,GAAKpP,KAAK6R,OAAOmD,iBAAiBtT,aAMtD,MAAO,GAAKL,EAGhB+zB,iBAAiBvnB,GACb,OAAO7N,KAAKqyB,aAAaxkB,EAAM9M,GAAG,IAQtCq6B,mBAAmBC,GACflsB,QAAQC,IAAI,sBACZ,MAAMksB,EAAOD,EAAKE,oBAClB,IAAI,IAAIr6B,EAAE,EAAGA,EAAEo6B,EAAKx6B,OAAQI,IAAK,CAC7B,MAAMoL,EAAIgvB,EAAKp6B,GACf,IAAIyqB,EAAQ,WACZ,GAAIrf,EAAEC,MAAMjB,YAAYxK,OAAO,EAAG,CAC9B,MAAMO,EAAIiL,EAAEC,MAAMjB,YAAY,GAC1BjK,aAAa8lB,eACbwE,EAAQ,QAAS3rB,KAAKqyB,aAAahxB,EAAEoM,OAC9BpM,aAAa+lB,IAEpBuE,GADatqB,aAAauJ,EACX,IAAM,IAAM,OAASvJ,EAAEmM,KAG9C2B,QAAQqsB,MAAMlvB,EAAErH,SAASjF,KAAK6R,QAAQ,GAAQ,IAAM8Z,IAI5DiK,YAAY/nB,EAAO2O,EAAcuI,EAASsL,GACtC,OAAO,IAAIoE,EAAqBz0B,KAAK6R,OAAQhE,EAAOA,EAAMlN,IAAI0vB,GAAaxiB,EAAM5L,GAAG,GAAI8iB,EAASvI,GAGrGia,aAAa1R,GACT,IAAIvZ,EAAM4W,EAAIiB,mBACd,IAAI,IAAIniB,EAAE,EAAEA,EAAE6jB,EAAQiB,MAAMllB,OAAOI,IAAK,CACpC,MAAMoL,EAAIyY,EAAQiB,MAAM9kB,GACxB,GAAIsK,IAAQ4W,EAAIiB,mBACZ7X,EAAMc,EAAEd,SACL,GAAIc,EAAEd,MAAMA,EACf,OAAO4W,EAAIiB,mBAGnB,OAAO7X,EAuBXumB,WAAWla,EAAKhV,EAAOxB,EAAGyB,GAItB,GAHI9C,KAAK+P,OACLZ,QAAQC,IAAI,QAAUvM,EAAQ,OAASC,EAAK,SAAW9C,KAAKqyB,aAAahxB,IAEpE,OAALyB,EACA,OAAO,KAGX,GADAA,EAAK9C,KAAKixB,YAAYpZ,EAAK/U,GACf,OAARD,GAAgBxB,GAAK,GAAKA,EAAIrB,KAAKmL,IAAIoC,aACvC,OAAOzK,EAOX,GALkB,OAAdD,EAAM6uB,QACN7uB,EAAM6uB,MAAQ,IAElB7uB,EAAM6uB,MAAMrwB,EAAE,GAAKyB,EAEf9C,KAAK+P,MAAO,CACZ,MAAMvG,EAA6B,OAAdxJ,KAAK6R,OAAgB,KAAO7R,KAAK6R,OAAOrI,aACvDC,EAA8B,OAAdzJ,KAAK6R,OAAgB,KAAO7R,KAAK6R,OAAOpI,cAC9D0F,QAAQC,IAAI,SAAWyI,EAAI5S,SAASuE,EAAcC,IAEtD,OAAO3G,EAkBXmuB,YAAYpZ,EAAK8d,GACb,GAAIA,IAAMnG,EAAaE,MACnB,OAAOiG,EAEX,MAAMntB,EAAWqP,EAAI9K,OAAOpM,IAAIg1B,GAChC,OAAc,OAAXntB,EACQA,GAEXmtB,EAAEvoB,YAAcyK,EAAI9K,OAAOjM,OACrB60B,EAAE5Q,QAAQjd,WACZ6tB,EAAE5Q,QAAQS,gBAAgBxlB,MAC1B21B,EAAE5Q,QAAQgB,aAAY,IAE1BlO,EAAI9K,OAAON,IAAIkpB,GACX31B,KAAK+P,OACLZ,QAAQC,IAAI,yBAA2BumB,GAEpCA,GAGXQ,4BAA4Bte,EAAKoN,EAAiBF,EAASsL,EAAY+D,GACnE,GAAIp0B,KAAK+P,OAAS/P,KAAKk1B,YAAa,CAChC,MAAM3xB,EAAW,IAAI7D,EAAS2wB,EAAY+D,EAAY,GACtDjlB,QAAQC,IAAI,wCAA0CyI,EAAIG,SAAW,IAAM+M,EACxD,WAAa/kB,KAAK6R,OAAOgD,iBAAiBvR,QAAQC,IAEvD,OAAdvD,KAAK6R,QACL7R,KAAK6R,OAAOnB,2BAA2BylB,4BAA4Bn2B,KAAK6R,OAAQgG,EAAKwY,EAAY+D,EAAWnP,EAAiBF,GAIrI6S,yBAAyB/f,EAAKma,EAAYjN,EAASsL,EAAY+D,GAC3D,GAAIp0B,KAAK+P,OAAS/P,KAAKk1B,YAAa,CAChC,MAAM3xB,EAAW,IAAI7D,EAAS2wB,EAAY+D,EAAY,GACtDjlB,QAAQC,IAAI,qCAAuCyI,EAAIG,SAAW,IAAM+M,EACrD,WAAa/kB,KAAK6R,OAAOgD,iBAAiBvR,QAAQC,IAEvD,OAAdvD,KAAK6R,QACL7R,KAAK6R,OAAOnB,2BAA2BknB,yBAAyB53B,KAAK6R,OAAQgG,EAAKwY,EAAY+D,EAAWpC,EAAYjN,GAK7HuR,gBAAgBze,EAAK8d,EAAGtF,EAAY+D,EACLqH,EAAOhD,EAAW1T,GAC7C,GAAI/kB,KAAK+P,OAAS/P,KAAKk1B,YAAa,CAChC,MAAM3xB,EAAW,IAAI7D,EAAS2wB,EAAY+D,EAAY,GACtDjlB,QAAQC,IAAI,mBAAqBqpB,EAAY,IAAM1T,EAChC,WAAa/kB,KAAK6R,OAAOgD,iBAAiBvR,QAAQC,IAEvD,OAAdvD,KAAK6R,QACL7R,KAAK6R,OAAOnB,2BAA2B4lB,gBAAgBt2B,KAAK6R,OAAQgG,EAAKwY,EAAY+D,EAAWqH,EAAOhD,EAAW1T,oBC1qD9H,MAAM,IAACtL,EAAG,OAAEjP,EAAM,QAAEiX,EAAO,UAAEI,GAAa,EAAQ,KAC5CO,EAAM,EAAQ,MACd,cAAC1X,GAAiB,EAAQ,MAC1B,aAACka,GAAgB,EAAQ,KACzB,UAACna,GAAa,EAAQ,MACtB,gBAAC8Y,GAAmB,EAAQ,KAO5BiR,EAAiB,CAsBnBuB,IAAK,EAoBLpB,GAAI,EAoBJ8C,yBAA0B,EA+F1BX,oCAAqC,SAAUlnB,EAAMmV,GAMjD,GAAIyP,EAAe2D,2BAA2BpT,GAC1C,OAAO,EAGX,GAAInV,IAAS4kB,EAAeuB,KAIpBhR,EAAQG,mBAAoB,CAE5B,MAAMwW,EAAM,IAAI9W,EAChB,IAAI,IAAI1jB,EAAE,EAAEA,EAAE6jB,EAAQiB,MAAMllB,OAAOI,IAAK,CACpC,IAAIoL,EAAIyY,EAAQiB,MAAM9kB,GACtBoL,EAAI,IAAI7B,EAAU,CAACkZ,gBAAgBJ,EAAgBU,MAAO3X,GAC1DovB,EAAIjvB,IAAIH,GAEZyY,EAAU2W,EAKlB,MAAMR,EAAU1G,EAAemC,yBAAyB5R,GACxD,OAAOyP,EAAemH,qBAAqBT,KAAa1G,EAAeoH,6BAA6B7W,IAaxGkT,yBAA0B,SAASlT,GAC/B,IAAI,IAAI7jB,EAAE,EAAEA,EAAE6jB,EAAQiB,MAAMllB,OAAOI,IAE/B,GADU6jB,EAAQiB,MAAM9kB,GAClBqL,iBAAiB7B,EACnB,OAAO,EAGf,OAAO,GAaXytB,2BAA4B,SAASpT,GACjC,IAAI,IAAI7jB,EAAE,EAAEA,EAAE6jB,EAAQiB,MAAMllB,OAAOI,IAE/B,KADU6jB,EAAQiB,MAAM9kB,GAChBqL,iBAAiB7B,GACrB,OAAO,EAGf,OAAO,GAiJX8sB,2BAA4B,SAAS0D,GACjC,OAAO1G,EAAemD,mBAAmBuD,IAW7CtE,mBAAoB,SAASsE,GACzB,OAAS1G,EAAeqH,wBAAwBX,IAUpDW,wBAAyB,SAASX,GAC9B,IAAI,IAAIh6B,EAAE,EAAEA,EAAEg6B,EAAQp6B,OAAOI,IAEzB,GAAkB,IADLg6B,EAAQh6B,GACZJ,OACL,OAAO,EAGf,OAAO,GAYX66B,qBAAsB,SAAST,GAC3B,IAAI,IAAIh6B,EAAE,EAAEA,EAAEg6B,EAAQp6B,OAAOI,IAEzB,GADag6B,EAAQh6B,GACZJ,OAAO,EACZ,OAAO,EAGf,OAAO,GAWX42B,gBAAiB,SAASwD,GACtB,IAAInzB,EAAQ,KACZ,IAAI,IAAI7G,EAAE,EAAEA,EAAEg6B,EAAQp6B,OAAOI,IAAK,CAC9B,MAAMm1B,EAAO6E,EAAQh6B,GACrB,GAAc,OAAV6G,EACAA,EAAQsuB,OACL,GAAIA,IAAOtuB,EACd,OAAO,EAGf,OAAO,GAWX0uB,aAAc,SAASyE,GACnB,MAAMY,EAAMtH,EAAe2G,QAAQD,GACnC,OAAiB,IAAbY,EAAIh7B,OACGg7B,EAAIjb,WAEJuB,EAAIiB,oBAYnB8X,QAAS,SAASD,GACd,MAAMY,EAAM,IAAItxB,EAEhB,OADA0wB,EAAQ9wB,KAAK,SAASisB,GAAQyF,EAAIrb,GAAG4V,MAC9ByF,GAYXnF,yBAA0B,SAAS5R,GAC/B,MAAMgX,EAAe,IAAItiB,EAWzB,OAVAsiB,EAAahb,aAAe,SAASoR,GAAOtQ,EAAUsQ,EAAI5lB,MAAMa,YAAa+kB,EAAI3lB,UACjFuvB,EAAa/a,eAAiB,SAAST,EAAIC,GAAM,OAAOD,EAAGhU,MAAMa,cAAgBoT,EAAGjU,MAAMa,aAAemT,EAAG/T,QAAQ6N,OAAOmG,EAAGhU,UAC9HuY,EAAQiB,MAAM5b,KAAI,SAAS+nB,GACvB,IAAIkE,EAAO0F,EAAap7B,IAAIwxB,GACf,OAATkE,IACAA,EAAO,IAAI7rB,EACXuxB,EAAa7f,IAAIiW,EAAKkE,IAE1BA,EAAK5pB,IAAI0lB,EAAI3mB,QAEVuwB,EAAaxa,aAWxBya,iBAAkB,SAASjX,GACvB,MAAMlV,EAAI,IAAI4R,EASd,OARAsD,EAAQiB,MAAM5b,KAAI,SAASkC,GACvB,IAAI+pB,EAAOxmB,EAAElP,IAAI2L,EAAEC,OACN,OAAT8pB,IACAA,EAAO,IAAI7rB,EACXqF,EAAEqM,IAAI5P,EAAEC,MAAO8pB,IAEnBA,EAAK5pB,IAAIH,EAAEd,QAERqE,GAGX+rB,6BAA8B,SAAS7W,GACnC,MAAMnE,EAAS4T,EAAewH,iBAAiBjX,GAASnE,SACxD,IAAI,IAAI1f,EAAE,EAAEA,EAAE0f,EAAO9f,OAAOI,IACxB,GAAuB,IAAnB0f,EAAO1f,GAAGJ,OACV,OAAO,EAGf,OAAO,GAGX62B,mBAAoB,SAASuD,GACzB,IAAIt2B,EAAS,KACb,IAAI,IAAI1D,EAAE,EAAEA,EAAEg6B,EAAQp6B,OAAOI,IAAK,CAC9B,MACM+6B,EADOf,EAAQh6B,GACD2f,WACpB,GAAY,OAATjc,EACCA,EAASq3B,OACN,GAAGr3B,IAASq3B,EACf,OAAO7Z,EAAIiB,mBAGnB,OAAOze,IAIfjF,EAAOC,QAAU40B,iBC5iBjB,MAAM,IAAEjqB,EAAG,KAAEiP,EAAI,YAAEE,GAAgB,EAAQ,KAU3C,MAAM6J,EAELzJ,WACC,MAAME,EAAO,IAAIR,EAEjB,OADAxZ,KAAK+Z,eAAeC,GACbA,EAAKI,SAgBbif,SAASxnB,EAAQ2K,IAoBjBgc,eAAe3mB,EAAQ2K,GACtB,OAAOxc,KAGRua,kBAAkBM,EAAGC,GACpB,GAAU,OAAND,GAAcA,IAAM0I,EAAgBU,KACvC,OAAOnJ,EAER,GAAU,OAANA,GAAcA,IAAMyI,EAAgBU,KACvC,OAAOpJ,EAER,MAAMjW,EAAS,IAAIs3B,EAAIrhB,EAAGC,GAC1B,OAA4B,IAAxBlW,EAAOu3B,MAAMr7B,OACT8D,EAAOu3B,MAAM,GAEbv3B,EAIT2V,iBAAiBM,EAAGC,GACnB,GAAU,OAAND,EACH,OAAOC,EAER,GAAU,OAANA,EACH,OAAOD,EAER,GAAIA,IAAM0I,EAAgBU,MAAQnJ,IAAMyI,EAAgBU,KACvD,OAAOV,EAAgBU,KAExB,MAAMrf,EAAS,IAAIw3B,EAAGvhB,EAAGC,GACzB,OAA4B,IAAxBlW,EAAOu3B,MAAMr7B,OACT8D,EAAOu3B,MAAM,GAEbv3B,GAMV,MAAMy3B,UAAkB9Y,EAEvB1jB,YAAY+M,EAAWomB,EAAWiI,GACjCl7B,QACAC,KAAK4M,eAA0B9K,IAAd8K,GAA2B,EAAIA,EAChD5M,KAAKgzB,eAA0BlxB,IAAdkxB,GAA2B,EAAIA,EAChDhzB,KAAKi7B,oBAAoCn5B,IAAnBm5B,GAAuCA,EAG9D5B,SAASxnB,EAAQ2K,GAChB,MAAM1G,EAAW9V,KAAKi7B,eAAiBze,EAAe,KACtD,OAAO3K,EAAOwM,QAAQvI,EAAU9V,KAAK4M,UAAW5M,KAAKgzB,WAGtDjZ,eAAeC,GACdA,EAAKC,OAAOja,KAAK4M,UAAW5M,KAAKgzB,UAAWhzB,KAAKi7B,gBAGlD5gB,OAAOxR,GACN,OAAI7I,OAAS6I,GAEAA,aAAiBwzB,GAGtBr8B,KAAK4M,YAAc/D,EAAM+D,WAC9B5M,KAAKgzB,YAAcnqB,EAAMmqB,WACzBhzB,KAAKi7B,iBAAmBpyB,EAAMoyB,eAIlCh2B,WACC,MAAO,IAAMjF,KAAK4M,UAAY,IAAM5M,KAAKgzB,UAAY,MAQvDzP,EAAgBU,KAAO,IAAIoY,EAG3B,MAAMC,UAA4B/Y,EAEjC1jB,YAAYwW,GACXtW,QACAC,KAAKqW,gBAA4BvU,IAAfuU,EAA2B,EAAIA,EAGlDgjB,SAASxnB,EAAQ2K,GAChB,OAAO3K,EAAO+E,SAAS4F,EAAcxc,KAAKqW,YAG3CmiB,eAAe3mB,EAAQ2K,GACtB,OAAI3K,EAAO+E,SAAS4F,EAAcxc,KAAKqW,YAC/BkN,EAAgBU,KAEhB,KAITsY,UAAU1zB,GACT,OAAO7I,KAAKqW,WAAaxN,EAAMwN,WAGhC0D,eAAeC,GACdA,EAAKC,OAAOja,KAAKqW,YAGlBgE,OAAOxR,GACN,OAAI7I,OAAS6I,GAEAA,aAAiByzB,GAGtBt8B,KAAKqW,aAAexN,EAAMwN,WAInCpR,WACC,MAAO,IAAMjF,KAAKqW,WAAa,WAGhCkE,kCAAkC/M,GACjC,MAAM5I,EAAS,GAMf,OALA4I,EAAIoT,SAASxW,KAAK,SAASoC,GACtBA,aAAmB8vB,GACtB13B,EAAOpD,KAAKgL,MAGP5H,GAIT,MAAMs3B,UAAY3Y,EAKjB1jB,YAAYgb,EAAGC,GACd/a,QACA,MAAMy8B,EAAW,IAAIjyB,EACjBsQ,aAAaqhB,EAChBrhB,EAAEshB,MAAM/xB,KAAI,SAASgL,GACpBonB,EAAS/vB,IAAI2I,MAGdonB,EAAS/vB,IAAIoO,GAEVC,aAAaohB,EAChBphB,EAAEqhB,MAAM/xB,KAAI,SAASgL,GACpBonB,EAAS/vB,IAAI2I,MAGdonB,EAAS/vB,IAAIqO,GAEd,MAAM2hB,EAAuBH,EAAoBI,2BAA2BF,GAC5E,GAAIC,EAAqB37B,OAAS,EAAG,CAEpC,IAAI67B,EAAU,KACdF,EAAqBryB,KAAK,SAASoN,IACrB,OAAVmlB,GAAkBnlB,EAAEnB,WAAWsmB,EAAQtmB,cACzCsmB,EAAUnlB,MAGZglB,EAAS/vB,IAAIkwB,GAEd38B,KAAKm8B,MAAQr1B,MAAM81B,KAAKJ,EAAS5b,UAGlCvG,OAAOxR,GACN,OAAI7I,OAAS6I,GAEAA,aAAiBqzB,GAGtBxiB,EAAY1Z,KAAKm8B,MAAOtzB,EAAMszB,OAIvCpiB,eAAeC,GACdA,EAAKC,OAAOja,KAAKm8B,MAAO,OAUzB9C,SAASxnB,EAAQ2K,GAChB,IAAK,IAAItb,EAAI,EAAGA,EAAIlB,KAAKm8B,MAAMr7B,OAAQI,IACtC,IAAKlB,KAAKm8B,MAAMj7B,GAAGm4B,SAASxnB,EAAQ2K,GACnC,OAAO,EAGT,OAAO,EAGRgc,eAAe3mB,EAAQ2K,GACtB,IAAIqgB,GAAU,EACd,MAAML,EAAW,GACjB,IAAK,IAAIt7B,EAAI,EAAGA,EAAIlB,KAAKm8B,MAAMr7B,OAAQI,IAAK,CAC3C,MAAMsL,EAAUxM,KAAKm8B,MAAMj7B,GACrB47B,EAAYtwB,EAAQgsB,eAAe3mB,EAAQ2K,GAEjD,GADAqgB,GAAYC,IAActwB,EACR,OAAdswB,EAEH,OAAO,KACGA,IAAcvZ,EAAgBU,MAExCuY,EAASh7B,KAAKs7B,GAGhB,IAAKD,EACJ,OAAO78B,KAER,GAAwB,IAApBw8B,EAAS17B,OAEZ,OAAOyiB,EAAgBU,KAExB,IAAIrf,EAAS,KAIb,OAHA43B,EAASpyB,KAAI,SAASgL,GACrBxQ,EAAoB,OAAXA,EAAkBwQ,EAAImO,EAAgByX,WAAWp2B,EAAQwQ,MAE5DxQ,EAGRK,WACC,MAAMxB,EAAIzD,KAAKm8B,MAAM/xB,KAAIgL,GAAKA,EAAEnQ,aAChC,OAAQxB,EAAE3C,OAAS,EAAI2C,EAAE+D,MAAM,GAAK/D,GAAGuG,KAAK,OAK9C,MAAMoyB,UAAW7Y,EAKhB1jB,YAAYgb,EAAGC,GACd/a,QACA,MAAMy8B,EAAW,IAAIjyB,EACjBsQ,aAAauhB,EAChBvhB,EAAEshB,MAAM/xB,KAAI,SAASgL,GACpBonB,EAAS/vB,IAAI2I,MAGdonB,EAAS/vB,IAAIoO,GAEVC,aAAashB,EAChBthB,EAAEqhB,MAAM/xB,KAAI,SAASgL,GACpBonB,EAAS/vB,IAAI2I,MAGdonB,EAAS/vB,IAAIqO,GAGd,MAAM2hB,EAAuBH,EAAoBI,2BAA2BF,GAC5E,GAAIC,EAAqB37B,OAAS,EAAG,CAEpC,MAAM2C,EAAIg5B,EAAqBM,MAAK,SAASliB,EAAGC,GAC/C,OAAOD,EAAE0hB,UAAUzhB,MAEd6hB,EAAUl5B,EAAEA,EAAE3C,OAAO,GAC3B07B,EAAS/vB,IAAIkwB,GAEd38B,KAAKm8B,MAAQr1B,MAAM81B,KAAKJ,EAAS5b,UAGlCvG,OAAOxR,GACN,OAAI7I,OAAS6I,GAEAA,aAAiBuzB,GAGtB1iB,EAAY1Z,KAAKm8B,MAAOtzB,EAAMszB,OAIvCpiB,eAAeC,GACdA,EAAKC,OAAOja,KAAKm8B,MAAO,MAQzB9C,SAASxnB,EAAQ2K,GAChB,IAAK,IAAItb,EAAI,EAAGA,EAAIlB,KAAKm8B,MAAMr7B,OAAQI,IACtC,GAAIlB,KAAKm8B,MAAMj7B,GAAGm4B,SAASxnB,EAAQ2K,GAClC,OAAO,EAGT,OAAO,EAGRgc,eAAe3mB,EAAQ2K,GACtB,IAAIqgB,GAAU,EACd,MAAML,EAAW,GACjB,IAAK,IAAIt7B,EAAI,EAAGA,EAAIlB,KAAKm8B,MAAMr7B,OAAQI,IAAK,CAC3C,MAAMsL,EAAUxM,KAAKm8B,MAAMj7B,GACrB47B,EAAYtwB,EAAQgsB,eAAe3mB,EAAQ2K,GAEjD,GADAqgB,GAAYC,IAActwB,EACtBswB,IAAcvZ,EAAgBU,KAEjC,OAAOV,EAAgBU,KACC,OAAd6Y,GAEVN,EAASh7B,KAAKs7B,GAGhB,IAAKD,EACJ,OAAO78B,KAER,GAAwB,IAApBw8B,EAAS17B,OAEZ,OAAO,KAMR,OAHA07B,EAASpyB,KAAI,SAASgL,GACrB,OAAyBA,KAFX,KAOhBnQ,WACC,MAAMxB,EAAIzD,KAAKm8B,MAAM/xB,KAAIgL,GAAKA,EAAEnQ,aAChC,OAAQxB,EAAE3C,OAAS,EAAI2C,EAAE+D,MAAM,GAAK/D,GAAGuG,KAAK,OAI9CrK,EAAOC,QAAU,CAChB2jB,gBAAAA,EACA+Y,oBAAAA,EACAD,UAAAA,iBCnYD,MAAM,MAAC78B,GAAS,EAAQ,MAClB,YAACoI,GAAe,EAAQ,MACxB,UAACy0B,EAAS,oBAAEC,GAAuB,EAAQ,KAejD,MAAMpV,EACFrnB,YAAY8E,GAER,GAAIA,MAAAA,EACA,KAAM,yBAEV3E,KAAK2E,OAASA,EAEd3E,KAAKqN,WAAY,EACjBrN,KAAKyN,MAAQ,MAMrByZ,EAAW/c,QAAU,EACrB+c,EAAWyG,MAAQ,EACnBzG,EAAW0G,KAAO,EAElB1G,EAAW2G,UAAY,EACvB3G,EAAW6G,KAAO,EAClB7G,EAAW8G,OAAS,EAEpB9G,EAAW+G,IAAM,EACjB/G,EAAWgH,QAAU,EACrBhH,EAAWiH,SAAW,EACtBjH,EAAW4G,WAAa,GAExB5G,EAAW4I,mBAAqB,CACpB,UACA,UACA,QACA,OACA,YACA,OACA,SACA,MACA,UACA,WACA,cAGZ5I,EAAW8V,mBAAqB,CACxBzV,kBAAmBL,EAAW/c,QAC9Bkd,gBAAiBH,EAAWyG,MAC5BhjB,eAAgBuc,EAAW0G,KAC3BpG,oBAAqBN,EAAW2G,UAChC1G,eAAgBD,EAAW6G,KAC3BzG,iBAAkBJ,EAAW8G,OAC7B5G,cAAeF,EAAW+G,IAC1BrjB,iBAAkBsc,EAAWgH,QAC7BrjB,mBAAoBqc,EAAWiH,SAC/B1G,8BAA+BP,EAAW4G,YA2FlD,MAAMhjB,UAAoCoc,EACtCrnB,YAAY8E,GACR5E,MAAM4E,IAiDd,MAAMyiB,UAAsBF,EACxBrnB,YAAY8E,EAAQ6I,GAChBzN,MAAM4E,GACN3E,KAAK+yB,kBAAoB7L,EAAW+G,IAChCzgB,MAAAA,EACAxN,KAAKyN,MAAQD,GAEbxN,KAAKyN,MAAQ,IAAI7F,EACjB5H,KAAKyN,MAAMvF,OAAO1I,EAAMyI,eAIhC0qB,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAOl9B,KAAKyN,MAAMzL,SAASkQ,GAG/BjN,WACI,OAAOjF,KAAKyN,MAAMxI,YAwD1BtF,EAAOC,QAAU,CACbsnB,WAAAA,EACAC,eAnNJ,cAA6BD,EACzBrnB,YAAY8E,EAAQ8I,GAChB1N,MAAM4E,GAEN3E,KAAKm9B,OAAS1vB,EACdzN,KAAKyN,MAAQzN,KAAKo9B,YAClBp9B,KAAK+yB,kBAAoB7L,EAAW6G,KAGxCqP,YACI,MAAM35B,EAAI,IAAImE,EAEd,OADAnE,EAAEyE,OAAOlI,KAAKm9B,QACP15B,EAGXkvB,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAOl9B,KAAKm9B,SAAWjrB,EAG3BjN,WACI,OAAOjF,KAAKm9B,SAgMhB/V,cAAAA,EACAxc,iBAxDJ,cAA+Bwc,EAC3BvnB,YAAY8E,EAAQ6I,GAChBzN,MAAM4E,EAAQ6I,GACdxN,KAAK+yB,kBAAoB7L,EAAWgH,QAGxCyE,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAOhrB,GAAU+qB,GAAkB/qB,GAAUgrB,IACpCn9B,MAAM4yB,QAAQzgB,EAAQ+qB,EAAgBC,GAGnDj4B,WACI,MAAO,IAAMlF,MAAMkF,aA6CvB0F,eA7LJ,cAA6Buc,EACzBrnB,YAAYw9B,EAAWzwB,EAAWyJ,EAAYlJ,GAC1CpN,MAAMs9B,GAENr9B,KAAK4M,UAAYA,EACjB5M,KAAKqW,WAAaA,EAElBrW,KAAKmN,YAAcA,EACnBnN,KAAK+yB,kBAAoB7L,EAAW0G,KACpC5tB,KAAKqN,WAAY,EAGrBslB,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAO,IAiLX5V,iBApGJ,cAA+BJ,EAC3BrnB,YAAY8E,EAAQiI,EAAW0R,EAAa2c,GACxCl7B,MAAM4E,GACN3E,KAAK+yB,kBAAoB7L,EAAW8G,OACpChuB,KAAK4M,UAAYA,EACjB5M,KAAKse,iBAA4Bxc,IAAdwc,GAA2B,EAAIA,EAClDte,KAAKi7B,oBAAkCn5B,IAAjBm5B,GAAqCA,EAC3Dj7B,KAAKqN,WAAY,EAGrBslB,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAO,EAGXj4B,WACI,MAAO,UAAYjF,KAAK4M,UAAY,IAAM5M,KAAKse,cAsFnDiJ,kBA9KJ,cAAgCL,EAC5BrnB,YAAY8E,EAAQynB,GAChBrsB,MAAM4E,GACN3E,KAAK+yB,kBAAoB7L,EAAW/c,QACpCnK,KAAKqN,WAAY,EACjBrN,KAAKosB,0BAA4BA,EAGrCuG,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAO,EAGXj4B,WACI,MAAO,YAkKXoiB,gBA7JJ,cAA8BH,EAC1BrnB,YAAY8E,EAAQhD,EAAOC,GACvB7B,MAAM4E,GACN3E,KAAK+yB,kBAAoB7L,EAAWyG,MACpC3tB,KAAK2B,MAAQA,EACb3B,KAAK4B,KAAOA,EACZ5B,KAAKyN,MAAQzN,KAAKo9B,YAGtBA,YACI,MAAM35B,EAAI,IAAImE,EAEd,OADAnE,EAAE2E,SAASpI,KAAK2B,MAAO3B,KAAK4B,MACrB6B,EAGXkvB,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAOhrB,GAAUlS,KAAK2B,OAASuQ,GAAUlS,KAAK4B,KAGlDqD,WACI,MAAO,IAAMqC,OAAOyC,aAAa/J,KAAK2B,OAAS,OAAS2F,OAAOyC,aAAa/J,KAAK4B,MAAQ,MA0I7FiJ,mBA7CJ,cAAiCqc,EAC7BrnB,YAAY8E,GACR5E,MAAM4E,GACN3E,KAAK+yB,kBAAoB7L,EAAWiH,SAGxCwE,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAOhrB,GAAU+qB,GAAkB/qB,GAAUgrB,EAGjDj4B,WACI,MAAO,MAmCXuiB,oBAhIJ,cAAkC1c,EAC9BjL,YAAY8E,EAAQiI,EAAWomB,EAAWiI,GACtCl7B,MAAM4E,GACN3E,KAAK+yB,kBAAoB7L,EAAW2G,UACpC7tB,KAAK4M,UAAYA,EACjB5M,KAAKgzB,UAAYA,EACjBhzB,KAAKi7B,eAAiBA,EACtBj7B,KAAKqN,WAAY,EAGrBslB,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAO,EAGXpC,eACI,OAAO,IAAIuB,EAAUr8B,KAAK4M,UAAW5M,KAAKgzB,UAAWhzB,KAAKi7B,gBAG9Dh2B,WACI,MAAO,QAAUjF,KAAK4M,UAAY,IAAM5M,KAAKgzB,YA8GjDvL,8BAhCJ,cAA4C3c,EACxCjL,YAAY8E,EAAQ0R,GAChBtW,MAAM4E,GACN3E,KAAK+yB,kBAAoB7L,EAAW4G,WACpC9tB,KAAKqW,WAAaA,EAClBrW,KAAKqN,WAAY,EAGrBslB,QAAQzgB,EAAQ+qB,EAAgBC,GAC5B,OAAO,EAGXpC,eACI,OAAO,IAAIwB,EAAoBt8B,KAAKqW,YAGxCpR,WACI,OAAOjF,KAAKqW,WAAa,WAgB7BvL,4BAAAA,kBCxSJlL,EAAQwiB,IAAM,EAAd,KACAxiB,EAAQ8R,gBAAkB,EAA1B,KACA9R,EAAQwwB,kBAAoB,EAA5B,KACAxwB,EAAQ09B,mBAAqB,EAA7B,KACA,sBCJA,MAAM,IAAC/yB,GAAO,EAAQ,MAChB,SAACglB,GAAY,EAAQ,MACrB,mBAACzI,GAAsB,EAAQ,MAC/B,aAAClC,GAAgB,EAAQ,KACzB,cAAC2Y,GAAiB,EAAQ,MAC1B,mBAACC,GAAsB,EAAQ,KAuJrC79B,EAAOC,QArJP,MACCC,YAAY01B,EAAevd,GAqB1B,QApBiBlW,IAAbkW,IACHA,EAAW,GAKZhY,KAAKu1B,cAAgBA,EACrBv1B,KAAKgY,SAAWA,EAKhBhY,KAAKy9B,QAAU,IAAIlzB,EACnBvK,KAAK0wB,GAAK,KAMV1wB,KAAKq1B,eAAgB,EACjBE,aAAyBzO,GAExByO,EAAcnI,qBAAsB,CACvCptB,KAAKq1B,eAAgB,EACrB,MAAMqI,EAAkB,IAAInO,EAAS,KAAM,IAAI3K,GAC/C8Y,EAAgBhM,MAAQ,GACxBgM,EAAgBrM,eAAgB,EAChCqM,EAAgB5H,qBAAsB,EACtC91B,KAAK0wB,GAAKgN,GAebpI,wBAAwBjf,GACvB,IAAMrW,KAAkB,cACvB,KAAM,6DAGP,OAAIqW,EAAa,GAAKA,GAAcrW,KAAK0wB,GAAGgB,MAAM5wB,OAC1C,KAEDd,KAAK0wB,GAAGgB,MAAMrb,IAAe,KAarCof,wBAAwBpf,EAAYgW,GACnC,IAAMrsB,KAAkB,cACvB,KAAM,6DAEHqW,EAAa,IASjBrW,KAAK0wB,GAAGgB,MAAMrb,GAAcgW,GAoB7BsR,iBAAiBtI,GAChB,GAAIr1B,KAAKq1B,gBAAgBA,EAAe,CAEvC,GADAr1B,KAAKy9B,QAAU,IAAIlzB,EACf8qB,EAAe,CAClB,MAAMqI,EAAkB,IAAInO,EAAS,KAAM,IAAI3K,GAC/C8Y,EAAgBhM,MAAQ,GACxBgM,EAAgBrM,eAAgB,EAChCqM,EAAgB5H,qBAAsB,EACtC91B,KAAK0wB,GAAKgN,OAEV19B,KAAK0wB,GAAK,KAEX1wB,KAAKq1B,cAAgBA,GAOvBuI,eAEC,OADa59B,KAAKy9B,QAAQ7c,SACdmc,MAAK,SAASliB,EAAGC,GAC5B,OAAOD,EAAEzN,YAAc0N,EAAE1N,eAI3BnI,SAASuE,EAAcC,GAGtB,OAFAD,EAAeA,GAAgB,KAC/BC,EAAgBA,GAAiB,KACjB,OAAZzJ,KAAK0wB,GACD,GAEW,IAAI6M,EAAcv9B,KAAMwJ,EAAcC,GACvCxE,WAGnBksB,gBACC,OAAgB,OAAZnxB,KAAK0wB,GACD,GAEW,IAAI8M,EAAmBx9B,MACxBiF,WAGf8H,aACH,OAAO/M,KAAKy9B,yBCxJd,MAAMhZ,EAAQ,EAAQ,KAKtB,MAAM8Y,EACF19B,YAAYgY,EAAKrO,EAAcC,GAC3BzJ,KAAK6X,IAAMA,EACX7X,KAAKwJ,aAAeA,GAAgB,GACpCxJ,KAAKyJ,cAAgBA,GAAiB,GAG1CxE,WACG,GAAmB,OAAhBjF,KAAK6X,IAAI6Y,GACR,OAAO,KAEX,IAAImN,EAAM,GACV,MAAM9wB,EAAS/M,KAAK6X,IAAI+lB,eACxB,IAAI,IAAI18B,EAAE,EAAGA,EAAE6L,EAAOjM,OAAQI,IAAK,CAC/B,MAAMuC,EAAIsJ,EAAO7L,GACjB,GAAa,OAAVuC,EAAEiuB,MAAc,CACd,MAAMvwB,EAAIsC,EAAEiuB,MAAM5wB,OAClB,IAAI,IAAImJ,EAAE,EAAEA,EAAE9I,EAAE8I,IAAK,CACjB,MAAM5I,EAAIoC,EAAEiuB,MAAMznB,IAAM,KACjB,OAAJ5I,GAA8B,aAAlBA,EAAE+L,cACbywB,EAAMA,EAAIxc,OAAOrhB,KAAK89B,eAAer6B,IACrCo6B,EAAMA,EAAIxc,OAAO,KACjBwc,EAAMA,EAAIxc,OAAOrhB,KAAK+9B,aAAa9zB,IACnC4zB,EAAMA,EAAIxc,OAAO,MACjBwc,EAAMA,EAAIxc,OAAOrhB,KAAK89B,eAAez8B,IACrCw8B,EAAMA,EAAIxc,OAAO,SAKlC,OAAoB,IAAbwc,EAAI/8B,OAAa,KAAO+8B,EAGlCE,aAAa78B,GACT,OAAQ,IAAJA,EACO,MACoB,OAArBlB,KAAKwJ,cAA6C,OAArBxJ,KAAKyJ,cACjCzJ,KAAKwJ,aAAatI,EAAE,IAAMlB,KAAKyJ,cAAcvI,EAAE,GAE/CoG,OAAOyC,aAAa7I,EAAE,GAIrC48B,eAAer6B,GACX,MAAMu6B,GAAiBv6B,EAAE4tB,cAAgB,IAAM,IAAM,IAAM5tB,EAAE2J,aAAgB3J,EAAEqyB,oBAAsB,IAAM,IAC3G,OAAGryB,EAAE4tB,cACoB,OAAjB5tB,EAAEuyB,WACKgI,EAAe,KAAOvZ,EAAMjF,cAAc/b,EAAEuyB,YAE5CgI,EAAe,KAAOv6B,EAAEuuB,WAAW/sB,WAGvC+4B,GAenBr+B,EAAOC,QAAU,CAAE29B,cAAAA,EAAgBC,mBAVnC,cAAiCD,EAC7B19B,YAAYgY,GACR9X,MAAM8X,EAAK,MAGfkmB,aAAa78B,GACT,MAAO,IAAMoG,OAAOyC,aAAa7I,GAAK,sBCnE9C,MAAM,aAAC0jB,GAAgB,EAAQ,KACzB,KAACpL,EAAI,IAAEjP,GAAO,EAAQ,KAyC5B,MAAMglB,EACL1vB,YAAYuN,EAAa2X,GA8CxB,OA7CoB,OAAhB3X,IACHA,GAAe,GAEA,OAAZ2X,IACHA,EAAU,IAAIH,GAEf5kB,KAAKoN,YAAcA,EACnBpN,KAAK+kB,QAAUA,EAKf/kB,KAAK0xB,MAAQ,KACb1xB,KAAKqxB,eAAgB,EAMrBrxB,KAAKgyB,WAAa,EAClBhyB,KAAKqkB,oBAAsB,KAO3BrkB,KAAK81B,qBAAsB,EAiB3B91B,KAAKg2B,WAAa,KACXh2B,KAORi+B,YACC,MAAM5H,EAAO,IAAI9rB,EACjB,GAAqB,OAAjBvK,KAAK+kB,QACR,IAAK,IAAI7jB,EAAI,EAAGA,EAAIlB,KAAK+kB,QAAQjkB,OAAQI,IAAK,CAC7C,MAAMoL,EAAItM,KAAK+kB,QAAQ7jB,GACvBm1B,EAAK5pB,IAAIH,EAAEd,KAGb,OAAoB,IAAhB6qB,EAAKv1B,OACD,KAEAu1B,EAiBThc,OAAOxR,GAEN,OAAO7I,OAAS6I,GACbA,aAAiB0mB,GACjBvvB,KAAK+kB,QAAQ1K,OAAOxR,EAAMkc,SAG9B9f,WACC,IAAIxB,EAASzD,KAAKoN,YAAc,IAAMpN,KAAK+kB,QAQ3C,OAPG/kB,KAAKqxB,gBACP5tB,GAAQ,KACgB,OAApBzD,KAAKg2B,WACRvyB,GAAQzD,KAAKg2B,WAEbvyB,GAAQzD,KAAKgyB,YAERvuB,EAGRqW,WACC,MAAME,EAAO,IAAIR,EAEjB,OADAQ,EAAKC,OAAOja,KAAK+kB,SACV/K,EAAKI,UAIdza,EAAOC,QAAU,CAAE2vB,SAAAA,EAAUgF,eAhJ7B,MACC10B,YAAY+4B,EAAMptB,GACjBxL,KAAKwL,IAAMA,EACXxL,KAAK44B,KAAOA,EAGb3zB,WACC,MAAO,IAAMjF,KAAK44B,KAAO,KAAO54B,KAAKwL,IAAM,qBCb7C5L,EAAQs+B,IAAM,EAAd,KACA,qBACA,0BACA,qCCHA,MAAM,OAAC1zB,GAAU,EAAQ,MACnB,cAAC2zB,GAAiB,EAAQ,MAC1B,SAACz+B,GAAY,EAAQ,KAiG3BC,EAAOC,QA3EP,cAAsCu+B,EACrCt+B,YAAYu+B,GACXr+B,QACAq+B,EAAYA,IAAa,EAEzBp+B,KAAKo+B,UAAYA,EAGlB9H,gBAAgB+H,EAAYxmB,EAAKwY,EAAY+D,EAAWqH,EAAOhD,EAAW1T,GACzE,GAAI/kB,KAAKo+B,YAAc3C,EACtB,OAED,MAAMjrB,EAAM,qBACXxQ,KAAKs+B,uBAAuBD,EAAYxmB,GACxC,eACA7X,KAAK62B,mBAAmB4B,EAAW1T,GACnC,YACAsZ,EAAWxpB,iBAAiBvR,QAAQ,IAAI5D,EAAS2wB,EAAY+D,IAAc,IAC5EiK,EAAWnpB,qBAAqB1E,GAGjC2lB,4BAA4BkI,EAAYxmB,EAAKwY,EAAY+D,EAAWnP,EAAiBF,GACpF,MAAMvU,EAAM,iCACXxQ,KAAKs+B,uBAAuBD,EAAYxmB,GACxC,YACAwmB,EAAWxpB,iBAAiBvR,QAAQ,IAAI5D,EAAS2wB,EAAY+D,IAAc,IAC5EiK,EAAWnpB,qBAAqB1E,GAGjConB,yBAAyByG,EAAYxmB,EAAKwY,EAAY+D,EAAWpC,EAAYjN,GAC5E,MAAMvU,EAAM,8BACXxQ,KAAKs+B,uBAAuBD,EAAYxmB,GACxC,YACAwmB,EAAWxpB,iBAAiBvR,QAAQ,IAAI5D,EAAS2wB,EAAY+D,IAAc,IAC5EiK,EAAWnpB,qBAAqB1E,GAGjC8tB,uBAAuBD,EAAYxmB,GAClC,MAAMG,EAAWH,EAAIG,SACfpL,EAAYiL,EAAI0d,cAAc3oB,UAE9BmF,EAAYssB,EAAWtsB,UAC7B,GAAInF,EAAY,GAAKA,GAAamF,EAAUjR,OAC3C,MAAO,GAAKkX,EAEb,MAAMX,EAAWtF,EAAUnF,IAAc,KACzC,OAAiB,OAAbyK,GAAyC,IAApBA,EAASvW,OAC1B,GAAKkX,EAEN,GAAGA,MAAaX,KAcxBwf,mBAAmB0H,EAAcxZ,GAChC,GAAqB,OAAjBwZ,EACH,OAAOA,EAER,MAAM35B,EAAS,IAAI4F,EACnB,IAAK,IAAItJ,EAAI,EAAGA,EAAI6jB,EAAQiB,MAAMllB,OAAQI,IACzC0D,EAAO6H,IAAIsY,EAAQiB,MAAM9kB,GAAGsK,KAE7B,MAAO,IAAI5G,EAAOgc,SAAS5W,KAAK,oBC1FlC,MAAMm0B,EACFxtB,YAAY0tB,EAAYG,EAAiBz4B,EAAMC,EAAQwK,EAAK/L,IAG5D6xB,gBAAgB+H,EAAYxmB,EAAKwY,EAAY+D,EAAWqH,EAAOhD,EAAW1T,IAG1EoR,4BAA4BkI,EAAYxmB,EAAKwY,EAAY+D,EAAWnP,EAAiBF,IAGrF6S,yBAAyByG,EAAYxmB,EAAKwY,EAAY+D,EAAWpC,EAAYjN,KAiBjF,MAAMjI,UAA6BqhB,EAC/Bt+B,cACIE,QAGJ4Q,YAAY0tB,EAAYG,EAAiBz4B,EAAMC,EAAQwK,EAAK/L,GACxD0K,QAAQqsB,MAAM,QAAUz1B,EAAO,IAAMC,EAAS,IAAMwK,IAQ5DsM,EAAqBG,SAAW,IAAIH,EA6BpCnd,EAAOC,QAAU,CAACu+B,cAAAA,EAAerhB,qBAAAA,EAAsBC,mBA3BvD,cAAiCohB,EAC7Bt+B,YAAY4+B,GAER,GADA1+B,QACgB,OAAZ0+B,EACA,KAAM,YAGV,OADAz+B,KAAKy+B,UAAYA,EACVz+B,KAGX2Q,YAAY0tB,EAAYG,EAAiBz4B,EAAMC,EAAQwK,EAAK/L,GACxDzE,KAAKy+B,UAAUr0B,KAAIwG,GAAKA,EAAED,YAAY0tB,EAAYG,EAAiBz4B,EAAMC,EAAQwK,EAAK/L,KAG1F6xB,gBAAgB+H,EAAYxmB,EAAKwY,EAAY+D,EAAWqH,EAAOhD,EAAW1T,GACtE/kB,KAAKy+B,UAAUr0B,KAAIwG,GAAKA,EAAE0lB,gBAAgB+H,EAAYxmB,EAAKwY,EAAY+D,EAAWqH,EAAOhD,EAAW1T,KAGxGoR,4BAA4BkI,EAAYxmB,EAAKwY,EAAY+D,EAAWnP,EAAiBF,GACjF/kB,KAAKy+B,UAAUr0B,KAAIwG,GAAKA,EAAEulB,4BAA4BkI,EAAYxmB,EAAKwY,EAAY+D,EAAWnP,EAAiBF,KAGnH6S,yBAAyByG,EAAYxmB,EAAKwY,EAAY+D,EAAWpC,EAAYjN,GACzE/kB,KAAKy+B,UAAUr0B,KAAIwG,GAAKA,EAAEgnB,yBAAyByG,EAAYxmB,EAAKwY,EAAY+D,EAAWpC,EAAYjN,uBCvE/G,MAAM,MAACvlB,GAAS,EAAQ,MAClB,qBAACi1B,EAAoB,uBAAEiK,EAAsB,yBAAEC,EAAwB,2BAAEC,GAA8B,EAAQ,MAC/G,SAACvY,GAAY,EAAQ,MACrB,SAAC3mB,EAAQ,YAAEkI,GAAe,EAAQ,KA4BxC,MAAM6J,UA1BN,MAEIlR,MAAM89B,IAGNrrB,cAAcqrB,IAGd9uB,QAAQ8uB,EAAY55B,IAGpBxD,KAAKo9B,IAGL/oB,oBAAoB+oB,IAGpBQ,YAAYR,MAUZx+B,cACIE,QAQAC,KAAK8+B,mBAAoB,EASzB9+B,KAAK++B,gBAAkB,EACvB/+B,KAAKg/B,gBAAkB,KACvBh/B,KAAKi/B,kBAAoB,KACzBj/B,KAAKk/B,eAAiB,EAO1B3+B,MAAM89B,GACFr+B,KAAKm/B,kBAAkBd,GAS3Be,oBAAoBf,GAChBr+B,KAAK8+B,mBAAoB,EAG7BxpB,oBAAoB+oB,GAChB,OAAOr+B,KAAK8+B,kBAQhBK,kBAAkBd,GACdr+B,KAAK8+B,mBAAoB,EACzB9+B,KAAKg/B,gBAAkB,KACvBh/B,KAAK++B,gBAAkB,EAO3BhsB,YAAYsrB,GACRr+B,KAAKm/B,kBAAkBd,GAsB3BQ,YAAYR,EAAY55B,GAGjBzE,KAAKsV,oBAAoB+oB,KAG5Br+B,KAAKo/B,oBAAoBf,GACpB55B,aAAagwB,EACdz0B,KAAKq/B,0BAA0BhB,EAAY55B,GACnCA,aAAai6B,EACrB1+B,KAAKs/B,oBAAoBjB,EAAY55B,GAC7BA,aAAak6B,EACrB3+B,KAAKu/B,sBAAsBlB,EAAY55B,IAEvC0K,QAAQC,IAAI,mCAAqC3K,EAAE5E,YAAY4G,MAC/D0I,QAAQC,IAAI3K,EAAE4K,OACdgvB,EAAWnpB,qBAAqBzQ,EAAE0Z,oBAAqB1Z,EAAE+6B,aAAc/6B,KAa/E8K,QAAQ8uB,EAAY55B,GACZzE,KAAK++B,iBAAiBV,EAAWrpB,iBAAiB9U,OACzB,OAAzBF,KAAKg/B,iBAA4Bh/B,KAAKg/B,gBAAgBvrB,QAAQ4qB,EAAW9xB,QAAQ,GAKjF8xB,EAAWz9B,UAEfZ,KAAK++B,eAAiBV,EAAWvwB,OAAO5N,MACX,OAAzBF,KAAKg/B,kBACLh/B,KAAKg/B,gBAAkB,IAE3Bh/B,KAAKg/B,gBAAgBx9B,KAAK68B,EAAW9xB,OACrC,MAAMkzB,EAAYz/B,KAAK0/B,oBAAoBrB,GAC3Cr+B,KAAK2/B,aAAatB,EAAYoB,GAkDlCx+B,KAAKo9B,GAED,GAAIr+B,KAAKsV,oBAAoB+oB,GACzB,OAEJ,MAAM56B,EAAI46B,EAAWpwB,QAAQ9C,IAAI4B,OAAOsxB,EAAW9xB,OAC7CqzB,EAAKvB,EAAWxpB,iBAAiB9T,GAAG,GAEpCiW,EAAaqnB,EAAWlzB,IAAI6L,WAAWvT,GAC7C,GAAGuT,EAAWhV,SAAS49B,GAGnB,OAFA5/B,KAAKi/B,kBAAoB,UACzBj/B,KAAKk/B,eAAiB7Y,EAASsJ,sBAE5B,GAAI3Y,EAAWhV,SAASxC,EAAM2K,SACH,OAA3BnK,KAAKi/B,oBAGJj/B,KAAKi/B,kBAAoBZ,EAAWlsB,KACpCnS,KAAK6/B,gBAAkBxB,EAAWnhB,mBAI1C,OAAQzZ,EAAEmsB,WACV,KAAKvJ,EAASkI,YACd,KAAKlI,EAASoI,iBACd,KAAKpI,EAASmI,iBACd,KAAKnI,EAASyI,gBAEV,GAA6C,OAAzC9uB,KAAK8/B,oBAAoBzB,GACzB,OAEA,MAAM,IAAIK,EAAuBL,GAEzC,KAAKhY,EAAS0I,eACd,KAAK1I,EAASwI,eACV7uB,KAAK+/B,oBAAoB1B,GACzB,MAAM2B,EAAY,IAAIp4B,EACtBo4B,EAAUp3B,OAAOy1B,EAAWnnB,qBAC5B,MAAM+oB,EAAiCD,EAAUp3B,OAAO5I,KAAK0/B,oBAAoBrB,IACjFr+B,KAAK2/B,aAAatB,EAAY4B,IAgBtCZ,0BAA0BhB,EAAY55B,GAClC,MAAMxE,EAASo+B,EAAWxpB,iBAC1B,IAAIhH,EAGIA,EAFM,OAAX5N,EACKwE,EAAEy7B,WAAWz+B,OAAOjC,EAAMwB,IAClB,QAEAf,EAAOqD,QAAQ,IAAI5D,EAAS+E,EAAEy7B,WAAW3+B,WAAYkD,EAAE0Q,eAAe5T,aAG1E,kBAEZ,MAAMiP,EAAM,kCAAoCxQ,KAAKmgC,iBAAiBtyB,GACtEwwB,EAAWnpB,qBAAqB1E,EAAK/L,EAAE0Q,eAAgB1Q,GAY3D66B,oBAAoBjB,EAAY55B,GAC5B,MAAM+L,EAAM,oBAAsBxQ,KAAKoe,qBAAqB3Z,EAAE0Q,gBAC1D,cAAgB1Q,EAAEyS,oBAAoBjS,SAASo5B,EAAW70B,aAAc60B,EAAW50B,eACvF40B,EAAWnpB,qBAAqB1E,EAAK/L,EAAE0Q,eAAgB1Q,GAY3D86B,sBAAsBlB,EAAY55B,GAC9B,MACM+L,EAAM,QADK6tB,EAAWtsB,UAAUssB,EAAWlsB,KAAKvF,WACrB,IAAMnI,EAAE8oB,QACzC8Q,EAAWnpB,qBAAqB1E,EAAK/L,EAAE0Q,eAAgB1Q,GAsB3Ds7B,oBAAoB1B,GAChB,GAAIr+B,KAAKsV,oBAAoB+oB,GACzB,OAEJr+B,KAAKo/B,oBAAoBf,GACzB,MAAMh9B,EAAIg9B,EAAWvrB,kBAGftC,EAAM,oBAFMxQ,KAAKoe,qBAAqB/c,GAEE,cAD5BrB,KAAKkX,kBAAkBmnB,GAE3Bp5B,SAASo5B,EAAW70B,aAAc60B,EAAW50B,eAC3D40B,EAAWnpB,qBAAqB1E,EAAKnP,EAAG,MAoB5C++B,mBAAmB/B,GACf,GAAKr+B,KAAKsV,oBAAoB+oB,GAC1B,OAEJr+B,KAAKo/B,oBAAoBf,GACzB,MAAMh9B,EAAIg9B,EAAWvrB,kBAEftC,EAAM,WADMxQ,KAAKkX,kBAAkBmnB,GACNp5B,SAASo5B,EAAW70B,aAAc60B,EAAW50B,eAC5E,OAASzJ,KAAKoe,qBAAqB/c,GACvCg9B,EAAWnpB,qBAAqB1E,EAAKnP,EAAG,MAqD5C2R,cAAcqrB,GAEV,MAAMgC,EAAgBrgC,KAAK8/B,oBAAoBzB,GAC/C,GAAsB,OAAlBgC,EAIA,OADAhC,EAAWz9B,UACJy/B,EAGX,GAAIrgC,KAAKsgC,qBAAqBjC,GAC1B,OAAOr+B,KAAKugC,iBAAiBlC,GAGjC,MAAM,IAAIK,EAAuBL,GAoBrCiC,qBAAqBjC,GACjB,MAAMmC,EAAoBnC,EAAWxpB,iBAAiB9T,GAAG,GAInDoK,EAAMkzB,EAAWpwB,QAAQ9C,IAEzBnC,EADemC,EAAI4B,OAAOsxB,EAAW9xB,OACjBjB,YAAY,GAAG3G,OAEzC,QADuBwG,EAAI6L,WAAWhO,EAAMq1B,EAAWlsB,MACpCnQ,SAASw+B,KACxBxgC,KAAKogC,mBAAmB/B,IACjB,GAyBfyB,oBAAoBzB,GAChB,MAAMoC,EAAgBpC,EAAWxpB,iBAAiB9T,GAAG,GAErD,GADkBf,KAAKkX,kBAAkBmnB,GAC3Br8B,SAASy+B,GAAgB,CACnCzgC,KAAK+/B,oBAAoB1B,GAKzBA,EAAWz9B,UAEX,MAAMy/B,EAAgBhC,EAAWvrB,kBAEjC,OADA9S,KAAK+S,YAAYsrB,GACVgC,EAEP,OAAO,KAyBfE,iBAAiBlC,GACb,MAAMqC,EAAgBrC,EAAWvrB,kBAE3B6tB,EADY3gC,KAAKkX,kBAAkBmnB,GACLt2B,QACpC,IAAI64B,EAEAA,EADAD,IAAoBnhC,EAAMwB,IACd,gBAEA,YAAcq9B,EAAW70B,aAAam3B,GAAqB,IAE3E,IAAI53B,EAAU23B,EACd,MAAMG,EAAWxC,EAAWxpB,iBAAiB5S,IAAI,GAIjD,OAHI8G,EAAQtH,OAAOjC,EAAMwB,KAAoB,OAAb6/B,IAC5B93B,EAAU83B,GAEPxC,EAAWrqB,kBAAkBnO,OAAOkD,EAAQjD,OAC/C66B,EAAmBC,EAAWphC,EAAM6G,iBACnC,GAAI,EAAG0C,EAAQhD,KAAMgD,EAAQ/C,QAGtCkR,kBAAkBmnB,GACd,OAAOA,EAAWnnB,oBAYtBkH,qBAAqB/c,GACjB,GAAU,OAANA,EACA,MAAO,aAEX,IAAIoC,EAAIpC,EAAEqC,KAQV,OAPU,OAAND,IAEIA,EADApC,EAAEI,OAAOjC,EAAMwB,IACX,QAEA,IAAMK,EAAEI,KAAO,KAGpBzB,KAAKmgC,iBAAiB18B,GAGjC08B,iBAAiB18B,GAIb,MAAO,KADPA,GADAA,GADAA,EAAIA,EAAE8F,QAAQ,MAAM,QACdA,QAAQ,MAAM,QACdA,QAAQ,MAAM,QACH,IAgGrBm2B,oBAAoBrB,GAChB,MAAMlzB,EAAMkzB,EAAWpwB,QAAQ9C,IAC/B,IAAIc,EAAMoyB,EAAWlsB,KACrB,MAAM2uB,EAAa,IAAIl5B,EACvB,KAAe,OAARqE,GAAgBA,EAAIuJ,eAAe,GAAG,CAEzC,MACMyB,EADgB9L,EAAI4B,OAAOd,EAAIuJ,eACZlK,YAAY,GAC/By1B,EAAS51B,EAAI6L,WAAWC,EAAG9J,aACjC2zB,EAAWl4B,OAAOm4B,GAClB90B,EAAMA,EAAI2J,UAGd,OADAkrB,EAAW13B,UAAU5J,EAAM2K,SACpB22B,EAIXnB,aAAatB,EAAY7wB,GACrB,IAAIwB,EAAQqvB,EAAWxpB,iBAAiB9T,GAAG,GAC3C,KAAOiO,IAAUxP,EAAMwB,MAAQwM,EAAIxL,SAASgN,IACxCqvB,EAAWz9B,UACXoO,EAAQqvB,EAAWxpB,iBAAiB9T,GAAG,IAqEnDpB,EAAOC,QAAU,CAACohC,kBAnClB,cAAgCvvB,EAC5B5R,cACIE,QASJwP,QAAQ8uB,EAAY55B,GAChB,IAAI+H,EAAU6xB,EAAWlsB,KACzB,KAAmB,OAAZ3F,GACHA,EAAQoM,UAAYnU,EACpB+H,EAAUA,EAAQoJ,UAEtB,MAAM,IAAIgpB,EAA2Bn6B,GAOzCuO,cAAcqrB,GACVr+B,KAAKuP,QAAQ8uB,EAAY,IAAIK,EAAuBL,IAIxDp9B,KAAKo9B,MAM4B5sB,qBAAAA,kBC1vBrC,MAAM,oBAAC+V,GAAuB,EAAQ,KAChC,SAAC9nB,GAAY,gBAEnB,MAAMiO,UAA6BszB,MAC/BphC,YAAY4jB,GACR1jB,MAAM0jB,EAAO8J,SACP0T,MAAMC,kBACRD,MAAMC,kBAAkBlhC,KAAM2N,IAElB,IAAIszB,OAAQ5xB,MAE5BrP,KAAKutB,QAAU9J,EAAO8J,QACtBvtB,KAAKq+B,WAAa5a,EAAO4a,WACzBr+B,KAAK6N,MAAQ4V,EAAO5V,MACpB7N,KAAKiM,IAAMwX,EAAOxX,IAMlBjM,KAAKmV,eAAiB,KAQtBnV,KAAKmhC,gBAAkB,EACD,OAAlBnhC,KAAKq+B,aACLr+B,KAAKmhC,eAAiBnhC,KAAKq+B,WAAW9xB,OAc9C2K,oBACI,OAAsB,OAAlBlX,KAAKq+B,WACEr+B,KAAKq+B,WAAWlzB,IAAI+L,kBAAkBlX,KAAKmhC,eAAgBnhC,KAAKiM,KAEhE,KAKfhH,WACI,OAAOjF,KAAKutB,SAyDpB,SAAS6T,EAAcC,EAAW9T,GAC9B,OAAe,OAAXA,EACOA,EAEA,sBAAwB8T,EAAY,KA+BnD,MAAMzC,UAAmCqC,MACrCphC,cACIE,QACAkhC,MAAMC,kBAAkBlhC,KAAM4+B,IAItCj/B,EAAOC,QAAU,CACb+N,qBAAAA,EACA8mB,qBA1EJ,cAAmC9mB,EAC/B9N,YAAYw+B,EAAYxwB,EAAOqyB,EAAY/qB,EAAgBmsB,EAAgBr1B,GACvEA,EAAMA,GAAOoyB,EAAWlsB,KACxBgD,EAAiBA,GAAkBkpB,EAAWvrB,kBAC9CotB,EAAaA,GAAc7B,EAAWvrB,kBACtCjF,EAAQA,GAASwwB,EAAWrpB,iBAC5BjV,MAAM,CAACwtB,QAAS,GAAI8Q,WAAYA,EAAYxwB,MAAOA,EAAO5B,IAAKA,IAG/DjM,KAAKshC,eAAiBA,EAKtBthC,KAAKkgC,WAAaA,EAClBlgC,KAAKmV,eAAiBA,IA4D1BvH,0BAlGJ,cAAwCD,EACpC9N,YAAYuG,EAAOyH,EAAOwiB,EAAYiR,GAClCvhC,MAAM,CAACwtB,QAAS,GAAI8Q,WAAYj4B,EAAOyH,MAAOA,EAAO5B,IAAK,OAC1DjM,KAAKqwB,WAAaA,EAClBrwB,KAAKshC,eAAiBA,EAG1Br8B,WACI,IAAIiN,EAAS,GAIb,OAHIlS,KAAKqwB,YAAc,GAAKrwB,KAAKqwB,WAAarwB,KAAK6N,MAAMpG,OACrDyK,EAASlS,KAAK6N,MAAMvK,QAAQ,IAAI5D,EAASM,KAAKqwB,WAAWrwB,KAAKqwB,cAE3D,4BAA8Bne,IAuFzCwsB,uBArDJ,cAAqC/wB,EACjC9N,YAAYw+B,GACRt+B,MAAM,CAACwtB,QAAS,GAAI8Q,WAAYA,EAAYxwB,MAAOwwB,EAAWrpB,iBAAkB/I,IAAKoyB,EAAWlsB,OAChGnS,KAAKmV,eAAiBkpB,EAAWvrB,oBAmDrC6rB,yBAjCJ,cAAuChxB,EACnC9N,YAAYw+B,EAAYgD,EAAW9T,GAC/BxtB,MAAM,CACFwtB,QAAS6T,EAAcC,EAAW9T,GAAW,MAAO8Q,WAAYA,EAChExwB,MAAOwwB,EAAWrpB,iBAAkB/I,IAAKoyB,EAAWlsB,OAExD,MACMwZ,EADI0S,EAAWpwB,QAAQ9C,IAAI4B,OAAOsxB,EAAW9xB,OACnCjB,YAAY,GACxBqgB,aAAiBnE,GACjBxnB,KAAK4M,UAAY+e,EAAM/e,UACvB5M,KAAKuhC,eAAiB5V,EAAMqH,YAE5BhzB,KAAK4M,UAAY,EACjB5M,KAAKuhC,eAAiB,GAE1BvhC,KAAKqhC,UAAYA,EACjBrhC,KAAKmV,eAAiBkpB,EAAWvrB,oBAkBrC8rB,2BAAAA,kBCvKJj/B,EAAOC,QAAQ+N,qBAAuB,EAAtC,0BACAhO,EAAOC,QAAQ60B,qBAAuB,EAAtC,0BACA,iCACA,8BACA90B,EAAOC,QAAQ++B,yBAA2B,EAA1C,8BACA,OACA,yBACA,4BACA,oCCTA/+B,EAAQuL,IAAM,EAAd,KACA,OACAvL,EAAQiY,IAAM,EAAd,IACA,OACAjY,EAAQ4hC,KAAO,EAAf,KACA5hC,EAAQ47B,MAAQ,EAAhB,KACA57B,EAAQJ,MAAQ,EAAhB,WACA,OACA,mBACAI,EAAQ+D,YAAc,EAAtB,KACA,OACA/D,EAAQ6hC,kBAAoB,EAA5B,KACA7hC,EAAQH,MAAQ,EAAhB,KACAG,EAAQyS,OAAS,EAAjB,IACA,IAAIqvB,EAAK,EAAQ,KACjB9hC,EAAQ,EAAyB8hC,EAAGplB,uBACpC1c,EAAQ4Y,kBAAoB,EAA5B,KACA,gBACA,mBACA,OACA,6BCvBKlR,OAAOsY,UAAU/Y,aACpB,WACA,aACA,IAAI86B,EAAkB,WAErB,IAAI/8B,EACJ,IACC,MAAMg9B,EAAS,GACTC,EAAkBrkB,OAAOmkB,eAC/B/8B,EAASi9B,EAAgBD,EAAQA,EAAQA,IAAWC,EACnD,MAAMrG,IAER,OAAO52B,EATa,GAWrB,MAAMiC,EAAc,SAASi7B,GAC5B,GAAY,MAAR9hC,KACH,MAAM+hC,YAEP,MAAMC,EAAS16B,OAAOtH,MAChByH,EAAOu6B,EAAOlhC,OAEpB,IAAIZ,EAAQ4hC,EAAWG,OAAOH,GAAY,EAK1C,GAJI5hC,GAAUA,IACbA,EAAQ,GAGLA,EAAQ,GAAKA,GAASuH,EACzB,OAGD,MAAMM,EAAQi6B,EAAOh7B,WAAW9G,GAChC,IAAIgiC,EACJ,OACCn6B,GAAS,OAAUA,GAAS,OAC5BN,EAAOvH,EAAQ,IAEfgiC,EAASF,EAAOh7B,WAAW9G,EAAQ,GAC/BgiC,GAAU,OAAUA,GAAU,OAEP,MAAlBn6B,EAAQ,OAAkBm6B,EAAS,MAAS,MAG/Cn6B,GAEJ45B,EACHA,EAAer6B,OAAOsY,UAAW,cAAe,CAC/C,MAAS/Y,EACT,cAAgB,EAChB,UAAY,IAGbS,OAAOsY,UAAU/Y,YAAcA,EAlDjC,aCDIS,OAAOC,eACV,WACA,MAAMo6B,EAAkB,WAEvB,IAAI/8B,EACJ,IACC,MAAMg9B,EAAS,GACTC,EAAkBrkB,OAAOmkB,eAC/B/8B,EAASi9B,EAAgBD,EAAQA,EAAQA,IAAWC,EACnD,MAAMrG,IACR,OAAO52B,EARe,GAUjBu9B,EAAqB76B,OAAOyC,aAC5Bq4B,EAAQh7B,KAAKg7B,MACb76B,EAAgB,SAAS86B,GAC9B,MAAMC,EAAW,MACXC,EAAY,GAClB,IAAIC,EACAC,EACAviC,GAAS,EACb,MAAMY,EAAS0gB,UAAU1gB,OACzB,IAAKA,EACJ,MAAO,GAER,IAAI8D,EAAS,GACb,OAAS1E,EAAQY,GAAQ,CACxB,IAAI8F,EAAYq7B,OAAOzgB,UAAUthB,IACjC,IACEwiC,SAAS97B,IACVA,EAAY,GACZA,EAAY,SACZw7B,EAAMx7B,KAAeA,EAErB,MAAM+7B,WAAW,uBAAyB/7B,GAEvCA,GAAa,MAChB27B,EAAU/gC,KAAKoF,IAGfA,GAAa,MACb47B,EAAoC,OAAnB57B,GAAa,IAC9B67B,EAAgB77B,EAAY,KAAS,MACrC27B,EAAU/gC,KAAKghC,EAAeC,KAE3BviC,EAAQ,IAAMY,GAAUyhC,EAAUzhC,OAASwhC,KAC9C19B,GAAUu9B,EAAmBrhB,MAAM,KAAMyhB,GACzCA,EAAUzhC,OAAS,GAGrB,OAAO8D,GAEJ+8B,EACHA,EAAer6B,OAAQ,gBAAiB,CACvC,MAASC,EACT,cAAgB,EAChB,UAAY,IAGbD,OAAOC,cAAgBA,EAzDzB,kBCGD,MAAM,MAAC/H,GAAS,EAAQ,MAClB,SAACE,GAAY,EAAQ,KACrB2Y,EAAmB,IAAI3Y,GAAU,GAAI,GAc3C,MAAMkjC,UANN,cAFA,QAGC/iC,cACCE,UAKDF,cACCE,SAcF,MAAMwR,UAAqBqxB,EAC1B/iC,cACCE,SAIF,MAAMyR,UAAkBD,EACvB1R,cACCE,SA4CF,MAAMuY,UAAyB/G,EAC9B1R,YAAYqS,GACXnS,QACAC,KAAK4V,UAAY,KACjB5V,KAAKkS,OAASA,EAGf8G,SAAS9X,GACR,OAAO,KAGR2hC,YACC,OAAO7iC,KAAKkS,OAGbjF,YACC,OAAOjN,KAAK4V,UAGb+I,aACC,OAAO3e,KAAKkS,OAGbqH,oBACC,GAAoB,OAAhBvZ,KAAKkS,OACR,OAAOmG,EAER,MAAM9W,EAAavB,KAAKkS,OAAO3Q,WAC/B,OAAO,IAAI7B,EAAS6B,EAAYA,GAGjC+X,gBACC,OAAO,EAGRwF,OAAOC,GACN,OAAOA,EAAQ/M,cAAchS,MAG9BsD,UACC,OAAOtD,KAAKkS,OAAOxO,KAGpBuB,WACC,OAAIjF,KAAKkS,OAAOzQ,OAASjC,EAAMwB,IACvB,QAEAhB,KAAKkS,OAAOxO,MA2BtB,MAAMo/B,EAULC,KAAKzvB,EAAUjS,GAGd,GAFkBA,aAAamQ,QACV1P,IAAlBT,EAAEoU,aAA6BpU,EAAEoU,cAEnCnC,EAASoC,eAAerU,QAClB,GAAIA,aAAakQ,EACvB+B,EAAStB,cAAc3Q,OACjB,CACNrB,KAAK4T,UAAUN,EAAUjS,GACzB,IAAK,IAAIH,EAAI,EAAGA,EAAIG,EAAEiY,gBAAiBpY,IAAK,CAC3C,MAAM4X,EAAQzX,EAAE2X,SAAS9X,GACzBlB,KAAK+iC,KAAKzvB,EAAUwF,GAErB9Y,KAAK+T,SAAST,EAAUjS,IAU1BuS,UAAUN,EAAUpH,GACnB,MAAMD,EAAMC,EAAEwS,iBACdpL,EAASxB,eAAe7F,GACxBA,EAAI2H,UAAUN,GASfS,SAAST,EAAUpH,GAClB,MAAMD,EAAMC,EAAEwS,iBACdzS,EAAI8H,SAAST,GACbA,EAASlB,cAAcnG,IAIzB62B,EAAgB58B,QAAU,IAAI48B,EAE9BnjC,EAAOC,QAAU,CAChB2e,SA/LD,cAAuBqkB,EACtB/iC,cACCE,QAGD2e,iBACC,MAAM,IAAIuiB,MAAM,sCA0LjBzvB,UAAAA,EACAD,aAAAA,EACAgH,cAxED,cAA4BD,EAC3BzY,YAAY2C,GACXzC,MAAMyC,GAGPiT,cACC,OAAO,EAGRqJ,OAAOC,GACN,OAAOA,EAAQrJ,eAAe1V,QA+D/BsY,iBAAAA,EACAhH,kBApJD,MACCU,cAAcC,IAGdyD,eAAezD,IAGfH,eAAeG,IAGfG,cAAcH,MA2Id+wB,iBA/KD,MACCC,MAAMh3B,GACJ,OAAInF,MAAM2Y,QAAQxT,GACXA,EAAI7B,KAAI,SAAS0O,GACvB,OAAOA,EAAMgG,OAAO9e,QAClBA,MAEIiM,EAAI6S,OAAO9e,MAIpBgf,cAAc/S,GACb,OAAIA,EAAI0M,SACA3Y,KAAKijC,MAAMh3B,EAAI0M,UAEf,KAIT3G,cAAcC,IAGdyD,eAAezD,MA0Jf6wB,gBAAAA,EACAzqB,iBAAAA,iBC7ND,MAAMoM,EAAQ,EAAQ,MAChB,MAACjlB,GAAS,EAAQ,MAClB,UAACgS,EAAS,aAAED,EAAY,SAAEgN,GAAY,EAAQ,KAG9CC,EAAQ,CAMVS,aAAc,SAASuiB,EAAMzvB,EAAWmN,GACpCnN,EAAYA,GAAa,KAEd,QADXmN,EAAQA,GAAS,QAEbnN,EAAYmN,EAAMnN,WAEtB,IAAItO,EAAI+a,EAAM0kB,YAAY1B,EAAMzvB,GAChCtO,EAAIghB,EAAM3C,iBAAiBre,GAAG,GAC9B,MAAM6I,EAAIk1B,EAAKloB,gBACf,GAAO,IAAJhN,EACC,OAAO7I,EAEX,IAAI0/B,EAAM,IAAM1/B,EAAI,IACjB6I,EAAE,IACD7I,EAAI+a,EAAMS,aAAauiB,EAAKxoB,SAAS,GAAIjH,GACzCoxB,EAAMA,EAAI9hB,OAAO5d,IAErB,IAAI,IAAIvC,EAAE,EAAEA,EAAEoL,EAAEpL,IACZuC,EAAI+a,EAAMS,aAAauiB,EAAKxoB,SAAS9X,GAAI6Q,GACzCoxB,EAAMA,EAAI9hB,OAAO,IAAM5d,GAG3B,OADA0/B,EAAMA,EAAI9hB,OAAO,KACV8hB,GAGXD,YAAa,SAAS7hC,EAAG0Q,EAAWmN,GAMhC,GALAnN,EAAYA,GAAa,KAEd,QADXmN,EAAQA,GAAS,QAEbnN,EAAYmN,EAAMnN,WAEP,OAAZA,EAAkB,CACjB,GAAI1Q,aAAakd,EAAU,CACvB,MACMM,EADUxd,EAAEqd,iBACQE,eAE1B,OAAkB,GAAbC,EACM9M,EAAU1Q,EAAEuL,WAAW,IAAIiS,EAE/B9M,EAAU1Q,EAAEuL,WAChB,GAAKvL,aAAamQ,EACrB,OAAOnQ,EAAE4D,WACN,GAAG5D,aAAakQ,GACL,OAAXlQ,EAAE6Q,OACD,OAAO7Q,EAAE6Q,OAAOxO,KAK5B,MAAMmY,EAAUxa,EAAEsd,aAClB,OAAI9C,aAAmBrc,EACZqc,EAAQnY,KAEZrC,EAAEsd,aAAa1Z,YAM1Bm+B,YAAa,SAAS/hC,GAClB,MAAMgiC,EAAO,GACb,IAAI,IAAIniC,EAAE,EAAEA,EAAEG,EAAEiY,gBAAgBpY,IAC5BmiC,EAAK7hC,KAAKH,EAAE2X,SAAS9X,IAEzB,OAAOmiC,GAOXC,aAAc,SAASjiC,GACnB,IAAIkiC,EAAY,GAEhB,IADAliC,EAAIA,EAAE4L,YACI,OAAJ5L,GACFkiC,EAAY,CAACliC,GAAGggB,OAAOkiB,GACvBliC,EAAIA,EAAE4L,YAEV,OAAOs2B,GAGXC,kBAAmB,SAASniC,EAAG2N,GAC3B,OAAOwP,EAAMilB,aAAapiC,EAAG2N,GAAO,IAGxC00B,iBAAkB,SAASriC,EAAGuL,GAC1B,OAAO4R,EAAMilB,aAAapiC,EAAGuL,GAAW,IAG5C62B,aAAc,SAASpiC,EAAGnB,EAAOyjC,GAC7B,MAAMC,EAAQ,GAEd,OADAplB,EAAMqlB,cAAcxiC,EAAGnB,EAAOyjC,EAAYC,GACnCA,GAGXC,cAAe,SAASxiC,EAAGnB,EAAOyjC,EAAYC,GAEvCD,GAAetiC,aAAakQ,EACxBlQ,EAAE6Q,OAAOzQ,OAAOvB,GACf0jC,EAAMpiC,KAAKH,IAERsiC,GAAetiC,aAAakd,GAChCld,EAAEuL,YAAY1M,GACb0jC,EAAMpiC,KAAKH,GAInB,IAAI,IAAIH,EAAE,EAAEA,EAAEG,EAAEiY,gBAAgBpY,IAC5Bsd,EAAMqlB,cAAcxiC,EAAE2X,SAAS9X,GAAIhB,EAAOyjC,EAAYC,IAI9DE,YAAa,SAASziC,GAClB,IAAIuiC,EAAQ,CAACviC,GACb,IAAI,IAAIH,EAAE,EAAEA,EAAEG,EAAEiY,gBAAgBpY,IAC5B0iC,EAAQA,EAAMviB,OAAO7C,EAAMslB,YAAYziC,EAAE2X,SAAS9X,KAEtD,OAAO0iC,IAIfjkC,EAAOC,QAAU4e,iBCpIjB,MAAMpG,EAAO,EAAQ,KACfoG,EAAQ,EAAQ,IACtB7e,EAAOC,QAAU,IAAIwY,EAAMoG,MAAAA,gBCNvBulB,EAA2B,GAG/B,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBniC,IAAjBoiC,EACH,OAAOA,EAAatkC,QAGrB,IAAID,EAASokC,EAAyBE,GAAY,CAGjDrkC,QAAS,IAOV,OAHAukC,EAAoBF,GAAUtkC,EAAQA,EAAOC,QAASokC,GAG/CrkC,EAAOC,iMCrBR,IAAMwkC,EAAb,WACE,WAAYC,gGAAM,SAChBrkC,KAAKskC,OAAS,GACdtkC,KAAKukC,SAAW,GAChBvkC,KAAKwkC,QAAU,GACfxkC,KAAKykC,gBAAkB,GACvBzkC,KAAK0kC,MAAQ,GACb1kC,KAAKuG,SAAW89B,UAPpB,yCAUE,SAAaM,GACX,IAAI5gC,EAAM,MAAH,OAAS4gC,EAAT,SACP,IAAK,IAAM1kB,KAAOjgB,KAAK2kC,GAAiB,CACtC,IAAMC,EAAY5kC,KAAK2kC,GAAgB1kB,GACvClc,GAAO,OAAJ,OAAWkc,EAAX,aAAmB2kB,EAAnB,MAEL,OAAO7gC,IAhBX,sBAmBE,WACE,IAAIA,EAAM,WAEV,IAAK,IAAM8gC,KADX11B,QAAQC,IAAI,UAAZ,UAA0BpP,KAAK0kC,MAA/B,SACiB1kC,KAAK0kC,MACpB3gC,GAAO8gC,EAAG5/B,WAEZ,OAAOlB,2EAzBX,uRCAO,IAAM+gC,EAAb,GACE,0GAAc,SACZ9kC,KAAK+kC,oBAAsB,GAE3B/kC,KAAKglC,mBAAqB,GAE1BhlC,KAAKilC,iBAAmB,GAExBjlC,KAAKklC,mBAAqB,GAE1BllC,KAAKmlC,eAAiB,GAEtBnlC,KAAKolC,mBAAqB,GAE1BplC,KAAKqlC,iBAAmB,GACxBrlC,KAAKslC,eAAiB,GAEtBtlC,KAAKulC,MAAQ,GACbvlC,KAAKwlC,cAAgB,GACrBxlC,KAAKylC,qBAAuB,GAC5BzlC,KAAK0lC,kBAAmB,EACxB1lC,KAAKyG,KAAO,GACZzG,KAAKyB,KAAO,GACZzB,KAAK4hC,OAAS,GAEd5hC,KAAKskC,OAAS,GACdtkC,KAAKukC,SAAW,iSC1Bb,IAAMoB,EAAb,GACE,WAAY7/B,gGAAQ,m8BCCf,IAAM8/B,EAAb,4sBACE,WAAY/3B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDwD,MAAQuE,EAFY,EAD7B,mCAUE,SAAeA,EAAO/H,GACpB,MAAuB,iBAAX+H,GAAgC,IAATA,IACjC/H,EAAOw+B,OAAO9iC,KAAK,8BACZ,SAbb,uBAME,WACE,MAAO,GAAP,OAAUxB,KAAKsJ,0FAPnB,GAAoCq8B,GCyC7B,IAAIlmB,EAAU3Y,MAAM2Y,+7BCxCpB,IAAMomB,EAAb,4sBACE,WAAYh4B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDW,KAAOoH,EAAMpH,KAClB,EAAKq/B,QAAUj4B,EAAMi4B,QAHI,EAD7B,mCAgBE,SAAej4B,EAAO/H,GACpB,QAA4B,iBAAhB+H,EAAMpH,OAAuBgZ,EAAQ5R,EAAMi4B,UAAqB,IAATj4B,KACjE/H,EAAOw+B,OAAO9iC,KAAK,8BACZ,SAnBb,uBAOE,WACE,IAAIuC,EAAM,GAAH,OAAM/D,KAAKyG,KAAX,QAKP,OAJAzG,KAAK8lC,QAAQh9B,SAAQ,SAAC84B,GACpB79B,GAAO,OAAJ,OAAW69B,EAAX,SAEL79B,GAAO,yFAZX,GAA2C4hC,07BCDpC,IAAMI,EAAb,4sBACE,WAAYl4B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDwD,MAAQ,GACbuE,EAAM03B,MAAMz8B,SAAQ,SAACrE,GACnB,EAAK6E,MAAM9H,KAAKiD,EAAE6E,UAEpBuE,EAAM23B,cAAc18B,SAAQ,SAACrE,GAC3B,EAAK6E,MAAM9H,KAAKiD,MAPO,EAD7B,mCAuBE,SAAeoJ,EAAO/H,GACpB,SAAKgB,MAAM2Y,QAAQ5R,EAAM03B,SAAWz+B,MAAM2Y,QAAQ5R,EAAM23B,gBAAkB33B,GAAS,MACjF/H,EAAOw+B,OAAO9iC,KAAK,+BACZ,SA1Bb,uBAYE,WACE,IAAIuC,EAAM,GACV,GAAI/D,KAAKsJ,MAAMxI,OAAS,EAAG,CACzB,IAAK,IAAII,EAAI,EAAGA,EAAIlB,KAAKsJ,MAAMxI,OAAS,EAAGI,IACzC6C,GAAO,KAAJ,OAAS/D,KAAKsJ,MAAMpI,GAApB,MAEL6C,GAAO,KAAJ,OAAS/D,KAAKsJ,MAAMtJ,KAAKsJ,MAAMxI,OAAS,IAE7C,OAAOiD,qFApBX,GAAqC4hC,07BCA9B,IAAMK,EAAb,4sBACE,WAAYn4B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDwD,MAAQuE,EAFY,EAD7B,mCAUE,SAAeA,EAAO/H,GACpB,MAAuB,iBAAX+H,GAAgC,IAATA,IACjC/H,EAAOw+B,OAAO9iC,KAAK,6BACZ,SAbb,uBAME,WACE,MAAO,GAAP,OAAUxB,KAAKsJ,0FAPnB,GAAmCq8B,07BCA5B,IAAMM,EAAb,4sBACE,WAAYp4B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDwD,MAAQuE,EAFY,EAD7B,mCAUE,SAAeA,EAAO/H,GACpB,MAAuB,iBAAX+H,GAAgC,IAATA,IACjC/H,EAAOw+B,OAAO9iC,KAAK,6BACZ,SAbb,uBAME,WACE,MAAO,GAAP,OAAUxB,KAAKsJ,0FAPnB,GAAmCq8B,07BCA5B,IAAMO,EAAb,4sBACE,WAAYr4B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDS,SAAW,GAChB,EAAK9E,KAAO,SACZ,EAAK0kC,aAAet4B,EAAM/H,OAC1B,EAAKW,KAAOoH,EAAMpH,KAClB,EAAKq/B,QAAWj4B,EAAMi4B,QAAQx8B,MAASuE,EAAMi4B,QAAU,GACvD,EAAKM,cAAiBv4B,EAAM/D,MAAMu8B,UAAax4B,EAAM/D,MAAMu8B,UAAY,GACvE,EAAKC,gBAAkB,GACvB,EAAKC,UAAa14B,EAAM/D,MAAM08B,MAAS34B,EAAM/D,MAAM08B,MAAQ,GAC3D,EAAKC,YAAc,GACnB,EAAKC,cAAiB74B,EAAM/D,MAAM68B,UAAa94B,EAAM/D,MAAM68B,UAAY,GACvE,EAAKC,gBAAkB,GACvB,EAAKC,YAAeh5B,EAAM/D,MAAMg9B,QAAWj5B,EAAM/D,MAAMg9B,QAAU,GACjE,EAAKC,cAAgB,GACrB,EAAKC,WAAa,GAfO,EAD7B,mCAwBE,SAAen5B,EAAO/H,GACpB,MAA+B,WAA3B,EAAQ+H,EAAMi4B,UAAiD,iBAAhBj4B,EAAMpH,MAA+C,WAAzB,EAAQoH,EAAM/D,QAAgC,IAAT+D,IAClH/H,EAAOw+B,OAAO9iC,KAAK,+BACZ,SA3Bb,uBAmBE,WACE,MAAoB,IAAhBxB,KAAK8lC,QAAwB,WAAP,OAAkB9lC,KAAKyG,KAAvB,kBAAqCzG,KAAKmmC,aAA1C,OACnB,WAAP,OAAkBnmC,KAAKyG,KAAvB,kBAAqCzG,KAAKmmC,aAA1C,aAA2DnmC,KAAK8lC,QAAhE,0FArBJ,GAAqCH,GCA9B,SAASsB,EAAUnB,EAASoB,GACjC,IAAMb,EAAY,GACZM,EAAY,GACZH,EAAQ,GACRM,EAAU,GA+DhB,OA7DAhB,EAAQh9B,SAAQ,SAACrE,GACf,GAAIA,aAAaohC,EAAuB,CACtC,IAAMjhC,EAASqiC,EAAUxiC,EAAEqhC,SAC3BlhC,EAAOyhC,UAAUv9B,SAAQ,SAACq+B,GACxBd,EAAU7kC,KAAK2lC,MAEjBviC,EAAO+hC,UAAU79B,SAAQ,SAACs+B,GACxBT,EAAUnlC,KAAK4lC,MAEjBxiC,EAAO4hC,MAAM19B,SAAQ,SAACvD,GACpBihC,EAAMhlC,KAAK+D,MAEbX,EAAOkiC,QAAQh+B,SAAQ,SAACnJ,GACtBmnC,EAAQtlC,KAAK7B,UAEV,CACL,IAAI0nC,EAAe,GACfD,EAAW,GACX7hC,EAAO,GACP5F,EAAS,GACPihB,EAASnc,EAAEylB,MAAM,KACvB,GAAiBpoB,MAAb8e,EAAO,GAAiB,CAC1B,IAAM0mB,EAAgB1mB,EAAO,GAAGsJ,MAAM,KAWtC,GAVAmd,EA6HR,SAA2BzmB,GACzB,IACI0mB,EADED,EAAe,GAEjB/9B,EAAQ,GAoBZ,OAnBAsX,EAAO9X,SAAQ,SAACd,GAEd,GAAwB,QADxBs/B,EAAgBt/B,EAAEkiB,MAAM,MACN,GAChB5gB,EAAQ,CAAEi+B,IAAK3mB,EAAO,GAAIna,KAAM6gC,EAAc,IACzCD,EAAaG,SAASl+B,IAAQ+9B,EAAa7lC,KAAK8H,QAChD,GAAqC,OAAjCg+B,EAAc,GAAGG,UAAU,GACc,KAA9CH,EAAc,GAAGA,EAAcxmC,OAAS,IAC1CwI,EAAQ,CAAEi+B,IAAK3mB,EAAO,GAAGsJ,MAAM,KAAK,GAAIzjB,KAAM6gC,EAAc,GAAGpd,MAAM,KAAK,IACrEmd,EAAaG,SAASl+B,IAAQ+9B,EAAa7lC,KAAK8H,KAErDA,EAAQ,CAAEi+B,IAAK3mB,EAAO,GAAGsJ,MAAM,KAAK,GAAIzjB,KAAM6gC,EAAc,GAAG9/B,MAAM,GAAI,IACpE6/B,EAAaG,SAASl+B,IAAQ+9B,EAAa7lC,KAAK8H,SAElD,GAAwC,SAApCg+B,EAAc,GAAGG,UAAU,EAAG,IAA+C,OAA9BH,EAAc,GAAG9/B,OAAO,GAAa,CAC7F,IAAMkgC,EAASJ,EAAc,GAAGpd,MAAM,MACtC5gB,EAAQ,CAAEi+B,IAAK3mB,EAAO,GAAIna,KAAMihC,EAAO,GAAGlgC,MAAM,GAAI,IAC/C6/B,EAAaG,SAASl+B,IAAQ+9B,EAAa7lC,KAAK8H,OAGlD+9B,EApJcM,CAAkB/mB,GACN,GAAvBymB,EAAavmC,SACfsmC,EAqJV,SAA2BxmB,EAAQ0mB,GACjC,IAAIF,EAAW,GACf,GAAwC,OAApCE,EAAc,GAAGG,UAAU,EAAG,IAAwC,IAAzBH,EAAcxmC,OAC7DsmC,EAAW,CAAEG,IAAK3mB,EAAO,GAAInf,KAAM6lC,EAAc,GAAGG,UAAU,GAAIhhC,KAAM6gC,EAAc,SACjF,GAAwC,KAApCA,EAAc,GAAGG,UAAU,EAAG,IAAaH,EAAcxmC,QAAU,EAAG,CAC/E,IAAM8mC,EAAQhnB,EAAO,GAAGsJ,MAAM,KAC9Bkd,EAAW,GACX,IAAK,IAAIlmC,EAAI,EAAGA,EAAI0mC,EAAM9mC,OAAQI,IAAK,CACrC,IAAM2mC,EAAUD,EAAM1mC,GAAGgpB,MAAM,KACtB,GAALhpB,EACgC,QAA9B2mC,EAAQ,GAAGJ,UAAU,EAAG,IAC1BL,EAAS5lC,KAAK,CAAE+lC,IAAK3mB,EAAO,GAAInf,KAAMomC,EAAQ,GAAGJ,UAAU,GAAIhhC,KAAMohC,EAAQ,KAExC,OAA9BA,EAAQ,GAAGJ,UAAU,EAAG,IACjCL,EAAS5lC,KAAK,CAAE+lC,IAAK3mB,EAAO,GAAInf,KAAMomC,EAAQ,GAAGJ,UAAU,GAAIhhC,KAAMohC,EAAQ,MAInF,OAAOT,EAvKYU,CAAkBlnB,EAAQ0mB,IAEhB,GAAnBF,EAAStmC,SACXyE,EAuKV,SAAuBqb,EAAQ0mB,GAC7B,IAAI/hC,EAAO,GAMX,OALwB,QAApB+hC,EAAc,IAE6B,OAApCA,EAAc,GAAGG,UAAU,EAAG,IAAmD,QAApCH,EAAc,GAAGG,UAAU,EAAG,MADpFliC,EAAO,CAAEgiC,IAAK3mB,EAAO,GAAInf,KAAM6lC,EAAc,GAAI7gC,KAAM6gC,EAAc,KAIhE/hC,EA9KQwiC,CAAcnnB,EAAQ0mB,IAEZ,GAAf/hC,EAAKzE,SACPnB,EA8KV,SAAyBihB,EAAQ0mB,GAC/B,IAAI3nC,EAAS,GAMb,OALwB,UAApB2nC,EAAc,IAE6B,OAApCA,EAAc,GAAGG,UAAU,EAAG,IAAmD,UAApCH,EAAc,GAAGG,UAAU,EAAG,MADpF9nC,EAAS,CAAE4nC,IAAK3mB,EAAO,GAAIna,KAAM6gC,EAAc,KAI1C3nC,EArLUqoC,CAAgBpnB,EAAQ0mB,IAEf,IAAhBD,EAAoB,CACtB,IAAIY,GAAO,EACXZ,EAAav+B,SAAQ,SAACq+B,GACpBd,EAAUv9B,SAAQ,SAACd,GACbA,EAAC,KAAQm/B,EAAQ,KAAQn/B,EAAEvB,MAAQ0gC,EAAS1gC,OAAQwhC,GAAO,MAE5DA,EAA2CA,GAAO,EAA1C5B,EAAU7kC,KAAK2lC,MAGhB,IAAZC,GAAmBT,EAAUa,SAASJ,KACpCtgC,MAAM2Y,QAAQ2nB,GAChBA,EAASt+B,SAAQ,SAACoD,GAChBy6B,EAAUnlC,KAAK0K,MAGjBy6B,EAAUnlC,KAAK4lC,IAGP,IAAR7hC,GAAeihC,EAAMgB,SAASjiC,IAChCihC,EAAMhlC,KAAK+D,GAET2hC,GAAsB,IAAVvnC,IAAiBmnC,EAAQU,SAAS7nC,IAChDmnC,EAAQtlC,KAAK7B,QAMd,CACL0mC,UAAAA,EAAWM,UAAAA,EAAWH,MAAAA,EAAOM,QAAAA,GAI1B,SAASoB,EAAYN,EAAOhjC,EAAQsiC,GAqCzC,OApCAU,EAAM9+B,SAAQ,SAACq/B,GACbC,EAAUD,EAAG/B,cAAexhC,EAAOyhC,WAAWv9B,SAAQ,SAACrE,GACrD0jC,EAAG7B,gBAAgB9kC,KAAKiD,MAG1B4jC,EAA0BF,EAAG/B,cAAe+B,EAAG7B,gBAAiB6B,EAAG5hC,UAAUuC,SAAQ,SAACrE,GACpFG,EAAO0/B,OAAO9iC,KAAKiD,MAGrB2jC,EAAUD,EAAGzB,cAAe9hC,EAAO+hC,WAAW79B,SAAQ,SAACrE,GACrD0jC,EAAGvB,gBAAgBplC,KAAKiD,MAG1B4jC,EAA0BF,EAAGzB,cAAeyB,EAAGvB,gBAAiBuB,EAAG5hC,UAAUuC,SAAQ,SAACrE,GACpFG,EAAO0/B,OAAO9iC,KAAKiD,MAGrB2jC,EAAUD,EAAG5B,UAAW3hC,EAAO4hC,OAAO19B,SAAQ,SAACrE,GAC7C0jC,EAAG1B,YAAYjlC,KAAKiD,MAGtB4jC,EAA0BF,EAAG5B,UAAW4B,EAAG1B,YAAa0B,EAAG5hC,UAAUuC,SAAQ,SAACrE,GAC5EG,EAAO0/B,OAAO9iC,KAAKiD,MAGjByiC,IACFkB,EAAUD,EAAGtB,YAAajiC,EAAOkiC,SAASh+B,SAAQ,SAACrE,GACjD0jC,EAAGpB,cAAcvlC,KAAKiD,MAGxB4jC,EAA0BF,EAAGtB,YAAasB,EAAGpB,cAAeoB,EAAG5hC,UAAUuC,SAAQ,SAACrE,GAChFG,EAAO0/B,OAAO9iC,KAAKiD,UAKlBG,EAGT,SAASwjC,EAAUE,EAAYtiB,GAC7B,IAAMuiB,EAAe,GAYrB,OAXID,EAAWxnC,OAAS,GACtBwnC,EAAWx/B,SAAQ,SAAC0/B,GAClBxiB,EAAMld,SAAQ,SAACd,GACTwgC,EAAG/mC,MAAQuG,EAAEvG,MAAQ+mC,EAAG/hC,MAAQuB,EAAEvB,KACpC8hC,EAAa/mC,KAAK,CAAEiF,KAAM+hC,EAAE,IAAMl/B,MAAOtB,IAC/BwgC,EAAG/mC,MAAQ+mC,EAAG/hC,MAAQuB,EAAEvB,MAClC8hC,EAAa/mC,KAAK,CAAEiF,KAAM+hC,EAAE,IAAMl/B,MAAOtB,UAK1CugC,EAGT,SAASF,EAA0BC,EAAYC,EAAchiC,GAC3D,IAAM+9B,EAAS,GACf,GAAIgE,EAAWxnC,QAAUynC,EAAaznC,OAAQ,CAC5C,IACI06B,EADAyM,GAAO,EAEXK,EAAWx/B,SAAQ,SAAC2/B,GAClBF,EAAaz/B,SAAQ,SAAC4/B,GAChBA,EAAGjnC,MAAQgnC,EAAGhnC,MAAQinC,EAAGjnC,MAAQgnC,EAAGhiC,MAAQiiC,EAAGjiC,KACjDwhC,GAAO,EACGS,EAAGjnC,MAAQgnC,EAAGhiC,MAAQiiC,EAAGjiC,OACnCwhC,GAAO,MAGNA,IAEDzM,EADEiN,EAAGhnC,KACG,6BAAH,OAAgC8E,EAAhC,wBAAwDkiC,EAAGhnC,KAA3D,cAAqEgnC,EAAGhiC,KAAxE,WAEG,6BAAH,OAAgCF,EAAhC,qBAAqDkiC,EAAGhiC,KAAxD,WAEP69B,EAAO9iC,KAAKg6B,OAIlB,OAAO8I,67BCvJF,IAAMqE,GAAb,+sBACE,WAAY96B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDwD,MAAQuE,EAFY,EAD7B,mCAUE,SAAeA,EAAO/H,GACpB,MAAuB,iBAAX+H,GAAgC,IAATA,IACjC/H,EAAOw+B,OAAO9iC,KAAK,+BACZ,SAbb,uBAME,WACE,MAAO,GAAP,OAAUxB,KAAKsJ,0FAPnB,GAAkCq8B,s8BCA3B,IAAMiD,GAAb,gtBACE,WAAY/6B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDS,SAAW,GAChB,EAAKu/B,QAAUj4B,EAAMi4B,QAHI,EAD7B,mCAWE,SAAej4B,EAAO/H,GACpB,MAA+B,WAA3B,GAAQ+H,EAAMi4B,UAAkC,IAATj4B,IACzC/H,EAAOw+B,OAAO9iC,KAAK,kCACZ,SAdb,uBAOE,WACE,MAAO,KAAP,OAAYxB,KAAKyG,KAAjB,gBAA6BzG,KAAK8lC,QAAlC,8FARJ,GAAwCH,s8BCAjC,IAAMkD,GAAb,gtBACE,WAAYh7B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDS,SAAW,GAChB,EAAKE,KAAOoH,EAAMpH,KAClB,EAAKhF,KAAOoM,EAAMpM,KAClB,EAAKqkC,QAAUj4B,EAAMi4B,QALI,EAD7B,mCAaE,SAAej4B,EAAO/H,GACpB,MAA+B,WAA3B,GAAQ+H,EAAMi4B,UAAiD,iBAAhBj4B,EAAMpH,MAA8C,iBAAhBoH,EAAMpH,MAA+B,IAAToH,IACjH/H,EAAOw+B,OAAO9iC,KAAK,6BACZ,SAhBb,uBASE,WACE,MAAO,SAAP,OAAgBxB,KAAKyB,KAArB,cAA+BzB,KAAKyG,KAApC,gBAAgDzG,KAAK8lC,QAArD,4FAVJ,GAAmCH,s8BCA5B,IAAMmD,GAAb,gtBACE,WAAYj7B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDS,SAAW,GAChB,EAAK9E,KAAOoM,EAAMpM,KAClB,EAAKgF,KAAOoH,EAAMpH,KAClB,EAAK2/B,cAAgBv4B,EAAM/D,MAAMu8B,UACjC,EAAKC,gBAAkB,GACvB,EAAKI,cAAgB74B,EAAM/D,MAAM68B,UACjC,EAAKC,gBAAkB,GACvB,EAAKL,UAAY14B,EAAM/D,MAAM08B,MAC7B,EAAKC,YAAc,GACnB,EAAKX,QAAUj4B,EAAMi4B,QACrB,EAAKiD,eAAiB,GAZG,EAD7B,mCAoBE,SAAel7B,EAAO/H,GACpB,MAA+B,WAA3B,GAAQ+H,EAAMi4B,UAAiD,iBAAhBj4B,EAAMpH,MAA8C,iBAAhBoH,EAAMpM,MAA+B,IAAToM,IACjH/H,EAAOw+B,OAAO9iC,KAAK,kCACZ,SAvBb,uBAgBE,WACE,MAAO,aAAP,OAAoBxB,KAAKyB,KAAzB,cAAmCzB,KAAKyG,KAAxC,gBAAoDzG,KAAK8lC,QAAzD,4FAjBJ,GAAuCH,s8BCAhC,IAAMqD,GAAb,gtBACE,WAAYn7B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDS,SAAW,GAChB,EAAKE,KAAOoH,EAAMpH,KAClB,EAAKq/B,QAAUj4B,EAAMi4B,QACrB,EAAKM,cAAgBv4B,EAAM/D,MAAMu8B,UACjC,EAAKC,gBAAkB,GACvB,EAAKI,cAAgB74B,EAAM/D,MAAM68B,UACjC,EAAKC,gBAAkB,GACvB,EAAKL,UAAY14B,EAAM/D,MAAM08B,MAC7B,EAAKC,YAAc,GAVM,EAD7B,mCAkBE,SAAe54B,EAAO/H,GACpB,MAA+B,WAA3B,GAAQ+H,EAAMi4B,UAAiD,iBAAhBj4B,EAAMpH,MAA+B,IAAToH,IAC7E/H,EAAOw+B,OAAO9iC,KAAK,+BACZ,SArBb,uBAcE,WACE,MAAO,WAAP,OAAkBxB,KAAKyG,KAAvB,gBAAmCzG,KAAK8lC,QAAxC,4FAfJ,GAAqCH,s8BCA9B,IAAMsD,GAAb,gtBACE,WAAYp7B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDS,SAAW,GAChB,EAAKE,KAAOoH,EAAMpH,KAClB,EAAKq/B,QAAUj4B,EAAMi4B,QAJI,EAD7B,mCAYE,SAAej4B,EAAO/H,GACpB,MAA+B,WAA3B,GAAQ+H,EAAMi4B,UAAiD,iBAAhBj4B,EAAMpH,MAA+B,IAAToH,IAC7E/H,EAAOw+B,OAAO9iC,KAAK,iCACZ,SAfb,uBAQE,WACE,MAAO,aAAP,OAAoBxB,KAAKyG,KAAzB,gBAAqCzG,KAAK8lC,QAA1C,4FATJ,GAAuCH,s8BCAhC,IAAMuD,GAAb,gtBACE,WAAYr7B,EAAO/H,GAAQ,mHACzB,cAAMA,IACDS,SAAW,GAChB,EAAKE,KAAOoH,EAAMpH,KAClB,EAAKq/B,QAAUj4B,EAAMi4B,QAJI,EAD7B,mCAYE,SAAej4B,EAAO/H,GACpB,MAA+B,WAA3B,GAAQ+H,EAAMi4B,UAAiD,iBAAhBj4B,EAAMpH,MAA+B,IAAToH,IAC7E/H,EAAOw+B,OAAO9iC,KAAK,iCACZ,SAfb,uBAQE,WACE,MAAO,aAAP,OAAoBxB,KAAKyG,KAAzB,gBAAqCzG,KAAK8lC,QAA1C,4FATJ,GAAuCH,08BCmBlBwD,GAAAA,SAAAA,qsBACnB,WAAYC,GAAM,mHAChB,gBACKA,KAAOA,EAFI,wCAMlB,SAAUn9B,4BAIV,SAASA,GAC8BjM,KAAKopC,KAAK9E,OAAgBtkC,KAAKopC,mCAItE,SAAen9B,iCAIf,SAAcA,sCAId,SAAmBA,IACmB,CAAEA,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OC1C7EA,KAAKC,aAAa9D,MAAQ,oCD8CxC,SAAkBt5B,GChDL,IAKOq9B,ENiBWz7B,EAAO/H,EMhB9BsjC,EACA3iC,EACAhF,EACAqkC,EAJYwD,ED4CiB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MC3ClFA,EAAOE,EAAYF,KAAKC,aACxB5iC,EAAQ2iC,EAAK3iC,KAAQ2iC,EAAK3iC,KAAK6C,MAAQ,GACvC7H,EAAQ2nC,EAAK3iC,KAAQ2iC,EAAK3nC,KAAK6H,MAAQ,GACvCw8B,EAAWsD,EAAKxH,OAAUwH,EAAKxH,OAAS,GAE9C0H,EAAYF,KAAKC,aAAalE,eAAe3jC,MNWhBqM,EMXsC,CAAEpH,KAAAA,EAAMhF,KAAAA,EAAMqkC,QAAAA,GNW7ChgC,EMXwDwjC,EAAYr9B,INatG48B,GAAcU,QAAQ17B,EAAO/H,GACzB,IAAI+iC,GAAch7B,EAAO/H,GAEzB,yCK0BR,SAAqBmG,IACqB,CAAEA,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OEnDjFA,KAAKC,aAAa9D,MAAQ,sCFuDxC,SAAoBt5B,GEzDP,IAKSq9B,EACdF,EACA3iC,EACAq/B,EACAhgC,EACAgE,EALcw/B,EFqDmB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MEpDtFA,EAAOE,EAAYF,KAAKC,aACxB5iC,EAAQ2iC,EAAK3iC,KAAQ2iC,EAAK3iC,KAAK6C,MAAQ,GACvCw8B,EAAWsD,EAAKxH,OAAUwH,EAAKxH,OAAS,GACxC97B,EAAUsjC,EAAK9D,eAAe8D,EAAK9D,eAAexkC,OAAS,GAAMsoC,EAAK9D,eAAe8D,EAAK9D,eAAexkC,OAAS,GAAK,GACvHgJ,EAASg8B,EAAQx8B,MAAS29B,EAAUnB,EAAQx8B,OAAO,GAAQ,GAEjEggC,EAAYF,KAAKC,aAAahE,iBAAiB7jC,KXoB5C,SAA4BqM,EAAO/H,GAOxC,OALIogC,EAAgBqD,QAAQ17B,EAAO/H,GAC3B,IAAIogC,EAAgBr4B,EAAO/H,GAE3B,GWzB8C0jC,CAAmB,CACrE/iC,KAAAA,EAAMq/B,QAAAA,EAAShgC,OAAAA,EAAQgE,MAAAA,GACtBw/B,EAAYr9B,uCFgDjB,SAAkBA,oCAIlB,SAAiBA,GGnEJ,IAKMq9B,EACXxjC,EADWwjC,EH+DgB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MG9DhFtjC,EAAUwjC,EAAYr9B,IAAIA,IAAI3I,UAAagmC,EAAYr9B,IAAIA,IAAI3I,UAAY,GACjFgmC,EAAYF,KAAKC,aAAa/D,eAAe9jC,KVY1C,SAAyBqM,EAAO/H,GAOrC,OALI6iC,GAAaY,QAAQ17B,EAAO/H,GACxB,IAAI6iC,GAAa96B,EAAO/H,GAExB,GUjB4C2jC,CAAgB3jC,EAAQwjC,EAAYr9B,4CHiExF,SAAuBA,IACuB,CAAEA,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OIvErFA,KAAKC,aAAa9D,MAAQ,wCJ2ExC,SAAsBt5B,GI7ET,IAKWq9B,ELgBWz7B,EAAO/H,EKflCsjC,EACA3iC,EACAq/B,EAHgBwD,EJyEqB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MIxE1FA,EAAOE,EAAYF,KAAKC,aACxB5iC,EAAQ2iC,EAAK3iC,KAAQ2iC,EAAK3iC,KAAK6C,MAAQ,GACvCw8B,EAAWsD,EAAKxH,OAAUwH,EAAKxH,OAAS,GAE9C0H,EAAYF,KAAKC,aAAajE,mBAAmB5jC,MLWhBqM,EKX0C,CAAEpH,KAAAA,EAAMq/B,QAAAA,GLW3ChgC,EKXsDwjC,EAAYr9B,ILaxGi9B,GAAkBK,QAAQ17B,EAAO/H,GAC7B,IAAIojC,GAAkBr7B,EAAO/H,GAE7B,4CCwDR,SAAwBmG,IACwB,CAAEA,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OKjFvFA,KAAKC,aAAa9D,MAAQ,yCLqFxC,SAAuBt5B,GKvFV,IAKYq9B,EXeWz7B,EAAO/H,EWdnCsjC,EACAtD,EAFiBwD,ELmFsB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MKlF5FA,EAAOE,EAAYF,KAAKC,aACxBvD,EAAWsD,EAAKxH,QAAyB,IAAfwH,EAAKxH,OAAgBwH,EAAKxH,OAAS,GAEnE0H,EAAYF,KAAKC,aAAatE,oBAAoBvjC,MXWhBqM,EWX2Ci4B,EXWpChgC,EWX6CwjC,EAAYr9B,IXahG28B,GAAmBW,QAAQ17B,EAAO/H,GAC9B,IAAI8iC,GAAmB/6B,EAAO/H,GAE9B,2CMmER,SAAuBmG,IACuB,CAAEA,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OM1FrFA,KAAKC,aAAa9D,MAAQ,wCN8FxC,SAAsBt5B,GMhGT,IAKWq9B,EVuBWz7B,EAAO/H,EUtBlCsjC,EACA3nC,EACAgF,EACAq/B,EACAh8B,EALgBw/B,EN4FqB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MM3F1FA,EAAOE,EAAYF,KAAKC,aACxB5nC,EAAQ2nC,EAAK3nC,KAAQ2nC,EAAK3nC,KAAK6H,MAAQ,GACvC7C,EAAQ2iC,EAAK3iC,KAAQ2iC,EAAK3iC,KAAK6C,MAAQ,GACvCw8B,EAAWsD,EAAKxH,QAAyB,IAAfwH,EAAKxH,OAAgBwH,EAAKxH,OAAS,GAC7D93B,EAAQm9B,EAAUnB,EAAQx8B,OAEhCggC,EAAYF,KAAKC,aAAanE,mBAAmB1jC,MVgBhBqM,EUhB0C,CACzEpM,KAAAA,EAAMgF,KAAAA,EAAMq/B,QAAAA,EAASh8B,MAAAA,GVeiBhE,EUdrCwjC,EAAYr9B,IVgBb68B,GAAkBS,QAAQ17B,EAAO/H,GAC7B,IAAIgjC,GAAkBj7B,EAAO/H,GAE7B,2CIoER,SAAuBmG,IACuB,CAAEA,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OOrGrFA,KAAKC,aAAa9D,MAAQ,wCPyGxC,SAAsBt5B,GO3GT,IAKWq9B,ETgBWz7B,EAAO/H,ESflCsjC,EACA3iC,EACAq/B,EAHgBwD,EPuGqB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MOtG1FA,EAAOE,EAAYF,KAAKC,aACxB5iC,EAAQ2iC,EAAK3iC,KAAQ2iC,EAAK3iC,KAAK6C,MAAQ,GACvCw8B,EAAWsD,EAAKxH,QAAyB,IAAfwH,EAAKxH,OAAgBwH,EAAKxH,OAAS,GAEnE0H,EAAYF,KAAKC,aAAarE,mBAAmBxjC,MTWhBqM,ESX0C,CAAEpH,KAAAA,EAAMq/B,QAAAA,GTW3ChgC,ESXsDwjC,EAAYr9B,ITaxGg9B,GAAkBM,QAAQ17B,EAAO/H,GAC7B,IAAImjC,GAAkBp7B,EAAO/H,GAE7B,yCEsFR,SAAqBmG,IACqB,CAAEA,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OQ9GjFA,KAAKC,aAAa9D,MAAQ,sCRkHxC,SAAoBt5B,GQpHP,IAKSq9B,EXqBWz7B,EAAO/H,EWpBhCsjC,EACA3iC,EACAq/B,EACAh8B,EAJcw/B,ERgHmB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MQ/GtFA,EAAOE,EAAYF,KAAKC,aACxB5iC,EAAQ2iC,EAAK3iC,KAAQ2iC,EAAK3iC,KAAK6C,MAAQ,GACvCw8B,EAAWsD,EAAKxH,QAAyB,IAAfwH,EAAKxH,OAAgBwH,EAAKxH,OAAS,GAC7D93B,EAAQm9B,EAAUnB,EAAQx8B,OAEhCggC,EAAYF,KAAKC,aAAapE,iBAAiBzjC,MXehBqM,EWfwC,CAAEpH,KAAAA,EAAMq/B,QAAAA,EAASh8B,MAAAA,GXelDhE,EWf2DwjC,EAAYr9B,IXiB3G+8B,GAAgBO,QAAQ17B,EAAO/H,GAC3B,IAAIkjC,GAAgBn7B,EAAO/H,GAE3B,8BG0FR,SAAUmG,4BAIV,SAASA,GS9HI,IACHq9B,EpBkBqBz7B,EAAO/H,EoBjB9BW,EADE6iC,ET8HO,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MS7H9D3iC,EAAQ6iC,EAAYr9B,IAAIA,IAAOq9B,EAAYr9B,IAAIA,IAAI3I,UAAUomC,WAAW,IAAK,IAAM,GACzFJ,EAAYF,KAAKC,aAAa5iC,MpBgBDoH,EoBhByBpH,EpBgBlBX,EoBhBwBwjC,EAAYr9B,IpBkBtE+5B,EAAcuD,QAAQ17B,EAAO/H,GACzB,IAAIkgC,EAAcn4B,EAAO/H,GAEzB,qCW2GR,SAAkBmG,oCAIlB,SAAiBA,GUvIJ,IACMq9B,EpBkBYz7B,EAAO/H,EoBjB9BrE,EADW6nC,EVuIgB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MUtIhF3nC,EAAQ6nC,EAAYr9B,IAAIA,IAAI3I,UAAagmC,EAAYr9B,IAAIA,IAAI3I,UAAUomC,WAAW,IAAK,IAAM,GACnGJ,EAAYF,KAAKC,aAAa5nC,MpBgBDoM,EoBhByBpM,EpBgBlBqE,EoBhBwBwjC,EAAYr9B,IpBkBtEg6B,EAAcsD,QAAQ17B,EAAO/H,GACzB,IAAImgC,EAAcp4B,EAAO/H,GAEzB,6BUoHR,SAAUmG,4BAIV,SAASA,+BAIT,SAAYA,8BAIZ,SAAWA,GWxJE,IACDq9B,EvB+BqBz7B,EAAO/H,EuB9BhCsjC,EACA7D,EACAC,EAHI8D,EXwJS,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MWvJlEA,EAAOE,EAAYF,KAAKC,aACxB9D,EAAS6D,EAAK7D,OAAS,GAAM6D,EAAK7D,MAAQ,GAC1CC,EAAiB4D,EAAK5D,eAAiB,GAAM4D,EAAK5D,cAAgB,GACxE8D,EAAYF,KAAKC,aAAazH,QvB2BC/zB,EuB3B2B,CAAE03B,MAAAA,EAAOC,cAAAA,GvB2B7B1/B,EuB3B8CwjC,EAAYr9B,IvB6B9F85B,EAAgBwD,QAAQ17B,EAAO/H,GAC3B,IAAIigC,EAAgBl4B,EAAO/H,GAE3B,8BYwHR,SAAWmG,6BAIX,SAAUA,IYjKG,SACFq9B,GACT,I3BiB8Bz7B,EAAO/H,E2BhBrC,GAAwB,GADKwjC,EAAYF,KAAKC,aAAtC3D,iBACuB,CAC7B,IAAMH,EAAS+D,EAAYr9B,IAAIA,IAAI3I,UAAagmC,EAAYr9B,IAAIA,IAAI3I,UAAY,GAChFgmC,EAAYF,KAAKC,aAAa9D,MAAM/jC,M3BcRqM,E2Bd+B03B,E3BcxBz/B,E2Bd+BwjC,EAAYr9B,I3BgB9E25B,EAAe2D,QAAQ17B,EAAO/H,GAC1B,IAAI8/B,EAAe/3B,EAAO/H,GAE1B,S2BlBC,CACL,IAAMy/B,EAAS+D,EAAYr9B,IAAIA,IAAI3I,UAAagmC,EAAYr9B,IAAIA,IAAI3I,UAAY,GAChFgmC,EAAYF,KAAKC,aAAa5D,qBAAqBjkC,KAAK+jC,IZ0J1DA,CAAiB,CAAEt5B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,wCAIxE,SAAkBn9B,GatKL,IACOq9B,GAAAA,EbsKgB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,OarK3EA,KAAKC,aAAa3D,kBAAmB,EACjD4D,EAAYF,KAAKC,aAAa5D,qBAAuB,mCbwKvD,SAAiBx5B,Ga3KJ,IAMMq9B,E1BoBoBz7B,EAAO/H,E0BnBtCsjC,EACA3iC,EACAq/B,EAHWwD,EbsKgB,CAAEr9B,IAAK,CAAEA,IAAAA,EAAKq4B,OAAQtkC,KAAKopC,KAAK9E,QAAU8E,KAAMppC,KAAKopC,MarKhFA,EAAOE,EAAYF,KAAKC,aACxB5iC,EAAQ6iC,EAAYr9B,IAAIA,IAAI3I,UAAagmC,EAAYr9B,IAAIA,IAAI3I,UAAU4mB,MAAM,KAAK,GAAK,GACvF4b,EAAWsD,EAAK3D,sBAAwB,GAAM2D,EAAK3D,qBAAuB,GAChF6D,EAAYF,KAAKC,aAAa7D,cAAchkC,M1BgBPqM,E0BhBqC,CAAEpH,KAAAA,EAAMq/B,QAAAA,G1BgBtChgC,E0BhBiDwjC,EAAYr9B,I1BkBvG45B,EAAsB0D,QAAQ17B,EAAO/H,GACjC,IAAI+/B,EAAsBh4B,EAAO/H,GAEjC,K0BpBNwjC,EAAYF,KAAKC,aAAa3D,kBAAmB,iCbqKnD,SAAgBz5B,kCAIhB,SAAeA,kCAIf,SAAeA,iCAIf,SAAcA,mCAId,SAAgBA,kCAIhB,SAAeA,qCAIf,SAAkBA,oCAIlB,SAAiBA,0CAIjB,SAAuBA,yCAIvB,SAAsBA,8BAItB,SAAWA,6BAIX,SAAUA,8BAIV,SAAWA,6BAIX,SAAUA,gFAjNSk9B,CAAgCQ,EAAOnI,KAAKlwB,s+DchBjE,IAAMs4B,GAAgB,CAAC,WACrB,mBACA,qBACA,sCACA,yBACA,oBACA,qBACA,oBACA,eACA,iBACA,mBACA,eACA,oBACA,eACA,eACA,oCACA,4BACA,kCACA,0BACA,wBACA,eACA,eACA,gBACA,kBACA,eACA,eACA,kBACA,eACA,eACA,gBACA,gBACA,kBACA,iBACA,eACA,kBACA,kBACA,eACA,gBACA,eACA,mBACA,eACA,mBACA,gBACA,iBACA,oBACA,wBACA,gBACA,qBACA,iBACA,gBACA,eACA,eACA,eACA,gBACA,gBACA,iBACA,kBACA,oBACA,oBACA,yBACA,qBACA,mBACA,oBACA,iBACA,uBACA,oBACA,oBACA,mBACA,oBACA,qBACA,oBACA,oBACA,mBACA,oBACA,oBACA,oBACA,qBACA,oBACA,kBACA,oBACA,oBACA,uBACA,iBACA,uBACA,oBACA,oBACA,iBACA,uBACA,oBACA,iBACA,eACA,eACA,eACA,eACA,iBACA,eACA,eACA,gBACA,eACA,gBACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,gBACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,gBACA,gBACA,gBACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,kBACA,mBACA,eACA,eACA,gBACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,iBACA,qBACA,WAA8C5/B,KAAK,IAE/CmB,IAAM,IAAIw+B,EAAOx+B,IAAIuG,iBAAkB+C,YAAYm1B,IAEnDC,GAAiB1+B,GAAImX,gBAAgBlY,KAAI,SAAC0/B,EAAI5pC,GAAL,OAAe,IAAIypC,EAAO9xB,IAAIqmB,IAAI4L,EAAI5pC,MAE/EuvB,GAAqB,IAAIka,EAAAA,EAEVI,GAAAA,SAAAA,uBA6BnB,WAAYl8B,GAAO,yBACjB,cAAMA,IACDI,QAAU,IAAI07B,EAAOx+B,IAAImyB,mBAAf,MAAwCnyB,GAAK0+B,GAAgBpa,IAC5E,EAAK1d,UAAYg4B,EAAgBh4B,UACjC,EAAKvI,aAAeugC,EAAgBvgC,aACpC,EAAKC,cAAgBsgC,EAAgBtgC,cALpB,8BAQnB,WACE,OAAO0B,0BAGT,SAAQ2K,EAAUlJ,EAAWomB,GAC1B,GACK,KADGpmB,EAEF,OAAO5M,KAAKgqC,0BAA0Bl0B,EAAUkd,GAEnD,KAAM,2BAAN,OAAiCpmB,4CAIvC,SAA0BkJ,EAAUkd,GACjC,OAAQA,GACP,KAAK,EACJ,OAAOhzB,KAAK4W,SAAS5W,KAAKmS,KAAM,GACjC,KAAK,EACJ,OAAOnS,KAAK4W,SAAS5W,KAAKmS,KAAM,GACjC,KAAK,EACJ,OAAOnS,KAAK4W,SAAS5W,KAAKmS,KAAM,GACjC,QACC,KAAM,2BAAN,OAAiC6gB,wBAItC,WACG,IAAMld,EAAW,IAAIm0B,GAAYjqC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACvDvM,KAAK4T,UAAUkC,EAAU,EAAGi0B,EAAgBG,WAC5C,IAAIC,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,GACIf,KAAKuM,MAAQ,GACbvM,KAAKoqC,YACLpqC,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SACI,KAAV,GAAPopC,IAAgR,IAAxP,GAAKA,GAAS,GAAKJ,EAAgBM,OAAW,GAAKN,EAAgBO,KAAS,GAAKP,EAAgBQ,SAAa,GAAKR,EAAgBS,UAAc,GAAKT,EAAgBU,SAAa,GAAKV,EAAgBW,SAAa,GAAKX,EAAgBY,UAChR,MAAO55B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAhBpC,QAqBI/Q,KAAK+T,WAET,OAAO+B,2BAGV,WACG,IAAMA,EAAW,IAAI80B,GAAiB5qC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC5DvM,KAAK4T,UAAUkC,EAAU,EAAGi0B,EAAgBc,gBAC5C,IAGI,OAFA7qC,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACdA,KAAK8N,OAAO/M,GAAG,IACvB,KAAKgpC,EAAgBQ,SACjBvqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAK8qC,oBACL,MACJ,KAAKf,EAAgBS,UACjBxqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAK+qC,qBACL,MACJ,KAAKhB,EAAgBU,SACjBzqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKgrC,oBACL,MACJ,KAAKjB,EAAgBW,SACjB1qC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKirC,oBACL,MACJ,KAAKlB,EAAgBY,OACjB3qC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKkrC,kBACL,MACJ,KAAKnB,EAAgBM,OACjBrqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKmrC,kBACL,MACJ,KAAKpB,EAAgBO,KACjBtqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKorC,gBACL,MACJ,QACI,MAAM,IAAIzB,EAAOnO,MAAM/G,qBAAqBz0B,OAElD,MAAO+Q,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GA9CpC,QAmDI/Q,KAAK+T,WAET,OAAO+B,+BAGV,WACG,IAAMA,EAAW,IAAIu1B,GAAqBrrC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAChEvM,KAAK4T,UAAUkC,EAAU,EAAGi0B,EAAgBuB,oBAC5C,IAAInB,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgBO,MAC3BtqC,KAAKuM,MAAQ,GACbvM,KAAKurC,eACLvrC,KAAKuM,MAAQ,GACbvM,KAAKyG,OACLzG,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,GACIf,KAAKuM,MAAQ,GACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SAChBopC,IAAQJ,EAAgB0B,YACjCzrC,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GA1BpC,QA+BI/Q,KAAK+T,WAET,OAAO+B,iCAGV,WACG,IAAMA,EAAW,IAAI61B,GAAuB3rC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAClEvM,KAAK4T,UAAUkC,EAAU,EAAGi0B,EAAgB6B,sBAC5C,IAAIzB,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgBM,QAC3BrqC,KAAKuM,MAAQ,GACbvM,KAAKyG,OACLzG,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,EAAG,CAGC,OAFAf,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACdA,KAAK8N,OAAO/M,GAAG,IACvB,KAAKgpC,EAAgB8B,OACjB7rC,KAAKuM,MAAQ,GACbvM,KAAKmmC,eACL,MACJ,KAAK4D,EAAgB0B,WACjBzrC,KAAKuM,MAAQ,GACbvM,KAAK4hC,SACL,MACJ,QACI,MAAM,IAAI+H,EAAOnO,MAAM/G,qBAAqBz0B,MAEhDA,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SAChBopC,IAAQJ,EAAgB8B,QAAU1B,IAAQJ,EAAgB0B,YACnEzrC,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GApCpC,QAyCI/Q,KAAK+T,WAET,OAAO+B,8BAGV,WACG,IAAMA,EAAW,IAAIg2B,GAAoB9rC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC/DvM,KAAK4T,UAAUkC,EAAU,EAAGi0B,EAAgBgC,mBAC5C,IACI/rC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgB8B,QAC3B7rC,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgBiC,OAC3BhsC,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC7B,MAAOl7B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAZpC,QAiBI/Q,KAAK+T,WAET,OAAO+B,mCAGV,WACG,IAAMA,EAAW,IAAIo2B,GAAyBlsC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACpEvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBoC,wBAC7C,IACInsC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgBQ,UAC3BvqC,KAAKuM,MAAQ,GACbvM,KAAKyG,OACLzG,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,GACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAhBpC,QAqBI/Q,KAAK+T,WAET,OAAO+B,oCAGV,WACG,IAAMA,EAAW,IAAIs2B,GAA0BpsC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACrEvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBsC,yBAC7C,IAAIlC,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgBS,WAC3BxqC,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,GACIf,KAAKuM,MAAQ,GACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,GACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SAChBopC,IAAQJ,EAAgB0B,YACjCzrC,KAAKuM,MAAQ,GACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAtBpC,QA2BI/Q,KAAK+T,WAET,OAAO+B,mCAGV,WACG,IAAMA,EAAW,IAAIw2B,GAAyBtsC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACpEvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBwC,wBAC7C,IACIvsC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBU,UAC3BzqC,KAAKuM,MAAQ,IACbvM,KAAKurC,eACLvrC,KAAKuM,MAAQ,IACbvM,KAAKyG,OACLzG,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,IACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAlBpC,QAuBI/Q,KAAK+T,WAET,OAAO+B,mCAGV,WACG,IAAMA,EAAW,IAAI02B,GAAyBxsC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACpEvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgB0C,wBAC7C,IAAItC,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBW,UAC3B1qC,KAAKuM,MAAQ,IACbvM,KAAKyG,OACLzG,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,GACIf,KAAKuM,MAAQ,IACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SAChBopC,IAAQJ,EAAgB0B,YACjCzrC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAxBpC,QA6BI/Q,KAAK+T,WAET,OAAO+B,iCAGV,WACG,IAAMA,EAAW,IAAI42B,GAAuB1sC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAClEvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgB4C,sBAC7C,IAAIxC,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBY,QAC3B3qC,KAAKuM,MAAQ,IACbvM,KAAKyG,OACLzG,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,GACIf,KAAKuM,MAAQ,IACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SAChBopC,IAAQJ,EAAgB0B,YACjCzrC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAxBpC,QA6BI/Q,KAAK+T,WAET,OAAO+B,sBAGV,WACG,IAAMA,EAAW,IAAI82B,GAAY5sC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACvDvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgB8C,WAC7C,IACI7sC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC7B,MAAOl7B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GARpC,QAaI/Q,KAAK+T,WAET,OAAO+B,8BAGV,WACG,IAAMA,EAAW,IAAIg3B,GAAoB9sC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC/DvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBgD,mBAC7C,IACI/sC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC7B,MAAOl7B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GARpC,QAaI/Q,KAAK+T,WAET,OAAO+B,sBAGV,WACG,IAAMA,EAAW,IAAIk3B,GAAYhtC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACvDvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBkD,WAC7C,IAII,OAHAjtC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACVA,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,EAAG9N,KAAKmS,OAE9D,KAAK,EACDnS,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBza,MAC3B,MAEJ,KAAK,EACDtvB,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBmD,MAC3B,MAEJ,KAAK,EACDltC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBmD,MAC3BltC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBoD,IAC3BntC,KAAKuM,MAAQ,IACbvM,KAAKyB,OACLzB,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBqD,IAC3B,MAEJ,KAAK,EACDptC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBsD,KAC3BrtC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBoD,IAC3BntC,KAAKuM,MAAQ,IACbvM,KAAKyB,OACLzB,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBqD,IAC3B,MAEJ,KAAK,EACDptC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBuD,QAC3BttC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBoD,IAC3BntC,KAAKuM,MAAQ,IACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBqD,KAGjC,MAAOr8B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAzDpC,QA8DI/Q,KAAK+T,WAET,OAAO+B,wBAGV,WACG,IAAMA,EAAW,IAAIy3B,GAAcvtC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACzDvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgByD,aAC7C,IACIxtC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtB,IAAIytC,EAAO,EACX,EAAG,CACF,GACK,IADGA,EAkBP,MAAM,IAAI9D,EAAOnO,MAAM/G,qBAAqBz0B,MAb5C,OAHAA,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACZA,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,EAAG9N,KAAKmS,OAE5D,KAAK,EACDnS,KAAKuM,MAAQ,IACbvM,KAAK0tC,eACL,MAEJ,KAAK,EACD1tC,KAAKuM,MAAQ,IACbvM,KAAKulC,QAOVvlC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,YAC1C,GAARs7B,GAAaA,GAAQ9D,EAAOx+B,IAAIiX,IAAIiB,oBAC/C,MAAOtS,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAlCpC,QAuCI/Q,KAAK+T,WAET,OAAO+B,uBAGV,WACG,IAAMA,EAAW,IAAI63B,GAAa3tC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACxDvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgB6D,YAC7C,IACI5tC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB0B,YAC3BzrC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBiC,OAC3BhsC,KAAKuM,MAAQ,IACbvM,KAAK6tC,aACP,MAAO98B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAZpC,QAiBI/Q,KAAK+T,WAET,OAAO+B,8BAGV,WACG,IAAMA,EAAW,IAAIg4B,GAAoB9tC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC/DvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBgE,mBAC7C,IACI/tC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB0B,YAC3BzrC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,IACbvM,KAAK4hC,SACL5hC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAdpC,QAmBI/Q,KAAK+T,WAET,OAAO+B,4BAGV,WACG,IAAMA,EAAW,IAAIk4B,GAAkBhuC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC7DvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBkE,iBAC7C,IAAI9D,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgByB,IAC3BxrC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBmE,WAC3BluC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBiC,OAC3BhsC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,GACIf,KAAKuM,MAAQ,IACbvM,KAAKstB,YACLttB,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SACI,KAAV,GAAPopC,IAAiN,IAAzL,GAAKA,GAAS,GAAKJ,EAAgBoE,UAAc,GAAKpE,EAAgBqE,QAAY,GAAKrE,EAAgB0B,WAAe,GAAK1B,EAAgBkC,OAAW,GAAKlC,EAAgBsE,UAC/MruC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBra,OAC3B1vB,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBiC,OAC3BhsC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC3BjsC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2B,IAC7B,MAAO36B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GA9BpC,QAmCI/Q,KAAK+T,WAET,OAAO+B,2BAGV,WACG,IAAMA,EAAW,IAAIw4B,GAAiBtuC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC5DvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBwE,gBAC7C,IAGI,OAFAvuC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACdA,KAAK8N,OAAO/M,GAAG,IACvB,KAAKgpC,EAAgBkC,OACjBjsC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC3B,MACJ,KAAKlC,EAAgBsE,OACjBruC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBsE,QAC3B,MACJ,KAAKtE,EAAgBqE,QACjBpuC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBqE,SAC3B,MACJ,KAAKrE,EAAgBoE,UACjBnuC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBoE,WAC3B,MACJ,KAAKpE,EAAgB0B,WACjBzrC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKwuC,eACL,MACJ,QACI,MAAM,IAAI7E,EAAOnO,MAAM/G,qBAAqBz0B,OAElD,MAAO+Q,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GApCpC,QAyCI/Q,KAAK+T,WAET,OAAO+B,4BAGV,WACG,IAAMA,EAAW,IAAI24B,GAAkBzuC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC7DvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgB2E,iBAC7C,IAII,OAHA1uC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACVA,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,OAE/D,KAAK,EACDnS,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBsE,QAC3B,MAEJ,KAAK,EACDruC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBqE,SAC3B,MAEJ,KAAK,EACDpuC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAK4nC,QACL,MAEJ,KAAK,EACD5nC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAK2uC,kBAAkB,GACvB,MAEJ,KAAK,EACD3uC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC3B,MAEJ,KAAK,EACDjsC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKyB,QAGX,MAAOsP,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GA7CpC,QAkDI/Q,KAAK+T,WAET,OAAO+B,8BAGV,WACG,IAAMA,EAAW,IAAI84B,GAAoB5uC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OAC/DvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgB8E,mBAE7C,IACI7uC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB0B,YAC3BzrC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBoD,IAC3BntC,KAAKuM,MAAQ,IACbvM,KAAK6tC,aACL7tC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MAEtB,IADA,IAAIytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,MAC/C,GAARs7B,GAAaA,GAAQ9D,EAAOx+B,IAAIiX,IAAIiB,oBAC1B,IAAToqB,IACAztC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB+E,MAC3B9uC,KAAKuM,MAAQ,IACbvM,KAAK6tC,cAET7tC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,MAG9DnS,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MAChBA,KAAK8N,OAAO/M,GAAG,KACTgpC,EAAgB+E,OACxB9uC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB+E,OAG/B9uC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBqD,IAC7B,MAAOr8B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GArCpC,QA0CI/Q,KAAK+T,WAET,OAAO+B,mCAGV,SAAkBi5B,QACLjtC,IAAPitC,IACFA,EAAK,GAEN,IAAMC,EAAahvC,KAAKmS,KAClB88B,EAAejvC,KAAKuM,MACtBuJ,EAAW,IAAIo5B,GAAyBlvC,KAAMA,KAAKmS,KAAM88B,GAG7DjvC,KAAKoW,mBAAmBN,EAAU,GAAIi0B,EAAgBoF,uBAAwBJ,GAC9E,IAAI5E,EAAM,EACV,IAKI,OAJAnqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACZA,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,OAE7D,KAAK,EACDnS,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB0B,YAC3B,MAEJ,KAAK,EACDzrC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBqF,MAC3BpvC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,GACrB,EAAG,CAGC,OAFAf,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACdA,KAAK8N,OAAO/M,GAAG,IACvB,KAAKgpC,EAAgBsF,YACjBrvC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBsF,aAC3B,MACJ,KAAKtF,EAAgBuF,MACjBtvC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBuF,OAC3B,MACJ,KAAKvF,EAAgBwF,IACjBvvC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtB,IAAIytC,EAAO,EACX,EAAG,CACF,GACK,IADGA,EAMP,MAAM,IAAI9D,EAAOnO,MAAM/G,qBAAqBz0B,MAJ5CA,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBwF,KAK5BvvC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,YAC1C,GAARs7B,GAAaA,GAAQ9D,EAAOx+B,IAAIiX,IAAIiB,oBAC7C,MACJ,QACI,MAAM,IAAIsmB,EAAOnO,MAAM/G,qBAAqBz0B,MAEhDA,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBmqC,EAAMnqC,KAAK8N,OAAO/M,GAAG,SACW,IAAvBopC,EAAM,IAAO,KAA+J,IAA9I,GAAMA,EAAM,IAAS,GAAMJ,EAAgBsF,YAAc,GAAQ,GAAMtF,EAAgBwF,IAAM,GAAQ,GAAMxF,EAAgBuF,MAAQ,MAC9KtvC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgByF,OAC3B,MAEJ,KAAK,EACDxvC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC3BjsC,KAAKuM,MAAQ,IACbvM,KAAK2uC,kBAAkB,GACvB3uC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgBkC,QAC3B,MAEJ,KAAK,EACDjsC,KAAKuM,MAAQ,IACbvM,KAAKwuC,eAOT,IAJAxuC,KAAKmS,KAAKvQ,KAAO5B,KAAK8N,OAAO7L,IAAI,GACjCjC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MAClBytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,MAC/C,GAARs7B,GAAaA,GAAQ9D,EAAOx+B,IAAIiX,IAAIiB,oBAAoB,CAC3D,GAAa,IAAToqB,EAQA,OAP6B,OAAzBztC,KAAK0S,iBACL1S,KAAK6T,uBAGT7T,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACZA,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,OAE7D,KAAK,EAID,GAHA2D,EAAW,IAAIo5B,GAAyBlvC,KAAMgvC,EAAYC,GAC1DjvC,KAAKsW,wBAAwBR,EA3FzB,GA2FgDi0B,EAAgBoF,wBACpEnvC,KAAKuM,MAAQ,KACPvM,KAAK4W,SAAS5W,KAAKmS,KAAM,GAC3B,MAAM,IAAIw3B,EAAOnO,MAAMmD,yBAAyB3+B,KAAM,+BAE1DA,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB0F,OAC3BzvC,KAAKuM,MAAQ,IACbvM,KAAK2uC,kBAAkB,GACvB,MAEJ,KAAK,EAID,GAHA74B,EAAW,IAAIo5B,GAAyBlvC,KAAMgvC,EAAYC,GAC1DjvC,KAAKsW,wBAAwBR,EAxGzB,GAwGgDi0B,EAAgBoF,wBACpEnvC,KAAKuM,MAAQ,KACPvM,KAAK4W,SAAS5W,KAAKmS,KAAM,GAC3B,MAAM,IAAIw3B,EAAOnO,MAAMmD,yBAAyB3+B,KAAM,+BAE1DA,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2F,IAC3B1vC,KAAKuM,MAAQ,IACbvM,KAAKE,QACLF,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB4F,IAC3B,MAEJ,KAAK,EAID,GAHA75B,EAAW,IAAIo5B,GAAyBlvC,KAAMgvC,EAAYC,GAC1DjvC,KAAKsW,wBAAwBR,EAvHzB,GAuHgDi0B,EAAgBoF,wBACpEnvC,KAAKuM,MAAQ,KACPvM,KAAK4W,SAAS5W,KAAKmS,KAAM,GAC3B,MAAM,IAAIw3B,EAAOnO,MAAMmD,yBAAyB3+B,KAAM,+BAE1DA,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB0F,OAC3BzvC,KAAKuM,MAAQ,IACbvM,KAAKE,QAIbF,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,OAEhE,MAAOqpB,GACL,KAAIA,aAAiBmO,EAAOnO,MAAM7tB,sBAKpC,MAAM6tB,EAJH1lB,EAAS8C,UAAY4iB,EACrBx7B,KAAKsS,YAAYusB,YAAY7+B,KAAMw7B,GACnCx7B,KAAKsS,YAAY/C,QAAQvP,KAAMw7B,GAxIpC,QA6IIx7B,KAAKwW,wBAAwBw4B,GAEjC,OAAOl5B,uBAGV,WACG,IAAMA,EAAW,IAAI85B,GAAa5vC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACxDvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgB8F,YAE7C,IAII,OAHA7vC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACVA,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,OAE/D,KAAK,EACDnS,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2F,IAC3B1vC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB4F,IAC3B,MAEJ,KAAK,EACD3vC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB2F,IAC3B1vC,KAAKuM,MAAQ,IACbvM,KAAK6tC,aACL7tC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MAEtB,IADA,IAAIytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,MAC/C,GAARs7B,GAAaA,GAAQ9D,EAAOx+B,IAAIiX,IAAIiB,oBAC1B,IAAToqB,IACAztC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB+E,MAC3B9uC,KAAKuM,MAAQ,IACbvM,KAAK6tC,cAET7tC,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MACtBytC,EAAOztC,KAAKiO,QAAQknB,gBAAgBn1B,KAAK8N,OAAQ,GAAI9N,KAAKmS,MAG9DnS,KAAKuM,MAAQ,IACbvM,KAAKsS,YAAYrR,KAAKjB,MAChBA,KAAK8N,OAAO/M,GAAG,KACTgpC,EAAgB+E,OACxB9uC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB+E,OAG/B9uC,KAAKuM,MAAQ,IACbvM,KAAKkP,MAAM66B,EAAgB4F,KAGjC,MAAO5+B,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAlDpC,QAuDI/Q,KAAK+T,WAET,OAAO+B,uBAGV,WACG,IAAMA,EAAW,IAAIg6B,GAAa9vC,KAAMA,KAAKmS,KAAMnS,KAAKuM,OACxDvM,KAAK4T,UAAUkC,EAAU,GAAIi0B,EAAgBgG,YAC7C,IAAI5F,EAAM,EACV,IACInqC,KAAK+V,cAAcD,EAAU,GAC7B9V,KAAKuM,MAAQ,KACb49B,EAAMnqC,KAAK8N,OAAO/M,GAAG,MACPgpC,EAAgBiG,MAAQ7F,IAAQJ,EAAgBsE,OAC9DruC,KAAKsS,YAAYU,cAAchT,OAE9BA,KAAKsS,YAAYS,YAAY/S,MAC1BA,KAAKY,WAEX,MAAOmQ,GACR,KAAIA,aAAc44B,EAAOnO,MAAM7tB,sBAK9B,MAAMoD,EAJH+E,EAAS8C,UAAY7H,EACrB/Q,KAAKsS,YAAYusB,YAAY7+B,KAAM+Q,GACnC/Q,KAAKsS,YAAY/C,QAAQvP,KAAM+Q,GAdpC,QAmBI/Q,KAAK+T,WAET,OAAO+B,QA1kCSi0B,CAAwBJ,EAAOt3B,WAA/B03B,GAAAA,kBACM,yBADNA,GAAAA,eAGG,CAAC,KAAM,WAAY,SAAU,WAAY,aAC7D,cAAe,aAAc,aAAc,WAC3C,SAAU,QAAS,WAAY,cAC/B,kBAAmB,MAAO,MAAO,MAAO,MACxC,MAAO,MAAO,MAAO,MAAO,MAAO,MAAO,MAC1C,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,KAC1C,KAAM,KAAM,UAAW,KAAM,KAAM,KAAM,KACzC,aAViBA,GAAAA,gBAYI,CAAC,KAAM,SAAU,OAAQ,SAAU,WACxD,YAAa,WAAY,WAAY,SACrC,OAAQ,MAAO,SAAU,YAAa,QACtC,KAAM,KAAM,QAAS,KAAM,KAAM,KAAM,KACvC,OAAQ,QAAS,QAAS,OAAQ,YAClC,UAAW,OAAQ,aAAc,SACjC,SAAU,UAAW,eAAgB,cACrC,KAAM,OAAQ,cAAe,MAAO,UACpC,QAAS,aApBQA,GAAAA,YAsBA,CAAC,OAAQ,YAAa,gBAAiB,kBACxD,eAAgB,oBAAqB,qBACrC,oBAAqB,oBAAqB,kBAC1C,OAAQ,eAAgB,OAAQ,SAAU,QAC1C,eAAgB,aAAc,YAAa,aAC3C,eAAgB,oBAAqB,QAAS,UAmjClDA,GAAgB/oC,IAAM2oC,EAAOnqC,MAAMwB,IACnC+oC,GAAgBM,OAAS,EACzBN,GAAgBO,KAAO,EACvBP,GAAgB8B,OAAS,EACzB9B,GAAgBQ,SAAW,EAC3BR,GAAgBS,UAAY,EAC5BT,GAAgBU,SAAW,EAC3BV,GAAgBW,SAAW,EAC3BX,GAAgBY,OAAS,EACzBZ,GAAgBmD,KAAO,EACvBnD,GAAgBsD,IAAM,GACtBtD,GAAgBuD,OAAS,GACzBvD,GAAgBmE,UAAY,GAC5BnE,GAAgBra,MAAQ,GACxBqa,GAAgByB,GAAK,GACrBzB,GAAgB2B,GAAK,GACrB3B,GAAgBiC,MAAQ,GACxBjC,GAAgBoD,GAAK,GACrBpD,GAAgBqD,GAAK,GACrBrD,GAAgB2F,GAAK,GACrB3F,GAAgB4F,GAAK,GACrB5F,GAAgB+E,KAAO,GACvB/E,GAAgB0F,MAAQ,GACxB1F,GAAgBkG,MAAQ,GACxBlG,GAAgBiG,KAAO,GACvBjG,GAAgBoE,UAAY,GAC5BpE,GAAgBqE,QAAU,GAC1BrE,GAAgBza,KAAO,GACvBya,GAAgB0B,WAAa,GAC7B1B,GAAgBkC,OAAS,GACzBlC,GAAgBsE,OAAS,GACzBtE,GAAgBmG,QAAU,GAC1BnG,GAAgBoG,aAAe,GAC/BpG,GAAgBqG,YAAc,GAC9BrG,GAAgBsG,GAAK,GACrBtG,GAAgBqF,KAAO,GACvBrF,GAAgBsF,YAAc,GAC9BtF,GAAgBwF,IAAM,GACtBxF,GAAgBuG,QAAU,GAC1BvG,GAAgBuF,MAAQ,GACxBvF,GAAgByF,MAAQ,GAExBzF,GAAgBG,UAAY,EAC5BH,GAAgBc,eAAiB,EACjCd,GAAgBuB,mBAAqB,EACrCvB,GAAgB6B,qBAAuB,EACvC7B,GAAgBgC,kBAAoB,EACpChC,GAAgBoC,uBAAyB,EACzCpC,GAAgBsC,wBAA0B,EAC1CtC,GAAgBwC,uBAAyB,EACzCxC,GAAgB0C,uBAAyB,EACzC1C,GAAgB4C,qBAAuB,EACvC5C,GAAgB8C,UAAY,GAC5B9C,GAAgBgD,kBAAoB,GACpChD,GAAgBkD,UAAY,GAC5BlD,GAAgByD,YAAc,GAC9BzD,GAAgB6D,WAAa,GAC7B7D,GAAgBgE,kBAAoB,GACpChE,GAAgBkE,gBAAkB,GAClClE,GAAgBwE,eAAiB,GACjCxE,GAAgB2E,gBAAkB,GAClC3E,GAAgB8E,kBAAoB,GACpC9E,GAAgBoF,uBAAyB,GACzCpF,GAAgB8F,WAAa,GAC7B9F,GAAgBgG,WAAa,OAEvB9F,GAAAA,SAAAA,uBACJ,WAAYp4B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,aAY/B,SAAUtU,GAInB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBwxB,IAE1B5qC,KAAKkZ,oBAAoB0xB,GAAkB1pC,MAXvD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBG,UATQ,sCAsB3C,SAAU52B,GACHA,aAAoB61B,IACpB71B,EAASi9B,UAAUvwC,8BAI1B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASk9B,SAASxwC,YA/BrBiqC,CAAoBN,EAAOnxB,mBAoC3BoyB,GAAAA,SAAAA,uBACJ,WAAY/4B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBc,eATQ,8CAY3C,WACG,OAAO7qC,KAAKkZ,oBAAoBgzB,GAA0B,qCAG7D,WACG,OAAOlsC,KAAKkZ,oBAAoBkzB,GAA2B,oCAG9D,WACG,OAAOpsC,KAAKkZ,oBAAoBozB,GAA0B,oCAG7D,WACG,OAAOtsC,KAAKkZ,oBAAoBszB,GAA0B,kCAG7D,WACG,OAAOxsC,KAAKkZ,oBAAoBwzB,GAAwB,kCAG3D,WACG,OAAO1sC,KAAKkZ,oBAAoByyB,GAAwB,gCAG3D,WACG,OAAO3rC,KAAKkZ,oBAAoBmyB,GAAsB,4BAGzD,SAAU/3B,GACHA,aAAoB61B,IACpB71B,EAASm9B,eAAezwC,8BAI/B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASo9B,cAAc1wC,YAjD1B4qC,CAAyBjB,EAAOnxB,mBAsDhC6yB,GAAAA,SAAAA,uBACJ,WAAYx5B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,UAgClC,SAAUtU,GAIhB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBm0B,IAE1BvtC,KAAKkZ,oBAAoBq0B,GAAersC,MA/BpD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBuB,mBATQ,iCAY3C,WACG,OAAOtrC,KAAKiZ,SAAS8wB,GAAgBO,KAAM,+BAG9C,WACG,OAAOtqC,KAAKkZ,oBAAoB4zB,GAAqB,uBAGxD,WACG,OAAO9sC,KAAKkZ,oBAAoB0zB,GAAa,qBAGhD,WACG,OAAO5sC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,qBAG5C,WACG,OAAOxrC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAa5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAASq9B,mBAAmB3wC,8BAInC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASs9B,kBAAkB5wC,YAnD9BqrC,CAA6B1B,EAAOnxB,mBAwDpCmzB,GAAAA,SAAAA,uBACJ,WAAY95B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,gBA4B5B,SAAUtU,GAItB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqB0yB,IAE1B9rC,KAAKkZ,oBAAoB4yB,GAAqB5qC,MAnCjB,mBAsClC,SAAUA,GAIhB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBm0B,IAE1BvtC,KAAKkZ,oBAAoBq0B,GAAersC,MArCpD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB6B,qBATQ,mCAY3C,WACG,OAAO5rC,KAAKiZ,SAAS8wB,GAAgBM,OAAQ,uBAGhD,WACG,OAAOrqC,KAAKkZ,oBAAoB0zB,GAAa,qBAGhD,WACG,OAAO5sC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,qBAG5C,WACG,OAAOxrC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAuB5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAASu9B,qBAAqB7wC,8BAIrC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASw9B,oBAAoB9wC,YAzDhC2rC,CAA+BhC,EAAOnxB,mBA8DtCszB,GAAAA,SAAAA,uBACJ,WAAYj6B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBgC,kBATQ,mCAY3C,WACG,OAAO/rC,KAAKiZ,SAAS8wB,GAAgB8B,OAAQ,wBAGhD,WACG,OAAO7rC,KAAKiZ,SAAS8wB,GAAgBiC,MAAO,yBAG/C,WACG,OAAOhsC,KAAKiZ,SAAS8wB,GAAgBkC,OAAQ,4BAGhD,SAAU34B,GACHA,aAAoB61B,IACpB71B,EAASy9B,kBAAkB/wC,8BAIlC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS09B,iBAAiBhxC,YAjC7B8rC,CAA4BnC,EAAOnxB,mBAsCnC0zB,GAAAA,SAAAA,uBACJ,WAAYr6B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBoC,uBATQ,qCAY3C,WACG,OAAOnsC,KAAKiZ,SAAS8wB,GAAgBQ,SAAU,uBAGlD,WACG,OAAOvqC,KAAKkZ,oBAAoB0zB,GAAa,qBAGhD,WACG,OAAO5sC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,yBAG5C,WACG,OAAOxrC,KAAKkZ,oBAAoBq0B,GAAe,qBAGlD,WACG,OAAOvtC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAG5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAAS29B,uBAAuBjxC,8BAIvC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS49B,sBAAsBlxC,YAzClCksC,CAAiCvC,EAAOnxB,mBA8CxC4zB,GAAAA,SAAAA,uBACJ,WAAYv6B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,UAwBlC,SAAUtU,GAIhB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBm0B,IAE1BvtC,KAAKkZ,oBAAoBq0B,GAAersC,MAvBpD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBsC,wBATQ,sCAY3C,WACG,OAAOrsC,KAAKiZ,SAAS8wB,GAAgBS,UAAW,qBAGnD,WACG,OAAOxqC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,qBAG5C,WACG,OAAOxrC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAa5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAAS69B,wBAAwBnxC,8BAIxC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS89B,uBAAuBpxC,YA3CnCosC,CAAkCzC,EAAOnxB,mBAgDzC8zB,GAAAA,SAAAA,uBACJ,WAAYz6B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBwC,uBATQ,qCAY3C,WACG,OAAOvsC,KAAKiZ,SAAS8wB,GAAgBU,SAAU,+BAGlD,WACG,OAAOzqC,KAAKkZ,oBAAoB4zB,GAAqB,uBAGxD,WACG,OAAO9sC,KAAKkZ,oBAAoB0zB,GAAa,qBAGhD,WACG,OAAO5sC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,yBAG5C,WACG,OAAOxrC,KAAKkZ,oBAAoBq0B,GAAe,qBAGlD,WACG,OAAOvtC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAG5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAAS+9B,uBAAuBrxC,8BAIvC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASg+B,sBAAsBtxC,YA7ClCssC,CAAiC3C,EAAOnxB,mBAkDxCg0B,GAAAA,SAAAA,uBACJ,WAAY36B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,UA4BlC,SAAUtU,GAIhB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBm0B,IAE1BvtC,KAAKkZ,oBAAoBq0B,GAAersC,MA3BpD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB0C,uBATQ,qCAY3C,WACG,OAAOzsC,KAAKiZ,SAAS8wB,GAAgBW,SAAU,uBAGlD,WACG,OAAO1qC,KAAKkZ,oBAAoB0zB,GAAa,qBAGhD,WACG,OAAO5sC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,qBAG5C,WACG,OAAOxrC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAa5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAASi+B,uBAAuBvxC,8BAIvC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASk+B,sBAAsBxxC,YA/ClCwsC,CAAiC7C,EAAOnxB,mBAoDxCk0B,GAAAA,SAAAA,uBACJ,WAAY76B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,UA4BlC,SAAUtU,GAIhB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBm0B,IAE1BvtC,KAAKkZ,oBAAoBq0B,GAAersC,MA3BpD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB4C,qBATQ,mCAY3C,WACG,OAAO3sC,KAAKiZ,SAAS8wB,GAAgBY,OAAQ,uBAGhD,WACG,OAAO3qC,KAAKkZ,oBAAoB0zB,GAAa,qBAGhD,WACG,OAAO5sC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,qBAG5C,WACG,OAAOxrC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAa5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAASm+B,qBAAqBzxC,8BAIrC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASo+B,oBAAoB1xC,YA/ChC0sC,CAA+B/C,EAAOnxB,mBAoDtCo0B,GAAAA,SAAAA,uBACJ,WAAY/6B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB8C,UATQ,mCAY3C,WACG,OAAO7sC,KAAKiZ,SAAS8wB,GAAgBkC,OAAQ,4BAGhD,SAAU34B,GACHA,aAAoB61B,IACpB71B,EAASq+B,UAAU3xC,8BAI1B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASs+B,SAAS5xC,YAzBrB4sC,CAAoBjD,EAAOnxB,mBA8B3Bs0B,GAAAA,SAAAA,uBACJ,WAAYj7B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBgD,kBATQ,mCAY3C,WACG,OAAO/sC,KAAKiZ,SAAS8wB,GAAgBkC,OAAQ,4BAGhD,SAAU34B,GACHA,aAAoB61B,IACpB71B,EAASu+B,kBAAkB7xC,8BAIlC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASw+B,iBAAiB9xC,YAzB7B8sC,CAA4BnD,EAAOnxB,mBA8BnCw0B,GAAAA,SAAAA,uBACJ,WAAYn7B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBkD,UATQ,iCAY3C,WACG,OAAOjtC,KAAKiZ,SAAS8wB,GAAgBza,KAAM,uBAG9C,WACG,OAAOtvB,KAAKiZ,SAAS8wB,GAAgBmD,KAAM,qBAG9C,WACG,OAAOltC,KAAKiZ,SAAS8wB,GAAgBoD,GAAI,uBAG5C,WACG,OAAOntC,KAAKkZ,oBAAoB8zB,EAAa,qBAGhD,WACG,OAAOhtC,KAAKiZ,SAAS8wB,GAAgBqD,GAAI,sBAG5C,WACG,OAAOptC,KAAKiZ,SAAS8wB,GAAgBsD,IAAK,yBAG7C,WACG,OAAOrtC,KAAKiZ,SAAS8wB,GAAgBuD,OAAQ,yBAGhD,WACG,OAAOttC,KAAKkZ,oBAAoBq0B,GAAe,4BAGlD,SAAUj6B,GACHA,aAAoB61B,IACpB71B,EAASy+B,UAAU/xC,8BAI1B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS0+B,SAAShyC,YArDrBgtC,CAAoBrD,EAAOnxB,mBA0D3B+0B,GAAAA,SAAAA,uBACJ,WAAY17B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,gBAY5B,SAAUtU,GAItB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqB00B,IAE1B9tC,KAAKkZ,oBAAoB40B,GAAqB5sC,MAnBjB,kBAsBnC,SAAUA,GAIf,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBu0B,IAE1B3tC,KAAKkZ,oBAAoBy0B,GAAczsC,MArBnD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgByD,YATQ,sCAgC3C,SAAUl6B,GACHA,aAAoB61B,IACpB71B,EAAS2+B,YAAYjyC,8BAI5B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS4+B,WAAWlyC,YAzCvButC,CAAsB5D,EAAOnxB,mBA8C7Bm1B,GAAAA,SAAAA,uBACJ,WAAY97B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB6D,WATQ,uCAY3C,WACG,OAAO5tC,KAAKiZ,SAAS8wB,GAAgB0B,WAAY,wBAGpD,WACG,OAAOzrC,KAAKiZ,SAAS8wB,GAAgBiC,MAAO,6BAG/C,WACG,OAAOhsC,KAAKkZ,oBAAoBu1B,GAAmB,4BAGtD,SAAUn7B,GACHA,aAAoB61B,IACpB71B,EAAS6+B,WAAWnyC,8BAI3B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS8+B,UAAUpyC,YAjCtB2tC,CAAqBhE,EAAOnxB,mBAsC5Bs1B,GAAAA,SAAAA,uBACJ,WAAYj8B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBgE,kBATQ,uCAY3C,WACG,OAAO/tC,KAAKiZ,SAAS8wB,GAAgB0B,WAAY,qBAGpD,WACG,OAAOzrC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,yBAG5C,WACG,OAAOxrC,KAAKkZ,oBAAoBq0B,GAAe,qBAGlD,WACG,OAAOvtC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAG5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAAS++B,kBAAkBryC,8BAIlC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASg/B,iBAAiBtyC,YArC7B8tC,CAA4BnE,EAAOnxB,mBA0CnCw1B,GAAAA,SAAAA,uBACJ,WAAYn8B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,SAoBnC,SAAUtU,GAIf,YAHSY,IAANZ,IACFA,EAAI,MAEK,OAANA,EACOlB,KAAK0B,UAAUqoC,GAAgBiC,OAE/BhsC,KAAKiZ,SAAS8wB,GAAgBiC,MAAO9qC,MA3BR,sBA0C/B,SAAUA,GAInB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBk1B,IAE1BtuC,KAAKkZ,oBAAoBo1B,GAAkBptC,MAzCvD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBkE,gBATQ,+BAY3C,WACG,OAAOjuC,KAAKiZ,SAAS8wB,GAAgByB,GAAI,4BAG5C,WACG,OAAOxrC,KAAKiZ,SAAS8wB,GAAgBmE,UAAW,wBAanD,WACG,OAAOluC,KAAKiZ,SAAS8wB,GAAgBra,MAAO,yBAG/C,WACG,OAAO1vB,KAAKiZ,SAAS8wB,GAAgBkC,OAAQ,qBAGhD,WACG,OAAOjsC,KAAKiZ,SAAS8wB,GAAgB2B,GAAI,4BAa5C,SAAUp4B,GACHA,aAAoB61B,IACpB71B,EAASi/B,gBAAgBvyC,8BAIhC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASk/B,eAAexyC,YA7D3BguC,CAA0BrE,EAAOnxB,mBAkEjC81B,GAAAA,SAAAA,uBACJ,WAAYz8B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBwE,eATQ,mCAY3C,WACG,OAAOvuC,KAAKiZ,SAAS8wB,GAAgBkC,OAAQ,yBAGhD,WACG,OAAOjsC,KAAKiZ,SAAS8wB,GAAgBsE,OAAQ,0BAGhD,WACG,OAAOruC,KAAKiZ,SAAS8wB,GAAgBqE,QAAS,4BAGjD,WACG,OAAOpuC,KAAKiZ,SAAS8wB,GAAgBoE,UAAW,+BAGnD,WACG,OAAOnuC,KAAKkZ,oBAAoB01B,GAAqB,4BAGxD,SAAUt7B,GACHA,aAAoB61B,IACpB71B,EAASm/B,eAAezyC,8BAI/B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASo/B,cAAc1yC,YAzC1BsuC,CAAyB3E,EAAOnxB,mBA8ChCi2B,GAAAA,SAAAA,uBACJ,WAAY58B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB2E,gBATQ,mCAY3C,WACG,OAAO1uC,KAAKiZ,SAAS8wB,GAAgBsE,OAAQ,0BAGhD,WACG,OAAOruC,KAAKiZ,SAAS8wB,GAAgBqE,QAAS,wBAGjD,WACG,OAAOpuC,KAAKkZ,oBAAoB02B,GAAc,oCAGjD,WACG,OAAO5vC,KAAKkZ,oBAAoBg2B,GAA0B,yBAG7D,WACG,OAAOlvC,KAAKiZ,SAAS8wB,GAAgBkC,OAAQ,uBAGhD,WACG,OAAOjsC,KAAKkZ,oBAAoB8zB,GAAa,4BAGhD,SAAU15B,GACHA,aAAoB61B,IACpB71B,EAASq/B,gBAAgB3yC,8BAIhC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASs/B,eAAe5yC,YA7C3ByuC,CAA0B9E,EAAOnxB,mBAkDjCo2B,GAAAA,SAAAA,uBACJ,WAAY/8B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,cAoB9B,SAAUtU,GAIpB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBq1B,IAE1BzuC,KAAKkZ,oBAAoBu1B,GAAmBvtC,MA3Bf,iBAkCpC,SAAUA,GAId,YAHSY,IAANZ,IACFA,EAAI,MAEK,OAANA,EACOlB,KAAK0B,UAAUqoC,GAAgB+E,MAE/B9uC,KAAKiZ,SAAS8wB,GAAgB+E,KAAM5tC,MAjChD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB8E,kBATQ,uCAY3C,WACG,OAAO7uC,KAAKiZ,SAAS8wB,GAAgB0B,WAAY,qBAGpD,WACG,OAAOzrC,KAAKiZ,SAAS8wB,GAAgBoD,GAAI,qBAa5C,WACG,OAAOntC,KAAKiZ,SAAS8wB,GAAgBqD,GAAI,4BAa5C,SAAU95B,GACHA,aAAoB61B,IACpB71B,EAASu/B,kBAAkB7yC,8BAIlC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAASw/B,iBAAiB9yC,YArD7B4uC,CAA4BjF,EAAOnxB,mBA0DnC02B,GAAAA,SAAAA,uBACJ,WAAYr9B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,eAwB7B,SAAUtU,GAIrB,YAHSY,IAANZ,IACFA,EAAI,MAEK,OAANA,EACOlB,KAAK0B,UAAUqoC,GAAgBsF,aAE/BrvC,KAAKiZ,SAAS8wB,GAAgBsF,YAAanuC,MA/Bd,kBAkCnC,SAAUA,GAIf,YAHSY,IAANZ,IACFA,EAAI,MAEK,OAANA,EACOlB,KAAK0B,UAAUqoC,GAAgBuF,OAE/BtvC,KAAKiZ,SAAS8wB,GAAgBuF,MAAOpuC,MAzCR,gBA4CrC,SAAUA,GAIb,YAHSY,IAANZ,IACFA,EAAI,MAEK,OAANA,EACOlB,KAAK0B,UAAUqoC,GAAgBwF,KAE/BvvC,KAAKiZ,SAAS8wB,GAAgBwF,IAAKruC,MAnDN,mBAsDlC,SAAUA,GAIhB,YAHSY,IAANZ,IACFA,EAAI,MAEK,OAANA,EACOlB,KAAK0B,UAAUqoC,GAAgBkC,QAE/BjsC,KAAKiZ,SAAS8wB,GAAgBkC,OAAQ/qC,MA7DT,8BAgEvB,SAAUA,GAI3B,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqB81B,GAE1BlvC,KAAKkZ,oBAAoBg2B,EAA0BhuC,MA/D/D,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBoF,uBATQ,uCAY3C,WACG,OAAOnvC,KAAKiZ,SAAS8wB,GAAgB0B,WAAY,uBAGpD,WACG,OAAOzrC,KAAKiZ,SAAS8wB,GAAgBqF,KAAM,wBAG9C,WACG,OAAOpvC,KAAKiZ,SAAS8wB,GAAgByF,MAAO,+BAqD/C,WACG,OAAOxvC,KAAKkZ,oBAAoB01B,GAAqB,wBAGxD,WACG,OAAO5uC,KAAKiZ,SAAS8wB,GAAgB0F,MAAO,qBAG/C,WACG,OAAOzvC,KAAKiZ,SAAS8wB,GAAgB2F,GAAI,wBAG5C,WACG,OAAO1vC,KAAKkZ,oBAAoB42B,GAAc,qBAGjD,WACG,OAAO9vC,KAAKiZ,SAAS8wB,GAAgB4F,GAAI,4BAG5C,SAAUr8B,GACHA,aAAoB61B,IACpB71B,EAASy/B,uBAAuB/yC,8BAIvC,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS0/B,sBAAsBhzC,YAvGlCkvC,CAAiCvF,EAAOnxB,mBA4GxCo3B,GAAAA,SAAAA,uBACJ,WAAY/9B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,GALsB,MAOzC,cAAMiD,EAAQjD,IAP2B,cAoB9B,SAAUtU,GAIpB,YAHUY,IAANZ,IACAA,EAAI,MAEE,OAANA,EACOlB,KAAKoZ,qBAAqBq1B,IAE1BzuC,KAAKkZ,oBAAoBu1B,GAAmBvtC,MA3Bf,iBA8BpC,SAAUA,GAId,YAHSY,IAANZ,IACFA,EAAI,MAEK,OAANA,EACOlB,KAAK0B,UAAUqoC,GAAgB+E,MAE/B9uC,KAAKiZ,SAAS8wB,GAAgB+E,KAAM5tC,MA7BhD,EAAK2Q,OAASA,EACd,EAAKjF,UAAYm9B,GAAgB8F,WATQ,+BAY3C,WACG,OAAO7vC,KAAKiZ,SAAS8wB,GAAgB2F,GAAI,qBAG5C,WACG,OAAO1vC,KAAKiZ,SAAS8wB,GAAgB4F,GAAI,4BAuB5C,SAAUr8B,GACHA,aAAoB61B,IACpB71B,EAAS2/B,WAAWjzC,8BAI3B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS4/B,UAAUlzC,YAjDtB4vC,CAAqBjG,EAAOnxB,mBAsD5Bs3B,GAAAA,SAAAA,uBACJ,WAAYj+B,EAAQ4G,EAAQjD,GAAe,6BAC1B1T,IAAX2W,IACFA,EAAS,MAEPjD,MAAAA,IACFA,GAAiB,IAEnB,cAAMiD,EAAQjD,IACT3D,OAASA,EACd,EAAKjF,UAAYm9B,GAAgBgG,WATQ,mCAY3C,WACG,OAAO/vC,KAAKiZ,SAAS8wB,GAAgBsE,OAAQ,uBAGhD,WACG,OAAOruC,KAAKiZ,SAAS8wB,GAAgBiG,KAAM,4BAG9C,SAAU18B,GACHA,aAAoB61B,IACpB71B,EAAS6/B,WAAWnzC,8BAI3B,SAASsT,GACFA,aAAoB61B,IACpB71B,EAAS8/B,UAAUpzC,YA7BtB8vC,CAAqBnG,EAAOnxB,olCAkClCuxB,GAAgBE,YAAcA,GAC9BF,GAAgBa,iBAAmBA,GACnCb,GAAgBsB,qBAAuBA,GACvCtB,GAAgB4B,uBAAyBA,GACzC5B,GAAgB+B,oBAAsBA,GACtC/B,GAAgBmC,yBAA2BA,GAC3CnC,GAAgBqC,0BAA4BA,GAC5CrC,GAAgBuC,yBAA2BA,GAC3CvC,GAAgByC,yBAA2BA,GAC3CzC,GAAgB2C,uBAAyBA,GACzC3C,GAAgB6C,YAAcA,GAC9B7C,GAAgB+C,oBAAsBA,GACtC/C,GAAgBiD,YAAcA,GAC9BjD,GAAgBwD,cAAgBA,GAChCxD,GAAgB4D,aAAeA,GAC/B5D,GAAgB+D,oBAAsBA,GACtC/D,GAAgBiE,kBAAoBA,GACpCjE,GAAgBuE,iBAAmBA,GACnCvE,GAAgB0E,kBAAoBA,GACpC1E,GAAgB6E,oBAAsBA,GACtC7E,GAAgBmF,yBAA2BA,GAC3CnF,GAAgB6F,aAAeA,GAC/B7F,GAAgB+F,aAAeA,GCl+E/B,IAAMlG,GAAgB,CAAC,WACrB,oBACA,qBACA,gCACA,+BACA,oBACA,qBACA,oBACA,qBACA,yBACA,sCACA,sCACA,qBACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,0BACA,8BACA,0BACA,2BACA,4BACA,kBACA,eACA,eACA,eACA,eACA,eACA,eACA,gBACA,eACA,eACA,eACA,gBACA,eACA,eACA,eACA,eACA,eACA,eACA,gBACA,kBACA,iBACA,eACA,0BACA,wBACA,qBACA,2BACA,0BACA,sBACA,wBACA,0BACA,yBACA,sBACA,uBACA,oBACA,0BACA,mBACA,uBACA,kCACA,6BACA,6BACA,qBACA,qCACA,wBACA,0BACA,gBACA,kBACA,eACA,eACA,eACA,eACA,eACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,oBACA,gBACA,eACA,eACA,eACA,eACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,kBACA,gBACA,kBACA,wBACA,oBACA,sBACA,oBACA,sBACA,sBACA,uBACA,sBACA,iBACA,gBACA,gBACA,iBACA,gBACA,iBACA,gBACA,gBACA,iBACA,eACA,gBACA,gBACA,gBACA,eACA,gBACA,iBACA,eACA,gBACA,gBACA,eACA,gBACA,eACA,gBACA,iBACA,eACA,gBACA,gBACA,gBACA,gBACA,eACA,iBACA,gBACA,gBACA,gBACA,gBACA,eACA,eACA,eACA,iBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,kBACA,eACA,eACA,eACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,eACA,eACA,eACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,eACA,eACA,eACA,eACA,gBACA,eACA,eACA,eACA,gBACA,eACA,kBACA,oBACA,eACA,eACA,iBACA,gBACA,eACA,eACA,eACA,gBACA,mBACA,eACA,gBACA,oBACA,oBACA,kBACA,gBACA,oBACA,eACA,eACA,eACA,eACA,eACA,eACA,gBACA,eACA,eACA,eACA,eACA,mBACA,eACA,kBACA,eACA,eACA,iBACA,gBACA,kBACA,eACA,eACA,kBACA,gBACA,eACA,eACA,kBACA,gBACA,gBACA,kBACA,iBACA,kBACA,iBACA,iBACA,mBACA,gBACA,gBACA,iBACA,eACA,eACA,aAA0D5/B,KAAK,IAE3DmB,IAAM,IAAIw+B,EAAOx+B,IAAIuG,iBAAkB+C,YAAYm1B,IAEnDC,GAAiB1+B,GAAImX,gBAAgBlY,KAAI,SAAC0/B,EAAI5pC,GAAL,OAAe,IAAIypC,EAAO9xB,IAAIqmB,IAAI4L,EAAI5pC,MAEhEmzC,GAAAA,SAAAA,qsBAkCnB,WAAYxlC,GAAO,mHACjB,cAAMA,IACDI,QAAU,IAAI07B,EAAOx+B,IAAIilB,kBAAf,MAAuCjlB,GAAK0+B,GAAgB,IAAIF,EAAAA,GAF9D,gCAKnB,WACE,OAAOx+B,+EAxCUkoC,CAAuB1J,EAAOlqC,OC1P5C,SAAS6zC,GAAqB1uC,EAAQjF,GAC3CiF,EAAOkE,SAAQ,SAACd,GACVA,EAAEurC,YACA5zC,EAAO8G,MAAQuB,EAAEurC,YACnB5zC,EAAOqnC,WAAWxlC,KAAKwG,MAM/B,SAASwrC,GAAgBC,EAAU7uC,EAAQ2uC,GACzC,IAAIjqC,EACUA,EAAV1E,GACM,CACN8uC,SAAU,GACV/M,UAAW,GACXgN,QAAS,GACTtN,UAAW,GACXS,QAAS,GACTN,MAAO,GACPoN,UAAW,GACXtP,OAAQ,IAMZ,ICrDoBzY,EAGdud,EDkDAjG,EAAM,GAsDZ,OA5CAA,EAAI3hC,MC5DE4nC,EAAO,IAAIhF,EAHGvY,ED+DL4nB,GE9DF,SAAoBpP,EAAMwP,EAAeC,EAAkBC,EAAa3K,GACrF,IAAI4K,EAAc7Q,EAElB,GAAsB,iBAAVkB,EAAoB,CAiB9B2P,EAAW3P,EACX,IAAMgF,EAAe,IAAIvE,EAEzBuE,EAAa4K,OAAUJ,GAAkB,GACzCxK,EAAa6K,UAAaJ,GAAqB,GAE/C1K,EAAK+K,oBAAsBJ,EAC3B3K,EAAKC,aAAeA,EAEpBlG,EC7BG,SAAetX,GACpB,IAAMhe,EAAQge,EAAImoB,SACZI,EAAQ,IAAIzK,EAAOhmC,YAAYkK,GAC/BzH,EAAQ,IAAIiuC,GAASD,GACrBn0C,EAAS,IAAI0pC,EAAOlI,kBAAkBr7B,GACtCyL,EAAS,IAAIyiC,GAAUr0C,GAC7B4R,EAAOW,iBAAkB,EACzB,IAAMgvB,EAAO3vB,EAAOwyB,OAEpB,OADAsF,EAAOnI,KAAKsB,gBAAgB58B,QAAQ68B,KAAKlX,EAAIvY,SAAUkuB,GAChD3V,EAAIvY,SDoBHihC,CAAgB,CACpBP,SAAAA,EAAU1gC,SAFD,IAAIkhC,GAAYpL,GAELA,KAAAA,EAAM/E,KAAAA,IAE5B+E,EAAK1E,MAAMljC,KAAK6nC,GAChBD,EAAK3E,gBAAgBjjC,KAAK6iC,ID9B5BoQ,CAAW5oB,EAAK,GAAI,GAAI,KAAMud,GACvBA,ID4DPjG,EAAIr6B,SAAQ,SAACoD,GACXA,EAAEw4B,MAAM57B,SAAQ,SAAC+7B,GACfA,EAAGO,mBAAmBt8B,SAAQ,SAACd,GAC7BA,EAAEzB,SAAW2F,EAAE3F,SACXgtC,IAAYvrC,EAAEurC,WAAaA,GAC/BjqC,EAAMoqC,SAASlyC,KAAKwG,MAEtB68B,EAAGK,mBAAmBp8B,SAAQ,SAACd,GAC7BA,EAAEzB,SAAW2F,EAAE3F,SACXgtC,IAAYvrC,EAAEurC,WAAaA,GAC/BjqC,EAAMq9B,UAAUnlC,KAAKwG,MAEvB68B,EAAGI,iBAAiBn8B,SAAQ,SAACd,GAC3BA,EAAEzB,SAAW2F,EAAE3F,SACXgtC,IAAYvrC,EAAEurC,WAAaA,GAC/BjqC,EAAMqqC,QAAQnyC,KAAKwG,MAErB68B,EAAGG,mBAAmBl8B,SAAQ,SAACd,GAC7BA,EAAEzB,SAAW2F,EAAE3F,SACXgtC,IAAYvrC,EAAEurC,WAAaA,GAC/BjqC,EAAM+8B,UAAU7kC,KAAKwG,MAEvB68B,EAAGM,eAAer8B,SAAQ,SAACd,GACzBA,EAAEzB,SAAW2F,EAAE3F,SACXgtC,IAAYvrC,EAAEurC,WAAaA,GAC/BjqC,EAAMk9B,MAAMhlC,KAAKwG,MAEnB68B,EAAGQ,iBAAiBv8B,SAAQ,SAACd,GAC3BA,EAAEzB,SAAW2F,EAAE3F,SACXgtC,IAAYvrC,EAAEurC,WAAaA,GAC/BjqC,EAAMw9B,QAAQtlC,KAAKwG,MAErB68B,EAAGE,oBAAoBj8B,SAAQ,SAACd,GAC9BA,EAAEzB,SAAW2F,EAAE3F,SACXgtC,IAAYvrC,EAAEurC,WAAaA,GAC/BjqC,EAAMsqC,UAAUpyC,KAAKwG,SAGzBkE,EAAEo4B,OAAOx7B,SAAQ,SAACrE,GAChB6E,EAAMg7B,OAAO9iC,KAAKiD,SAGf6E,KDyKY+pC,GAAAA,kBACM,wBADNA,GAAAA,eAGG,CAAC,wBAAyB,cAH7BA,GAAAA,YAKA,CAAC,eAAgB,cALjBA,GAAAA,eAOG,CAAC,KAAM,WAAY,SAAU,WAAY,aAC7D,cAAe,aAAc,aAAc,WAC3C,SAAU,QAAS,WAAY,cAAe,kBAC9C,MAAO,MAAO,MAAO,MAAO,MAAO,MAAO,MAC1C,MAAO,MAAO,MAAO,MAAO,KAAM,KAAM,KAAM,KAC9C,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,UACpC,KAAM,KAAM,KAAM,KAAM,aAbPA,GAAAA,gBAeI,CAAC,KAAM,SAAU,OAAQ,SAAU,WACxD,YAAa,WAAY,WAAY,SACrC,OAAQ,MAAO,SAAU,YAAa,QACtC,KAAM,KAAM,QAAS,KAAM,KAAM,KAAM,KAAM,OAC7C,QAAS,QAAS,OAAQ,YAAa,UACvC,OAAQ,aAAc,SAAU,SAAU,UAC1C,eAAgB,cAAe,KAAM,OAAQ,cAC7C,MAAO,UAAW,QAAS,aAtBVA,GAAAA,YAwBA,CAAC,SAAU,OAAQ,SAAU,WAAY,YAC1D,WAAY,WAAY,SAAU,OAAQ,MAAO,SACjD,YAAa,QAAS,KAAM,KAAM,QAAS,KAAM,KACjD,KAAM,KAAM,OAAQ,QAAS,QAAS,OAAQ,YAC9C,UAAW,OAAQ,aAAc,gBACjC,SAAU,SAAU,MAAO,UAAW,MAAO,gBAC7C,SAAU,UAAW,eAAgB,cACrC,KAAM,OAAQ,cAAe,MAAO,OAAQ,iBAC5C,UAAW,QAAS,UAYxBA,GAAeryC,IAAM2oC,EAAOnqC,MAAMwB,IAClCqyC,GAAehJ,OAAS,EACxBgJ,GAAe/I,KAAO,EACtB+I,GAAexH,OAAS,EACxBwH,GAAe9I,SAAW,EAC1B8I,GAAe7I,UAAY,EAC3B6I,GAAe5I,SAAW,EAC1B4I,GAAe3I,SAAW,EAC1B2I,GAAe1I,OAAS,EACxB0I,GAAenG,KAAO,EACtBmG,GAAehG,IAAM,GACrBgG,GAAe/F,OAAS,GACxB+F,GAAenF,UAAY,GAC3BmF,GAAe3jB,MAAQ,GACvB2jB,GAAe7H,GAAK,GACpB6H,GAAe3H,GAAK,GACpB2H,GAAerH,MAAQ,GACvBqH,GAAelG,GAAK,GACpBkG,GAAejG,GAAK,GACpBiG,GAAe3D,GAAK,GACpB2D,GAAe1D,GAAK,GACpB0D,GAAevE,KAAO,GACtBuE,GAAe5D,MAAQ,GACvB4D,GAAepD,MAAQ,GACvBoD,GAAerD,KAAO,GACtBqD,GAAelF,UAAY,GAC3BkF,GAAejF,QAAU,GACzBiF,GAAe/jB,KAAO,GACtB+jB,GAAe5H,WAAa,GAC5B4H,GAAepH,OAAS,GACxBoH,GAAehF,OAAS,GACxBgF,GAAenD,QAAU,GACzBmD,GAAelD,aAAe,GAC9BkD,GAAejD,YAAc,GAC7BiD,GAAehD,GAAK,GACpBgD,GAAejE,KAAO,GACtBiE,GAAehE,YAAc,GAC7BgE,GAAe9D,IAAM,GACrB8D,GAAe/C,QAAU,GACzB+C,GAAe/D,MAAQ,GACvB+D,GAAe7D,MAAQ,GAEvB6D,GAAeqB,OAAS,EK3WxBC,UAAY,SAASC,GACpB,IAIgCC,EACzBjwC,EALD4hC,GAI0BqO,EAJTD,EAAMrvC,KAKtBX,EJLD,SAA2BiwC,GAEhC,IADA,IAAIjwC,EAAS4uC,GAAgBqB,GACpB3zC,EAAI,EAAGA,EAAI0D,EAAOkiC,QAAQhmC,OAAQI,IAAK,CAC9C,IACIiE,EADWP,EAAOkiC,QAAQ5lC,GAAGilC,aAAa78B,MAAM4gB,MAAM,KACxC,GAClB/kB,EAAOA,EAAKukC,WAAW,IAAK,IAG5B,IAFA,IAAMoL,EAAmBD,EAAU3qB,MAAM,KACrC6qB,EAAa,GACR7zC,EAAI,EAAGA,EAAI4zC,EAAiBh0C,OAAS,EAAGI,IAC/C6zC,GAAc,GAAJ,OAAOD,EAAiB5zC,GAAxB,KAEe0D,EAAvBO,EAAKqiC,SAAS,MAAkBgM,GAAgBruC,EAAKoE,QAAQ,KAAMwrC,GAAanwC,EAAQA,EAAOkiC,QAAQ5lC,GAAGuF,MAAkBtB,EAAKqiC,SAAS,KAAiBgM,GAAgBruC,EAAKoE,QAAQ,IAAKwrC,GAAanwC,EAAQA,EAAOkiC,QAAQ5lC,GAAGuF,MAAyB+sC,GAAgBuB,EAAa5vC,EAAMP,EAAQA,EAAOkiC,QAAQ5lC,GAAGuF,MAIhU,OAGF,SAAyB7B,GAKvB,OAJAA,EAASsjC,EAAYtjC,EAAO+hC,UAAW/hC,GACvCA,EAASsjC,EAAYtjC,EAAOkiC,QAASliC,GAAQ,GACpCsjC,EAAYtjC,EAAO+uC,QAAS/uC,GAR5BowC,CAAgBpwC,GIRVqwC,CAAkBJ,GAE7BjwC,EAAO8uC,SAAS5yC,OAAS,GAgB3B8D,EAAOkiC,QAAQh+B,SAAQ,SAACnJ,GACtB2zC,GAAqB1uC,EAAOyhC,UAAW1mC,GACvC2zC,GAAqB1uC,EAAO8uC,SAAU/zC,GACtC2zC,GAAqB1uC,EAAO+hC,UAAWhnC,GACvC2zC,GAAqB1uC,EAAO+uC,QAASh0C,GACrC2zC,GAAqB1uC,EAAO4hC,MAAO7mC,GACnC2zC,GAAqB1uC,EAAOgvC,UAAWj0C,MASb,GAAxBiF,EAAO0/B,OAAOxjC,SAChBqO,QAAQC,IAAI,sDACZxK,EAAO0/B,OAAOx7B,SAAQ,SAACrE,GAAD,OAAO0K,QAAQC,IAAI3K,QAG3CG,EAAO0/B,OAAO9iC,KAAK,qBAGdoD,GA7CRswC,YAAY1O","sources":["webpack://hcl/./node_modules/antlr4/src/antlr4/BufferedTokenStream.js","webpack://hcl/./node_modules/antlr4/src/antlr4/CharStreams.js","webpack://hcl/./node_modules/antlr4/src/antlr4/CommonTokenFactory.js","webpack://hcl/./node_modules/antlr4/src/antlr4/CommonTokenStream.js","webpack://hcl/./node_modules/antlr4/src/antlr4/FileStream.js","webpack://hcl/./node_modules/antlr4/src/antlr4/InputStream.js","webpack://hcl/./node_modules/antlr4/src/antlr4/IntervalSet.js","webpack://hcl/./node_modules/antlr4/src/antlr4/LL1Analyzer.js","webpack://hcl/./node_modules/antlr4/src/antlr4/Lexer.js","webpack://hcl/./node_modules/antlr4/src/antlr4/Parser.js","webpack://hcl/./node_modules/antlr4/src/antlr4/ParserRuleContext.js","webpack://hcl/./node_modules/antlr4/src/antlr4/PredictionContext.js","webpack://hcl/./node_modules/antlr4/src/antlr4/Recognizer.js","webpack://hcl/./node_modules/antlr4/src/antlr4/RuleContext.js","webpack://hcl/./node_modules/antlr4/src/antlr4/Token.js","webpack://hcl/./node_modules/antlr4/src/antlr4/Utils.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATN.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATNConfig.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATNConfigSet.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATNDeserializationOptions.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATNDeserializer.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATNSimulator.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATNState.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ATNType.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/LexerATNSimulator.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/LexerAction.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/LexerActionExecutor.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/ParserATNSimulator.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/PredictionMode.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/SemanticContext.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/Transition.js","webpack://hcl/./node_modules/antlr4/src/antlr4/atn/index.js","webpack://hcl/./node_modules/antlr4/src/antlr4/dfa/DFA.js","webpack://hcl/./node_modules/antlr4/src/antlr4/dfa/DFASerializer.js","webpack://hcl/./node_modules/antlr4/src/antlr4/dfa/DFAState.js","webpack://hcl/./node_modules/antlr4/src/antlr4/dfa/index.js","webpack://hcl/./node_modules/antlr4/src/antlr4/error/DiagnosticErrorListener.js","webpack://hcl/./node_modules/antlr4/src/antlr4/error/ErrorListener.js","webpack://hcl/./node_modules/antlr4/src/antlr4/error/ErrorStrategy.js","webpack://hcl/./node_modules/antlr4/src/antlr4/error/Errors.js","webpack://hcl/./node_modules/antlr4/src/antlr4/error/index.js","webpack://hcl/./node_modules/antlr4/src/antlr4/index.js","webpack://hcl/./node_modules/antlr4/src/antlr4/polyfills/codepointat.js","webpack://hcl/./node_modules/antlr4/src/antlr4/polyfills/fromcodepoint.js","webpack://hcl/./node_modules/antlr4/src/antlr4/tree/Tree.js","webpack://hcl/./node_modules/antlr4/src/antlr4/tree/Trees.js","webpack://hcl/./node_modules/antlr4/src/antlr4/tree/index.js","webpack://hcl/webpack/bootstrap","webpack://hcl/./src/model/prog.js","webpack://hcl/./src/model/file.js","webpack://hcl/./src/model/terraform_node.js","webpack://hcl/./src/model/field.js","webpack://hcl/./node_modules/mathjs/lib/esm/utils/is.js","webpack://hcl/./src/model/complex_field.js","webpack://hcl/./src/model/object.js","webpack://hcl/./src/model/name.js","webpack://hcl/./src/model/provider_type.js","webpack://hcl/./src/model/module_directive.js","webpack://hcl/./src/parser/compiler/get_links_between_objects.js","webpack://hcl/./src/model/module_source.js","webpack://hcl/./src/model/terraform_directive.js","webpack://hcl/./src/model/data_directive.js","webpack://hcl/./src/model/resource_directive.js","webpack://hcl/./src/model/output_directive.js","webpack://hcl/./src/model/variable_directive.js","webpack://hcl/./src/model/provider_directive.js","webpack://hcl/./src/listener/terraformListener.js","webpack://hcl/./src/listener/data_directive.js","webpack://hcl/./src/listener/module_directive.js","webpack://hcl/./src/listener/module_source.js","webpack://hcl/./src/listener/provider_directive.js","webpack://hcl/./src/listener/terraform_directive.js","webpack://hcl/./src/listener/resource_directive.js","webpack://hcl/./src/listener/variable_directive.js","webpack://hcl/./src/listener/output_directive.js","webpack://hcl/./src/listener/name.js","webpack://hcl/./src/listener/provider_type.js","webpack://hcl/./src/listener/object.js","webpack://hcl/./src/listener/field.js","webpack://hcl/./src/listener/complex_field.js","webpack://hcl/./src/parser/grammar_parsing/terraformParser.js","webpack://hcl/./src/parser/grammar_parsing/terraformLexer.js","webpack://hcl/./src/parser/compiler/parse_directory.js","webpack://hcl/./src/parser/compiler/parse_file.js","webpack://hcl/./src/parser/compiler/prog_init.js","webpack://hcl/./src/parser/grammar_parsing/index.js","webpack://hcl/./src/plugins/terraform/index.js"],"sourcesContent":["/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst Lexer = require('./Lexer');\nconst {Interval} = require('./IntervalSet');\n\n// this is just to keep meaningful parameter types to Parser\nclass TokenStream {}\n\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * <p>\n * This token stream ignores the value of {@link Token//getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token//DEFAULT_CHANNEL} or\n * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.</p>\n */\nclass BufferedTokenStream extends TokenStream {\n\tconstructor(tokenSource) {\n\n\t\tsuper();\n\t\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\t\tthis.tokenSource = tokenSource;\n\t\t/**\n\t\t * A collection of all tokens fetched from the token source. The list is\n\t\t * considered a complete view of the input once {@link //fetchedEOF} is set\n\t\t * to {@code true}.\n\t\t */\n\t\tthis.tokens = [];\n\n\t\t/**\n\t\t * The index into {@link //tokens} of the current token (next token to\n\t\t * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t\t * be\n\t\t * {@link //LT LT(1)}.\n\t\t *\n\t\t * <p>This field is set to -1 when the stream is first constructed or when\n\t\t * {@link //setTokenSource} is called, indicating that the first token has\n\t\t * not yet been fetched from the token source. For additional information,\n\t\t * see the documentation of {@link IntStream} for a description of\n\t\t * Initializing Methods.</p>\n\t\t */\n\t\tthis.index = -1;\n\n\t\t/**\n\t\t * Indicates whether the {@link Token//EOF} token has been fetched from\n\t\t * {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t\t * performance for the following cases:\n\t\t *\n\t\t * <ul>\n\t\t * <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t\t * prevent\n\t\t * consuming the EOF symbol is optimized by checking the values of\n\t\t * {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t\t * //LA}.</li>\n\t\t * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t\t * into\n\t\t * {@link //tokens} is trivial with this field.</li>\n\t\t * <ul>\n\t\t */\n\t\tthis.fetchedEOF = false;\n\t}\n\n\tmark() {\n\t\treturn 0;\n\t}\n\n\trelease(marker) {\n\t\t// no resources to release\n\t}\n\n\treset() {\n\t\tthis.seek(0);\n\t}\n\n\tseek(index) {\n\t\tthis.lazyInit();\n\t\tthis.index = this.adjustSeekIndex(index);\n\t}\n\n\tget(index) {\n\t\tthis.lazyInit();\n\t\treturn this.tokens[index];\n\t}\n\n\tconsume() {\n\t\tlet skipEofCheck = false;\n\t\tif (this.index >= 0) {\n\t\t\tif (this.fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t\t} else {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t\t}\n\t\t} else {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\t\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\t\tthrow \"cannot consume EOF\";\n\t\t}\n\t\tif (this.sync(this.index + 1)) {\n\t\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t\t}\n\t}\n\n\t/**\n\t * Make sure index {@code i} in tokens has a token.\n\t *\n\t * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise\n\t * {@code false}.\n\t * @see //get(int i)\n\t */\n\tsync(i) {\n\t\tconst n = i - this.tokens.length + 1; // how many more elements we need?\n\t\tif (n > 0) {\n\t\t\tconst fetched = this.fetch(n);\n\t\t\treturn fetched >= n;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * Add {@code n} elements to buffer.\n\t *\n\t * @return {Number} The actual number of elements added to the buffer.\n\t */\n\tfetch(n) {\n\t\tif (this.fetchedEOF) {\n\t\t\treturn 0;\n\t\t}\n\t\tfor (let i = 0; i < n; i++) {\n\t\t\tconst t = this.tokenSource.nextToken();\n\t\t\tt.tokenIndex = this.tokens.length;\n\t\t\tthis.tokens.push(t);\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tthis.fetchedEOF = true;\n\t\t\t\treturn i + 1;\n\t\t\t}\n\t\t}\n\t\treturn n;\n\t}\n\n// Get all tokens from start..stop inclusively///\n\tgetTokens(start, stop, types) {\n\t\tif (types === undefined) {\n\t\t\ttypes = null;\n\t\t}\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn null;\n\t\t}\n\t\tthis.lazyInit();\n\t\tconst subset = [];\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tfor (let i = start; i < stop; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (types === null || types.contains(t.type)) {\n\t\t\t\tsubset.push(t);\n\t\t\t}\n\t\t}\n\t\treturn subset;\n\t}\n\n\tLA(i) {\n\t\treturn this.LT(i).type;\n\t}\n\n\tLB(k) {\n\t\tif (this.index - k < 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.tokens[this.index - k];\n\t}\n\n\tLT(k) {\n\t\tthis.lazyInit();\n\t\tif (k === 0) {\n\t\t\treturn null;\n\t\t}\n\t\tif (k < 0) {\n\t\t\treturn this.LB(-k);\n\t\t}\n\t\tconst i = this.index + k - 1;\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) { // return EOF token\n\t\t\t// EOF must be last token\n\t\t\treturn this.tokens[this.tokens.length - 1];\n\t\t}\n\t\treturn this.tokens[i];\n\t}\n\n\t/**\n\t * Allowed derived classes to modify the behavior of operations which change\n\t * the current stream position by adjusting the target token index of a seek\n\t * operation. The default implementation simply returns {@code i}. If an\n\t * exception is thrown in this method, the current stream index should not be\n\t * changed.\n\t *\n\t * <p>For example, {@link CommonTokenStream} overrides this method to ensure\n\t * that\n\t * the seek target is always an on-channel token.</p>\n\t *\n\t * @param {Number} i The target token index.\n\t * @return {Number} The adjusted target token index.\n\t */\n\tadjustSeekIndex(i) {\n\t\treturn i;\n\t}\n\n\tlazyInit() {\n\t\tif (this.index === -1) {\n\t\t\tthis.setup();\n\t\t}\n\t}\n\n\tsetup() {\n\t\tthis.sync(0);\n\t\tthis.index = this.adjustSeekIndex(0);\n\t}\n\n// Reset this token stream by setting its token source.///\n\tsetTokenSource(tokenSource) {\n\t\tthis.tokenSource = tokenSource;\n\t\tthis.tokens = [];\n\t\tthis.index = -1;\n\t\tthis.fetchedEOF = false;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the next token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and EOF.\n\t */\n\tnextTokenOnChannel(i, channel) {\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) {\n\t\t\treturn -1;\n\t\t}\n\t\tlet token = this.tokens[i];\n\t\twhile (token.channel !== this.channel) {\n\t\t\tif (token.type === Token.EOF) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ti += 1;\n\t\t\tthis.sync(i);\n\t\t\ttoken = this.tokens[i];\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the previous token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and 0.\n\t */\n\tpreviousTokenOnChannel(i, channel) {\n\t\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\t\ti -= 1;\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the right of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n\t * EOF. If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToRight(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tconst from_ = tokenIndex + 1;\n\t\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\t\tconst to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the left of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n\t * If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToLeft(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tif (prevOnChannel === tokenIndex - 1) {\n\t\t\treturn null;\n\t\t}\n\t\t// if none on channel to left, prevOnChannel=-1 then from=0\n\t\tconst from_ = prevOnChannel + 1;\n\t\tconst to = tokenIndex - 1;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\tfilterForChannel(left, right, channel) {\n\t\tconst hidden = [];\n\t\tfor (let i = left; i < right + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (channel === -1) {\n\t\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t} else if (t.channel === channel) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t}\n\t\tif (hidden.length === 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn hidden;\n\t}\n\n\tgetSourceName() {\n\t\treturn this.tokenSource.getSourceName();\n\t}\n\n// Get the text of all tokens in this buffer.///\n\tgetText(interval) {\n\t\tthis.lazyInit();\n\t\tthis.fill();\n\t\tif (interval === undefined || interval === null) {\n\t\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t\t}\n\t\tlet start = interval.start;\n\t\tif (start instanceof Token) {\n\t\t\tstart = start.tokenIndex;\n\t\t}\n\t\tlet stop = interval.stop;\n\t\tif (stop instanceof Token) {\n\t\t\tstop = stop.tokenIndex;\n\t\t}\n\t\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\t\treturn \"\";\n\t\t}\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tlet s = \"\";\n\t\tfor (let i = start; i < stop + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ts = s + t.text;\n\t\t}\n\t\treturn s;\n\t}\n\n// Get all tokens from lexer until EOF///\n\tfill() {\n\t\tthis.lazyInit();\n\t\twhile (this.fetch(1000) === 1000) {\n\t\t\tcontinue;\n\t\t}\n\t}\n}\n\n\nmodule.exports = BufferedTokenStream;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst InputStream = require('./InputStream');\nconst fs = require(\"fs\");\n\n/**\n * Utility functions to create InputStreams from various sources.\n *\n * All returned InputStreams support the full range of Unicode\n * up to U+10FFFF (the default behavior of InputStream only supports\n * code points up to U+FFFF).\n */\nconst CharStreams = {\n  // Creates an InputStream from a string.\n  fromString: function(str) {\n    return new InputStream(str, true);\n  },\n\n  /**\n   * Asynchronously creates an InputStream from a blob given the\n   * encoding of the bytes in that blob (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes onLoad(result) on success, onError(error) on\n   * failure.\n   */\n  fromBlob: function(blob, encoding, onLoad, onError) {\n    const reader = new window.FileReader();\n    reader.onload = function(e) {\n      const is = new InputStream(e.target.result, true);\n      onLoad(is);\n    };\n    reader.onerror = onError;\n    reader.readAsText(blob, encoding);\n  },\n\n  /**\n   * Creates an InputStream from a Buffer given the\n   * encoding of the bytes in that buffer (defaults to 'utf8' if\n   * encoding is null).\n   */\n  fromBuffer: function(buffer, encoding) {\n    return new InputStream(buffer.toString(encoding), true);\n  },\n\n  /** Asynchronously creates an InputStream from a file on disk given\n   * the encoding of the bytes in that file (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes callback(error, result) on completion.\n   */\n  fromPath: function(path, encoding, callback) {\n    fs.readFile(path, encoding, function(err, data) {\n      let is = null;\n      if (data !== null) {\n        is = new InputStream(data, true);\n      }\n      callback(err, is);\n    });\n  },\n\n  /**\n   * Synchronously creates an InputStream given a path to a file\n   * on disk and the encoding of the bytes in that file (defaults to\n   * 'utf8' if encoding is null).\n   */\n  fromPathSync: function(path, encoding) {\n    const data = fs.readFileSync(path, encoding);\n    return new InputStream(data, true);\n  }\n};\n\nmodule.exports = CharStreams;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst CommonToken = require('./Token').CommonToken;\n\nclass TokenFactory {}\n\n/**\n * This default implementation of {@link TokenFactory} creates\n * {@link CommonToken} objects.\n */\nclass CommonTokenFactory extends TokenFactory {\n    constructor(copyText) {\n        super();\n        /**\n         * Indicates whether {@link CommonToken//setText} should be called after\n         * constructing tokens to explicitly set the text. This is useful for cases\n         * where the input stream might not be able to provide arbitrary substrings\n         * of text from the input after the lexer creates a token (e.g. the\n         * implementation of {@link CharStream//getText} in\n         * {@link UnbufferedCharStream} throws an\n         * {@link UnsupportedOperationException}). Explicitly setting the token text\n         * allows {@link Token//getText} to be called at any time regardless of the\n         * input stream implementation.\n         *\n         * <p>\n         * The default value is {@code false} to avoid the performance and memory\n         * overhead of copying text for every token unless explicitly requested.</p>\n         */\n        this.copyText = copyText===undefined ? false : copyText;\n    }\n\n    create(source, type, text, channel, start, stop, line, column) {\n        const t = new CommonToken(source, type, channel, start, stop);\n        t.line = line;\n        t.column = column;\n        if (text !==null) {\n            t.text = text;\n        } else if (this.copyText && source[1] !==null) {\n            t.text = source[1].getText(start,stop);\n        }\n        return t;\n    }\n\n    createThin(type, text) {\n        const t = new CommonToken(null, type);\n        t.text = text;\n        return t;\n    }\n}\n\n/**\n * The default {@link CommonTokenFactory} instance.\n *\n * <p>\n * This token factory does not explicitly copy token text when constructing\n * tokens.</p>\n */\nCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n\nmodule.exports = CommonTokenFactory;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n\nconst Token = require('./Token').Token;\nconst BufferedTokenStream = require('./BufferedTokenStream');\n\n/**\n * This class extends {@link BufferedTokenStream} with functionality to filter\n * token streams to tokens on a particular channel (tokens where\n * {@link Token//getChannel} returns a particular value).\n *\n * <p>\n * This token stream provides access to all tokens by index or when calling\n * methods like {@link //getText}. The channel filtering is only used for code\n * accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n * {@link //LB}.</p>\n *\n * <p>\n * By default, tokens are placed on the default channel\n * ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n * {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n * call {@link Lexer//setChannel}.\n * </p>\n *\n * <p>\n * Note: lexer rules which use the {@code ->skip} lexer command or call\n * {@link Lexer//skip} do not produce tokens at all, so input text matched by\n * such a rule will not be available as part of the token stream, regardless of\n * channel.</p>\n */\nclass CommonTokenStream extends BufferedTokenStream {\n    constructor(lexer, channel) {\n        super(lexer);\n        this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;\n    }\n\n    adjustSeekIndex(i) {\n        return this.nextTokenOnChannel(i, this.channel);\n    }\n\n    LB(k) {\n        if (k===0 || this.index-k<0) {\n            return null;\n        }\n        let i = this.index;\n        let n = 1;\n        // find k good tokens looking backwards\n        while (n <= k) {\n            // skip off-channel tokens\n            i = this.previousTokenOnChannel(i - 1, this.channel);\n            n += 1;\n        }\n        if (i < 0) {\n            return null;\n        }\n        return this.tokens[i];\n    }\n\n    LT(k) {\n        this.lazyInit();\n        if (k === 0) {\n            return null;\n        }\n        if (k < 0) {\n            return this.LB(-k);\n        }\n        let i = this.index;\n        let n = 1; // we know tokens[pos] is a good one\n        // find k good tokens\n        while (n < k) {\n            // skip off-channel tokens, but make sure to not look past EOF\n            if (this.sync(i + 1)) {\n                i = this.nextTokenOnChannel(i + 1, this.channel);\n            }\n            n += 1;\n        }\n        return this.tokens[i];\n    }\n\n    // Count EOF just once.\n    getNumberOfOnChannelTokens() {\n        let n = 0;\n        this.fill();\n        for (let i =0; i< this.tokens.length;i++) {\n            const t = this.tokens[i];\n            if( t.channel===this.channel) {\n                n += 1;\n            }\n            if( t.type===Token.EOF) {\n                break;\n            }\n        }\n        return n;\n    }\n}\n\nmodule.exports = CommonTokenStream;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst InputStream = require('./InputStream');\nconst fs = require(\"fs\");\n\n/**\n * This is an InputStream that is loaded from a file all at once\n * when you construct the object.\n */\nclass FileStream extends InputStream {\n\tconstructor(fileName, decodeToUnicodeCodePoints) {\n\t\tconst data = fs.readFileSync(fileName, \"utf8\");\n\t\tsuper(data, decodeToUnicodeCodePoints);\n\t\tthis.fileName = fileName;\n\t}\n}\n\nmodule.exports = FileStream\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nrequire('./polyfills/codepointat');\nrequire('./polyfills/fromcodepoint');\n\n/**\n * If decodeToUnicodeCodePoints is true, the input is treated\n * as a series of Unicode code points.\n *\n * Otherwise, the input is treated as a series of 16-bit UTF-16 code\n * units.\n */\nclass InputStream {\n\tconstructor(data, decodeToUnicodeCodePoints) {\n\t\tthis.name = \"<empty>\";\n\t\tthis.strdata = data;\n\t\tthis.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;\n\t\t// _loadString - Vacuum all input from a string and then treat it like a buffer.\n\t\tthis._index = 0;\n\t\tthis.data = [];\n\t\tif (this.decodeToUnicodeCodePoints) {\n\t\t\tfor (let i = 0; i < this.strdata.length; ) {\n\t\t\t\tconst codePoint = this.strdata.codePointAt(i);\n\t\t\t\tthis.data.push(codePoint);\n\t\t\t\ti += codePoint <= 0xFFFF ? 1 : 2;\n\t\t\t}\n\t\t} else {\n\t\t\tthis.data = new Array(this.strdata.length);\n\t\t\tfor (let i = 0; i < this.strdata.length; i++) {\n\t\t\t\tconst codeUnit = this.strdata.charCodeAt(i);\n\t\t\t\tthis.data[i] = codeUnit;\n\t\t\t}\n\t\t}\n\t\tthis._size = this.data.length;\n\t}\n\n\t/**\n\t * Reset the stream so that it's in the same state it was\n\t * when the object was created *except* the data array is not\n\t * touched.\n\t */\n\treset() {\n\t\tthis._index = 0;\n\t}\n\n\tconsume() {\n\t\tif (this._index >= this._size) {\n\t\t\t// assert this.LA(1) == Token.EOF\n\t\t\tthrow (\"cannot consume EOF\");\n\t\t}\n\t\tthis._index += 1;\n\t}\n\n\tLA(offset) {\n\t\tif (offset === 0) {\n\t\t\treturn 0; // undefined\n\t\t}\n\t\tif (offset < 0) {\n\t\t\toffset += 1; // e.g., translate LA(-1) to use offset=0\n\t\t}\n\t\tconst pos = this._index + offset - 1;\n\t\tif (pos < 0 || pos >= this._size) { // invalid\n\t\t\treturn Token.EOF;\n\t\t}\n\t\treturn this.data[pos];\n\t}\n\n\tLT(offset) {\n\t\treturn this.LA(offset);\n\t}\n\n// mark/release do nothing; we have entire buffer\n\tmark() {\n\t\treturn -1;\n\t}\n\n\trelease(marker) {\n\t}\n\n\t/**\n\t * consume() ahead until p==_index; can't just set p=_index as we must\n\t * update line and column. If we seek backwards, just set p\n\t */\n\tseek(_index) {\n\t\tif (_index <= this._index) {\n\t\t\tthis._index = _index; // just jump; don't update stream state (line,\n\t\t\t\t\t\t\t\t\t// ...)\n\t\t\treturn;\n\t\t}\n\t\t// seek forward\n\t\tthis._index = Math.min(_index, this._size);\n\t}\n\n\tgetText(start, stop) {\n\t\tif (stop >= this._size) {\n\t\t\tstop = this._size - 1;\n\t\t}\n\t\tif (start >= this._size) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\tif (this.decodeToUnicodeCodePoints) {\n\t\t\t\tlet result = \"\";\n\t\t\t\tfor (let i = start; i <= stop; i++) {\n\t\t\t\t\tresult += String.fromCodePoint(this.data[i]);\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t} else {\n\t\t\t\treturn this.strdata.slice(start, stop + 1);\n\t\t\t}\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn this.strdata;\n\t}\n\n\tget index(){\n\t\treturn this._index;\n\t}\n\n\tget size(){\n\t\treturn this._size;\n\t}\n}\n\n\nmodule.exports = InputStream;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\n\n/* stop is not included! */\nclass Interval {\n\n\tconstructor(start, stop) {\n\t\tthis.start = start;\n\t\tthis.stop = stop;\n\t}\n\n\tclone() {\n\t\treturn new Interval(this.start, this.stop);\n\t}\n\n\tcontains(item) {\n\t\treturn item >= this.start && item < this.stop;\n\t}\n\n\ttoString() {\n\t\tif(this.start===this.stop-1) {\n\t\t\treturn this.start.toString();\n\t\t} else {\n\t\t\treturn this.start.toString() + \"..\" + (this.stop-1).toString();\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.stop - this.start;\n\t}\n}\n\n\nclass IntervalSet {\n\tconstructor() {\n\t\tthis.intervals = null;\n\t\tthis.readOnly = false;\n\t}\n\n\tfirst(v) {\n\t\tif (this.intervals === null || this.intervals.length===0) {\n\t\t\treturn Token.INVALID_TYPE;\n\t\t} else {\n\t\t\treturn this.intervals[0].start;\n\t\t}\n\t}\n\n\taddOne(v) {\n\t\tthis.addInterval(new Interval(v, v + 1));\n\t}\n\n\taddRange(l, h) {\n\t\tthis.addInterval(new Interval(l, h + 1));\n\t}\n\n\taddInterval(toAdd) {\n\t\tif (this.intervals === null) {\n\t\t\tthis.intervals = [];\n\t\t\tthis.intervals.push(toAdd.clone());\n\t\t} else {\n\t\t\t// find insert pos\n\t\t\tfor (let pos = 0; pos < this.intervals.length; pos++) {\n\t\t\t\tconst existing = this.intervals[pos];\n\t\t\t\t// distinct range -> insert\n\t\t\t\tif (toAdd.stop < existing.start) {\n\t\t\t\t\tthis.intervals.splice(pos, 0, toAdd);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// contiguous range -> adjust\n\t\t\t\telse if (toAdd.stop === existing.start) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(toAdd.start, existing.stop)\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// overlapping range -> adjust and reduce\n\t\t\t\telse if (toAdd.start <= existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(Math.min(existing.start, toAdd.start), Math.max(existing.stop, toAdd.stop));\n\t\t\t\t\tthis.reduce(pos);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// greater than any existing\n\t\t\tthis.intervals.push(toAdd.clone());\n\t\t}\n\t}\n\n\taddSet(other) {\n\t\tif (other.intervals !== null) {\n\t\t\tother.intervals.forEach( toAdd => this.addInterval(toAdd), this);\n\t\t}\n\t\treturn this;\n\t}\n\n\treduce(pos) {\n\t\t// only need to reduce if pos is not the last\n\t\tif (pos < this.intervals.length - 1) {\n\t\t\tconst current = this.intervals[pos];\n\t\t\tconst next = this.intervals[pos + 1];\n\t\t\t// if next contained in current\n\t\t\tif (current.stop >= next.stop) {\n\t\t\t\tthis.intervals.splice(pos + 1, 1);\n\t\t\t\tthis.reduce(pos);\n\t\t\t} else if (current.stop >= next.start) {\n\t\t\t\tthis.intervals[pos] = new Interval(current.start, next.stop);\n\t\t\t\tthis.intervals.splice(pos + 1, 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tcomplement(start, stop) {\n\t\tconst result = new IntervalSet();\n\t\tresult.addInterval(new Interval(start, stop + 1));\n\t\tif(this.intervals !== null)\n\t\t\tthis.intervals.forEach(toRemove => result.removeRange(toRemove));\n\t\treturn result;\n\t}\n\n\tcontains(item) {\n\t\tif (this.intervals === null) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tfor (let k = 0; k < this.intervals.length; k++) {\n\t\t\t\tif(this.intervals[k].contains(item)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tremoveRange(toRemove) {\n\t\tif(toRemove.start===toRemove.stop-1) {\n\t\t\tthis.removeOne(toRemove.start);\n\t\t} else if (this.intervals !== null) {\n\t\t\tlet pos = 0;\n\t\t\tfor(let n=0; n<this.intervals.length; n++) {\n\t\t\t\tconst existing = this.intervals[pos];\n\t\t\t\t// intervals are ordered\n\t\t\t\tif (toRemove.stop<=existing.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for including range, split it\n\t\t\t\telse if(toRemove.start>existing.start && toRemove.stop<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(existing.start, toRemove.start);\n\t\t\t\t\tconst x = new Interval(toRemove.stop, existing.stop);\n\t\t\t\t\tthis.intervals.splice(pos, 0, x);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for included range, remove it\n\t\t\t\telse if(toRemove.start<=existing.start && toRemove.stop>=existing.stop) {\n\t\t\t\t\tthis.intervals.splice(pos, 1);\n\t\t\t\t\tpos = pos - 1; // need another pass\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if(toRemove.start<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(existing.start, toRemove.start);\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if(toRemove.stop<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(toRemove.stop, existing.stop);\n\t\t\t\t}\n\t\t\t\tpos += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tremoveOne(value) {\n\t\tif (this.intervals !== null) {\n\t\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\t\tconst existing = this.intervals[i];\n\t\t\t\t// intervals are ordered\n\t\t\t\tif (value < existing.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for single value range\n\t\t\t\telse if (value === existing.start && value === existing.stop - 1) {\n\t\t\t\t\tthis.intervals.splice(i, 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if (value === existing.start) {\n\t\t\t\t\tthis.intervals[i] = new Interval(existing.start + 1, existing.stop);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if (value === existing.stop - 1) {\n\t\t\t\t\tthis.intervals[i] = new Interval(existing.start, existing.stop - 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// split existing range\n\t\t\t\telse if (value < existing.stop - 1) {\n\t\t\t\t\tconst replace = new Interval(existing.start, value);\n\t\t\t\t\texisting.start = value + 1;\n\t\t\t\t\tthis.intervals.splice(i, 0, replace);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\ttoString(literalNames, symbolicNames, elemsAreChar) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\telemsAreChar = elemsAreChar || false;\n\t\tif (this.intervals === null) {\n\t\t\treturn \"{}\";\n\t\t} else if(literalNames!==null || symbolicNames!==null) {\n\t\t\treturn this.toTokenString(literalNames, symbolicNames);\n\t\t} else if(elemsAreChar) {\n\t\t\treturn this.toCharString();\n\t\t} else {\n\t\t\treturn this.toIndexString();\n\t\t}\n\t}\n\n\ttoCharString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tif(existing.stop===existing.start+1) {\n\t\t\t\tif ( existing.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(\"'\" + String.fromCharCode(existing.start) + \"'\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(\"'\" + String.fromCharCode(existing.start) + \"'..'\" + String.fromCharCode(existing.stop-1) + \"'\");\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoIndexString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tif(existing.stop===existing.start+1) {\n\t\t\t\tif ( existing.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(existing.start.toString());\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(existing.start.toString() + \"..\" + (existing.stop-1).toString());\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoTokenString(literalNames, symbolicNames) {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tfor (let j = existing.start; j < existing.stop; j++) {\n\t\t\t\tnames.push(this.elementName(literalNames, symbolicNames, j));\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\telementName(literalNames, symbolicNames, token) {\n\t\tif (token === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (token === Token.EPSILON) {\n\t\t\treturn \"<EPSILON>\";\n\t\t} else {\n\t\t\treturn literalNames[token] || symbolicNames[token];\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.intervals.map( interval => interval.length ).reduce((acc, val) => acc + val);\n\t}\n}\n\nmodule.exports = {\n\tInterval,\n\tIntervalSet\n};\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Set, BitSet} = require('./Utils');\nconst {Token} = require('./Token');\nconst {ATNConfig} = require('./atn/ATNConfig');\nconst {IntervalSet} = require('./IntervalSet');\nconst {RuleStopState} = require('./atn/ATNState');\nconst {RuleTransition, NotSetTransition, WildcardTransition, AbstractPredicateTransition} = require('./atn/Transition');\nconst {predictionContextFromRuleContext, PredictionContext, SingletonPredictionContext} = require('./PredictionContext');\n\nclass LL1Analyzer {\n    constructor(atn) {\n        this.atn = atn;\n    }\n\n    /**\n     * Calculates the SLL(1) expected lookahead set for each outgoing transition\n     * of an {@link ATNState}. The returned array has one element for each\n     * outgoing transition in {@code s}. If the closure from transition\n     * <em>i</em> leads to a semantic predicate before matching a symbol, the\n     * element at index <em>i</em> of the result will be {@code null}.\n     *\n     * @param s the ATN state\n     * @return the expected symbols for each outgoing transition of {@code s}.\n     */\n    getDecisionLookahead(s) {\n        if (s === null) {\n            return null;\n        }\n        const count = s.transitions.length;\n        const look = [];\n        for(let alt=0; alt< count; alt++) {\n            look[alt] = new IntervalSet();\n            const lookBusy = new Set();\n            const seeThruPreds = false; // fail to get lookahead upon pred\n            this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,\n                  look[alt], lookBusy, new BitSet(), seeThruPreds, false);\n            // Wipe out lookahead for this alternative if we found nothing\n            // or we had a predicate when we !seeThruPreds\n            if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n                look[alt] = null;\n            }\n        }\n        return look;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and the end of the rule containing\n     * {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n     * If {@code ctx} is not {@code null} and the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx the complete parser context, or {@code null} if the context\n     * should be ignored\n     *\n     * @return The set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     */\n    LOOK(s, stopState, ctx) {\n        const r = new IntervalSet();\n        const seeThruPreds = true; // ignore preds; get all lookahead\n        ctx = ctx || null;\n        const lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n        this._LOOK(s, stopState, lookContext, r, new Set(), new BitSet(), seeThruPreds, true);\n        return r;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n     * rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n     * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n     * {@code true} and {@code stopState} or the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state.\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx The outer context, or {@code null} if the outer context should\n     * not be used.\n     * @param look The result lookahead set.\n     * @param lookBusy A set used for preventing epsilon closures in the ATN\n     * from causing a stack overflow. Outside code should pass\n     * {@code new Set<ATNConfig>} for this argument.\n     * @param calledRuleStack A set used for preventing left recursion in the\n     * ATN from causing a stack overflow. Outside code should pass\n     * {@code new BitSet()} for this argument.\n     * @param seeThruPreds {@code true} to true semantic predicates as\n     * implicitly {@code true} and \"see through them\", otherwise {@code false}\n     * to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n     * result if one is encountered.\n     * @param addEOF Add {@link Token//EOF} to the result if the end of the\n     * outermost context is reached. This parameter has no effect if {@code ctx}\n     * is {@code null}.\n     */\n    _LOOK(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n        const c = new ATNConfig({state:s, alt:0, context: ctx}, null);\n        if (lookBusy.contains(c)) {\n            return;\n        }\n        lookBusy.add(c);\n        if (s === stopState) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n        }\n        if (s instanceof RuleStopState ) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n            if (ctx !== PredictionContext.EMPTY) {\n                const removed = calledRuleStack.contains(s.ruleIndex);\n                try {\n                    calledRuleStack.remove(s.ruleIndex);\n                    // run thru all possible stack tops in ctx\n                    for (let i = 0; i < ctx.length; i++) {\n                        const returnState = this.atn.states[ctx.getReturnState(i)];\n                        this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                    }\n                }finally {\n                    if (removed) {\n                        calledRuleStack.add(s.ruleIndex);\n                    }\n                }\n                return;\n            }\n        }\n        for(let j=0; j<s.transitions.length; j++) {\n            const t = s.transitions[j];\n            if (t.constructor === RuleTransition) {\n                if (calledRuleStack.contains(t.target.ruleIndex)) {\n                    continue;\n                }\n                const newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n                try {\n                    calledRuleStack.add(t.target.ruleIndex);\n                    this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } finally {\n                    calledRuleStack.remove(t.target.ruleIndex);\n                }\n            } else if (t instanceof AbstractPredicateTransition ) {\n                if (seeThruPreds) {\n                    this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } else {\n                    look.addOne(LL1Analyzer.HIT_PRED);\n                }\n            } else if( t.isEpsilon) {\n                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } else if (t.constructor === WildcardTransition) {\n                look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );\n            } else {\n                let set = t.label;\n                if (set !== null) {\n                    if (t instanceof NotSetTransition) {\n                        set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n                    }\n                    look.addSet(set);\n                }\n            }\n        }\n    }\n}\n\n/**\n * Special value added to the lookahead sets to indicate that we hit\n * a predicate during analysis if {@code seeThruPreds==false}.\n */\nLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n\nmodule.exports = LL1Analyzer;\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst Recognizer = require('./Recognizer');\nconst CommonTokenFactory = require('./CommonTokenFactory');\nconst {RecognitionException} = require('./error/Errors');\nconst {LexerNoViableAltException} = require('./error/Errors');\n\nclass TokenSource {}\n\n/**\n * A lexer is recognizer that draws input symbols from a character stream.\n * lexer grammars result in a subclass of this object. A Lexer object\n * uses simplified match() and error recovery mechanisms in the interest of speed.\n */\nclass Lexer extends Recognizer {\n\tconstructor(input) {\n\t\tsuper();\n\t\tthis._input = input;\n\t\tthis._factory = CommonTokenFactory.DEFAULT;\n\t\tthis._tokenFactorySourcePair = [ this, input ];\n\n\t\tthis._interp = null; // child classes must populate this\n\n\t\t/**\n\t\t * The goal of all lexer rules/methods is to create a token object.\n\t\t * this is an instance variable as multiple rules may collaborate to\n\t\t * create a single token. nextToken will return this object after\n\t\t * matching lexer rule(s). If you subclass to allow multiple token\n\t\t * emissions, then set this to the last token to be matched or\n\t\t * something nonnull so that the auto token emit mechanism will not\n\t\t * emit another token.\n\t\t */\n\t\tthis._token = null;\n\n\t\t/**\n\t\t * What character index in the stream did the current token start at?\n\t\t * Needed, for example, to get the text for current token. Set at\n\t\t * the start of nextToken.\n\t\t */\n\t\tthis._tokenStartCharIndex = -1;\n\n\t\t// The line on which the first character of the token resides///\n\t\tthis._tokenStartLine = -1;\n\n\t\t// The character position of first character within the line///\n\t\tthis._tokenStartColumn = -1;\n\n\t\t// Once we see EOF on char stream, next token will be EOF.\n\t\t// If you have DONE : EOF ; then you see DONE EOF.\n\t\tthis._hitEOF = false;\n\n\t\t// The channel number for the current token///\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\n\t\t// The token type for the current token///\n\t\tthis._type = Token.INVALID_TYPE;\n\n\t\tthis._modeStack = [];\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\n\t\t/**\n\t\t * You can set the text for the current token to override what is in\n\t\t * the input char buffer. Use setText() or can set this instance var.\n\t\t */\n\t\tthis._text = null;\n\t}\n\n\treset() {\n\t\t// wack Lexer state variables\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0); // rewind the input\n\t\t}\n\t\tthis._token = null;\n\t\tthis._type = Token.INVALID_TYPE;\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\tthis._tokenStartCharIndex = -1;\n\t\tthis._tokenStartColumn = -1;\n\t\tthis._tokenStartLine = -1;\n\t\tthis._text = null;\n\n\t\tthis._hitEOF = false;\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\t\tthis._modeStack = [];\n\n\t\tthis._interp.reset();\n\t}\n\n// Return a token from this source; i.e., match a token on the char stream.\n\tnextToken() {\n\t\tif (this._input === null) {\n\t\t\tthrow \"nextToken requires a non-null input stream.\";\n\t\t}\n\n\t\t/**\n\t\t * Mark start location in char stream so unbuffered streams are\n\t\t * guaranteed at least have text of current token\n\t\t */\n\t\tconst tokenStartMarker = this._input.mark();\n\t\ttry {\n\t\t\twhile (true) {\n\t\t\t\tif (this._hitEOF) {\n\t\t\t\t\tthis.emitEOF();\n\t\t\t\t\treturn this._token;\n\t\t\t\t}\n\t\t\t\tthis._token = null;\n\t\t\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\t\t\tthis._tokenStartCharIndex = this._input.index;\n\t\t\t\tthis._tokenStartColumn = this._interp.column;\n\t\t\t\tthis._tokenStartLine = this._interp.line;\n\t\t\t\tthis._text = null;\n\t\t\t\tlet continueOuter = false;\n\t\t\t\twhile (true) {\n\t\t\t\t\tthis._type = Token.INVALID_TYPE;\n\t\t\t\t\tlet ttype = Lexer.SKIP;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tttype = this._interp.match(this._input, this._mode);\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\tif(e instanceof RecognitionException) {\n\t\t\t\t\t\t\tthis.notifyListeners(e); // report error\n\t\t\t\t\t\t\tthis.recover(e);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tconsole.log(e.stack);\n\t\t\t\t\t\t\tthrow e;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (this._input.LA(1) === Token.EOF) {\n\t\t\t\t\t\tthis._hitEOF = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Token.INVALID_TYPE) {\n\t\t\t\t\t\tthis._type = ttype;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Lexer.SKIP) {\n\t\t\t\t\t\tcontinueOuter = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type !== Lexer.MORE) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (continueOuter) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (this._token === null) {\n\t\t\t\t\tthis.emit();\n\t\t\t\t}\n\t\t\t\treturn this._token;\n\t\t\t}\n\t\t} finally {\n\t\t\t// make sure we release marker after match or\n\t\t\t// unbuffered char stream will keep buffering\n\t\t\tthis._input.release(tokenStartMarker);\n\t\t}\n\t}\n\n\t/**\n\t * Instruct the lexer to skip creating a token for current lexer rule\n\t * and look for another token. nextToken() knows to keep looking when\n\t * a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n\t * if token==null at end of any token rule, it creates one for you\n\t * and emits it.\n\t */\n\tskip() {\n\t\tthis._type = Lexer.SKIP;\n\t}\n\n\tmore() {\n\t\tthis._type = Lexer.MORE;\n\t}\n\n\tmode(m) {\n\t\tthis._mode = m;\n\t}\n\n\tpushMode(m) {\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"pushMode \" + m);\n\t\t}\n\t\tthis._modeStack.push(this._mode);\n\t\tthis.mode(m);\n\t}\n\n\tpopMode() {\n\t\tif (this._modeStack.length === 0) {\n\t\t\tthrow \"Empty Stack\";\n\t\t}\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n\t\t}\n\t\tthis.mode(this._modeStack.pop());\n\t\treturn this._mode;\n\t}\n\n\t/**\n\t * By default does not support multiple emits per nextToken invocation\n\t * for efficiency reasons. Subclass and override this method, nextToken,\n\t * and getToken (to push tokens into a list and pull from that list\n\t * rather than a single variable as this implementation does).\n\t */\n\temitToken(token) {\n\t\tthis._token = token;\n\t}\n\n\t/**\n\t * The standard method called to automatically emit a token at the\n\t * outermost lexical rule. The token object should point into the\n\t * char buffer start..stop. If there is a text override in 'text',\n\t * use that to set the token's text. Override this method to emit\n\t * custom Token objects or provide a new factory.\n\t */\n\temit() {\n\t\tconst t = this._factory.create(this._tokenFactorySourcePair, this._type,\n\t\t\t\tthis._text, this._channel, this._tokenStartCharIndex, this\n\t\t\t\t\t\t.getCharIndex() - 1, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn);\n\t\tthis.emitToken(t);\n\t\treturn t;\n\t}\n\n\temitEOF() {\n\t\tconst cpos = this.column;\n\t\tconst lpos = this.line;\n\t\tconst eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,\n\t\t\t\tnull, Token.DEFAULT_CHANNEL, this._input.index,\n\t\t\t\tthis._input.index - 1, lpos, cpos);\n\t\tthis.emitToken(eof);\n\t\treturn eof;\n\t}\n\n// What is the index of the current character of lookahead?///\n\tgetCharIndex() {\n\t\treturn this._input.index;\n\t}\n\n\t/**\n\t * Return a list of all Token objects in input char stream.\n\t * Forces load of all tokens. Does not include EOF token.\n\t */\n\tgetAllTokens() {\n\t\tconst tokens = [];\n\t\tlet t = this.nextToken();\n\t\twhile (t.type !== Token.EOF) {\n\t\t\ttokens.push(t);\n\t\t\tt = this.nextToken();\n\t\t}\n\t\treturn tokens;\n\t}\n\n\tnotifyListeners(e) {\n\t\tconst start = this._tokenStartCharIndex;\n\t\tconst stop = this._input.index;\n\t\tconst text = this._input.getText(start, stop);\n\t\tconst msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n\t\tconst listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, null, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn, msg, e);\n\t}\n\n\tgetErrorDisplay(s) {\n\t\tconst d = [];\n\t\tfor (let i = 0; i < s.length; i++) {\n\t\t\td.push(s[i]);\n\t\t}\n\t\treturn d.join('');\n\t}\n\n\tgetErrorDisplayForChar(c) {\n\t\tif (c.charCodeAt(0) === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (c === '\\n') {\n\t\t\treturn \"\\\\n\";\n\t\t} else if (c === '\\t') {\n\t\t\treturn \"\\\\t\";\n\t\t} else if (c === '\\r') {\n\t\t\treturn \"\\\\r\";\n\t\t} else {\n\t\t\treturn c;\n\t\t}\n\t}\n\n\tgetCharErrorDisplay(c) {\n\t\treturn \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n\t}\n\n\t/**\n\t * Lexers can normally match any char in it's vocabulary after matching\n\t * a token, so do the easy thing and just kill a character and hope\n\t * it all works out. You can instead use the rule invocation stack\n\t * to do sophisticated error recovery if you are in a fragment rule.\n\t */\n\trecover(re) {\n\t\tif (this._input.LA(1) !== Token.EOF) {\n\t\t\tif (re instanceof LexerNoViableAltException) {\n\t\t\t\t// skip a char and try again\n\t\t\t\tthis._interp.consume(this._input);\n\t\t\t} else {\n\t\t\t\t// TODO: Do we lose character or line position information?\n\t\t\t\tthis._input.consume();\n\t\t\t}\n\t\t}\n\t}\n\n\tget inputStream(){\n\t\treturn this._input;\n\t}\n\n\tset inputStream(input) {\n\t\tthis._input = null;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\tthis.reset();\n\t\tthis._input = input;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t}\n\n\tget sourceName(){\n\t\treturn this._input.sourceName;\n\t}\n\n\tget type(){\n\t\treturn this._type;\n\t}\n\n\tset type(type) {\n\t\tthis._type = type;\n\t}\n\n\tget line(){\n\t\treturn this._interp.line;\n\t}\n\n\tset line(line) {\n\t\tthis._interp.line = line;\n\t}\n\n\tget column(){\n\t\treturn this._interp.column;\n\t}\n\n\tset column(column) {\n\t\tthis._interp.column = column;\n\t}\n\n\tget text(){\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t} else {\n\t\t\treturn this._interp.getText(this._input);\n\t\t}\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\n\n\n\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\n\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = 0x0000;\nLexer.MAX_CHAR_VALUE = 0x10FFFF;\n\n// Set the char stream and reset the lexer\n\n\nmodule.exports = Lexer;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst {ParseTreeListener, TerminalNode, ErrorNode} = require('./tree/Tree');\nconst Recognizer = require('./Recognizer');\nconst {DefaultErrorStrategy} = require('./error/ErrorStrategy');\nconst ATNDeserializer = require('./atn/ATNDeserializer');\nconst ATNDeserializationOptions = require('./atn/ATNDeserializationOptions');\nconst Lexer = require('./Lexer');\n\nclass TraceListener extends ParseTreeListener {\n\tconstructor(parser) {\n\t\tsuper();\n\t\tthis.parser = parser;\n\t}\n\n\tenterEveryRule(ctx) {\n\t\tconsole.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t}\n\n\tvisitTerminal(node) {\n\t\tconsole.log(\"consume \" + node.symbol + \" rule \" + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n\t}\n\n\texitEveryRule(ctx) {\n\t\tconsole.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t}\n}\n\nclass Parser extends Recognizer {\n\t/**\n\t * this is all the parsing support code essentially; most of it is error\n\t * recovery stuff.\n\t */\n\tconstructor(input) {\n\t\tsuper();\n\t\t// The input stream.\n\t\tthis._input = null;\n\t\t/**\n\t\t * The error handling strategy for the parser. The default value is a new\n\t\t * instance of {@link DefaultErrorStrategy}.\n\t\t */\n\t\tthis._errHandler = new DefaultErrorStrategy();\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\t/**\n\t\t * The {@link ParserRuleContext} object for the currently executing rule.\n\t\t * this is always non-null during the parsing process.\n\t\t */\n\t\tthis._ctx = null;\n\t\t/**\n\t\t * Specifies whether or not the parser should construct a parse tree during\n\t\t * the parsing process. The default value is {@code true}.\n\t\t */\n\t\tthis.buildParseTrees = true;\n\t\t/**\n\t\t * When {@link //setTrace}{@code (true)} is called, a reference to the\n\t\t * {@link TraceListener} is stored here so it can be easily removed in a\n\t\t * later call to {@link //setTrace}{@code (false)}. The listener itself is\n\t\t * implemented as a parser listener so this field is not directly used by\n\t\t * other parser methods.\n\t\t */\n\t\tthis._tracer = null;\n\t\t/**\n\t\t * The list of {@link ParseTreeListener} listeners registered to receive\n\t\t * events during the parse.\n\t\t */\n\t\tthis._parseListeners = null;\n\t\t/**\n\t\t * The number of syntax errors reported during parsing. this value is\n\t\t * incremented each time {@link //notifyErrorListeners} is called.\n\t\t */\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setInputStream(input);\n\t}\n\n\t// reset the parser's state\n\treset() {\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0);\n\t\t}\n\t\tthis._errHandler.reset(this);\n\t\tthis._ctx = null;\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setTrace(false);\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\tif (this._interp !== null) {\n\t\t\tthis._interp.reset();\n\t\t}\n\t}\n\n\t/**\n\t * Match current input symbol against {@code ttype}. If the symbol type\n\t * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n\t * called to complete the match process.\n\t *\n\t * <p>If the symbol type does not match,\n\t * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t * strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t * {@code true} and the token index of the symbol returned by\n\t * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t *\n\t * @param ttype the token type to match\n\t * @return the matched symbol\n\t * @throws RecognitionException if the current input symbol did not match\n\t * {@code ttype} and the error strategy could not recover from the\n\t * mismatched symbol\n\t */\n\tmatch(ttype) {\n\t\tlet t = this.getCurrentToken();\n\t\tif (t.type === ttype) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this.buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t}\n\n\t/**\n\t * Match current input symbol as a wildcard. If the symbol type matches\n\t * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n\t * and {@link //consume} are called to complete the match process.\n\t *\n\t * <p>If the symbol type does not match,\n\t * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t * strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t * {@code true} and the token index of the symbol returned by\n\t * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t *\n\t * @return the matched symbol\n\t * @throws RecognitionException if the current input symbol did not match\n\t * a wildcard and the error strategy could not recover from the mismatched\n\t * symbol\n\t */\n\tmatchWildcard() {\n\t\tlet t = this.getCurrentToken();\n\t\tif (t.type > 0) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this._buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t}\n\n\tgetParseListeners() {\n\t\treturn this._parseListeners || [];\n\t}\n\n\t/**\n\t * Registers {@code listener} to receive events during the parsing process.\n\t *\n\t * <p>To support output-preserving grammar transformations (including but not\n\t * limited to left-recursion removal, automated left-factoring, and\n\t * optimized code generation), calls to listener methods during the parse\n\t * may differ substantially from calls made by\n\t * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n\t * particular, rule entry and exit events may occur in a different order\n\t * during the parse than after the parser. In addition, calls to certain\n\t * rule entry methods may be omitted.</p>\n\t *\n\t * <p>With the following specific exceptions, calls to listener events are\n\t * <em>deterministic</em>, i.e. for identical input the calls to listener\n\t * methods will be the same.</p>\n\t *\n\t * <ul>\n\t * <li>Alterations to the grammar used to generate code may change the\n\t * behavior of the listener calls.</li>\n\t * <li>Alterations to the command line options passed to ANTLR 4 when\n\t * generating the parser may change the behavior of the listener calls.</li>\n\t * <li>Changing the version of the ANTLR Tool used to generate the parser\n\t * may change the behavior of the listener calls.</li>\n\t * </ul>\n\t *\n\t * @param listener the listener to add\n\t *\n\t * @throws NullPointerException if {@code} listener is {@code null}\n\t */\n\taddParseListener(listener) {\n\t\tif (listener === null) {\n\t\t\tthrow \"listener\";\n\t\t}\n\t\tif (this._parseListeners === null) {\n\t\t\tthis._parseListeners = [];\n\t\t}\n\t\tthis._parseListeners.push(listener);\n\t}\n\n\t/**\n\t * Remove {@code listener} from the list of parse listeners.\n\t *\n\t * <p>If {@code listener} is {@code null} or has not been added as a parse\n\t * listener, this method does nothing.</p>\n\t * @param listener the listener to remove\n\t */\n\tremoveParseListener(listener) {\n\t\tif (this._parseListeners !== null) {\n\t\t\tconst idx = this._parseListeners.indexOf(listener);\n\t\t\tif (idx >= 0) {\n\t\t\t\tthis._parseListeners.splice(idx, 1);\n\t\t\t}\n\t\t\tif (this._parseListeners.length === 0) {\n\t\t\t\tthis._parseListeners = null;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Remove all parse listeners.\n\tremoveParseListeners() {\n\t\tthis._parseListeners = null;\n\t}\n\n\t// Notify any parse listeners of an enter rule event.\n\ttriggerEnterRuleEvent() {\n\t\tif (this._parseListeners !== null) {\n\t\t\tconst ctx = this._ctx;\n\t\t\tthis._parseListeners.forEach(function(listener) {\n\t\t\t\tlistener.enterEveryRule(ctx);\n\t\t\t\tctx.enterRule(listener);\n\t\t\t});\n\t\t}\n\t}\n\n\t/**\n\t * Notify any parse listeners of an exit rule event.\n\t * @see //addParseListener\n\t */\n\ttriggerExitRuleEvent() {\n\t\tif (this._parseListeners !== null) {\n\t\t\t// reverse order walk of listeners\n\t\t\tconst ctx = this._ctx;\n\t\t\tthis._parseListeners.slice(0).reverse().forEach(function(listener) {\n\t\t\t\tctx.exitRule(listener);\n\t\t\t\tlistener.exitEveryRule(ctx);\n\t\t\t});\n\t\t}\n\t}\n\n\tgetTokenFactory() {\n\t\treturn this._input.tokenSource._factory;\n\t}\n\n\t// Tell our token source and error strategy about a new way to create tokens.\n\tsetTokenFactory(factory) {\n\t\tthis._input.tokenSource._factory = factory;\n\t}\n\n\t/**\n\t * The ATN with bypass alternatives is expensive to create so we create it\n\t * lazily.\n\t *\n\t * @throws UnsupportedOperationException if the current parser does not\n\t * implement the {@link //getSerializedATN()} method.\n\t */\n\tgetATNWithBypassAlts() {\n\t\tconst serializedAtn = this.getSerializedATN();\n\t\tif (serializedAtn === null) {\n\t\t\tthrow \"The current parser does not support an ATN with bypass alternatives.\";\n\t\t}\n\t\tlet result = this.bypassAltsAtnCache[serializedAtn];\n\t\tif (result === null) {\n\t\t\tconst deserializationOptions = new ATNDeserializationOptions();\n\t\t\tdeserializationOptions.generateRuleBypassTransitions = true;\n\t\t\tresult = new ATNDeserializer(deserializationOptions)\n\t\t\t\t\t.deserialize(serializedAtn);\n\t\t\tthis.bypassAltsAtnCache[serializedAtn] = result;\n\t\t}\n\t\treturn result;\n\t}\n\n\t/**\n\t * The preferred method of getting a tree pattern. For example, here's a\n\t * sample use:\n\t *\n\t * <pre>\n\t * ParseTree t = parser.expr();\n\t * ParseTreePattern p = parser.compileParseTreePattern(\"&lt;ID&gt;+0\",\n\t * MyParser.RULE_expr);\n\t * ParseTreeMatch m = p.match(t);\n\t * String id = m.get(\"ID\");\n\t * </pre>\n\t */\n\tcompileParseTreePattern(pattern, patternRuleIndex, lexer) {\n\t\tlexer = lexer || null;\n\t\tif (lexer === null) {\n\t\t\tif (this.getTokenStream() !== null) {\n\t\t\t\tconst tokenSource = this.getTokenStream().tokenSource;\n\t\t\t\tif (tokenSource instanceof Lexer) {\n\t\t\t\t\tlexer = tokenSource;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (lexer === null) {\n\t\t\tthrow \"Parser can't discover a lexer to use\";\n\t\t}\n\t\tconst m = new ParseTreePatternMatcher(lexer, this);\n\t\treturn m.compile(pattern, patternRuleIndex);\n\t}\n\n\tgetInputStream() {\n\t\treturn this.getTokenStream();\n\t}\n\n\tsetInputStream(input) {\n\t\tthis.setTokenStream(input);\n\t}\n\n\tgetTokenStream() {\n\t\treturn this._input;\n\t}\n\n\t// Set the token stream and reset the parser.\n\tsetTokenStream(input) {\n\t\tthis._input = null;\n\t\tthis.reset();\n\t\tthis._input = input;\n\t}\n\n\t/**\n\t * Match needs to return the current input symbol, which gets put\n\t * into the label for the associated token ref; e.g., x=ID.\n\t */\n\tgetCurrentToken() {\n\t\treturn this._input.LT(1);\n\t}\n\n\tnotifyErrorListeners(msg, offendingToken, err) {\n\t\toffendingToken = offendingToken || null;\n\t\terr = err || null;\n\t\tif (offendingToken === null) {\n\t\t\toffendingToken = this.getCurrentToken();\n\t\t}\n\t\tthis._syntaxErrors += 1;\n\t\tconst line = offendingToken.line;\n\t\tconst column = offendingToken.column;\n\t\tconst listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, offendingToken, line, column, msg, err);\n\t}\n\n\t/**\n\t * Consume and return the {@linkplain //getCurrentToken current symbol}.\n\t *\n\t * <p>E.g., given the following input with {@code A} being the current\n\t * lookahead symbol, this function moves the cursor to {@code B} and returns\n\t * {@code A}.</p>\n\t *\n\t * <pre>\n\t * A B\n\t * ^\n\t * </pre>\n\t *\n\t * If the parser is not in error recovery mode, the consumed symbol is added\n\t * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n\t * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n\t * If the parser <em>is</em> in error recovery mode, the consumed symbol is\n\t * added to the parse tree using\n\t * {@link ParserRuleContext//addErrorNode(Token)}, and\n\t * {@link ParseTreeListener//visitErrorNode} is called on any parse\n\t * listeners.\n\t */\n\tconsume() {\n\t\tconst o = this.getCurrentToken();\n\t\tif (o.type !== Token.EOF) {\n\t\t\tthis.getInputStream().consume();\n\t\t}\n\t\tconst hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n\t\tif (this.buildParseTrees || hasListener) {\n\t\t\tlet node;\n\t\t\tif (this._errHandler.inErrorRecoveryMode(this)) {\n\t\t\t\tnode = this._ctx.addErrorNode(o);\n\t\t\t} else {\n\t\t\t\tnode = this._ctx.addTokenNode(o);\n\t\t\t}\n\t\t\tnode.invokingState = this.state;\n\t\t\tif (hasListener) {\n\t\t\t\tthis._parseListeners.forEach(function(listener) {\n\t\t\t\t\tif (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {\n\t\t\t\t\t\tlistener.visitErrorNode(node);\n\t\t\t\t\t} else if (node instanceof TerminalNode) {\n\t\t\t\t\t\tlistener.visitTerminal(node);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn o;\n\t}\n\n\taddContextToParseTree() {\n\t\t// add current context to parent if we have a parent\n\t\tif (this._ctx.parentCtx !== null) {\n\t\t\tthis._ctx.parentCtx.addChild(this._ctx);\n\t\t}\n\t}\n\n\t/**\n\t * Always called by generated parsers upon entry to a rule. Access field\n\t * {@link //_ctx} get the current context.\n\t */\n\tenterRule(localctx, state, ruleIndex) {\n\t\tthis.state = state;\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = this._input.LT(1);\n\t\tif (this.buildParseTrees) {\n\t\t\tthis.addContextToParseTree();\n\t\t}\n\t\tthis.triggerEnterRuleEvent();\n\t}\n\n\texitRule() {\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\t// trigger event on _ctx, before it reverts to parent\n\t\tthis.triggerExitRuleEvent();\n\t\tthis.state = this._ctx.invokingState;\n\t\tthis._ctx = this._ctx.parentCtx;\n\t}\n\n\tenterOuterAlt(localctx, altNum) {\n\t\tlocalctx.setAltNumber(altNum);\n\t\t// if we have new localctx, make sure we replace existing ctx\n\t\t// that is previous child of parse tree\n\t\tif (this.buildParseTrees && this._ctx !== localctx) {\n\t\t\tif (this._ctx.parentCtx !== null) {\n\t\t\t\tthis._ctx.parentCtx.removeLastChild();\n\t\t\t\tthis._ctx.parentCtx.addChild(localctx);\n\t\t\t}\n\t\t}\n\t\tthis._ctx = localctx;\n\t}\n\n\t/**\n\t * Get the precedence level for the top-most precedence rule.\n\t *\n\t * @return The precedence level for the top-most precedence rule, or -1 if\n\t * the parser context is not nested within a precedence rule.\n\t */\n\tgetPrecedence() {\n\t\tif (this._precedenceStack.length === 0) {\n\t\t\treturn -1;\n\t\t} else {\n\t\t\treturn this._precedenceStack[this._precedenceStack.length-1];\n\t\t}\n\t}\n\n\tenterRecursionRule(localctx, state, ruleIndex, precedence) {\n\t   this.state = state;\n\t   this._precedenceStack.push(precedence);\n\t   this._ctx = localctx;\n\t   this._ctx.start = this._input.LT(1);\n\t   this.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules\n   }\n\n\t// Like {@link //enterRule} but for recursive rules.\n\tpushNewRecursionContext(localctx, state, ruleIndex) {\n\t\tconst previous = this._ctx;\n\t\tprevious.parentCtx = localctx;\n\t\tprevious.invokingState = state;\n\t\tprevious.stop = this._input.LT(-1);\n\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = previous.start;\n\t\tif (this.buildParseTrees) {\n\t\t\tthis._ctx.addChild(previous);\n\t\t}\n\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules\n\t}\n\n\tunrollRecursionContexts(parentCtx) {\n\t\tthis._precedenceStack.pop();\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\tconst retCtx = this._ctx; // save current ctx (return value)\n\t\t// unroll so _ctx is as it was before call to recursive method\n\t\tconst parseListeners = this.getParseListeners();\n\t\tif (parseListeners !== null && parseListeners.length > 0) {\n\t\t\twhile (this._ctx !== parentCtx) {\n\t\t\t\tthis.triggerExitRuleEvent();\n\t\t\t\tthis._ctx = this._ctx.parentCtx;\n\t\t\t}\n\t\t} else {\n\t\t\tthis._ctx = parentCtx;\n\t\t}\n\t\t// hook into tree\n\t\tretCtx.parentCtx = parentCtx;\n\t\tif (this.buildParseTrees && parentCtx !== null) {\n\t\t\t// add return ctx into invoking rule's tree\n\t\t\tparentCtx.addChild(retCtx);\n\t\t}\n\t}\n\n\tgetInvokingContext(ruleIndex) {\n\t\tlet ctx = this._ctx;\n\t\twhile (ctx !== null) {\n\t\t\tif (ctx.ruleIndex === ruleIndex) {\n\t\t\t\treturn ctx;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\treturn null;\n\t}\n\n\tprecpred(localctx, precedence) {\n\t\treturn precedence >= this._precedenceStack[this._precedenceStack.length-1];\n\t}\n\n\tinContext(context) {\n\t\t// TODO: useful in parser?\n\t\treturn false;\n\t}\n\n\t/**\n\t * Checks whether or not {@code symbol} can follow the current state in the\n\t * ATN. The behavior of this method is equivalent to the following, but is\n\t * implemented such that the complete context-sensitive follow set does not\n\t * need to be explicitly constructed.\n\t *\n\t * <pre>\n\t * return getExpectedTokens().contains(symbol);\n\t * </pre>\n\t *\n\t * @param symbol the symbol type to check\n\t * @return {@code true} if {@code symbol} can follow the current state in\n\t * the ATN, otherwise {@code false}.\n\t */\n\tisExpectedToken(symbol) {\n\t\tconst atn = this._interp.atn;\n\t\tlet ctx = this._ctx;\n\t\tconst s = atn.states[this.state];\n\t\tlet following = atn.nextTokens(s);\n\t\tif (following.contains(symbol)) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!following.contains(Token.EPSILON)) {\n\t\t\treturn false;\n\t\t}\n\t\twhile (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n\t\t\tconst invokingState = atn.states[ctx.invokingState];\n\t\t\tconst rt = invokingState.transitions[0];\n\t\t\tfollowing = atn.nextTokens(rt.followState);\n\t\t\tif (following.contains(symbol)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\tif (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\t/**\n\t * Computes the set of input symbols which could follow the current parser\n\t * state and context, as given by {@link //getState} and {@link //getContext},\n\t * respectively.\n\t *\n\t * @see ATN//getExpectedTokens(int, RuleContext)\n\t */\n\tgetExpectedTokens() {\n\t\treturn this._interp.atn.getExpectedTokens(this.state, this._ctx);\n\t}\n\n\tgetExpectedTokensWithinCurrentRule() {\n\t\tconst atn = this._interp.atn;\n\t\tconst s = atn.states[this.state];\n\t\treturn atn.nextTokens(s);\n\t}\n\n\t// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.\n\tgetRuleIndex(ruleName) {\n\t\tconst ruleIndex = this.getRuleIndexMap()[ruleName];\n\t\tif (ruleIndex !== null) {\n\t\t\treturn ruleIndex;\n\t\t} else {\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t/**\n\t * Return List&lt;String&gt; of the rule names in your parser instance\n\t * leading up to a call to the current rule. You could override if\n\t * you want more details such as the file/line info of where\n\t * in the ATN a rule is invoked.\n\t *\n\t * this is very useful for error messages.\n\t */\n\tgetRuleInvocationStack(p) {\n\t\tp = p || null;\n\t\tif (p === null) {\n\t\t\tp = this._ctx;\n\t\t}\n\t\tconst stack = [];\n\t\twhile (p !== null) {\n\t\t\t// compute what follows who invoked us\n\t\t\tconst ruleIndex = p.ruleIndex;\n\t\t\tif (ruleIndex < 0) {\n\t\t\t\tstack.push(\"n/a\");\n\t\t\t} else {\n\t\t\t\tstack.push(this.ruleNames[ruleIndex]);\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\treturn stack;\n\t}\n\n\t// For debugging and other purposes.\n\tgetDFAStrings() {\n\t\treturn this._interp.decisionToDFA.toString();\n\t}\n\n\t// For debugging and other purposes.\n\tdumpDFA() {\n\t\tlet seenOne = false;\n\t\tfor (let i = 0; i < this._interp.decisionToDFA.length; i++) {\n\t\t\tconst dfa = this._interp.decisionToDFA[i];\n\t\t\tif (dfa.states.length > 0) {\n\t\t\t\tif (seenOne) {\n\t\t\t\t\tconsole.log();\n\t\t\t\t}\n\t\t\t\tthis.printer.println(\"Decision \" + dfa.decision + \":\");\n\t\t\t\tthis.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n\t\t\t\tseenOne = true;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t\t\"\t\t\tprinter = function() {\\r\\n\" +\n\t\t\"\t\t\t\tthis.println = function(s) { document.getElementById('output') += s + '\\\\n'; }\\r\\n\" +\n\t\t\"\t\t\t\tthis.print = function(s) { document.getElementById('output') += s; }\\r\\n\" +\n\t\t\"\t\t\t};\\r\\n\" +\n\t\t*/\n\tgetSourceName() {\n\t\treturn this._input.sourceName;\n\t}\n\n\t/**\n\t * During a parse is sometimes useful to listen in on the rule entry and exit\n\t * events as well as token matches. this is for quick and dirty debugging.\n\t */\n\tsetTrace(trace) {\n\t\tif (!trace) {\n\t\t\tthis.removeParseListener(this._tracer);\n\t\t\tthis._tracer = null;\n\t\t} else {\n\t\t\tif (this._tracer !== null) {\n\t\t\t\tthis.removeParseListener(this._tracer);\n\t\t\t}\n\t\t\tthis._tracer = new TraceListener(this);\n\t\t\tthis.addParseListener(this._tracer);\n\t\t}\n\t}\n}\n\n/**\n * this field maps from the serialized ATN string to the deserialized {@link\n * ATN} with\n * bypass alternatives.\n *\n * @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n */\nParser.bypassAltsAtnCache = {};\n\nmodule.exports = Parser;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst RuleContext = require('./RuleContext');\nconst Tree = require('./tree/Tree');\nconst INVALID_INTERVAL = Tree.INVALID_INTERVAL;\nconst TerminalNode = Tree.TerminalNode;\nconst TerminalNodeImpl = Tree.TerminalNodeImpl;\nconst ErrorNodeImpl = Tree.ErrorNodeImpl;\nconst Interval = require(\"./IntervalSet\").Interval;\n\n/**\n * A rule invocation record for parsing.\n *\n *  Contains all of the information about the current rule not stored in the\n *  RuleContext. It handles parse tree children list, Any ATN state\n *  tracing, and the default values available for rule indications:\n *  start, stop, rule index, current alt number, current\n *  ATN state.\n *\n *  Subclasses made for each rule and grammar track the parameters,\n *  return values, locals, and labels specific to that rule. These\n *  are the objects that are returned from rules.\n *\n *  Note text is not an actual field of a rule return value; it is computed\n *  from start and stop using the input stream's toString() method.  I\n *  could add a ctor to this so that we can pass in and store the input\n *  stream, but I'm not sure we want to do that.  It would seem to be undefined\n *  to get the .text property anyway if the rule matches tokens from multiple\n *  input streams.\n *\n *  I do not use getters for fields of objects that are used simply to\n *  group values such as this aggregate.  The getters/setters are there to\n *  satisfy the superclass interface.\n */\nclass ParserRuleContext extends RuleContext {\n\tconstructor(parent, invokingStateNumber) {\n\t\tparent = parent || null;\n\t\tinvokingStateNumber = invokingStateNumber || null;\n\t\tsuper(parent, invokingStateNumber);\n\t\tthis.ruleIndex = -1;\n\t\t/**\n\t\t * If we are debugging or building a parse tree for a visitor,\n\t\t * we need to track all of the tokens and rule invocations associated\n\t\t * with this rule's context. This is empty for parsing w/o tree constr.\n\t\t * operation because we don't the need to track the details about\n\t\t * how we parse this rule.\n\t\t */\n\t\tthis.children = null;\n\t\tthis.start = null;\n\t\tthis.stop = null;\n\t\t/**\n\t\t * The exception that forced this rule to return. If the rule successfully\n\t\t * completed, this is {@code null}.\n\t\t */\n\t\tthis.exception = null;\n\t}\n\n\t// COPY a ctx (I'm deliberately not using copy constructor)\n\tcopyFrom(ctx) {\n\t\t// from RuleContext\n\t\tthis.parentCtx = ctx.parentCtx;\n\t\tthis.invokingState = ctx.invokingState;\n\t\tthis.children = null;\n\t\tthis.start = ctx.start;\n\t\tthis.stop = ctx.stop;\n\t\t// copy any error nodes to alt label node\n\t\tif(ctx.children) {\n\t\t\tthis.children = [];\n\t\t\t// reset parent pointer for any error nodes\n\t\t\tctx.children.map(function(child) {\n\t\t\t\tif (child instanceof ErrorNodeImpl) {\n\t\t\t\t\tthis.children.push(child);\n\t\t\t\t\tchild.parentCtx = this;\n\t\t\t\t}\n\t\t\t}, this);\n\t\t}\n\t}\n\n\t// Double dispatch methods for listeners\n\tenterRule(listener) {\n\t}\n\n\texitRule(listener) {\n\t}\n\n\t// Does not set parent link; other add methods do that\n\taddChild(child) {\n\t\tif (this.children === null) {\n\t\t\tthis.children = [];\n\t\t}\n\t\tthis.children.push(child);\n\t\treturn child;\n\t}\n\n\t/** Used by enterOuterAlt to toss out a RuleContext previously added as\n\t * we entered a rule. If we have // label, we will need to remove\n\t * generic ruleContext object.\n\t */\n\tremoveLastChild() {\n\t\tif (this.children !== null) {\n\t\t\tthis.children.pop();\n\t\t}\n\t}\n\n\taddTokenNode(token) {\n\t\tconst node = new TerminalNodeImpl(token);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\taddErrorNode(badToken) {\n\t\tconst node = new ErrorNodeImpl(badToken);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\tgetChild(i, type) {\n\t\ttype = type || null;\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tif (type === null) {\n\t\t\treturn this.children[i];\n\t\t} else {\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif(child instanceof type) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tgetToken(ttype, i) {\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\tconst child = this.children[j];\n\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}\n\n\tgetTokens(ttype ) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst tokens = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\t\ttokens.push(child);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn tokens;\n\t\t}\n\t}\n\n\tgetTypedRuleContext(ctxType, i) {\n\t\treturn this.getChild(i, ctxType);\n\t}\n\n\tgetTypedRuleContexts(ctxType) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst contexts = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof ctxType) {\n\t\t\t\t\tcontexts.push(child);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn contexts;\n\t\t}\n\t}\n\n\tgetChildCount() {\n\t\tif (this.children=== null) {\n\t\t\treturn 0;\n\t\t} else {\n\t\t\treturn this.children.length;\n\t\t}\n\t}\n\n\tgetSourceInterval() {\n\t\tif( this.start === null || this.stop === null) {\n\t\t\treturn INVALID_INTERVAL;\n\t\t} else {\n\t\t\treturn new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n\t\t}\n\t}\n}\n\nRuleContext.EMPTY = new ParserRuleContext();\n\nclass InterpreterRuleContext extends ParserRuleContext {\n\tconstructor(parent, invokingStateNumber, ruleIndex) {\n\t\tsuper(parent, invokingStateNumber);\n\t\tthis.ruleIndex = ruleIndex;\n\t}\n}\n\nmodule.exports = ParserRuleContext;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst RuleContext = require('./RuleContext');\nconst {Hash, Map, equalArrays} = require('./Utils');\n\nclass PredictionContext {\n\n\tconstructor(cachedHashCode) {\n\t\tthis.cachedHashCode = cachedHashCode;\n\t}\n\n\t/**\n\t * Stores the computed hash code of this {@link PredictionContext}. The hash\n\t * code is computed in parts to match the following reference algorithm.\n\t *\n\t * <pre>\n\t * private int referenceHashCode() {\n\t * int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n\t * //INITIAL_HASH});\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n\t * getParent}(i));\n\t * }\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n\t * //getReturnState getReturnState}(i));\n\t * }\n\t *\n\t * hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n\t * //size()});\n\t * return hash;\n\t * }\n\t * </pre>\n\t * This means only the {@link //EMPTY} context is in set.\n\t */\n\tisEmpty() {\n\t\treturn this === PredictionContext.EMPTY;\n\t}\n\n\thasEmptyPath() {\n\t\treturn this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n}\n\n/**\n * Represents {@code $} in local context prediction, which means wildcard.\n * {@code//+x =//}.\n */\nPredictionContext.EMPTY = null;\n\n/**\n * Represents {@code $} in an array in full context mode, when {@code $}\n * doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n * {@code $} = {@link //EMPTY_RETURN_STATE}.\n */\nPredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;\n\nPredictionContext.globalNodeCount = 1;\nPredictionContext.id = PredictionContext.globalNodeCount;\n\n\n/*\nfunction calculateHashString(parent, returnState) {\n\treturn \"\" + parent + returnState;\n}\n*/\n\n/**\n * Used to cache {@link PredictionContext} objects. Its used for the shared\n * context cash associated with contexts in DFA states. This cache\n * can be used for both lexers and parsers.\n */\nclass PredictionContextCache {\n\n\tconstructor() {\n\t\tthis.cache = new Map();\n\t}\n\n\t/**\n\t * Add a context to the cache and return it. If the context already exists,\n\t * return that one instead and do not add a new context to the cache.\n\t * Protect shared cache from unsafe thread access.\n\t */\n\tadd(ctx) {\n\t\tif (ctx === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY;\n\t\t}\n\t\tconst existing = this.cache.get(ctx) || null;\n\t\tif (existing !== null) {\n\t\t\treturn existing;\n\t\t}\n\t\tthis.cache.put(ctx, ctx);\n\t\treturn ctx;\n\t}\n\n\tget(ctx) {\n\t\treturn this.cache.get(ctx) || null;\n\t}\n\n\tget length(){\n\t\treturn this.cache.length;\n\t}\n}\n\n\nclass SingletonPredictionContext extends PredictionContext {\n\n\tconstructor(parent, returnState) {\n\t\tlet hashCode = 0;\n\t\tconst hash = new Hash();\n\t\tif(parent !== null) {\n\t\t\thash.update(parent, returnState);\n\t\t} else {\n\t\t\thash.update(1);\n\t\t}\n\t\thashCode = hash.finish();\n\t\tsuper(hashCode);\n\t\tthis.parentCtx = parent;\n\t\tthis.returnState = returnState;\n\t}\n\n\tgetParent(index) {\n\t\treturn this.parentCtx;\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnState;\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof SingletonPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashCode() !== other.hashCode()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\tif(this.returnState !== other.returnState)\n\t\t\t\treturn false;\n\t\t\telse if(this.parentCtx==null)\n\t\t\t\treturn other.parentCtx==null\n\t\t\telse\n\t\t\t\treturn this.parentCtx.equals(other.parentCtx);\n\t\t}\n\t}\n\n\ttoString() {\n\t\tconst up = this.parentCtx === null ? \"\" : this.parentCtx.toString();\n\t\tif (up.length === 0) {\n\t\t\tif (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\treturn \"$\";\n\t\t\t} else {\n\t\t\t\treturn \"\" + this.returnState;\n\t\t\t}\n\t\t} else {\n\t\t\treturn \"\" + this.returnState + \" \" + up;\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn 1;\n\t}\n\n\tstatic create(parent, returnState) {\n\t\tif (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n\t\t\t// someone can pass in the bits of an array ctx that mean $\n\t\t\treturn PredictionContext.EMPTY;\n\t\t} else {\n\t\t\treturn new SingletonPredictionContext(parent, returnState);\n\t\t}\n\t}\n}\n\nclass EmptyPredictionContext extends SingletonPredictionContext {\n\n\tconstructor() {\n\t\tsuper(null, PredictionContext.EMPTY_RETURN_STATE);\n\t}\n\n\tisEmpty() {\n\t\treturn true;\n\t}\n\n\tgetParent(index) {\n\t\treturn null;\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnState;\n\t}\n\n\tequals(other) {\n\t\treturn this === other;\n\t}\n\n\ttoString() {\n\t\treturn \"$\";\n\t}\n}\n\n\nPredictionContext.EMPTY = new EmptyPredictionContext();\n\nclass ArrayPredictionContext extends PredictionContext {\n\n\tconstructor(parents, returnStates) {\n\t\t/**\n\t\t * Parent can be null only if full ctx mode and we make an array\n\t\t * from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n\t\t * null parent and\n\t\t * returnState == {@link //EMPTY_RETURN_STATE}.\n\t\t */\n\t\tconst h = new Hash();\n\t\th.update(parents, returnStates);\n\t\tconst hashCode = h.finish();\n\t\tsuper(hashCode);\n\t\tthis.parents = parents;\n\t\tthis.returnStates = returnStates;\n\t\treturn this;\n\t}\n\n\tisEmpty() {\n\t\t// since EMPTY_RETURN_STATE can only appear in the last position, we\n\t\t// don't need to verify that size==1\n\t\treturn this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n\t}\n\n\tgetParent(index) {\n\t\treturn this.parents[index];\n\t}\n\n\tgetReturnState(index) {\n\t\treturn this.returnStates[index];\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof ArrayPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashCode() !== other.hashCode()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\treturn equalArrays(this.returnStates, other.returnStates) &&\n\t\t\t\tequalArrays(this.parents, other.parents);\n\t\t}\n\t}\n\n\ttoString() {\n\t\tif (this.isEmpty()) {\n\t\t\treturn \"[]\";\n\t\t} else {\n\t\t\tlet s = \"[\";\n\t\t\tfor (let i = 0; i < this.returnStates.length; i++) {\n\t\t\t\tif (i > 0) {\n\t\t\t\t\ts = s + \", \";\n\t\t\t\t}\n\t\t\t\tif (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\ts = s + \"$\";\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\ts = s + this.returnStates[i];\n\t\t\t\tif (this.parents[i] !== null) {\n\t\t\t\t\ts = s + \" \" + this.parents[i];\n\t\t\t\t} else {\n\t\t\t\t\ts = s + \"null\";\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn s + \"]\";\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.returnStates.length;\n\t}\n}\n\n\n/**\n * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n * Return {@link //EMPTY} if {@code outerContext} is empty or null.\n */\nfunction predictionContextFromRuleContext(atn, outerContext) {\n\tif (outerContext === undefined || outerContext === null) {\n\t\touterContext = RuleContext.EMPTY;\n\t}\n\t// if we are in RuleContext of start rule, s, then PredictionContext\n\t// is EMPTY. Nobody called us. (if we are empty, return empty)\n\tif (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n\t\treturn PredictionContext.EMPTY;\n\t}\n\t// If we have a parent, convert it to a PredictionContext graph\n\tconst parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n\tconst state = atn.states[outerContext.invokingState];\n\tconst transition = state.transitions[0];\n\treturn SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}\n/*\nfunction calculateListsHashString(parents, returnStates) {\n\tconst s = \"\";\n\tparents.map(function(p) {\n\t\ts = s + p;\n\t});\n\treturnStates.map(function(r) {\n\t\ts = s + r;\n\t});\n\treturn s;\n}\n*/\nfunction merge(a, b, rootIsWildcard, mergeCache) {\n\t// share same graph if both same\n\tif (a === b) {\n\t\treturn a;\n\t}\n\tif (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\treturn mergeSingletons(a, b, rootIsWildcard, mergeCache);\n\t}\n\t// At least one of a or b is array\n\t// If one is $ and rootIsWildcard, return $ as// wildcard\n\tif (rootIsWildcard) {\n\t\tif (a instanceof EmptyPredictionContext) {\n\t\t\treturn a;\n\t\t}\n\t\tif (b instanceof EmptyPredictionContext) {\n\t\t\treturn b;\n\t\t}\n\t}\n\t// convert singleton so both are arrays to normalize\n\tif (a instanceof SingletonPredictionContext) {\n\t\ta = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n\t}\n\tif (b instanceof SingletonPredictionContext) {\n\t\tb = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n\t}\n\treturn mergeArrays(a, b, rootIsWildcard, mergeCache);\n}\n\n/**\n * Merge two {@link SingletonPredictionContext} instances.\n *\n * <p>Stack tops equal, parents merge is same; return left graph.<br>\n * <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Same stack top, parents differ; merge parents giving array node, then\n * remainders of those graphs. A new root node is created to point to the\n * merged parents.<br>\n * <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to same parent. Make array node for the\n * root where both element in the root point to the same (original)\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to different parents. Make array node for\n * the root where each element points to the corresponding original\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n * @param mergeCache\n */\nfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tlet previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\n\tconst rootMerge = mergeRoot(a, b, rootIsWildcard);\n\tif (rootMerge !== null) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, rootMerge);\n\t\t}\n\t\treturn rootMerge;\n\t}\n\tif (a.returnState === b.returnState) {\n\t\tconst parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n\t\t// if parent is same as existing a or b parent or reduced to a parent,\n\t\t// return it\n\t\tif (parent === a.parentCtx) {\n\t\t\treturn a; // ax + bx = ax, if a=b\n\t\t}\n\t\tif (parent === b.parentCtx) {\n\t\t\treturn b; // ax + bx = bx, if a=b\n\t\t}\n\t\t// else: ax + ay = a'[x,y]\n\t\t// merge parents x and y, giving array node with x,y then remainders\n\t\t// of those graphs. dup a, a' points at merged array\n\t\t// new joined parent so create new singleton pointing to it, a'\n\t\tconst spc = SingletonPredictionContext.create(parent, a.returnState);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, spc);\n\t\t}\n\t\treturn spc;\n\t} else { // a != b payloads differ\n\t\t// see if we can collapse parents due to $+x parents if local ctx\n\t\tlet singleParent = null;\n\t\tif (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// bx =\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// [a,b]x\n\t\t\tsingleParent = a.parentCtx;\n\t\t}\n\t\tif (singleParent !== null) { // parents are same\n\t\t\t// sort payloads and use same parent\n\t\t\tconst payloads = [ a.returnState, b.returnState ];\n\t\t\tif (a.returnState > b.returnState) {\n\t\t\t\tpayloads[0] = b.returnState;\n\t\t\t\tpayloads[1] = a.returnState;\n\t\t\t}\n\t\t\tconst parents = [ singleParent, singleParent ];\n\t\t\tconst apc = new ArrayPredictionContext(parents, payloads);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, apc);\n\t\t\t}\n\t\t\treturn apc;\n\t\t}\n\t\t// parents differ and can't merge them. Just pack together\n\t\t// into array; can't merge.\n\t\t// ax + by = [ax,by]\n\t\tconst payloads = [ a.returnState, b.returnState ];\n\t\tlet parents = [ a.parentCtx, b.parentCtx ];\n\t\tif (a.returnState > b.returnState) { // sort by payload\n\t\t\tpayloads[0] = b.returnState;\n\t\t\tpayloads[1] = a.returnState;\n\t\t\tparents = [ b.parentCtx, a.parentCtx ];\n\t\t}\n\t\tconst a_ = new ArrayPredictionContext(parents, payloads);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a_);\n\t\t}\n\t\treturn a_;\n\t}\n}\n\n/**\n * Handle case where at least one of {@code a} or {@code b} is\n * {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n * to represent {@link //EMPTY}.\n *\n * <h2>Local-Context Merges</h2>\n *\n * <p>These local-context merge operations are used when {@code rootIsWildcard}\n * is true.</p>\n *\n * <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n * <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n * {@code //EMPTY}; return left graph.<br>\n * <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Special case of last merge if local context.<br>\n * <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <h2>Full-Context Merges</h2>\n *\n * <p>These full-context merge operations are used when {@code rootIsWildcard}\n * is false.</p>\n *\n * <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n * null parent).<br>\n * <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n */\nfunction mergeRoot(a, b, rootIsWildcard) {\n\tif (rootIsWildcard) {\n\t\tif (a === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // // + b =//\n\t\t}\n\t\tif (b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // a +// =//\n\t\t}\n\t} else {\n\t\tif (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // $ + $ = $\n\t\t} else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]\n\t\t\tconst payloads = [ b.returnState,\n\t\t\t\t\tPredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tconst parents = [ b.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t} else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)\n\t\t\tconst payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tconst parents = [ a.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t}\n\t}\n\treturn null;\n}\n\n/**\n * Merge two {@link ArrayPredictionContext} instances.\n *\n * <p>Different tops, different parents.<br>\n * <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, same parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, different parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, all shared parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Equal tops, merge parents and reduce top to\n * {@link SingletonPredictionContext}.<br>\n * <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n */\nfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tlet previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\t// merge sorted payloads a + b => M\n\tlet i = 0; // walks a\n\tlet j = 0; // walks b\n\tlet k = 0; // walks target M array\n\n\tlet mergedReturnStates = [];\n\tlet mergedParents = [];\n\t// walk and merge to yield mergedParents, mergedReturnStates\n\twhile (i < a.returnStates.length && j < b.returnStates.length) {\n\t\tconst a_parent = a.parents[i];\n\t\tconst b_parent = b.parents[j];\n\t\tif (a.returnStates[i] === b.returnStates[j]) {\n\t\t\t// same payload (stack tops are equal), must yield merged singleton\n\t\t\tconst payload = a.returnStates[i];\n\t\t\t// $+$ = $\n\t\t\tconst bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&\n\t\t\t\t\ta_parent === null && b_parent === null;\n\t\t\tconst ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ->\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ax\n\t\t\tif (bothDollars || ax_ax) {\n\t\t\t\tmergedParents[k] = a_parent; // choose left\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t} else { // ax+ay -> a'[x,y]\n\t\t\t\tmergedParents[k] = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t}\n\t\t\ti += 1; // hop over left one as usual\n\t\t\tj += 1; // but also skip one in right side since we merge\n\t\t} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M\n\t\t\tmergedParents[k] = a_parent;\n\t\t\tmergedReturnStates[k] = a.returnStates[i];\n\t\t\ti += 1;\n\t\t} else { // b > a, copy b[j] to M\n\t\t\tmergedParents[k] = b_parent;\n\t\t\tmergedReturnStates[k] = b.returnStates[j];\n\t\t\tj += 1;\n\t\t}\n\t\tk += 1;\n\t}\n\t// copy over any payloads remaining in either array\n\tif (i < a.returnStates.length) {\n\t\tfor (let p = i; p < a.returnStates.length; p++) {\n\t\t\tmergedParents[k] = a.parents[p];\n\t\t\tmergedReturnStates[k] = a.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t} else {\n\t\tfor (let p = j; p < b.returnStates.length; p++) {\n\t\t\tmergedParents[k] = b.parents[p];\n\t\t\tmergedReturnStates[k] = b.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t}\n\t// trim merged if we combined a few that had same stack tops\n\tif (k < mergedParents.length) { // write index < last position; trim\n\t\tif (k === 1) { // for just one merged element, return singleton top\n\t\t\tconst a_ = SingletonPredictionContext.create(mergedParents[0],\n\t\t\t\t\tmergedReturnStates[0]);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, a_);\n\t\t\t}\n\t\t\treturn a_;\n\t\t}\n\t\tmergedParents = mergedParents.slice(0, k);\n\t\tmergedReturnStates = mergedReturnStates.slice(0, k);\n\t}\n\n\tconst M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\n\t// if we created same array as a or b, return that instead\n\t// TODO: track whether this is possible above during merge sort for speed\n\tif (M === a) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a);\n\t\t}\n\t\treturn a;\n\t}\n\tif (M === b) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, b);\n\t\t}\n\t\treturn b;\n\t}\n\tcombineCommonParents(mergedParents);\n\n\tif (mergeCache !== null) {\n\t\tmergeCache.set(a, b, M);\n\t}\n\treturn M;\n}\n\n/**\n * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n * ones.\n */\nfunction combineCommonParents(parents) {\n\tconst uniqueParents = new Map();\n\n\tfor (let p = 0; p < parents.length; p++) {\n\t\tconst parent = parents[p];\n\t\tif (!(uniqueParents.containsKey(parent))) {\n\t\t\tuniqueParents.put(parent, parent);\n\t\t}\n\t}\n\tfor (let q = 0; q < parents.length; q++) {\n\t\tparents[q] = uniqueParents.get(parents[q]);\n\t}\n}\n\nfunction getCachedPredictionContext(context, contextCache, visited) {\n\tif (context.isEmpty()) {\n\t\treturn context;\n\t}\n\tlet existing = visited.get(context) || null;\n\tif (existing !== null) {\n\t\treturn existing;\n\t}\n\texisting = contextCache.get(context);\n\tif (existing !== null) {\n\t\tvisited.put(context, existing);\n\t\treturn existing;\n\t}\n\tlet changed = false;\n\tlet parents = [];\n\tfor (let i = 0; i < parents.length; i++) {\n\t\tconst parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n\t\tif (changed || parent !== context.getParent(i)) {\n\t\t\tif (!changed) {\n\t\t\t\tparents = [];\n\t\t\t\tfor (let j = 0; j < context.length; j++) {\n\t\t\t\t\tparents[j] = context.getParent(j);\n\t\t\t\t}\n\t\t\t\tchanged = true;\n\t\t\t}\n\t\t\tparents[i] = parent;\n\t\t}\n\t}\n\tif (!changed) {\n\t\tcontextCache.add(context);\n\t\tvisited.put(context, context);\n\t\treturn context;\n\t}\n\tlet updated = null;\n\tif (parents.length === 0) {\n\t\tupdated = PredictionContext.EMPTY;\n\t} else if (parents.length === 1) {\n\t\tupdated = SingletonPredictionContext.create(parents[0], context\n\t\t\t\t.getReturnState(0));\n\t} else {\n\t\tupdated = new ArrayPredictionContext(parents, context.returnStates);\n\t}\n\tcontextCache.add(updated);\n\tvisited.put(updated, updated);\n\tvisited.put(context, updated);\n\n\treturn updated;\n}\n\n// ter's recursive version of Sam's getAllNodes()\nfunction getAllContextNodes(context, nodes, visited) {\n\tif (nodes === null) {\n\t\tnodes = [];\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else if (visited === null) {\n\t\tvisited = new Map();\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else {\n\t\tif (context === null || visited.containsKey(context)) {\n\t\t\treturn nodes;\n\t\t}\n\t\tvisited.put(context, context);\n\t\tnodes.push(context);\n\t\tfor (let i = 0; i < context.length; i++) {\n\t\t\tgetAllContextNodes(context.getParent(i), nodes, visited);\n\t\t}\n\t\treturn nodes;\n\t}\n}\n\nmodule.exports = {\n\tmerge,\n\tPredictionContext,\n\tPredictionContextCache,\n\tSingletonPredictionContext,\n\tpredictionContextFromRuleContext,\n\tgetCachedPredictionContext\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst {ConsoleErrorListener} = require('./error/ErrorListener');\nconst {ProxyErrorListener} = require('./error/ErrorListener');\n\nclass Recognizer {\n    constructor() {\n        this._listeners = [ ConsoleErrorListener.INSTANCE ];\n        this._interp = null;\n        this._stateNumber = -1;\n    }\n\n    checkVersion(toolVersion) {\n        const runtimeVersion = \"4.9.3\";\n        if (runtimeVersion!==toolVersion) {\n            console.log(\"ANTLR runtime and generated code versions disagree: \"+runtimeVersion+\"!=\"+toolVersion);\n        }\n    }\n\n    addErrorListener(listener) {\n        this._listeners.push(listener);\n    }\n\n    removeErrorListeners() {\n        this._listeners = [];\n    }\n\n    getLiteralNames() {\n        return Object.getPrototypeOf(this).constructor.literalNames || [];\n    }\n\n    getSymbolicNames() {\n        return Object.getPrototypeOf(this).constructor.symbolicNames || [];\n    }\n\n    getTokenNames() {\n        if(!this.tokenNames) {\n            const literalNames = this.getLiteralNames();\n            const symbolicNames = this.getSymbolicNames();\n            const length = literalNames.length > symbolicNames.length ? literalNames.length : symbolicNames.length;\n            this.tokenNames = [];\n            for(let i=0; i<length; i++) {\n                this.tokenNames[i] = literalNames[i] || symbolicNames[i] || \"<INVALID\";\n            }\n        }\n        return this.tokenNames;\n    }\n\n    getTokenTypeMap() {\n        const tokenNames = this.getTokenNames();\n        if (tokenNames===null) {\n            throw(\"The current recognizer does not provide a list of token names.\");\n        }\n        let result = this.tokenTypeMapCache[tokenNames];\n        if(result===undefined) {\n            result = tokenNames.reduce(function(o, k, i) { o[k] = i; });\n            result.EOF = Token.EOF;\n            this.tokenTypeMapCache[tokenNames] = result;\n        }\n        return result;\n    }\n\n    /**\n     * Get a map from rule names to rule indexes.\n     * <p>Used for XPath and tree pattern compilation.</p>\n     */\n    getRuleIndexMap() {\n        const ruleNames = this.ruleNames;\n        if (ruleNames===null) {\n            throw(\"The current recognizer does not provide a list of rule names.\");\n        }\n        let result = this.ruleIndexMapCache[ruleNames]; // todo: should it be Recognizer.ruleIndexMapCache ?\n        if(result===undefined) {\n            result = ruleNames.reduce(function(o, k, i) { o[k] = i; });\n            this.ruleIndexMapCache[ruleNames] = result;\n        }\n        return result;\n    }\n\n    getTokenType(tokenName) {\n        const ttype = this.getTokenTypeMap()[tokenName];\n        if (ttype !==undefined) {\n            return ttype;\n        } else {\n            return Token.INVALID_TYPE;\n        }\n    }\n\n    // What is the error header, normally line/character position information?\n    getErrorHeader(e) {\n        const line = e.getOffendingToken().line;\n        const column = e.getOffendingToken().column;\n        return \"line \" + line + \":\" + column;\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out.  Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     *\n     * @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n     * implementations of {@link ANTLRErrorStrategy} may provide a similar\n     * feature when necessary. For example, see\n     * {@link DefaultErrorStrategy//getTokenErrorDisplay}.*/\n    getTokenErrorDisplay(t) {\n        if (t===null) {\n            return \"<no token>\";\n        }\n        let s = t.text;\n        if (s===null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        s = s.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    getErrorListenerDispatch() {\n        return new ProxyErrorListener(this._listeners);\n    }\n\n    /**\n     * subclass needs to override these if there are sempreds or actions\n     * that the ATN interp needs to execute\n     */\n    sempred(localctx, ruleIndex, actionIndex) {\n        return true;\n    }\n\n    precpred(localctx , precedence) {\n        return true;\n    }\n\n    get state(){\n        return this._stateNumber;\n    }\n\n    set state(state) {\n        this._stateNumber = state;\n    }\n}\n\nRecognizer.tokenTypeMapCache = {};\nRecognizer.ruleIndexMapCache = {};\n\nmodule.exports = Recognizer;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {RuleNode} = require('./tree/Tree');\nconst {INVALID_INTERVAL} = require('./tree/Tree');\nconst Trees = require('./tree/Trees');\n\nclass RuleContext extends RuleNode {\n\t/** A rule context is a record of a single rule invocation. It knows\n\t * which context invoked it, if any. If there is no parent context, then\n\t * naturally the invoking state is not valid.  The parent link\n\t * provides a chain upwards from the current rule invocation to the root\n\t * of the invocation tree, forming a stack. We actually carry no\n\t * information about the rule associated with this context (except\n\t * when parsing). We keep only the state number of the invoking state from\n\t * the ATN submachine that invoked this. Contrast this with the s\n\t * pointer inside ParserRuleContext that tracks the current state\n\t * being \"executed\" for the current rule.\n\t *\n\t * The parent contexts are useful for computing lookahead sets and\n\t * getting error information.\n\t *\n\t * These objects are used during parsing and prediction.\n\t * For the special case of parsers, we use the subclass\n\t * ParserRuleContext.\n\t *\n\t * @see ParserRuleContext\n\t */\n\tconstructor(parent, invokingState) {\n\t\t// What context invoked this rule?\n\t\tsuper();\n\t\tthis.parentCtx = parent || null;\n\t\t/**\n\t\t * What state invoked the rule associated with this context?\n\t\t * The \"return address\" is the followState of invokingState\n\t\t * If parent is null, this should be -1.\n\t\t */\n\t\tthis.invokingState = invokingState || -1;\n\t}\n\n\tdepth() {\n\t\tlet n = 0;\n\t\tlet p = this;\n\t\twhile (p !== null) {\n\t\t\tp = p.parentCtx;\n\t\t\tn += 1;\n\t\t}\n\t\treturn n;\n\t}\n\n\t/**\n\t * A context is empty if there is no invoking state; meaning nobody call\n\t * current context.\n\t */\n\tisEmpty() {\n\t\treturn this.invokingState === -1;\n\t}\n\n// satisfy the ParseTree / SyntaxTree interface\n\tgetSourceInterval() {\n\t\treturn INVALID_INTERVAL;\n\t}\n\n\tgetRuleContext() {\n\t\treturn this;\n\t}\n\n\tgetPayload() {\n\t\treturn this;\n\t}\n\n\t/**\n\t * Return the combined text of all child nodes. This method only considers\n\t * tokens which have been added to the parse tree.\n\t * <p>\n\t * Since tokens on hidden channels (e.g. whitespace or comments) are not\n\t * added to the parse trees, they will not appear in the output of this\n\t * method.\n\t */\n\tgetText() {\n\t\tif (this.getChildCount() === 0) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\treturn this.children.map(function(child) {\n\t\t\t\treturn child.getText();\n\t\t\t}).join(\"\");\n\t\t}\n\t}\n\n\t/**\n\t * For rule associated with this parse tree internal node, return\n\t * the outer alternative number used to match the input. Default\n\t * implementation does not compute nor store this alt num. Create\n\t * a subclass of ParserRuleContext with backing field and set\n\t * option contextSuperClass.\n\t * to set it.\n\t */\n\tgetAltNumber() {\n\t    // use constant value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n\t    return 0;\n    }\n\n\t/**\n\t * Set the outer alternative number for this context node. Default\n\t * implementation does nothing to avoid backing field overhead for\n\t * trees that don't need it.  Create\n\t * a subclass of ParserRuleContext with backing field and set\n\t * option contextSuperClass.\n\t */\n\tsetAltNumber(altNumber) { }\n\n\tgetChild(i) {\n\t\treturn null;\n\t}\n\n\tgetChildCount() {\n\t\treturn 0;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitChildren(this);\n\t}\n\n\t/**\n\t * Print out a whole tree, not just a node, in LISP format\n\t * (root child1 .. childN). Print just a node if this is a leaf.\n\t */\n\ttoStringTree(ruleNames, recog) {\n\t\treturn Trees.toStringTree(this, ruleNames, recog);\n\t}\n\n\ttoString(ruleNames, stop) {\n\t\truleNames = ruleNames || null;\n\t\tstop = stop || null;\n\t\tlet p = this;\n\t\tlet s = \"[\";\n\t\twhile (p !== null && p !== stop) {\n\t\t\tif (ruleNames === null) {\n\t\t\t\tif (!p.isEmpty()) {\n\t\t\t\t\ts += p.invokingState;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst ri = p.ruleIndex;\n\t\t\t\tconst ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]\n\t\t\t\t\t\t: \"\" + ri;\n\t\t\t\ts += ruleName;\n\t\t\t}\n\t\t\tif (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n\t\t\t\ts += \" \";\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\ts += \"]\";\n\t\treturn s;\n\t}\n}\n\nmodule.exports = RuleContext;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * A token has properties: text, type, line, character position in the line\n * (so we can ignore tabs), token channel, index, and source from which\n * we obtained this token.\n */\nclass Token {\n\tconstructor() {\n\t\tthis.source = null;\n\t\tthis.type = null; // token type of the token\n\t\tthis.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n\t\tthis.start = null; // optional; return -1 if not implemented.\n\t\tthis.stop = null; // optional; return -1 if not implemented.\n\t\tthis.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n\t\tthis.line = null; // line=1..n of the 1st character\n\t\tthis.column = null; // beginning of the line at which it occurs, 0..n-1\n\t\tthis._text = null; // text of the token.\n\t}\n\n\tgetTokenSource() {\n\t\treturn this.source[0];\n\t}\n\n\tgetInputStream() {\n\t\treturn this.source[1];\n\t}\n\n\tget text(){\n\t\treturn this._text;\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\nToken.INVALID_TYPE = 0;\n\n/**\n * During lookahead operations, this \"token\" signifies we hit rule end ATN state\n * and did not follow it despite needing to.\n */\nToken.EPSILON = -2;\n\nToken.MIN_USER_TOKEN_TYPE = 1;\n\nToken.EOF = -1;\n\n/**\n * All tokens go to the parser (unless skip() is called in that rule)\n * on a particular \"channel\". The parser tunes to a particular channel\n * so that whitespace etc... can go to the parser on a \"hidden\" channel.\n */\nToken.DEFAULT_CHANNEL = 0;\n\n/**\n * Anything on different channel than DEFAULT_CHANNEL is not parsed\n * by parser.\n */\nToken.HIDDEN_CHANNEL = 1;\n\n\nclass CommonToken extends Token {\n\tconstructor(source, type, channel, start, stop) {\n\t\tsuper();\n\t\tthis.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n\t\tthis.type = type !== undefined ? type : null;\n\t\tthis.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n\t\tthis.start = start !== undefined ? start : -1;\n\t\tthis.stop = stop !== undefined ? stop : -1;\n\t\tthis.tokenIndex = -1;\n\t\tif (this.source[0] !== null) {\n\t\t\tthis.line = source[0].line;\n\t\t\tthis.column = source[0].column;\n\t\t} else {\n\t\t\tthis.column = -1;\n\t\t}\n\t}\n\n\t/**\n\t * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n\t *\n\t * <p>\n\t * If {@code oldToken} is also a {@link CommonToken} instance, the newly\n\t * constructed token will share a reference to the {@link //text} field and\n\t * the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n\t * be assigned the result of calling {@link //getText}, and {@link //source}\n\t * will be constructed from the result of {@link Token//getTokenSource} and\n\t * {@link Token//getInputStream}.</p>\n\t *\n\t * @param oldToken The token to copy.\n\t */\n\tclone() {\n\t\tconst t = new CommonToken(this.source, this.type, this.channel, this.start, this.stop);\n\t\tt.tokenIndex = this.tokenIndex;\n\t\tt.line = this.line;\n\t\tt.column = this.column;\n\t\tt.text = this.text;\n\t\treturn t;\n\t}\n\n\ttoString() {\n\t\tlet txt = this.text;\n\t\tif (txt !== null) {\n\t\t\ttxt = txt.replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\").replace(/\\t/g, \"\\\\t\");\n\t\t} else {\n\t\t\ttxt = \"<no text>\";\n\t\t}\n\t\treturn \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" +\n\t\t\t\ttxt + \"',<\" + this.type + \">\" +\n\t\t\t\t(this.channel > 0 ? \",channel=\" + this.channel : \"\") + \",\" +\n\t\t\t\tthis.line + \":\" + this.column + \"]\";\n\t}\n\n\tget text(){\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t}\n\t\tconst input = this.getInputStream();\n\t\tif (input === null) {\n\t\t\treturn null;\n\t\t}\n\t\tconst n = input.size;\n\t\tif (this.start < n && this.stop < n) {\n\t\t\treturn input.getText(this.start, this.stop);\n\t\t} else {\n\t\t\treturn \"<EOF>\";\n\t\t}\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\n/**\n * An empty {@link Pair} which is used as the default value of\n * {@link //source} for tokens that do not have a source.\n */\nCommonToken.EMPTY_SOURCE = [ null, null ];\n\nmodule.exports = {\n\tToken,\n\tCommonToken\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nfunction valueToString(v) {\n    return v === null ? \"null\" : v;\n}\n\nfunction arrayToString(a) {\n    return Array.isArray(a) ? (\"[\" + a.map(valueToString).join(\", \") + \"]\") : \"null\";\n}\n\nString.prototype.seed = String.prototype.seed || Math.round(Math.random() * Math.pow(2, 32));\n\nString.prototype.hashCode = function () {\n    const key = this.toString();\n    let h1b, k1;\n\n    const remainder = key.length & 3; // key.length % 4\n    const bytes = key.length - remainder;\n    let h1 = String.prototype.seed;\n    const c1 = 0xcc9e2d51;\n    const c2 = 0x1b873593;\n    let i = 0;\n\n    while (i < bytes) {\n        k1 =\n            ((key.charCodeAt(i) & 0xff)) |\n            ((key.charCodeAt(++i) & 0xff) << 8) |\n            ((key.charCodeAt(++i) & 0xff) << 16) |\n            ((key.charCodeAt(++i) & 0xff) << 24);\n        ++i;\n\n        k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;\n        k1 = (k1 << 15) | (k1 >>> 17);\n        k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;\n\n        h1 ^= k1;\n        h1 = (h1 << 13) | (h1 >>> 19);\n        h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;\n        h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));\n    }\n\n    k1 = 0;\n\n    switch (remainder) {\n        case 3:\n            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n        case 2:\n            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n        case 1:\n            k1 ^= (key.charCodeAt(i) & 0xff);\n\n            k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n            k1 = (k1 << 15) | (k1 >>> 17);\n            k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n            h1 ^= k1;\n    }\n\n    h1 ^= key.length;\n\n    h1 ^= h1 >>> 16;\n    h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;\n    h1 ^= h1 >>> 13;\n    h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;\n    h1 ^= h1 >>> 16;\n\n    return h1 >>> 0;\n};\n\nfunction standardEqualsFunction(a, b) {\n    return a ? a.equals(b) : a==b;\n}\n\nfunction standardHashCodeFunction(a) {\n    return a ? a.hashCode() : -1;\n}\n\nclass Set {\n    constructor(hashFunction, equalsFunction) {\n        this.data = {};\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    add(value) {\n        const hash = this.hashFunction(value);\n        const key = \"hash_\" + hash;\n        if (key in this.data) {\n            const values = this.data[key];\n            for (let i = 0; i < values.length; i++) {\n                if (this.equalsFunction(value, values[i])) {\n                    return values[i];\n                }\n            }\n            values.push(value);\n            return value;\n        } else {\n            this.data[key] = [value];\n            return value;\n        }\n    }\n\n    contains(value) {\n        return this.get(value) != null;\n    }\n\n    get(value) {\n        const hash = this.hashFunction(value);\n        const key = \"hash_\" + hash;\n        if (key in this.data) {\n            const values = this.data[key];\n            for (let i = 0; i < values.length; i++) {\n                if (this.equalsFunction(value, values[i])) {\n                    return values[i];\n                }\n            }\n        }\n        return null;\n    }\n\n    values() {\n        let l = [];\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l.concat(this.data[key]);\n            }\n        }\n        return l;\n    }\n\n    toString() {\n        return arrayToString(this.values());\n    }\n\n    get length(){\n        let l = 0;\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l + this.data[key].length;\n            }\n        }\n        return l;\n    }\n}\n\n\nclass BitSet {\n    constructor() {\n        this.data = [];\n    }\n\n    add(value) {\n        this.data[value] = true;\n    }\n\n    or(set) {\n        const bits = this;\n        Object.keys(set.data).map(function (alt) {\n            bits.add(alt);\n        });\n    }\n\n    remove(value) {\n        delete this.data[value];\n    }\n\n    contains(value) {\n        return this.data[value] === true;\n    }\n\n    values() {\n        return Object.keys(this.data);\n    }\n\n    minValue() {\n        return Math.min.apply(null, this.values());\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        hash.update(this.values());\n        return hash.finish();\n    }\n\n    equals(other) {\n        if (!(other instanceof BitSet)) {\n            return false;\n        }\n        return this.hashCode() === other.hashCode();\n    }\n\n    toString() {\n        return \"{\" + this.values().join(\", \") + \"}\";\n    }\n\n    get length(){\n        return this.values().length;\n    }\n}\n\n\nclass Map {\n    constructor(hashFunction, equalsFunction) {\n        this.data = {};\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    put(key, value) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if (hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key)) {\n                    const oldValue = entry.value;\n                    entry.value = value;\n                    return oldValue;\n                }\n            }\n            entries.push({key:key, value:value});\n            return value;\n        } else {\n            this.data[hashKey] = [{key:key, value:value}];\n            return value;\n        }\n    }\n\n    containsKey(key) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if(hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key))\n                    return true;\n            }\n        }\n        return false;\n    }\n\n    get(key) {\n        const hashKey = \"hash_\" + this.hashFunction(key);\n        if(hashKey in this.data) {\n            const entries = this.data[hashKey];\n            for (let i = 0; i < entries.length; i++) {\n                const entry = entries[i];\n                if (this.equalsFunction(key, entry.key))\n                    return entry.value;\n            }\n        }\n        return null;\n    }\n\n    entries() {\n        let l = [];\n        for (const key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l.concat(this.data[key]);\n            }\n        }\n        return l;\n    }\n\n    getKeys() {\n        return this.entries().map(function(e) {\n            return e.key;\n        });\n    }\n\n    getValues() {\n        return this.entries().map(function(e) {\n                return e.value;\n        });\n    }\n\n    toString() {\n        const ss = this.entries().map(function(entry) {\n            return '{' + entry.key + ':' + entry.value + '}';\n        });\n        return '[' + ss.join(\", \") + ']';\n    }\n\n    get length(){\n        let l = 0;\n        for (const hashKey in this.data) {\n            if (hashKey.indexOf(\"hash_\") === 0) {\n                l = l + this.data[hashKey].length;\n            }\n        }\n        return l;\n    }\n}\n\n\nclass AltDict {\n    constructor() {\n        this.data = {};\n    }\n\n    get(key) {\n        key = \"k-\" + key;\n        if (key in this.data) {\n            return this.data[key];\n        } else {\n            return null;\n        }\n    }\n\n    put(key, value) {\n        key = \"k-\" + key;\n        this.data[key] = value;\n    }\n\n    values() {\n        const data = this.data;\n        const keys = Object.keys(this.data);\n        return keys.map(function (key) {\n            return data[key];\n        });\n    }\n}\n\n\nclass DoubleDict {\n    constructor(defaultMapCtor) {\n        this.defaultMapCtor = defaultMapCtor || Map;\n        this.cacheMap = new this.defaultMapCtor();\n    }\n\n    get(a, b) {\n        const d = this.cacheMap.get(a) || null;\n        return d === null ? null : (d.get(b) || null);\n    }\n\n    set(a, b, o) {\n        let d = this.cacheMap.get(a) || null;\n        if (d === null) {\n            d = new this.defaultMapCtor();\n            this.cacheMap.put(a, d);\n        }\n        d.put(b, o);\n    }\n}\n\nclass Hash {\n    constructor() {\n        this.count = 0;\n        this.hash = 0;\n    }\n\n    update() {\n        for(let i=0;i<arguments.length;i++) {\n            const value = arguments[i];\n            if (value == null)\n                continue;\n            if(Array.isArray(value))\n                this.update.apply(this, value);\n            else {\n                let k = 0;\n                switch (typeof(value)) {\n                    case 'undefined':\n                    case 'function':\n                        continue;\n                    case 'number':\n                    case 'boolean':\n                        k = value;\n                        break;\n                    case 'string':\n                        k = value.hashCode();\n                        break;\n                    default:\n                        if(value.updateHashCode)\n                            value.updateHashCode(this);\n                        else\n                            console.log(\"No updateHashCode for \" + value.toString())\n                        continue;\n                }\n                k = k * 0xCC9E2D51;\n                k = (k << 15) | (k >>> (32 - 15));\n                k = k * 0x1B873593;\n                this.count = this.count + 1;\n                let hash = this.hash ^ k;\n                hash = (hash << 13) | (hash >>> (32 - 13));\n                hash = hash * 5 + 0xE6546B64;\n                this.hash = hash;\n            }\n        }\n    }\n\n    finish() {\n        let hash = this.hash ^ (this.count * 4);\n        hash = hash ^ (hash >>> 16);\n        hash = hash * 0x85EBCA6B;\n        hash = hash ^ (hash >>> 13);\n        hash = hash * 0xC2B2AE35;\n        hash = hash ^ (hash >>> 16);\n        return hash;\n    }\n}\n\nfunction hashStuff() {\n    const hash = new Hash();\n    hash.update.apply(hash, arguments);\n    return hash.finish();\n}\n\n\nfunction escapeWhitespace(s, escapeSpaces) {\n    s = s.replace(/\\t/g, \"\\\\t\")\n         .replace(/\\n/g, \"\\\\n\")\n         .replace(/\\r/g, \"\\\\r\");\n    if (escapeSpaces) {\n        s = s.replace(/ /g, \"\\u00B7\");\n    }\n    return s;\n}\n\nfunction titleCase(str) {\n    return str.replace(/\\w\\S*/g, function (txt) {\n        return txt.charAt(0).toUpperCase() + txt.substr(1);\n    });\n}\n\nfunction equalArrays(a, b) {\n    if (!Array.isArray(a) || !Array.isArray(b))\n        return false;\n    if (a === b)\n        return true;\n    if (a.length !== b.length)\n        return false;\n    for (let i = 0; i < a.length; i++) {\n        if (a[i] === b[i])\n            continue;\n        if (!a[i].equals || !a[i].equals(b[i]))\n            return false;\n    }\n    return true;\n}\n\nmodule.exports = {\n    Hash,\n    Set,\n    Map,\n    BitSet,\n    AltDict,\n    DoubleDict,\n    hashStuff,\n    escapeWhitespace,\n    arrayToString,\n    titleCase,\n    equalArrays\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst LL1Analyzer = require('./../LL1Analyzer');\nconst {IntervalSet} = require('./../IntervalSet');\nconst {Token} = require('./../Token');\n\nclass ATN {\n\n    constructor(grammarType , maxTokenType) {\n        /**\n         * Used for runtime deserialization of ATNs from strings\n         * The type of the ATN.\n        */\n        this.grammarType = grammarType;\n        // The maximum value for any symbol recognized by a transition in the ATN.\n        this.maxTokenType = maxTokenType;\n        this.states = [];\n        /**\n         * Each subrule/rule is a decision point and we must track them so we\n         * can go back later and build DFA predictors for them.  This includes\n         * all the rules, subrules, optional blocks, ()+, ()* etc...\n         */\n        this.decisionToState = [];\n        // Maps from rule index to starting state number.\n        this.ruleToStartState = [];\n        // Maps from rule index to stop state number.\n        this.ruleToStopState = null;\n        this.modeNameToStartState = {};\n        /**\n         * For lexer ATNs, this maps the rule index to the resulting token type.\n         * For parser ATNs, this maps the rule index to the generated bypass token\n         * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n         * deserialization option was specified; otherwise, this is {@code null}\n         */\n        this.ruleToTokenType = null;\n        /**\n         * For lexer ATNs, this is an array of {@link LexerAction} objects which may\n         * be referenced by action transitions in the ATN\n         */\n        this.lexerActions = null;\n        this.modeToStartState = [];\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in state {@code s}.\n     * If {@code ctx} is null, the set of tokens will not include what can follow\n     * the rule surrounding {@code s}. In other words, the set will be\n     * restricted to tokens reachable staying within {@code s}'s rule\n     */\n    nextTokensInContext(s, ctx) {\n        const anal = new LL1Analyzer(this);\n        return anal.LOOK(s, null, ctx);\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in {@code s} and\n     * staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n     * rule\n     */\n    nextTokensNoContext(s) {\n        if (s.nextTokenWithinRule !== null ) {\n            return s.nextTokenWithinRule;\n        }\n        s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n        s.nextTokenWithinRule.readOnly = true;\n        return s.nextTokenWithinRule;\n    }\n\n    nextTokens(s, ctx) {\n        if ( ctx===undefined ) {\n            return this.nextTokensNoContext(s);\n        } else {\n            return this.nextTokensInContext(s, ctx);\n        }\n    }\n\n    addState(state) {\n        if ( state !== null ) {\n            state.atn = this;\n            state.stateNumber = this.states.length;\n        }\n        this.states.push(state);\n    }\n\n    removeState(state) {\n        this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n    }\n\n    defineDecisionState(s) {\n        this.decisionToState.push(s);\n        s.decision = this.decisionToState.length-1;\n        return s.decision;\n    }\n\n    getDecisionState(decision) {\n        if (this.decisionToState.length===0) {\n            return null;\n        } else {\n            return this.decisionToState[decision];\n        }\n    }\n\n    /**\n     * Computes the set of input symbols which could follow ATN state number\n     * {@code stateNumber} in the specified full {@code context}. This method\n     * considers the complete parser context, but does not evaluate semantic\n     * predicates (i.e. all predicates encountered during the calculation are\n     * assumed true). If a path in the ATN exists from the starting state to the\n     * {@link RuleStopState} of the outermost context without matching any\n     * symbols, {@link Token//EOF} is added to the returned set.\n     *\n     * <p>If {@code context} is {@code null}, it is treated as\n     * {@link ParserRuleContext//EMPTY}.</p>\n     *\n     * @param stateNumber the ATN state number\n     * @param ctx the full parse context\n     *\n     * @return {IntervalSet} The set of potentially valid input symbols which could follow the\n     * specified state in the specified context.\n     *\n     * @throws IllegalArgumentException if the ATN does not contain a state with\n     * number {@code stateNumber}\n     */\n    getExpectedTokens(stateNumber, ctx ) {\n        if ( stateNumber < 0 || stateNumber >= this.states.length ) {\n            throw(\"Invalid state number.\");\n        }\n        const s = this.states[stateNumber];\n        let following = this.nextTokens(s);\n        if (!following.contains(Token.EPSILON)) {\n            return following;\n        }\n        const expected = new IntervalSet();\n        expected.addSet(following);\n        expected.removeOne(Token.EPSILON);\n        while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n            const invokingState = this.states[ctx.invokingState];\n            const rt = invokingState.transitions[0];\n            following = this.nextTokens(rt.followState);\n            expected.addSet(following);\n            expected.removeOne(Token.EPSILON);\n            ctx = ctx.parentCtx;\n        }\n        if (following.contains(Token.EPSILON)) {\n            expected.addOne(Token.EOF);\n        }\n        return expected;\n    }\n}\n\nATN.INVALID_ALT_NUMBER = 0;\n\nmodule.exports = ATN;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {DecisionState} = require('./ATNState');\nconst {SemanticContext} = require('./SemanticContext');\nconst {Hash} = require(\"../Utils\");\n\n\nfunction checkParams(params, isCfg) {\n\tif(params===null) {\n\t\tconst result = { state:null, alt:null, context:null, semanticContext:null };\n\t\tif(isCfg) {\n\t\t\tresult.reachesIntoOuterContext = 0;\n\t\t}\n\t\treturn result;\n\t} else {\n\t\tconst props = {};\n\t\tprops.state = params.state || null;\n\t\tprops.alt = (params.alt === undefined) ? null : params.alt;\n\t\tprops.context = params.context || null;\n\t\tprops.semanticContext = params.semanticContext || null;\n\t\tif(isCfg) {\n\t\t\tprops.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n\t\t\tprops.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n\t\t}\n\t\treturn props;\n\t}\n}\n\nclass ATNConfig {\n    /**\n     * @param {Object} params A tuple: (ATN state, predicted alt, syntactic, semantic context).\n     * The syntactic context is a graph-structured stack node whose\n     * path(s) to the root is the rule invocation(s)\n     * chain used to arrive at the state.  The semantic context is\n     * the tree of semantic predicates encountered before reaching\n     * an ATN state\n     */\n    constructor(params, config) {\n        this.checkContext(params, config);\n        params = checkParams(params);\n        config = checkParams(config, true);\n        // The ATN state associated with this configuration///\n        this.state = params.state!==null ? params.state : config.state;\n        // What alt (or lexer rule) is predicted by this configuration///\n        this.alt = params.alt!==null ? params.alt : config.alt;\n        /**\n         * The stack of invoking states leading to the rule/states associated\n         * with this config.  We track only those contexts pushed during\n         * execution of the ATN simulator\n         */\n        this.context = params.context!==null ? params.context : config.context;\n        this.semanticContext = params.semanticContext!==null ? params.semanticContext :\n            (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);\n        // TODO: make it a boolean then\n        /**\n         * We cannot execute predicates dependent upon local context unless\n         * we know for sure we are in the correct context. Because there is\n         * no way to do this efficiently, we simply cannot evaluate\n         * dependent predicates unless we are in the rule that initially\n         * invokes the ATN simulator.\n         * closure() tracks the depth of how far we dip into the\n         * outer context: depth &gt; 0.  Note that it may not be totally\n         * accurate depth since I don't ever decrement\n         */\n        this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n        this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n    }\n\n    checkContext(params, config) {\n        if((params.context===null || params.context===undefined) &&\n                (config===null || config.context===null || config.context===undefined)) {\n            this.context = null;\n        }\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        this.updateHashCode(hash);\n        return hash.finish();\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);\n    }\n\n    /**\n     * An ATN configuration is equal to another if both have\n     * the same state, they predict the same alternative, and\n     * syntactic/semantic contexts are the same\n     */\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                (this.context===null ? other.context===null : this.context.equals(other.context)) &&\n                this.semanticContext.equals(other.semanticContext) &&\n                this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;\n        }\n    }\n\n    hashCodeForConfigSet() {\n        const hash = new Hash();\n        hash.update(this.state.stateNumber, this.alt, this.semanticContext);\n        return hash.finish();\n    }\n\n    equalsForConfigSet(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                this.semanticContext.equals(other.semanticContext);\n        }\n    }\n\n    toString() {\n        return \"(\" + this.state + \",\" + this.alt +\n            (this.context!==null ? \",[\" + this.context.toString() + \"]\" : \"\") +\n            (this.semanticContext !== SemanticContext.NONE ?\n                    (\",\" + this.semanticContext.toString())\n                    : \"\") +\n            (this.reachesIntoOuterContext>0 ?\n                    (\",up=\" + this.reachesIntoOuterContext)\n                    : \"\") + \")\";\n    }\n}\n\n\nclass LexerATNConfig extends ATNConfig {\n    constructor(params, config) {\n        super(params, config);\n\n        // This is the backing field for {@link //getLexerActionExecutor}.\n        const lexerActionExecutor = params.lexerActionExecutor || null;\n        this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);\n        this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;\n        this.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;\n        this.equalsForConfigSet = LexerATNConfig.prototype.equals;\n        return this;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext, this.passedThroughNonGreedyDecision, this.lexerActionExecutor);\n    }\n\n    equals(other) {\n        return this === other ||\n                (other instanceof LexerATNConfig &&\n                this.passedThroughNonGreedyDecision === other.passedThroughNonGreedyDecision &&\n                (this.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) &&\n                super.equals(other));\n    }\n\n    checkNonGreedyDecision(source, target) {\n        return source.passedThroughNonGreedyDecision ||\n            (target instanceof DecisionState) && target.nonGreedy;\n    }\n}\n\n\nmodule.exports.ATNConfig = ATNConfig;\nmodule.exports.LexerATNConfig = LexerATNConfig;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst ATN = require('./ATN');\nconst Utils = require('./../Utils');\nconst {SemanticContext} = require('./SemanticContext');\nconst {merge} = require('./../PredictionContext');\n\nfunction hashATNConfig(c) {\n\treturn c.hashCodeForConfigSet();\n}\n\nfunction equalATNConfigs(a, b) {\n\tif ( a===b ) {\n\t\treturn true;\n\t} else if ( a===null || b===null ) {\n\t\treturn false;\n\t} else\n       return a.equalsForConfigSet(b);\n }\n\n/**\n * Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n * info about the set, with support for combining similar configurations using a\n * graph-structured stack\n */\nclass ATNConfigSet {\n\tconstructor(fullCtx) {\n\t\t/**\n\t\t * The reason that we need this is because we don't want the hash map to use\n\t\t * the standard hash code and equals. We need all configurations with the\n\t\t * same\n\t\t * {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n\t\t * doubles\n\t\t * the number of objects associated with ATNConfigs. The other solution is\n\t\t * to\n\t\t * use a hash table that lets us specify the equals/hashcode operation.\n\t\t * All configs but hashed by (s, i, _, pi) not including context. Wiped out\n\t\t * when we go readonly as this set becomes a DFA state\n\t\t */\n\t\tthis.configLookup = new Utils.Set(hashATNConfig, equalATNConfigs);\n\t\t/**\n\t\t * Indicates that this configuration set is part of a full context\n\t\t * LL prediction. It will be used to determine how to merge $. With SLL\n\t\t * it's a wildcard whereas it is not for LL context merge\n\t\t */\n\t\tthis.fullCtx = fullCtx === undefined ? true : fullCtx;\n\t\t/**\n\t\t * Indicates that the set of configurations is read-only. Do not\n\t\t * allow any code to manipulate the set; DFA states will point at\n\t\t * the sets and they must not change. This does not protect the other\n\t\t * fields; in particular, conflictingAlts is set after\n\t\t * we've made this readonly\n\t\t */\n\t\tthis.readOnly = false;\n\t\t// Track the elements as they are added to the set; supports get(i)///\n\t\tthis.configs = [];\n\n\t\t// TODO: these fields make me pretty uncomfortable but nice to pack up info\n\t\t// together, saves recomputation\n\t\t// TODO: can we track conflicts as they are added to save scanning configs\n\t\t// later?\n\t\tthis.uniqueAlt = 0;\n\t\tthis.conflictingAlts = null;\n\n\t\t/**\n\t\t * Used in parser and lexer. In lexer, it indicates we hit a pred\n\t\t * while computing a closure operation. Don't make a DFA state from this\n\t\t */\n\t\tthis.hasSemanticContext = false;\n\t\tthis.dipsIntoOuterContext = false;\n\n\t\tthis.cachedHashCode = -1;\n\t}\n\n\t/**\n\t * Adding a new config means merging contexts with existing configs for\n\t * {@code (s, i, pi, _)}, where {@code s} is the\n\t * {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n\t * {@code pi} is the {@link ATNConfig//semanticContext}. We use\n\t * {@code (s,i,pi)} as key.\n\t *\n\t * <p>This method updates {@link //dipsIntoOuterContext} and\n\t * {@link //hasSemanticContext} when necessary.</p>\n\t */\n\tadd(config, mergeCache) {\n\t\tif (mergeCache === undefined) {\n\t\t\tmergeCache = null;\n\t\t}\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (config.semanticContext !== SemanticContext.NONE) {\n\t\t\tthis.hasSemanticContext = true;\n\t\t}\n\t\tif (config.reachesIntoOuterContext > 0) {\n\t\t\tthis.dipsIntoOuterContext = true;\n\t\t}\n\t\tconst existing = this.configLookup.add(config);\n\t\tif (existing === config) {\n\t\t\tthis.cachedHashCode = -1;\n\t\t\tthis.configs.push(config); // track order here\n\t\t\treturn true;\n\t\t}\n\t\t// a previous (s,i,pi,_), merge with it and save result\n\t\tconst rootIsWildcard = !this.fullCtx;\n\t\tconst merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n\t\t/**\n\t\t * no need to check for existing.context, config.context in cache\n\t\t * since only way to create new graphs is \"call rule\" and here. We\n\t\t * cache at both places\n\t\t */\n\t\texisting.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n\t\t// make sure to preserve the precedence filter suppression during the merge\n\t\tif (config.precedenceFilterSuppressed) {\n\t\t\texisting.precedenceFilterSuppressed = true;\n\t\t}\n\t\texisting.context = merged; // replace context; no need to alt mapping\n\t\treturn true;\n\t}\n\n\tgetStates() {\n\t\tconst states = new Utils.Set();\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tstates.add(this.configs[i].state);\n\t\t}\n\t\treturn states;\n\t}\n\n\tgetPredicates() {\n\t\tconst preds = [];\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst c = this.configs[i].semanticContext;\n\t\t\tif (c !== SemanticContext.NONE) {\n\t\t\t\tpreds.push(c.semanticContext);\n\t\t\t}\n\t\t}\n\t\treturn preds;\n\t}\n\n\toptimizeConfigs(interpreter) {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (this.configLookup.length === 0) {\n\t\t\treturn;\n\t\t}\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst config = this.configs[i];\n\t\t\tconfig.context = interpreter.getCachedContext(config.context);\n\t\t}\n\t}\n\n\taddAll(coll) {\n\t\tfor (let i = 0; i < coll.length; i++) {\n\t\t\tthis.add(coll[i]);\n\t\t}\n\t\treturn false;\n\t}\n\n\tequals(other) {\n\t\treturn this === other ||\n\t\t\t(other instanceof ATNConfigSet &&\n\t\t\tUtils.equalArrays(this.configs, other.configs) &&\n\t\t\tthis.fullCtx === other.fullCtx &&\n\t\t\tthis.uniqueAlt === other.uniqueAlt &&\n\t\t\tthis.conflictingAlts === other.conflictingAlts &&\n\t\t\tthis.hasSemanticContext === other.hasSemanticContext &&\n\t\t\tthis.dipsIntoOuterContext === other.dipsIntoOuterContext);\n\t}\n\n\thashCode() {\n\t\tconst hash = new Utils.Hash();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n\n\tupdateHashCode(hash) {\n\t\tif (this.readOnly) {\n\t\t\tif (this.cachedHashCode === -1) {\n\t\t\t\tthis.cachedHashCode = this.hashCode();\n\t\t\t}\n\t\t\thash.update(this.cachedHashCode);\n\t\t} else {\n\t\t\thash.update(this.hashCode());\n\t\t}\n\t}\n\n\tisEmpty() {\n\t\treturn this.configs.length === 0;\n\t}\n\n\tcontains(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.contains(item);\n\t}\n\n\tcontainsFast(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.containsFast(item);\n\t}\n\n\tclear() {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tthis.configs = [];\n\t\tthis.cachedHashCode = -1;\n\t\tthis.configLookup = new Utils.Set();\n\t}\n\n\tsetReadonly(readOnly) {\n\t\tthis.readOnly = readOnly;\n\t\tif (readOnly) {\n\t\t\tthis.configLookup = null; // can't mod, no need for lookup cache\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn Utils.arrayToString(this.configs) +\n\t\t\t(this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") +\n\t\t\t(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") +\n\t\t\t(this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") +\n\t\t\t(this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n\t}\n\n\tget items(){\n\t\treturn this.configs;\n\t}\n\n\tget length(){\n\t\treturn this.configs.length;\n\t}\n}\n\n\nclass OrderedATNConfigSet extends ATNConfigSet {\n\tconstructor() {\n\t\tsuper();\n\t\tthis.configLookup = new Utils.Set();\n\t}\n}\n\nmodule.exports = {\n\tATNConfigSet,\n\tOrderedATNConfigSet\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nclass ATNDeserializationOptions {\n\tconstructor(copyFrom) {\n\t\tif(copyFrom===undefined) {\n\t\t\tcopyFrom = null;\n\t\t}\n\t\tthis.readOnly = false;\n\t\tthis.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;\n\t\tthis.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;\n\t}\n}\n\nATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\nATNDeserializationOptions.defaultOptions.readOnly = true;\n\n//    def __setattr__(self, key, value):\n//        if key!=\"readOnly\" and self.readOnly:\n//            raise Exception(\"The object is read only.\")\n//        super(type(self), self).__setattr__(key,value)\n\nmodule.exports = ATNDeserializationOptions\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst ATN = require('./ATN');\nconst ATNType = require('./ATNType');\n\nconst {\n    ATNState,\n    BasicState,\n    DecisionState,\n    BlockStartState,\n    BlockEndState,\n    LoopEndState,\n    RuleStartState,\n    RuleStopState,\n    TokensStartState,\n    PlusLoopbackState,\n    StarLoopbackState,\n    StarLoopEntryState,\n    PlusBlockStartState,\n    StarBlockStartState,\n    BasicBlockStartState\n} = require('./ATNState');\n\nconst {\n    Transition,\n    AtomTransition,\n    SetTransition,\n    NotSetTransition,\n    RuleTransition,\n    RangeTransition,\n    ActionTransition,\n    EpsilonTransition,\n    WildcardTransition,\n    PredicateTransition,\n    PrecedencePredicateTransition\n} = require('./Transition')\n\nconst {IntervalSet} = require('./../IntervalSet');\nconst ATNDeserializationOptions = require('./ATNDeserializationOptions');\n\nconst {\n    LexerActionType,\n    LexerSkipAction,\n    LexerChannelAction,\n    LexerCustomAction,\n    LexerMoreAction,\n    LexerTypeAction,\n    LexerPushModeAction,\n    LexerPopModeAction,\n    LexerModeAction,\n} = require('./LexerAction');\n\n// This is the earliest supported serialized UUID.\n// stick to serialized version for now, we don't need a UUID instance\nconst BASE_SERIALIZED_UUID = \"AADB8D7E-AEEF-4415-AD2B-8204D6CF042E\";\n\n//\n// This UUID indicates the serialized ATN contains two sets of\n// IntervalSets, where the second set's values are encoded as\n// 32-bit integers to support the full Unicode SMP range up to U+10FFFF.\n//\nconst ADDED_UNICODE_SMP = \"59627784-3BE5-417A-B9EB-8131A7286089\";\n\n// This list contains all of the currently supported UUIDs, ordered by when\n// the feature first appeared in this branch.\nconst SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID, ADDED_UNICODE_SMP ];\n\nconst SERIALIZED_VERSION = 3;\n\n// This is the current serialized UUID.\nconst SERIALIZED_UUID = ADDED_UNICODE_SMP;\n\nfunction initArray( length, value) {\n\tconst tmp = [];\n\ttmp[length-1] = value;\n\treturn tmp.map(function(i) {return value;});\n}\n\nclass ATNDeserializer {\n    constructor(options) {\n\n        if ( options=== undefined || options === null ) {\n            options = ATNDeserializationOptions.defaultOptions;\n        }\n        this.deserializationOptions = options;\n        this.stateFactories = null;\n        this.actionFactories = null;\n    }\n\n    /**\n     * Determines if a particular serialized representation of an ATN supports\n     * a particular feature, identified by the {@link UUID} used for serializing\n     * the ATN at the time the feature was first introduced.\n     *\n     * @param feature The {@link UUID} marking the first time the feature was\n     * supported in the serialized ATN.\n     * @param actualUuid The {@link UUID} of the actual serialized ATN which is\n     * currently being deserialized.\n     * @return {@code true} if the {@code actualUuid} value represents a\n     * serialized ATN at or after the feature identified by {@code feature} was\n     * introduced; otherwise, {@code false}.\n    */\n    isFeatureSupported(feature, actualUuid) {\n        const idx1 = SUPPORTED_UUIDS.indexOf(feature);\n        if (idx1<0) {\n            return false;\n        }\n        const idx2 = SUPPORTED_UUIDS.indexOf(actualUuid);\n        return idx2 >= idx1;\n    }\n\n    deserialize(data) {\n        this.reset(data);\n        this.checkVersion();\n        this.checkUUID();\n        const atn = this.readATN();\n        this.readStates(atn);\n        this.readRules(atn);\n        this.readModes(atn);\n        const sets = [];\n        // First, deserialize sets with 16-bit arguments <= U+FFFF.\n        this.readSets(atn, sets, this.readInt.bind(this));\n        // Next, if the ATN was serialized with the Unicode SMP feature,\n        // deserialize sets with 32-bit arguments <= U+10FFFF.\n        if (this.isFeatureSupported(ADDED_UNICODE_SMP, this.uuid)) {\n            this.readSets(atn, sets, this.readInt32.bind(this));\n        }\n        this.readEdges(atn, sets);\n        this.readDecisions(atn);\n        this.readLexerActions(atn);\n        this.markPrecedenceDecisions(atn);\n        this.verifyATN(atn);\n        if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {\n            this.generateRuleBypassTransitions(atn);\n            // re-verify after modification\n            this.verifyATN(atn);\n        }\n        return atn;\n    }\n\n    reset(data) {\n        const adjust = function(c) {\n            const v = c.charCodeAt(0);\n            return v>1  ? v-2 : v + 65534;\n        };\n        const temp = data.split(\"\").map(adjust);\n        // don't adjust the first value since that's the version number\n        temp[0] = data.charCodeAt(0);\n        this.data = temp;\n        this.pos = 0;\n    }\n\n    checkVersion() {\n        const version = this.readInt();\n        if ( version !== SERIALIZED_VERSION ) {\n            throw (\"Could not deserialize ATN with version \" + version + \" (expected \" + SERIALIZED_VERSION + \").\");\n        }\n    }\n\n    checkUUID() {\n        const uuid = this.readUUID();\n        if (SUPPORTED_UUIDS.indexOf(uuid)<0) {\n            throw (\"Could not deserialize ATN with UUID: \" + uuid +\n                            \" (expected \" + SERIALIZED_UUID + \" or a legacy UUID).\", uuid, SERIALIZED_UUID);\n        }\n        this.uuid = uuid;\n    }\n\n    readATN() {\n        const grammarType = this.readInt();\n        const maxTokenType = this.readInt();\n        return new ATN(grammarType, maxTokenType);\n    }\n\n    readStates(atn) {\n        let j, pair, stateNumber;\n        const  loopBackStateNumbers = [];\n        const  endStateNumbers = [];\n        const  nstates = this.readInt();\n        for(let i=0; i<nstates; i++) {\n            const  stype = this.readInt();\n            // ignore bad type of states\n            if (stype===ATNState.INVALID_TYPE) {\n                atn.addState(null);\n                continue;\n            }\n            let ruleIndex = this.readInt();\n            if (ruleIndex === 0xFFFF) {\n                ruleIndex = -1;\n            }\n            const  s = this.stateFactory(stype, ruleIndex);\n            if (stype === ATNState.LOOP_END) { // special case\n                const  loopBackStateNumber = this.readInt();\n                loopBackStateNumbers.push([s, loopBackStateNumber]);\n            } else if(s instanceof BlockStartState) {\n                const  endStateNumber = this.readInt();\n                endStateNumbers.push([s, endStateNumber]);\n            }\n            atn.addState(s);\n        }\n        // delay the assignment of loop back and end states until we know all the\n        // state instances have been initialized\n        for (j=0; j<loopBackStateNumbers.length; j++) {\n            pair = loopBackStateNumbers[j];\n            pair[0].loopBackState = atn.states[pair[1]];\n        }\n\n        for (j=0; j<endStateNumbers.length; j++) {\n            pair = endStateNumbers[j];\n            pair[0].endState = atn.states[pair[1]];\n        }\n\n        let numNonGreedyStates = this.readInt();\n        for (j=0; j<numNonGreedyStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].nonGreedy = true;\n        }\n\n        let numPrecedenceStates = this.readInt();\n        for (j=0; j<numPrecedenceStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].isPrecedenceRule = true;\n        }\n    }\n\n    readRules(atn) {\n        let i;\n        const nrules = this.readInt();\n        if (atn.grammarType === ATNType.LEXER ) {\n            atn.ruleToTokenType = initArray(nrules, 0);\n        }\n        atn.ruleToStartState = initArray(nrules, 0);\n        for (i=0; i<nrules; i++) {\n            const s = this.readInt();\n            atn.ruleToStartState[i] = atn.states[s];\n            if ( atn.grammarType === ATNType.LEXER ) {\n                let tokenType = this.readInt();\n                if (tokenType === 0xFFFF) {\n                    tokenType = Token.EOF;\n                }\n                atn.ruleToTokenType[i] = tokenType;\n            }\n        }\n        atn.ruleToStopState = initArray(nrules, 0);\n        for (i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!(state instanceof RuleStopState)) {\n                continue;\n            }\n            atn.ruleToStopState[state.ruleIndex] = state;\n            atn.ruleToStartState[state.ruleIndex].stopState = state;\n        }\n    }\n\n    readModes(atn) {\n        const nmodes = this.readInt();\n        for (let i=0; i<nmodes; i++) {\n            let s = this.readInt();\n            atn.modeToStartState.push(atn.states[s]);\n        }\n    }\n\n    readSets(atn, sets, readUnicode) {\n        const m = this.readInt();\n        for (let i=0; i<m; i++) {\n            const iset = new IntervalSet();\n            sets.push(iset);\n            const n = this.readInt();\n            const containsEof = this.readInt();\n            if (containsEof!==0) {\n                iset.addOne(-1);\n            }\n            for (let j=0; j<n; j++) {\n                const i1 = readUnicode();\n                const i2 = readUnicode();\n                iset.addRange(i1, i2);\n            }\n        }\n    }\n\n    readEdges(atn, sets) {\n        let i, j, state, trans, target;\n        const nedges = this.readInt();\n        for (i=0; i<nedges; i++) {\n            const src = this.readInt();\n            const trg = this.readInt();\n            const ttype = this.readInt();\n            const arg1 = this.readInt();\n            const arg2 = this.readInt();\n            const arg3 = this.readInt();\n            trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n            const srcState = atn.states[src];\n            srcState.addTransition(trans);\n        }\n        // edges for rule stop states can be derived, so they aren't serialized\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for (j=0; j<state.transitions.length; j++) {\n                const t = state.transitions[j];\n                if (!(t instanceof RuleTransition)) {\n                    continue;\n                }\n                let outermostPrecedenceReturn = -1;\n                if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n                    if (t.precedence === 0) {\n                        outermostPrecedenceReturn = t.target.ruleIndex;\n                    }\n                }\n\n                trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n                atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n            }\n        }\n\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            if (state instanceof BlockStartState) {\n                // we need to know the end state to set its start state\n                if (state.endState === null) {\n                    throw (\"IllegalState\");\n                }\n                // block end states can only be associated to a single block start\n                // state\n                if ( state.endState.startState !== null) {\n                    throw (\"IllegalState\");\n                }\n                state.endState.startState = state;\n            }\n            if (state instanceof PlusLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof PlusBlockStartState) {\n                        target.loopBackState = state;\n                    }\n                }\n            } else if (state instanceof StarLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof StarLoopEntryState) {\n                        target.loopBackState = state;\n                    }\n                }\n            }\n        }\n    }\n\n    readDecisions(atn) {\n        const ndecisions = this.readInt();\n        for (let i=0; i<ndecisions; i++) {\n            const s = this.readInt();\n            const decState = atn.states[s];\n            atn.decisionToState.push(decState);\n            decState.decision = i;\n        }\n    }\n\n    readLexerActions(atn) {\n        if (atn.grammarType === ATNType.LEXER) {\n            const count = this.readInt();\n            atn.lexerActions = initArray(count, null);\n            for (let i=0; i<count; i++) {\n                const actionType = this.readInt();\n                let data1 = this.readInt();\n                if (data1 === 0xFFFF) {\n                    data1 = -1;\n                }\n                let data2 = this.readInt();\n                if (data2 === 0xFFFF) {\n                    data2 = -1;\n                }\n\n                atn.lexerActions[i] = this.lexerActionFactory(actionType, data1, data2);\n            }\n        }\n    }\n\n    generateRuleBypassTransitions(atn) {\n        let i;\n        const count = atn.ruleToStartState.length;\n        for(i=0; i<count; i++) {\n            atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n        }\n        for(i=0; i<count; i++) {\n            this.generateRuleBypassTransition(atn, i);\n        }\n    }\n\n    generateRuleBypassTransition(atn, idx) {\n        let i, state;\n        const bypassStart = new BasicBlockStartState();\n        bypassStart.ruleIndex = idx;\n        atn.addState(bypassStart);\n\n        const bypassStop = new BlockEndState();\n        bypassStop.ruleIndex = idx;\n        atn.addState(bypassStop);\n\n        bypassStart.endState = bypassStop;\n        atn.defineDecisionState(bypassStart);\n\n        bypassStop.startState = bypassStart;\n\n        let excludeTransition = null;\n        let endState = null;\n\n        if (atn.ruleToStartState[idx].isPrecedenceRule) {\n            // wrap from the beginning of the rule to the StarLoopEntryState\n            endState = null;\n            for(i=0; i<atn.states.length; i++) {\n                state = atn.states[i];\n                if (this.stateIsEndStateFor(state, idx)) {\n                    endState = state;\n                    excludeTransition = state.loopBackState.transitions[0];\n                    break;\n                }\n            }\n            if (excludeTransition === null) {\n                throw (\"Couldn't identify final state of the precedence rule prefix section.\");\n            }\n        } else {\n            endState = atn.ruleToStopState[idx];\n        }\n\n        // all non-excluded transitions that currently target end state need to\n        // target blockEnd instead\n        for(i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for(let j=0; j<state.transitions.length; j++) {\n                const transition = state.transitions[j];\n                if (transition === excludeTransition) {\n                    continue;\n                }\n                if (transition.target === endState) {\n                    transition.target = bypassStop;\n                }\n            }\n        }\n\n        // all transitions leaving the rule start state need to leave blockStart\n        // instead\n        const ruleToStartState = atn.ruleToStartState[idx];\n        const count = ruleToStartState.transitions.length;\n        while ( count > 0) {\n            bypassStart.addTransition(ruleToStartState.transitions[count-1]);\n            ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n        }\n        // link the new states\n        atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n        bypassStop.addTransition(new EpsilonTransition(endState));\n\n        const matchState = new BasicState();\n        atn.addState(matchState);\n        matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n        bypassStart.addTransition(new EpsilonTransition(matchState));\n    }\n\n    stateIsEndStateFor(state, idx) {\n        if ( state.ruleIndex !== idx) {\n            return null;\n        }\n        if (!( state instanceof StarLoopEntryState)) {\n            return null;\n        }\n        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n        if (!( maybeLoopEndState instanceof LoopEndState)) {\n            return null;\n        }\n        if (maybeLoopEndState.epsilonOnlyTransitions &&\n            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n            return state;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n     * the {@link StarLoopEntryState//isPrecedenceDecision} field to the\n     * correct value.\n     * @param atn The ATN.\n     */\n    markPrecedenceDecisions(atn) {\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!( state instanceof StarLoopEntryState)) {\n                continue;\n            }\n            // We analyze the ATN to determine if this ATN decision state is the\n            // decision for the closure block that determines whether a\n            // precedence rule should continue or complete.\n            if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n                const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n                if (maybeLoopEndState instanceof LoopEndState) {\n                    if ( maybeLoopEndState.epsilonOnlyTransitions &&\n                            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n                        state.isPrecedenceDecision = true;\n                    }\n                }\n            }\n        }\n    }\n\n    verifyATN(atn) {\n        if (!this.deserializationOptions.verifyATN) {\n            return;\n        }\n        // verify assumptions\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (state === null) {\n                continue;\n            }\n            this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n            if (state instanceof PlusBlockStartState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else  if (state instanceof StarLoopEntryState) {\n                this.checkCondition(state.loopBackState !== null);\n                this.checkCondition(state.transitions.length === 2);\n                if (state.transitions[0].target instanceof StarBlockStartState) {\n                    this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n                    this.checkCondition(!state.nonGreedy);\n                } else if (state.transitions[0].target instanceof LoopEndState) {\n                    this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n                    this.checkCondition(state.nonGreedy);\n                } else {\n                    throw(\"IllegalState\");\n                }\n            } else if (state instanceof StarLoopbackState) {\n                this.checkCondition(state.transitions.length === 1);\n                this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n            } else if (state instanceof LoopEndState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else if (state instanceof RuleStartState) {\n                this.checkCondition(state.stopState !== null);\n            } else if (state instanceof BlockStartState) {\n                this.checkCondition(state.endState !== null);\n            } else if (state instanceof BlockEndState) {\n                this.checkCondition(state.startState !== null);\n            } else if (state instanceof DecisionState) {\n                this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n            } else {\n                this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));\n            }\n        }\n    }\n\n    checkCondition(condition, message) {\n        if (!condition) {\n            if (message === undefined || message===null) {\n                message = \"IllegalState\";\n            }\n            throw (message);\n        }\n    }\n\n    readInt() {\n        return this.data[this.pos++];\n    }\n\n    readInt32() {\n        const low = this.readInt();\n        const high = this.readInt();\n        return low | (high << 16);\n    }\n\n    readLong() {\n        const low = this.readInt32();\n        const high = this.readInt32();\n        return (low & 0x00000000FFFFFFFF) | (high << 32);\n    }\n\n    readUUID() {\n        const bb = [];\n        for(let i=7;i>=0;i--) {\n            const int = this.readInt();\n            /* jshint bitwise: false */\n            bb[(2*i)+1] = int & 0xFF;\n            bb[2*i] = (int >> 8) & 0xFF;\n        }\n        return byteToHex[bb[0]] + byteToHex[bb[1]] +\n        byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +\n        byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +\n        byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +\n        byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +\n        byteToHex[bb[10]] + byteToHex[bb[11]] +\n        byteToHex[bb[12]] + byteToHex[bb[13]] +\n        byteToHex[bb[14]] + byteToHex[bb[15]];\n    }\n\n    edgeFactory(atn, type, src, trg, arg1, arg2, arg3, sets) {\n        const target = atn.states[trg];\n        switch(type) {\n        case Transition.EPSILON:\n            return new EpsilonTransition(target);\n        case Transition.RANGE:\n            return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n        case Transition.RULE:\n            return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n        case Transition.PREDICATE:\n            return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.PRECEDENCE:\n            return new PrecedencePredicateTransition(target, arg1);\n        case Transition.ATOM:\n            return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n        case Transition.ACTION:\n            return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.SET:\n            return new SetTransition(target, sets[arg1]);\n        case Transition.NOT_SET:\n            return new NotSetTransition(target, sets[arg1]);\n        case Transition.WILDCARD:\n            return new WildcardTransition(target);\n        default:\n            throw \"The specified transition type: \" + type + \" is not valid.\";\n        }\n    }\n\n    stateFactory(type, ruleIndex) {\n        if (this.stateFactories === null) {\n            const sf = [];\n            sf[ATNState.INVALID_TYPE] = null;\n            sf[ATNState.BASIC] = () => new BasicState();\n            sf[ATNState.RULE_START] = () => new RuleStartState();\n            sf[ATNState.BLOCK_START] = () => new BasicBlockStartState();\n            sf[ATNState.PLUS_BLOCK_START] = () => new PlusBlockStartState();\n            sf[ATNState.STAR_BLOCK_START] = () => new StarBlockStartState();\n            sf[ATNState.TOKEN_START] = () => new TokensStartState();\n            sf[ATNState.RULE_STOP] = () => new RuleStopState();\n            sf[ATNState.BLOCK_END] = () => new BlockEndState();\n            sf[ATNState.STAR_LOOP_BACK] = () => new StarLoopbackState();\n            sf[ATNState.STAR_LOOP_ENTRY] = () => new StarLoopEntryState();\n            sf[ATNState.PLUS_LOOP_BACK] = () => new PlusLoopbackState();\n            sf[ATNState.LOOP_END] = () => new LoopEndState();\n            this.stateFactories = sf;\n        }\n        if (type>this.stateFactories.length || this.stateFactories[type] === null) {\n            throw(\"The specified state type \" + type + \" is not valid.\");\n        } else {\n            const s = this.stateFactories[type]();\n            if (s!==null) {\n                s.ruleIndex = ruleIndex;\n                return s;\n            }\n        }\n    }\n\n    lexerActionFactory(type, data1, data2) {\n        if (this.actionFactories === null) {\n            const af = [];\n            af[LexerActionType.CHANNEL] = (data1, data2) => new LexerChannelAction(data1);\n            af[LexerActionType.CUSTOM] = (data1, data2) => new LexerCustomAction(data1, data2);\n            af[LexerActionType.MODE] = (data1, data2) => new LexerModeAction(data1);\n            af[LexerActionType.MORE] = (data1, data2) => LexerMoreAction.INSTANCE;\n            af[LexerActionType.POP_MODE] = (data1, data2) => LexerPopModeAction.INSTANCE;\n            af[LexerActionType.PUSH_MODE] = (data1, data2) => new LexerPushModeAction(data1);\n            af[LexerActionType.SKIP] = (data1, data2) => LexerSkipAction.INSTANCE;\n            af[LexerActionType.TYPE] = (data1, data2) => new LexerTypeAction(data1);\n            this.actionFactories = af;\n        }\n        if (type>this.actionFactories.length || this.actionFactories[type] === null) {\n            throw(\"The specified lexer action type \" + type + \" is not valid.\");\n        } else {\n            return this.actionFactories[type](data1, data2);\n        }\n    }\n}\n\nfunction createByteToHex() {\n\tconst bth = [];\n\tfor (let i = 0; i < 256; i++) {\n\t\tbth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();\n\t}\n\treturn bth;\n}\n\nconst byteToHex = createByteToHex();\n\n\nmodule.exports = ATNDeserializer;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {DFAState} = require('./../dfa/DFAState');\nconst {ATNConfigSet} = require('./ATNConfigSet');\nconst {getCachedPredictionContext} = require('./../PredictionContext');\nconst {Map} = require('./../Utils');\n\nclass ATNSimulator {\n    constructor(atn, sharedContextCache) {\n        /**\n         * The context cache maps all PredictionContext objects that are ==\n         * to a single cached copy. This cache is shared across all contexts\n         * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n         * to use only cached nodes/graphs in addDFAState(). We don't want to\n         * fill this during closure() since there are lots of contexts that\n         * pop up but are not used ever again. It also greatly slows down closure().\n         *\n         * <p>This cache makes a huge difference in memory and a little bit in speed.\n         * For the Java grammar on java.*, it dropped the memory requirements\n         * at the end from 25M to 16M. We don't store any of the full context\n         * graphs in the DFA because they are limited to local context only,\n         * but apparently there's a lot of repetition there as well. We optimize\n         * the config contexts before storing the config set in the DFA states\n         * by literally rebuilding them with cached subgraphs only.</p>\n         *\n         * <p>I tried a cache for use during closure operations, that was\n         * whacked after each adaptivePredict(). It cost a little bit\n         * more time I think and doesn't save on the overall footprint\n         * so it's not worth the complexity.</p>\n         */\n        this.atn = atn;\n        this.sharedContextCache = sharedContextCache;\n        return this;\n    }\n\n    getCachedContext(context) {\n        if (this.sharedContextCache ===null) {\n            return context;\n        }\n        const visited = new Map();\n        return getCachedPredictionContext(context, this.sharedContextCache, visited);\n    }\n}\n\n// Must distinguish between missing edge and edge we know leads nowhere///\nATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());\n\n\nmodule.exports = ATNSimulator;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst INITIAL_NUM_TRANSITIONS = 4;\n\n/**\n * The following images show the relation of states and\n * {@link ATNState//transitions} for various grammar constructs.\n *\n * <ul>\n *\n * <li>Solid edges marked with an &//0949; indicate a required\n * {@link EpsilonTransition}.</li>\n *\n * <li>Dashed edges indicate locations where any transition derived from\n * {@link Transition} might appear.</li>\n *\n * <li>Dashed nodes are place holders for either a sequence of linked\n * {@link BasicState} states or the inclusion of a block representing a nested\n * construct in one of the forms below.</li>\n *\n * <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n * any number of alternatives (one or more). Nodes without the {@code ...} only\n * support the exact number of alternatives shown in the diagram.</li>\n *\n * </ul>\n *\n * <h2>Basic Blocks</h2>\n *\n * <h3>Rule</h3>\n *\n * <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Block of 1 or more alternatives</h3>\n *\n * <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Greedy Loops</h2>\n *\n * <h3>Greedy Closure: {@code (...)*}</h3>\n *\n * <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Positive Closure: {@code (...)+}</h3>\n *\n * <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Optional: {@code (...)?}</h3>\n *\n * <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Non-Greedy Loops</h2>\n *\n * <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n *\n * <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n *\n * <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Optional: {@code (...)??}</h3>\n *\n * <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n */\nclass ATNState {\n    constructor() {\n        // Which ATN are we in?\n        this.atn = null;\n        this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n        this.stateType = null;\n        this.ruleIndex = 0; // at runtime, we don't have Rule objects\n        this.epsilonOnlyTransitions = false;\n        // Track the transitions emanating from this ATN state.\n        this.transitions = [];\n        // Used to cache lookahead during parsing, not used during construction\n        this.nextTokenWithinRule = null;\n    }\n\n    toString() {\n        return this.stateNumber;\n    }\n\n    equals(other) {\n        if (other instanceof ATNState) {\n            return this.stateNumber===other.stateNumber;\n        } else {\n            return false;\n        }\n    }\n\n    isNonGreedyExitState() {\n        return false;\n    }\n\n    addTransition(trans, index) {\n        if(index===undefined) {\n            index = -1;\n        }\n        if (this.transitions.length===0) {\n            this.epsilonOnlyTransitions = trans.isEpsilon;\n        } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {\n            this.epsilonOnlyTransitions = false;\n        }\n        if (index===-1) {\n            this.transitions.push(trans);\n        } else {\n            this.transitions.splice(index, 1, trans);\n        }\n    }\n}\n\n// constants for serialization\nATNState.INVALID_TYPE = 0;\nATNState.BASIC = 1;\nATNState.RULE_START = 2;\nATNState.BLOCK_START = 3;\nATNState.PLUS_BLOCK_START = 4;\nATNState.STAR_BLOCK_START = 5;\nATNState.TOKEN_START = 6;\nATNState.RULE_STOP = 7;\nATNState.BLOCK_END = 8;\nATNState.STAR_LOOP_BACK = 9;\nATNState.STAR_LOOP_ENTRY = 10;\nATNState.PLUS_LOOP_BACK = 11;\nATNState.LOOP_END = 12;\n\nATNState.serializationNames = [\n            \"INVALID\",\n            \"BASIC\",\n            \"RULE_START\",\n            \"BLOCK_START\",\n            \"PLUS_BLOCK_START\",\n            \"STAR_BLOCK_START\",\n            \"TOKEN_START\",\n            \"RULE_STOP\",\n            \"BLOCK_END\",\n            \"STAR_LOOP_BACK\",\n            \"STAR_LOOP_ENTRY\",\n            \"PLUS_LOOP_BACK\",\n            \"LOOP_END\" ];\n\nATNState.INVALID_STATE_NUMBER = -1;\n\n\nclass BasicState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BASIC;\n    }\n}\n\nclass DecisionState extends ATNState {\n    constructor() {\n        super();\n        this.decision = -1;\n        this.nonGreedy = false;\n        return this;\n    }\n}\n\n/**\n *  The start of a regular {@code (...)} block\n */\nclass BlockStartState extends DecisionState {\n    constructor() {\n        super();\n        this.endState = null;\n        return this;\n    }\n}\n\nclass BasicBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_START;\n        return this;\n    }\n}\n\n/**\n * Terminal node of a simple {@code (a|b|c)} block\n */\nclass BlockEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_END;\n        this.startState = null;\n        return this;\n    }\n}\n\n/**\n * The last node in the ATN for a rule, unless that rule is the start symbol.\n * In that case, there is one transition to EOF. Later, we might encode\n * references to all calls to this rule to compute FOLLOW sets for\n * error handling\n */\nclass RuleStopState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_STOP;\n        return this;\n    }\n}\n\nclass RuleStartState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_START;\n        this.stopState = null;\n        this.isPrecedenceRule = false;\n        return this;\n    }\n}\n\n/**\n * Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n * one to the loop back to start of the block and one to exit.\n */\nclass PlusLoopbackState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_LOOP_BACK;\n        return this;\n    }\n}\n\n/**\n * Start of {@code (A|B|...)+} loop. Technically a decision state, but\n * we don't use for code generation; somebody might need it, so I'm defining\n * it for completeness. In reality, the {@link PlusLoopbackState} node is the\n * real decision-making note for {@code A+}\n */\nclass PlusBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_BLOCK_START;\n        this.loopBackState = null;\n        return this;\n    }\n}\n\n/**\n * The block that begins a closure loop\n */\nclass StarBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_BLOCK_START;\n        return this;\n    }\n}\n\nclass StarLoopbackState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_BACK;\n        return this;\n    }\n}\n\nclass StarLoopEntryState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_ENTRY;\n        this.loopBackState = null;\n        // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n        this.isPrecedenceDecision = null;\n        return this;\n    }\n}\n\n/**\n * Mark the end of a * or + loop\n */\nclass LoopEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.LOOP_END;\n        this.loopBackState = null;\n        return this;\n    }\n}\n\n/**\n * The Tokens rule start state linking to each lexer rule start state\n */\nclass TokensStartState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.TOKEN_START;\n        return this;\n    }\n}\n\nmodule.exports = {\n    ATNState,\n    BasicState,\n    DecisionState,\n    BlockStartState,\n    BlockEndState,\n    LoopEndState,\n    RuleStartState,\n    RuleStopState,\n    TokensStartState,\n    PlusLoopbackState,\n    StarLoopbackState,\n    StarLoopEntryState,\n    PlusBlockStartState,\n    StarBlockStartState,\n    BasicBlockStartState\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Represents the type of recognizer an ATN applies to\n */\nmodule.exports = {\n    LEXER: 0,\n    PARSER: 1\n};\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst Lexer = require('./../Lexer');\nconst ATN = require('./ATN');\nconst ATNSimulator = require('./ATNSimulator');\nconst {DFAState} = require('./../dfa/DFAState');\nconst {OrderedATNConfigSet} = require('./ATNConfigSet');\nconst {PredictionContext} = require('./../PredictionContext');\nconst {SingletonPredictionContext} = require('./../PredictionContext');\nconst {RuleStopState} = require('./ATNState');\nconst {LexerATNConfig} = require('./ATNConfig');\nconst {Transition} = require('./Transition');\nconst LexerActionExecutor = require('./LexerActionExecutor');\nconst {LexerNoViableAltException} = require('./../error/Errors');\n\nfunction resetSimState(sim) {\n\tsim.index = -1;\n\tsim.line = 0;\n\tsim.column = -1;\n\tsim.dfaState = null;\n}\n\nclass SimState {\n\tconstructor() {\n\t\tresetSimState(this);\n\t}\n\n\treset() {\n\t\tresetSimState(this);\n\t}\n}\n\nclass LexerATNSimulator extends ATNSimulator {\n\t/**\n\t * When we hit an accept state in either the DFA or the ATN, we\n\t * have to notify the character stream to start buffering characters\n\t * via {@link IntStream//mark} and record the current state. The current sim state\n\t * includes the current index into the input, the current line,\n\t * and current character position in that line. Note that the Lexer is\n\t * tracking the starting line and characterization of the token. These\n\t * variables track the \"state\" of the simulator when it hits an accept state.\n\t *\n\t * <p>We track these variables separately for the DFA and ATN simulation\n\t * because the DFA simulation often has to fail over to the ATN\n\t * simulation. If the ATN simulation fails, we need the DFA to fall\n\t * back to its previously accepted state, if any. If the ATN succeeds,\n\t * then the ATN does the accept and the DFA simulator that invoked it\n\t * can simply return the predicted token type.</p>\n\t */\n\tconstructor(recog, atn, decisionToDFA, sharedContextCache) {\n\t\tsuper(atn, sharedContextCache);\n\t\tthis.decisionToDFA = decisionToDFA;\n\t\tthis.recog = recog;\n\t\t/**\n\t\t * The current token's starting index into the character stream.\n\t\t * Shared across DFA to ATN simulation in case the ATN fails and the\n\t\t * DFA did not have a previous accept state. In this case, we use the\n\t\t * ATN-generated exception object\n\t\t */\n\t\tthis.startIndex = -1;\n\t\t// line number 1..n within the input///\n\t\tthis.line = 1;\n\t\t/**\n\t\t * The index of the character relative to the beginning of the line\n\t\t * 0..n-1\n\t\t */\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t\t/**\n\t\t * Used during DFA/ATN exec to record the most recent accept configuration\n\t\t * info\n\t\t */\n\t\tthis.prevAccept = new SimState();\n\t}\n\n\tcopyState(simulator) {\n\t\tthis.column = simulator.column;\n\t\tthis.line = simulator.line;\n\t\tthis.mode = simulator.mode;\n\t\tthis.startIndex = simulator.startIndex;\n\t}\n\n\tmatch(input, mode) {\n\t\tthis.match_calls += 1;\n\t\tthis.mode = mode;\n\t\tconst mark = input.mark();\n\t\ttry {\n\t\t\tthis.startIndex = input.index;\n\t\t\tthis.prevAccept.reset();\n\t\t\tconst dfa = this.decisionToDFA[mode];\n\t\t\tif (dfa.s0 === null) {\n\t\t\t\treturn this.matchATN(input);\n\t\t\t} else {\n\t\t\t\treturn this.execATN(input, dfa.s0);\n\t\t\t}\n\t\t} finally {\n\t\t\tinput.release(mark);\n\t\t}\n\t}\n\n\treset() {\n\t\tthis.prevAccept.reset();\n\t\tthis.startIndex = -1;\n\t\tthis.line = 1;\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t}\n\n\tmatchATN(input) {\n\t\tconst startState = this.atn.modeToStartState[this.mode];\n\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n\t\t}\n\t\tconst old_mode = this.mode;\n\t\tconst s0_closure = this.computeStartState(input, startState);\n\t\tconst suppressEdge = s0_closure.hasSemanticContext;\n\t\ts0_closure.hasSemanticContext = false;\n\n\t\tconst next = this.addDFAState(s0_closure);\n\t\tif (!suppressEdge) {\n\t\t\tthis.decisionToDFA[this.mode].s0 = next;\n\t\t}\n\n\t\tconst predict = this.execATN(input, next);\n\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"DFA after matchATN: \" + this.decisionToDFA[old_mode].toLexerString());\n\t\t}\n\t\treturn predict;\n\t}\n\n\texecATN(input, ds0) {\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"start state closure=\" + ds0.configs);\n\t\t}\n\t\tif (ds0.isAcceptState) {\n\t\t\t// allow zero-length tokens\n\t\t\tthis.captureSimState(this.prevAccept, input, ds0);\n\t\t}\n\t\tlet t = input.LA(1);\n\t\tlet s = ds0; // s is current/from DFA state\n\n\t\twhile (true) { // while more work\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"execATN loop starting closure: \" + s.configs);\n\t\t\t}\n\n\t\t\t/**\n\t\t\t * As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t\t * avoid looking up the DFA state again, which is expensive.\n\t\t\t * If the previous target was already part of the DFA, we might\n\t\t\t * be able to avoid doing a reach operation upon t. If s!=null,\n\t\t\t * it means that semantic predicates didn't prevent us from\n\t\t\t * creating a DFA state. Once we know s!=null, we check to see if\n\t\t\t * the DFA state has an edge already for t. If so, we can just reuse\n\t\t\t * it's configuration set; there's no point in re-computing it.\n\t\t\t * This is kind of like doing DFA simulation within the ATN\n\t\t\t * simulation because DFA simulation is really just a way to avoid\n\t\t\t * computing reach/closure sets. Technically, once we know that\n\t\t\t * we have a previously added DFA state, we could jump over to\n\t\t\t * the DFA simulator. But, that would mean popping back and forth\n\t\t\t * a lot and making things more complicated algorithmically.\n\t\t\t * This optimization makes a lot of sense for loops within DFA.\n\t\t\t * A character will take us back to an existing DFA state\n\t\t\t * that already has lots of edges out of it. e.g., .* in comments.\n\t\t\t * print(\"Target for:\" + str(s) + \" and:\" + str(t))\n\t\t\t */\n\t\t\tlet target = this.getExistingTargetState(s, t);\n\t\t\t// print(\"Existing:\" + str(target))\n\t\t\tif (target === null) {\n\t\t\t\ttarget = this.computeTargetState(input, s, t);\n\t\t\t\t// print(\"Computed:\" + str(target))\n\t\t\t}\n\t\t\tif (target === ATNSimulator.ERROR) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t// If this is a consumable input element, make sure to consume before\n\t\t\t// capturing the accept state so the input index, line, and char\n\t\t\t// position accurately reflect the state of the interpreter at the\n\t\t\t// end of the token.\n\t\t\tif (t !== Token.EOF) {\n\t\t\t\tthis.consume(input);\n\t\t\t}\n\t\t\tif (target.isAcceptState) {\n\t\t\t\tthis.captureSimState(this.prevAccept, input, target);\n\t\t\t\tif (t === Token.EOF) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tt = input.LA(1);\n\t\t\ts = target; // flip; current DFA target becomes new src/from state\n\t\t}\n\t\treturn this.failOrAccept(this.prevAccept, input, s.configs, t);\n\t}\n\n\t/**\n\t * Get an existing target state for an edge in the DFA. If the target state\n\t * for the edge has not yet been computed or is otherwise not available,\n\t * this method returns {@code null}.\n\t *\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t * @return The existing target DFA state for the given input symbol\n\t * {@code t}, or {@code null} if the target state for this edge is not\n\t * already cached\n\t */\n\tgetExistingTargetState(s, t) {\n\t\tif (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n\t\tif(target===undefined) {\n\t\t\ttarget = null;\n\t\t}\n\t\tif (LexerATNSimulator.debug && target !== null) {\n\t\t\tconsole.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n\t\t}\n\t\treturn target;\n\t}\n\n\t/**\n\t * Compute a target state for an edge in the DFA, and attempt to add the\n\t * computed state and corresponding edge to the DFA.\n\t *\n\t * @param input The input stream\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t *\n\t * @return The computed target DFA state for the given input symbol\n\t * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n\t * returns {@link //ERROR}.\n\t */\n\tcomputeTargetState(input, s, t) {\n\t\tconst reach = new OrderedATNConfigSet();\n\t\t// if we don't find an existing DFA state\n\t\t// Fill reach starting from closure, following t transitions\n\t\tthis.getReachableConfigSet(input, s.configs, reach, t);\n\n\t\tif (reach.items.length === 0) { // we got nowhere on t from s\n\t\t\tif (!reach.hasSemanticContext) {\n\t\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t\t// cause a failover from DFA later.\n\t\t\t\tthis.addDFAEdge(s, t, ATNSimulator.ERROR);\n\t\t\t}\n\t\t\t// stop when we can't match any more char\n\t\t\treturn ATNSimulator.ERROR;\n\t\t}\n\t\t// Add an edge from s to target DFA found/created for reach\n\t\treturn this.addDFAEdge(s, t, null, reach);\n\t}\n\n\tfailOrAccept(prevAccept, input, reach, t) {\n\t\tif (this.prevAccept.dfaState !== null) {\n\t\t\tconst lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n\t\t\tthis.accept(input, lexerActionExecutor, this.startIndex,\n\t\t\t\t\tprevAccept.index, prevAccept.line, prevAccept.column);\n\t\t\treturn prevAccept.dfaState.prediction;\n\t\t} else {\n\t\t\t// if no accept and EOF is first char, return EOF\n\t\t\tif (t === Token.EOF && input.index === this.startIndex) {\n\t\t\t\treturn Token.EOF;\n\t\t\t}\n\t\t\tthrow new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n\t\t}\n\t}\n\n\t/**\n\t * Given a starting configuration set, figure out all ATN configurations\n\t * we can reach upon input {@code t}. Parameter {@code reach} is a return\n\t * parameter.\n\t */\n\tgetReachableConfigSet(input, closure,\n\t\t\treach, t) {\n\t\t// this is used to skip processing for configs which have a lower priority\n\t\t// than a config that already reached an accept state for the same rule\n\t\tlet skipAlt = ATN.INVALID_ALT_NUMBER;\n\t\tfor (let i = 0; i < closure.items.length; i++) {\n\t\t\tconst cfg = closure.items[i];\n\t\t\tconst currentAltReachedAcceptState = (cfg.alt === skipAlt);\n\t\t\tif (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg\n\t\t\t\t\t\t.toString(this.recog, true));\n\t\t\t}\n\t\t\tfor (let j = 0; j < cfg.state.transitions.length; j++) {\n\t\t\t\tconst trans = cfg.state.transitions[j]; // for each transition\n\t\t\t\tconst target = this.getReachableTarget(trans, t);\n\t\t\t\tif (target !== null) {\n\t\t\t\t\tlet lexerActionExecutor = cfg.lexerActionExecutor;\n\t\t\t\t\tif (lexerActionExecutor !== null) {\n\t\t\t\t\t\tlexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n\t\t\t\t\t}\n\t\t\t\t\tconst treatEofAsEpsilon = (t === Token.EOF);\n\t\t\t\t\tconst config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);\n\t\t\t\t\tif (this.closure(input, config, reach,\n\t\t\t\t\t\t\tcurrentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n\t\t\t\t\t\t// any remaining configs for this alt have a lower priority\n\t\t\t\t\t\t// than the one that just reached an accept state.\n\t\t\t\t\t\tskipAlt = cfg.alt;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\taccept(input, lexerActionExecutor,\n\t\t\t   startIndex, index, line, charPos) {\n\t\t   if (LexerATNSimulator.debug) {\n\t\t\t   console.log(\"ACTION %s\\n\", lexerActionExecutor);\n\t\t   }\n\t\t   // seek to after last char in token\n\t\t   input.seek(index);\n\t\t   this.line = line;\n\t\t   this.column = charPos;\n\t\t   if (lexerActionExecutor !== null && this.recog !== null) {\n\t\t\t   lexerActionExecutor.execute(this.recog, input, startIndex);\n\t\t   }\n\t   }\n\n\tgetReachableTarget(trans, t) {\n\t\tif (trans.matches(t, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\t\treturn trans.target;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tcomputeStartState(input, p) {\n\t\tconst initialContext = PredictionContext.EMPTY;\n\t\tconst configs = new OrderedATNConfigSet();\n\t\tfor (let i = 0; i < p.transitions.length; i++) {\n\t\t\tconst target = p.transitions[i].target;\n\t\t\tconst cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);\n\t\t\tthis.closure(input, cfg, configs, false, false, false);\n\t\t}\n\t\treturn configs;\n\t}\n\n\t/**\n\t * Since the alternatives within any lexer decision are ordered by\n\t * preference, this method stops pursuing the closure as soon as an accept\n\t * state is reached. After the first accept state is reached by depth-first\n\t * search from {@code config}, all other (potentially reachable) states for\n\t * this rule would have a lower priority.\n\t *\n\t * @return {Boolean} {@code true} if an accept state is reached, otherwise\n\t * {@code false}.\n\t */\n\tclosure(input, config, configs,\n\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n\t\tlet cfg = null;\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"closure(\" + config.toString(this.recog, true) + \")\");\n\t\t}\n\t\tif (config.state instanceof RuleStopState) {\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tif (this.recog !== null) {\n\t\t\t\t\tconsole.log(\"closure at %s rule stop %s\\n\", this.recog.ruleNames[config.state.ruleIndex], config);\n\t\t\t\t} else {\n\t\t\t\t\tconsole.log(\"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\tif (config.context === null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t} else {\n\t\t\t\t\tconfigs.add(new LexerATNConfig({ state:config.state, context:PredictionContext.EMPTY}, config));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context !== null && !config.context.isEmpty()) {\n\t\t\t\tfor (let i = 0; i < config.context.length; i++) {\n\t\t\t\t\tif (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\t\tconst newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\t\tconst returnState = this.atn.states[config.context.getReturnState(i)];\n\t\t\t\t\t\tcfg = new LexerATNConfig({ state:returnState, context:newContext }, config);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg,\n\t\t\t\t\t\t\t\tconfigs, currentAltReachedAcceptState, speculative,\n\t\t\t\t\t\t\t\ttreatEofAsEpsilon);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\t\t// optimization\n\t\tif (!config.state.epsilonOnlyTransitions) {\n\t\t\tif (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\t\tfor (let j = 0; j < config.state.transitions.length; j++) {\n\t\t\tconst trans = config.state.transitions[j];\n\t\t\tcfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n\t\t\tif (cfg !== null) {\n\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg, configs,\n\t\t\t\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon);\n\t\t\t}\n\t\t}\n\t\treturn currentAltReachedAcceptState;\n\t}\n\n\t// side-effect: can alter configs.hasSemanticContext\n\tgetEpsilonTarget(input, config, trans,\n\t\t\tconfigs, speculative, treatEofAsEpsilon) {\n\t\tlet cfg = null;\n\t\tif (trans.serializationType === Transition.RULE) {\n\t\t\tconst newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n\t\t\tcfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);\n\t\t} else if (trans.serializationType === Transition.PRECEDENCE) {\n\t\t\tthrow \"Precedence predicates are not supported in lexers.\";\n\t\t} else if (trans.serializationType === Transition.PREDICATE) {\n\t\t\t// Track traversing semantic predicates. If we traverse,\n\t\t\t// we cannot add a DFA state for this \"reach\" computation\n\t\t\t// because the DFA would not test the predicate again in the\n\t\t\t// future. Rather than creating collections of semantic predicates\n\t\t\t// like v3 and testing them on prediction, v4 will test them on the\n\t\t\t// fly all the time using the ATN not the DFA. This is slower but\n\t\t\t// semantically it's not used that often. One of the key elements to\n\t\t\t// this predicate mechanism is not adding DFA states that see\n\t\t\t// predicates immediately afterwards in the ATN. For example,\n\n\t\t\t// a : ID {p1}? | ID {p2}? ;\n\n\t\t\t// should create the start state for rule 'a' (to save start state\n\t\t\t// competition), but should not create target of ID state. The\n\t\t\t// collection of ATN states the following ID references includes\n\t\t\t// states reached by traversing predicates. Since this is when we\n\t\t\t// test them, we cannot cash the DFA state target of ID.\n\n\t\t\tif (LexerATNSimulator.debug) {\n\t\t\t\tconsole.log(\"EVAL rule \" + trans.ruleIndex + \":\" + trans.predIndex);\n\t\t\t}\n\t\t\tconfigs.hasSemanticContext = true;\n\t\t\tif (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.ACTION) {\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\t// execute actions anywhere in the start rule for a token.\n\t\t\t\t//\n\t\t\t\t// TODO: if the entry rule is invoked recursively, some\n\t\t\t\t// actions may be executed during the recursive call. The\n\t\t\t\t// problem can appear when hasEmptyPath() is true but\n\t\t\t\t// isEmpty() is false. In this case, the config needs to be\n\t\t\t\t// split into two contexts - one with just the empty path\n\t\t\t\t// and another with everything but the empty path.\n\t\t\t\t// Unfortunately, the current algorithm does not allow\n\t\t\t\t// getEpsilonTarget to return two configurations, so\n\t\t\t\t// additional modifications are needed before we can support\n\t\t\t\t// the split operation.\n\t\t\t\tconst lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,\n\t\t\t\t\t\tthis.atn.lexerActions[trans.actionIndex]);\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);\n\t\t\t} else {\n\t\t\t\t// ignore actions in referenced rules\n\t\t\t\tcfg = new LexerATNConfig( { state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.EPSILON) {\n\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t} else if (trans.serializationType === Transition.ATOM ||\n\t\t\t\t\ttrans.serializationType === Transition.RANGE ||\n\t\t\t\t\ttrans.serializationType === Transition.SET) {\n\t\t\tif (treatEofAsEpsilon) {\n\t\t\t\tif (trans.matches(Token.EOF, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\t\t\t\tcfg = new LexerATNConfig( { state:trans.target }, config);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn cfg;\n\t}\n\n\t/**\n\t * Evaluate a predicate specified in the lexer.\n\t *\n\t * <p>If {@code speculative} is {@code true}, this method was called before\n\t * {@link //consume} for the matched character. This method should call\n\t * {@link //consume} before evaluating the predicate to ensure position\n\t * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n\t * and {@link Lexer//getcolumn}, properly reflect the current\n\t * lexer state. This method should restore {@code input} and the simulator\n\t * to the original state before returning (i.e. undo the actions made by the\n\t * call to {@link //consume}.</p>\n\t *\n\t * @param input The input stream.\n\t * @param ruleIndex The rule containing the predicate.\n\t * @param predIndex The index of the predicate within the rule.\n\t * @param speculative {@code true} if the current index in {@code input} is\n\t * one character before the predicate's location.\n\t *\n\t * @return {@code true} if the specified predicate evaluates to\n\t * {@code true}.\n\t */\n\tevaluatePredicate(input, ruleIndex,\n\t\t\tpredIndex, speculative) {\n\t\t// assume true if no recognizer was provided\n\t\tif (this.recog === null) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!speculative) {\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t}\n\t\tconst savedcolumn = this.column;\n\t\tconst savedLine = this.line;\n\t\tconst index = input.index;\n\t\tconst marker = input.mark();\n\t\ttry {\n\t\t\tthis.consume(input);\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t} finally {\n\t\t\tthis.column = savedcolumn;\n\t\t\tthis.line = savedLine;\n\t\t\tinput.seek(index);\n\t\t\tinput.release(marker);\n\t\t}\n\t}\n\n\tcaptureSimState(settings, input, dfaState) {\n\t\tsettings.index = input.index;\n\t\tsettings.line = this.line;\n\t\tsettings.column = this.column;\n\t\tsettings.dfaState = dfaState;\n\t}\n\n\taddDFAEdge(from_, tk, to, cfgs) {\n\t\tif (to === undefined) {\n\t\t\tto = null;\n\t\t}\n\t\tif (cfgs === undefined) {\n\t\t\tcfgs = null;\n\t\t}\n\t\tif (to === null && cfgs !== null) {\n\t\t\t// leading to this call, ATNConfigSet.hasSemanticContext is used as a\n\t\t\t// marker indicating dynamic predicate evaluation makes this edge\n\t\t\t// dependent on the specific input sequence, so the static edge in the\n\t\t\t// DFA should be omitted. The target DFAState is still created since\n\t\t\t// execATN has the ability to resynchronize with the DFA state cache\n\t\t\t// following the predicate evaluation step.\n\t\t\t//\n\t\t\t// TJP notes: next time through the DFA, we see a pred again and eval.\n\t\t\t// If that gets us to a previously created (but dangling) DFA\n\t\t\t// state, we can continue in pure DFA mode from there.\n\t\t\t// /\n\t\t\tconst suppressEdge = cfgs.hasSemanticContext;\n\t\t\tcfgs.hasSemanticContext = false;\n\n\t\t\tto = this.addDFAState(cfgs);\n\n\t\t\tif (suppressEdge) {\n\t\t\t\treturn to;\n\t\t\t}\n\t\t}\n\t\t// add the edge\n\t\tif (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\t// Only track edges within the DFA bounds\n\t\t\treturn to;\n\t\t}\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + tk);\n\t\t}\n\t\tif (from_.edges === null) {\n\t\t\t// make room for tokens 1..n and -1 masquerading as index 0\n\t\t\tfrom_.edges = [];\n\t\t}\n\t\tfrom_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\n\t\treturn to;\n\t}\n\n\t/**\n\t * Add a new DFA state if there isn't one with this set of\n\t * configurations already. This method also detects the first\n\t * configuration containing an ATN rule stop state. Later, when\n\t * traversing the DFA, we will know which rule to accept.\n\t */\n\taddDFAState(configs) {\n\t\tconst proposed = new DFAState(null, configs);\n\t\tlet firstConfigWithRuleStopState = null;\n\t\tfor (let i = 0; i < configs.items.length; i++) {\n\t\t\tconst cfg = configs.items[i];\n\t\t\tif (cfg.state instanceof RuleStopState) {\n\t\t\t\tfirstConfigWithRuleStopState = cfg;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (firstConfigWithRuleStopState !== null) {\n\t\t\tproposed.isAcceptState = true;\n\t\t\tproposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n\t\t\tproposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n\t\t}\n\t\tconst dfa = this.decisionToDFA[this.mode];\n\t\tconst existing = dfa.states.get(proposed);\n\t\tif (existing!==null) {\n\t\t\treturn existing;\n\t\t}\n\t\tconst newState = proposed;\n\t\tnewState.stateNumber = dfa.states.length;\n\t\tconfigs.setReadonly(true);\n\t\tnewState.configs = configs;\n\t\tdfa.states.add(newState);\n\t\treturn newState;\n\t}\n\n\tgetDFA(mode) {\n\t\treturn this.decisionToDFA[mode];\n\t}\n\n// Get the text matched so far for the current token.\n\tgetText(input) {\n\t\t// index is first lookahead char, don't include.\n\t\treturn input.getText(this.startIndex, input.index - 1);\n\t}\n\n\tconsume(input) {\n\t\tconst curChar = input.LA(1);\n\t\tif (curChar === \"\\n\".charCodeAt(0)) {\n\t\t\tthis.line += 1;\n\t\t\tthis.column = 0;\n\t\t} else {\n\t\t\tthis.column += 1;\n\t\t}\n\t\tinput.consume();\n\t}\n\n\tgetTokenName(tt) {\n\t\tif (tt === -1) {\n\t\t\treturn \"EOF\";\n\t\t} else {\n\t\t\treturn \"'\" + String.fromCharCode(tt) + \"'\";\n\t\t}\n\t}\n}\n\nLexerATNSimulator.debug = false;\nLexerATNSimulator.dfa_debug = false;\n\nLexerATNSimulator.MIN_DFA_EDGE = 0;\nLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n\nLexerATNSimulator.match_calls = 0;\n\nmodule.exports = LexerATNSimulator;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst LexerActionType = {\n    // The type of a {@link LexerChannelAction} action.\n    CHANNEL: 0,\n    // The type of a {@link LexerCustomAction} action\n    CUSTOM: 1,\n    // The type of a {@link LexerModeAction} action.\n    MODE: 2,\n    //The type of a {@link LexerMoreAction} action.\n    MORE: 3,\n    //The type of a {@link LexerPopModeAction} action.\n    POP_MODE: 4,\n    //The type of a {@link LexerPushModeAction} action.\n    PUSH_MODE: 5,\n    //The type of a {@link LexerSkipAction} action.\n    SKIP: 6,\n    //The type of a {@link LexerTypeAction} action.\n    TYPE: 7\n}\n\nclass LexerAction {\n    constructor(action) {\n        this.actionType = action;\n        this.isPositionDependent = false;\n    }\n\n    hashCode() {\n        const hash = new Hash();\n        this.updateHashCode(hash);\n        return hash.finish()\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType);\n    }\n\n    equals(other) {\n        return this === other;\n    }\n}\n\n\n/**\n * Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n *\n * <p>The {@code skip} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerSkipAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.SKIP);\n    }\n\n    execute(lexer) {\n        lexer.skip();\n    }\n\n    toString() {\n        return \"skip\";\n    }\n}\n\n// Provides a singleton instance of this parameterless lexer action.\nLexerSkipAction.INSTANCE = new LexerSkipAction();\n\n/**\n * Implements the {@code type} lexer action by calling {@link Lexer//setType}\n * with the assigned type\n */\nclass LexerTypeAction extends LexerAction {\n    constructor(type) {\n        super(LexerActionType.TYPE);\n        this.type = type;\n    }\n\n    execute(lexer) {\n        lexer.type = this.type;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.type);\n    }\n\n    equals(other) {\n        if(this === other) {\n            return true;\n        } else if (! (other instanceof LexerTypeAction)) {\n            return false;\n        } else {\n            return this.type === other.type;\n        }\n    }\n\n    toString() {\n        return \"type(\" + this.type + \")\";\n    }\n}\n\n\n/**\n * Implements the {@code pushMode} lexer action by calling\n * {@link Lexer//pushMode} with the assigned mode\n */\nclass LexerPushModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.PUSH_MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//pushMode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.pushMode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerPushModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"pushMode(\" + this.mode + \")\";\n    }\n}\n\n/**\n * Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n *\n * <p>The {@code popMode} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerPopModeAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.POP_MODE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.popMode();\n    }\n\n    toString() {\n        return \"popMode\";\n    }\n}\n\nLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n\n/**\n * Implements the {@code more} lexer action by calling {@link Lexer//more}.\n *\n * <p>The {@code more} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nclass LexerMoreAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.MORE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.more();\n    }\n\n    toString() {\n        return \"more\";\n    }\n}\n\nLexerMoreAction.INSTANCE = new LexerMoreAction();\n\n\n/**\n * Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n * the assigned mode\n */\nclass LexerModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//mode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.mode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"mode(\" + this.mode + \")\";\n    }\n}\n\n/**\n * Executes a custom lexer action by calling {@link Recognizer//action} with the\n * rule and action indexes assigned to the custom action. The implementation of\n * a custom action is added to the generated code for the lexer in an override\n * of {@link Recognizer//action} when the grammar is compiled.\n *\n * <p>This class may represent embedded actions created with the <code>{...}</code>\n * syntax in ANTLR 4, as well as actions created for lexer commands where the\n * command argument could not be evaluated when the grammar was compiled.</p>\n */\nclass LexerCustomAction extends LexerAction {\n    /**\n     * Constructs a custom lexer action with the specified rule and action\n     * indexes.\n     *\n     * @param ruleIndex The rule index to use for calls to\n     * {@link Recognizer//action}.\n     * @param actionIndex The action index to use for calls to\n     * {@link Recognizer//action}.\n     */\n    constructor(ruleIndex, actionIndex) {\n        super(LexerActionType.CUSTOM);\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>Custom actions are implemented by calling {@link Lexer//action} with the\n     * appropriate rule and action indexes.</p>\n     */\n    execute(lexer) {\n        lexer.action(null, this.ruleIndex, this.actionIndex);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.ruleIndex, this.actionIndex);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerCustomAction)) {\n            return false;\n        } else {\n            return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n        }\n    }\n}\n\n/**\n * Implements the {@code channel} lexer action by calling\n * {@link Lexer//setChannel} with the assigned channel.\n * Constructs a new {@code channel} action with the specified channel value.\n * @param channel The channel value to pass to {@link Lexer//setChannel}\n */\nclass LexerChannelAction extends LexerAction {\n    constructor(channel) {\n        super(LexerActionType.CHANNEL);\n        this.channel = channel;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//setChannel} with the\n     * value provided by {@link //getChannel}.</p>\n     */\n    execute(lexer) {\n        lexer._channel = this.channel;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.channel);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerChannelAction)) {\n            return false;\n        } else {\n            return this.channel === other.channel;\n        }\n    }\n\n    toString() {\n        return \"channel(\" + this.channel + \")\";\n    }\n}\n\n\n/**\n * This implementation of {@link LexerAction} is used for tracking input offsets\n * for position-dependent actions within a {@link LexerActionExecutor}.\n *\n * <p>This action is not serialized as part of the ATN, and is only required for\n * position-dependent lexer actions which appear at a location other than the\n * end of a rule. For more information about DFA optimizations employed for\n * lexer actions, see {@link LexerActionExecutor//append} and\n * {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n *\n * Constructs a new indexed custom action by associating a character offset\n * with a {@link LexerAction}.\n *\n * <p>Note: This class is only required for lexer actions for which\n * {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n *\n * @param offset The offset into the input {@link CharStream}, relative to\n * the token start index, at which the specified lexer action should be\n * executed.\n * @param action The lexer action to execute at a particular offset in the\n * input {@link CharStream}.\n */\nclass LexerIndexedCustomAction extends LexerAction {\n    constructor(offset, action) {\n        super(action.actionType);\n        this.offset = offset;\n        this.action = action;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>This method calls {@link //execute} on the result of {@link //getAction}\n     * using the provided {@code lexer}.</p>\n     */\n    execute(lexer) {\n        // assume the input stream position was properly set by the calling code\n        this.action.execute(lexer);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.offset, this.action);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerIndexedCustomAction)) {\n            return false;\n        } else {\n            return this.offset === other.offset && this.action === other.action;\n        }\n    }\n}\n\nmodule.exports = {\n    LexerActionType,\n    LexerSkipAction,\n    LexerChannelAction,\n    LexerCustomAction,\n    LexerIndexedCustomAction,\n    LexerMoreAction,\n    LexerTypeAction,\n    LexerPushModeAction,\n    LexerPopModeAction,\n    LexerModeAction\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {hashStuff} = require(\"../Utils\");\nconst {LexerIndexedCustomAction} = require('./LexerAction');\n\nclass LexerActionExecutor {\n\t/**\n\t * Represents an executor for a sequence of lexer actions which traversed during\n\t * the matching operation of a lexer rule (token).\n\t *\n\t * <p>The executor tracks position information for position-dependent lexer actions\n\t * efficiently, ensuring that actions appearing only at the end of the rule do\n\t * not cause bloating of the {@link DFA} created for the lexer.</p>\n\t */\n\tconstructor(lexerActions) {\n\t\tthis.lexerActions = lexerActions === null ? [] : lexerActions;\n\t\t/**\n\t\t * Caches the result of {@link //hashCode} since the hash code is an element\n\t\t * of the performance-critical {@link LexerATNConfig//hashCode} operation\n\t\t */\n\t\tthis.cachedHashCode = hashStuff(lexerActions); // \"\".join([str(la) for la in\n\t\t// lexerActions]))\n\t\treturn this;\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which encodes the current offset\n\t * for position-dependent lexer actions.\n\t *\n\t * <p>Normally, when the executor encounters lexer actions where\n\t * {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n\t * {@link IntStream//seek} on the input {@link CharStream} to set the input\n\t * position to the <em>end</em> of the current token. This behavior provides\n\t * for efficient DFA representation of lexer actions which appear at the end\n\t * of a lexer rule, even when the lexer rule matches a variable number of\n\t * characters.</p>\n\t *\n\t * <p>Prior to traversing a match transition in the ATN, the current offset\n\t * from the token start index is assigned to all position-dependent lexer\n\t * actions which have not already been assigned a fixed offset. By storing\n\t * the offsets relative to the token start index, the DFA representation of\n\t * lexer actions which appear in the middle of tokens remains efficient due\n\t * to sharing among tokens of the same length, regardless of their absolute\n\t * position in the input stream.</p>\n\t *\n\t * <p>If the current executor already has offsets assigned to all\n\t * position-dependent lexer actions, the method returns {@code this}.</p>\n\t *\n\t * @param offset The current offset to assign to all position-dependent\n\t * lexer actions which do not already have offsets assigned.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets\n\t * for all position-dependent lexer actions.\n\t */\n\tfixOffsetBeforeMatch(offset) {\n\t\tlet updatedLexerActions = null;\n\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\tif (this.lexerActions[i].isPositionDependent &&\n\t\t\t\t\t!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n\t\t\t\tif (updatedLexerActions === null) {\n\t\t\t\t\tupdatedLexerActions = this.lexerActions.concat([]);\n\t\t\t\t}\n\t\t\t\tupdatedLexerActions[i] = new LexerIndexedCustomAction(offset,\n\t\t\t\t\t\tthis.lexerActions[i]);\n\t\t\t}\n\t\t}\n\t\tif (updatedLexerActions === null) {\n\t\t\treturn this;\n\t\t} else {\n\t\t\treturn new LexerActionExecutor(updatedLexerActions);\n\t\t}\n\t}\n\n\t/**\n\t * Execute the actions encapsulated by this executor within the context of a\n\t * particular {@link Lexer}.\n\t *\n\t * <p>This method calls {@link IntStream//seek} to set the position of the\n\t * {@code input} {@link CharStream} prior to calling\n\t * {@link LexerAction//execute} on a position-dependent action. Before the\n\t * method returns, the input position will be restored to the same position\n\t * it was in when the method was invoked.</p>\n\t *\n\t * @param lexer The lexer instance.\n\t * @param input The input stream which is the source for the current token.\n\t * When this method is called, the current {@link IntStream//index} for\n\t * {@code input} should be the start of the following token, i.e. 1\n\t * character past the end of the current token.\n\t * @param startIndex The token start index. This value may be passed to\n\t * {@link IntStream//seek} to set the {@code input} position to the beginning\n\t * of the token.\n\t */\n\texecute(lexer, input, startIndex) {\n\t\tlet requiresSeek = false;\n\t\tconst stopIndex = input.index;\n\t\ttry {\n\t\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\t\tlet lexerAction = this.lexerActions[i];\n\t\t\t\tif (lexerAction instanceof LexerIndexedCustomAction) {\n\t\t\t\t\tconst offset = lexerAction.offset;\n\t\t\t\t\tinput.seek(startIndex + offset);\n\t\t\t\t\tlexerAction = lexerAction.action;\n\t\t\t\t\trequiresSeek = (startIndex + offset) !== stopIndex;\n\t\t\t\t} else if (lexerAction.isPositionDependent) {\n\t\t\t\t\tinput.seek(stopIndex);\n\t\t\t\t\trequiresSeek = false;\n\t\t\t\t}\n\t\t\t\tlexerAction.execute(lexer);\n\t\t\t}\n\t\t} finally {\n\t\t\tif (requiresSeek) {\n\t\t\t\tinput.seek(stopIndex);\n\t\t\t}\n\t\t}\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof LexerActionExecutor)) {\n\t\t\treturn false;\n\t\t} else if (this.cachedHashCode != other.cachedHashCode) {\n\t\t\treturn false;\n\t\t} else if (this.lexerActions.length != other.lexerActions.length) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tconst numActions = this.lexerActions.length\n\t\t\tfor (let idx = 0; idx < numActions; ++idx) {\n\t\t\t\tif (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which executes the actions for\n\t * the input {@code lexerActionExecutor} followed by a specified\n\t * {@code lexerAction}.\n\t *\n\t * @param lexerActionExecutor The executor for actions already traversed by\n\t * the lexer while matching a token within a particular\n\t * {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n\t * though it were an empty executor.\n\t * @param lexerAction The lexer action to execute after the actions\n\t * specified in {@code lexerActionExecutor}.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions\n\t * of {@code lexerActionExecutor} and {@code lexerAction}.\n\t */\n\tstatic append(lexerActionExecutor, lexerAction) {\n\t\tif (lexerActionExecutor === null) {\n\t\t\treturn new LexerActionExecutor([ lexerAction ]);\n\t\t}\n\t\tconst lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);\n\t\treturn new LexerActionExecutor(lexerActions);\n\t}\n}\n\n\nmodule.exports = LexerActionExecutor;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Utils = require('./../Utils');\nconst {Set, BitSet, DoubleDict} = Utils;\n\nconst ATN = require('./ATN');\nconst {ATNState, RuleStopState} = require('./ATNState');\n\nconst {ATNConfig} = require('./ATNConfig');\nconst {ATNConfigSet} = require('./ATNConfigSet');\nconst {Token} = require('./../Token');\nconst {DFAState, PredPrediction} = require('./../dfa/DFAState');\nconst ATNSimulator = require('./ATNSimulator');\nconst PredictionMode = require('./PredictionMode');\nconst RuleContext = require('./../RuleContext');\nconst ParserRuleContext = require('./../ParserRuleContext');\nconst {SemanticContext} = require('./SemanticContext');\nconst {PredictionContext} = require('./../PredictionContext');\nconst {Interval} = require('./../IntervalSet');\nconst {Transition, SetTransition, NotSetTransition, RuleTransition, ActionTransition} = require('./Transition');\nconst {NoViableAltException} = require('./../error/Errors');\nconst {SingletonPredictionContext, predictionContextFromRuleContext} = require('./../PredictionContext');\n\n\n/**\n * The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n *\n * <p>\n * The basic complexity of the adaptive strategy makes it harder to understand.\n * We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n * requests go through the DFA first. If they reach a state without an edge for\n * the current symbol, the algorithm fails over to the ATN simulation to\n * complete the DFA path for the current input (until it finds a conflict state\n * or uniquely predicting state).</p>\n *\n * <p>\n * All of that is done without using the outer context because we want to create\n * a DFA that is not dependent upon the rule invocation stack when we do a\n * prediction. One DFA works in all contexts. We avoid using context not\n * necessarily because it's slower, although it can be, but because of the DFA\n * caching problem. The closure routine only considers the rule invocation stack\n * created during prediction beginning in the decision rule. For example, if\n * prediction occurs without invoking another rule's ATN, there are no context\n * stacks in the configurations. When lack of context leads to a conflict, we\n * don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n * strategy (versus full LL(*)).</p>\n *\n * <p>\n * When SLL yields a configuration set with conflict, we rewind the input and\n * retry the ATN simulation, this time using full outer context without adding\n * to the DFA. Configuration context stacks will be the full invocation stacks\n * from the start rule. If we get a conflict using full context, then we can\n * definitively say we have a true ambiguity for that input sequence. If we\n * don't get a conflict, it implies that the decision is sensitive to the outer\n * context. (It is not context-sensitive in the sense of context-sensitive\n * grammars.)</p>\n *\n * <p>\n * The next time we reach this DFA state with an SLL conflict, through DFA\n * simulation, we will again retry the ATN simulation using full context mode.\n * This is slow because we can't save the results and have to \"interpret\" the\n * ATN each time we get that input.</p>\n *\n * <p>\n * <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n *\n * <p>\n * We could cache results from full context to predicted alternative easily and\n * that saves a lot of time but doesn't work in presence of predicates. The set\n * of visible predicates from the ATN start state changes depending on the\n * context, because closure can fall off the end of a rule. I tried to cache\n * tuples (stack context, semantic context, predicted alt) but it was slower\n * than interpreting and much more complicated. Also required a huge amount of\n * memory. The goal is not to create the world's fastest parser anyway. I'd like\n * to keep this algorithm simple. By launching multiple threads, we can improve\n * the speed of parsing across a large number of files.</p>\n *\n * <p>\n * There is no strict ordering between the amount of input used by SLL vs LL,\n * which makes it really hard to build a cache for full context. Let's say that\n * we have input A B C that leads to an SLL conflict with full context X. That\n * implies that using X we might only use A B but we could also use A B C D to\n * resolve conflict. Input A B C D could predict alternative 1 in one position\n * in the input and A B C E could predict alternative 2 in another position in\n * input. The conflicting SLL configurations could still be non-unique in the\n * full context prediction, which would lead us to requiring more input than the\n * original A B C.\tTo make a\tprediction cache work, we have to track\tthe exact\n * input\tused during the previous prediction. That amounts to a cache that maps\n * X to a specific DFA for that context.</p>\n *\n * <p>\n * Something should be done for left-recursive expression predictions. They are\n * likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n * with full LL thing Sam does.</p>\n *\n * <p>\n * <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n *\n * <p>\n * We avoid doing full context retry when the outer context is empty, we did not\n * dip into the outer context by falling off the end of the decision state rule,\n * or when we force SLL mode.</p>\n *\n * <p>\n * As an example of the not dip into outer context case, consider as super\n * constructor calls versus function calls. One grammar might look like\n * this:</p>\n *\n * <pre>\n * ctorBody\n *   : '{' superCall? stat* '}'\n *   ;\n * </pre>\n *\n * <p>\n * Or, you might see something like</p>\n *\n * <pre>\n * stat\n *   : superCall ';'\n *   | expression ';'\n *   | ...\n *   ;\n * </pre>\n *\n * <p>\n * In both cases I believe that no closure operations will dip into the outer\n * context. In the first case ctorBody in the worst case will stop at the '}'.\n * In the 2nd case it should stop at the ';'. Both cases should stay within the\n * entry rule and not dip into the outer context.</p>\n *\n * <p>\n * <strong>PREDICATES</strong></p>\n *\n * <p>\n * Predicates are always evaluated if present in either SLL or LL both. SLL and\n * LL simulation deals with predicates differently. SLL collects predicates as\n * it performs closure operations like ANTLR v3 did. It delays predicate\n * evaluation until it reaches and accept state. This allows us to cache the SLL\n * ATN simulation whereas, if we had evaluated predicates on-the-fly during\n * closure, the DFA state configuration sets would be different and we couldn't\n * build up a suitable DFA.</p>\n *\n * <p>\n * When building a DFA accept state during ATN simulation, we evaluate any\n * predicates and return the sole semantically valid alternative. If there is\n * more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n * we throw an exception. Alternatives without predicates act like they have\n * true predicates. The simple way to think about it is to strip away all\n * alternatives with false predicates and choose the minimum alternative that\n * remains.</p>\n *\n * <p>\n * When we start in the DFA and reach an accept state that's predicated, we test\n * those and return the minimum semantically viable alternative. If no\n * alternatives are viable, we throw an exception.</p>\n *\n * <p>\n * During full LL ATN simulation, closure always evaluates predicates and\n * on-the-fly. This is crucial to reducing the configuration set size during\n * closure. It hits a landmine when parsing with the Java grammar, for example,\n * without this on-the-fly evaluation.</p>\n *\n * <p>\n * <strong>SHARING DFA</strong></p>\n *\n * <p>\n * All instances of the same parser share the same decision DFAs through a\n * static field. Each instance gets its own ATN simulator but they share the\n * same {@link //decisionToDFA} field. They also share a\n * {@link PredictionContextCache} object that makes sure that all\n * {@link PredictionContext} objects are shared among the DFA states. This makes\n * a big size difference.</p>\n *\n * <p>\n * <strong>THREAD SAFETY</strong></p>\n *\n * <p>\n * The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n * it adds a new DFA object to that array. {@link //addDFAEdge}\n * locks on the DFA for the current decision when setting the\n * {@link DFAState//edges} field. {@link //addDFAState} locks on\n * the DFA for the current decision when looking up a DFA state to see if it\n * already exists. We must make sure that all requests to add DFA states that\n * are equivalent result in the same shared DFA object. This is because lots of\n * threads will be trying to update the DFA at once. The\n * {@link //addDFAState} method also locks inside the DFA lock\n * but this time on the shared context cache when it rebuilds the\n * configurations' {@link PredictionContext} objects using cached\n * subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n * safe as long as we can guarantee that all threads referencing\n * {@code s.edge[t]} get the same physical target {@link DFAState}, or\n * {@code null}. Once into the DFA, the DFA simulation does not reference the\n * {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n * targets. The DFA simulator will either find {@link DFAState//edges} to be\n * {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n * {@code dfa.edges[t]} to be non-null. The\n * {@link //addDFAEdge} method could be racing to set the field\n * but in either case the DFA simulator works; if {@code null}, and requests ATN\n * simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n * way it will work because it's not doing a test and set operation.</p>\n *\n * <p>\n * <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n * Parsing)</strong></p>\n *\n * <p>\n * Sam pointed out that if SLL does not give a syntax error, then there is no\n * point in doing full LL, which is slower. We only have to try LL if we get a\n * syntax error. For maximum speed, Sam starts the parser set to pure SLL\n * mode with the {@link BailErrorStrategy}:</p>\n *\n * <pre>\n * parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n * parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n * </pre>\n *\n * <p>\n * If it does not get a syntax error, then we're done. If it does get a syntax\n * error, we need to retry with the combined SLL/LL strategy.</p>\n *\n * <p>\n * The reason this works is as follows. If there are no SLL conflicts, then the\n * grammar is SLL (at least for that input set). If there is an SLL conflict,\n * the full LL analysis must yield a set of viable alternatives which is a\n * subset of the alternatives reported by SLL. If the LL set is a singleton,\n * then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n * set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n * is truly ambiguous on the current input. If the LL set is smaller, then the\n * SLL conflict resolution might choose an alternative that the full LL would\n * rule out as a possibility based upon better context information. If that's\n * the case, then the SLL parse will definitely get an error because the full LL\n * analysis says it's not viable. If SLL conflict resolution chooses an\n * alternative within the LL set, them both SLL and LL would choose the same\n * alternative because they both choose the minimum of multiple conflicting\n * alternatives.</p>\n *\n * <p>\n * Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n * a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n * parsing will get an error because SLL will pursue alternative 1. If\n * <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n * choose the same alternative because alternative one is the minimum of either\n * set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n * error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n *\n * <p>\n * Of course, if the input is invalid, then we will get an error for sure in\n * both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n * the input.</p>\n */\nclass ParserATNSimulator extends ATNSimulator {\n    constructor(parser, atn, decisionToDFA, sharedContextCache) {\n        super(atn, sharedContextCache);\n        this.parser = parser;\n        this.decisionToDFA = decisionToDFA;\n        // SLL, LL, or LL + exact ambig detection?//\n        this.predictionMode = PredictionMode.LL;\n        // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n        this._input = null;\n        this._startIndex = 0;\n        this._outerContext = null;\n        this._dfa = null;\n        /**\n         * Each prediction operation uses a cache for merge of prediction contexts.\n         *  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n         *  isn't synchronized but we're ok since two threads shouldn't reuse same\n         *  parser/atnsim object because it can only handle one input at a time.\n         *  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n         *  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n         *  also be examined during cache lookup.\n         */\n        this.mergeCache = null;\n        this.debug = false;\n        this.debug_closure = false;\n        this.debug_add = false;\n        this.debug_list_atn_decisions = false;\n        this.dfa_debug = false;\n        this.retry_debug = false;\n    }\n\n    reset() {}\n\n    adaptivePredict(input, decision, outerContext) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"adaptivePredict decision \" + decision +\n                                   \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                   \" line \" + input.LT(1).line + \":\" +\n                                   input.LT(1).column);\n        }\n        this._input = input;\n        this._startIndex = input.index;\n        this._outerContext = outerContext;\n\n        const dfa = this.decisionToDFA[decision];\n        this._dfa = dfa;\n        const m = input.mark();\n        const index = input.index;\n\n        // Now we are certain to have a specific decision's DFA\n        // But, do we still need an initial state?\n        try {\n            let s0;\n            if (dfa.precedenceDfa) {\n                // the start state for a precedence DFA depends on the current\n                // parser precedence, and is provided by a DFA method.\n                s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n            } else {\n                // the start state for a \"regular\" DFA is just s0\n                s0 = dfa.s0;\n            }\n            if (s0===null) {\n                if (outerContext===null) {\n                    outerContext = RuleContext.EMPTY;\n                }\n                if (this.debug || this.debug_list_atn_decisions) {\n                    console.log(\"predictATN decision \" + dfa.decision +\n                                       \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                       \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n                }\n\n                const fullCtx = false;\n                let s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\n                if( dfa.precedenceDfa) {\n                    // If this is a precedence DFA, we use applyPrecedenceFilter\n                    // to convert the computed start state to a precedence start\n                    // state. We then use DFA.setPrecedenceStartState to set the\n                    // appropriate start state for the precedence level rather\n                    // than simply setting DFA.s0.\n                    //\n                    dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway\n                    s0_closure = this.applyPrecedenceFilter(s0_closure);\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n                } else {\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.s0 = s0;\n                }\n            }\n            const alt = this.execATN(dfa, s0, input, index, outerContext);\n            if (this.debug) {\n                console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.literalNames, this.parser.symbolicNames));\n            }\n            return alt;\n        } finally {\n            this._dfa = null;\n            this.mergeCache = null; // wack cache after each prediction\n            input.seek(index);\n            input.release(m);\n        }\n    }\n\n    /**\n     * Performs ATN simulation to compute a predicted alternative based\n     *  upon the remaining input, but also updates the DFA cache to avoid\n     *  having to traverse the ATN again for the same input sequence.\n     *\n     * There are some key conditions we're looking for after computing a new\n     * set of ATN configs (proposed DFA state):\n     *       if the set is empty, there is no viable alternative for current symbol\n     *       does the state uniquely predict an alternative?\n     *       does the state have a conflict that would prevent us from\n     *         putting it on the work list?\n     *\n     * We also have some key operations to do:\n     *       add an edge from previous DFA state to potentially new DFA state, D,\n     *         upon current symbol but only if adding to work list, which means in all\n     *         cases except no viable alternative (and possibly non-greedy decisions?)\n     *       collecting predicates and adding semantic context to DFA accept states\n     *       adding rule context to context-sensitive DFA accept states\n     *       consuming an input symbol\n     *       reporting a conflict\n     *       reporting an ambiguity\n     *       reporting a context sensitivity\n     *       reporting insufficient predicates\n     *\n     * cover these cases:\n     *    dead end\n     *    single alt\n     *    single alt + preds\n     *    conflict\n     *    conflict + preds\n     *\n     */\n    execATN(dfa, s0, input, startIndex, outerContext ) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"execATN decision \" + dfa.decision +\n                    \" exec LA(1)==\" + this.getLookaheadName(input) +\n                    \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n        }\n        let alt;\n        let previousD = s0;\n\n        if (this.debug) {\n            console.log(\"s0 = \" + s0);\n        }\n        let t = input.LA(1);\n        while(true) { // while more work\n            let D = this.getExistingTargetState(previousD, t);\n            if(D===null) {\n                D = this.computeTargetState(dfa, previousD, t);\n            }\n            if(D===ATNSimulator.ERROR) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for SLL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n                input.seek(startIndex);\n                alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n                // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n                let conflictingAlts = null;\n                if (D.predicates!==null) {\n                    if (this.debug) {\n                        console.log(\"DFA state has preds in DFA sim LL failover\");\n                    }\n                    const conflictIndex = input.index;\n                    if(conflictIndex !== startIndex) {\n                        input.seek(startIndex);\n                    }\n                    conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n                    if (conflictingAlts.length===1) {\n                        if(this.debug) {\n                            console.log(\"Full LL avoided\");\n                        }\n                        return conflictingAlts.minValue();\n                    }\n                    if (conflictIndex !== startIndex) {\n                        // restore the index so reporting the fallback to full\n                        // context occurs with the index at the correct spot\n                        input.seek(conflictIndex);\n                    }\n                }\n                if (this.dfa_debug) {\n                    console.log(\"ctx sensitive state \" + outerContext +\" in \" + D);\n                }\n                const fullCtx = true;\n                const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n                this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n                alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n                return alt;\n            }\n            if (D.isAcceptState) {\n                if (D.predicates===null) {\n                    return D.prediction;\n                }\n                const stopIndex = input.index;\n                input.seek(startIndex);\n                const alts = this.evalSemanticContext(D.predicates, outerContext, true);\n                if (alts.length===0) {\n                    throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n                } else if (alts.length===1) {\n                    return alts.minValue();\n                } else {\n                    // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n                    this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n                    return alts.minValue();\n                }\n            }\n            previousD = D;\n\n            if (t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n    }\n\n    /**\n     * Get an existing target state for an edge in the DFA. If the target state\n     * for the edge has not yet been computed or is otherwise not available,\n     * this method returns {@code null}.\n     *\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     * @return The existing target DFA state for the given input symbol\n     * {@code t}, or {@code null} if the target state for this edge is not\n     * already cached\n     */\n    getExistingTargetState(previousD, t) {\n        const edges = previousD.edges;\n        if (edges===null) {\n            return null;\n        } else {\n            return edges[t + 1] || null;\n        }\n    }\n\n    /**\n     * Compute a target state for an edge in the DFA, and attempt to add the\n     * computed state and corresponding edge to the DFA.\n     *\n     * @param dfa The DFA\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     *\n     * @return The computed target DFA state for the given input symbol\n     * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n     * returns {@link //ERROR\n     */\n    computeTargetState(dfa, previousD, t) {\n       const reach = this.computeReachSet(previousD.configs, t, false);\n        if(reach===null) {\n            this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n            return ATNSimulator.ERROR;\n        }\n        // create new target state; we'll add to DFA after it's complete\n        let D = new DFAState(null, reach);\n\n        const predictedAlt = this.getUniqueAlt(reach);\n\n        if (this.debug) {\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            console.log(\"SLL altSubSets=\" + Utils.arrayToString(altSubSets) +\n                        /*\", previous=\" + previousD.configs + */\n                        \", configs=\" + reach +\n                        \", predict=\" + predictedAlt +\n                        \", allSubsetsConflict=\" +\n                        PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" +\n                        this.getConflictingAlts(reach));\n        }\n        if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {\n            // NO CONFLICT, UNIQUELY PREDICTED ALT\n            D.isAcceptState = true;\n            D.configs.uniqueAlt = predictedAlt;\n            D.prediction = predictedAlt;\n        } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n            // MORE THAN ONE VIABLE ALTERNATIVE\n            D.configs.conflictingAlts = this.getConflictingAlts(reach);\n            D.requiresFullContext = true;\n            // in SLL-only mode, we will stop at this state and return the minimum alt\n            D.isAcceptState = true;\n            D.prediction = D.configs.conflictingAlts.minValue();\n        }\n        if (D.isAcceptState && D.configs.hasSemanticContext) {\n            this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n            if( D.predicates!==null) {\n                D.prediction = ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        // all adds to dfa are done after we've created full D state\n        D = this.addDFAEdge(dfa, previousD, t, D);\n        return D;\n    }\n\n    predicateDFAState(dfaState, decisionState) {\n        // We need to test all predicates, even in DFA states that\n        // uniquely predict alternative.\n        const nalts = decisionState.transitions.length;\n        // Update DFA so reach becomes accept state with (predicate,alt)\n        // pairs if preds found for conflicting alts\n        const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n        const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n        if (altToPred!==null) {\n            dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n            dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n        } else {\n            // There are preds in configs but they might go away\n            // when OR'd together like {p}? || NONE == NONE. If neither\n            // alt has preds, resolve to min alt\n            dfaState.prediction = altsToCollectPredsFrom.minValue();\n        }\n    }\n\n// comes back with reach.uniqueAlt set to a valid alt\n    execATNWithFullContext(dfa, D, // how far we got before failing over\n                                         s0,\n                                         input,\n                                         startIndex,\n                                         outerContext) {\n        if (this.debug || this.debug_list_atn_decisions) {\n            console.log(\"execATNWithFullContext \"+s0);\n        }\n        const fullCtx = true;\n        let foundExactAmbig = false;\n        let reach;\n        let previous = s0;\n        input.seek(startIndex);\n        let t = input.LA(1);\n        let predictedAlt = -1;\n        while (true) { // while more work\n            reach = this.computeReachSet(previous, t, fullCtx);\n            if (reach===null) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for LL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previous, startIndex);\n                input.seek(startIndex);\n                const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            if(this.debug) {\n                console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" +\n                      PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" +\n                      PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n            }\n            reach.uniqueAlt = this.getUniqueAlt(reach);\n            // unique prediction?\n            if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {\n                predictedAlt = reach.uniqueAlt;\n                break;\n            } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n                predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n                if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n                    break;\n                }\n            } else {\n                // In exact ambiguity mode, we never try to terminate early.\n                // Just keeps scarfing until we know what the conflict is\n                if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n                    foundExactAmbig = true;\n                    predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n                    break;\n                }\n                // else there are multiple non-conflicting subsets or\n                // we're not sure what the ambiguity is yet.\n                // So, keep going.\n            }\n            previous = reach;\n            if( t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n        // If the configuration set uniquely predicts an alternative,\n        // without conflict, then we know that it's a full LL decision\n        // not SLL.\n        if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {\n            this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n            return predictedAlt;\n        }\n        // We do not check predicates here because we have checked them\n        // on-the-fly when doing full context prediction.\n\n        //\n        // In non-exact ambiguity detection mode, we might\tactually be able to\n        // detect an exact ambiguity, but I'm not going to spend the cycles\n        // needed to check. We only emit ambiguity warnings in exact ambiguity\n        // mode.\n        //\n        // For example, we might know that we have conflicting configurations.\n        // But, that does not mean that there is no way forward without a\n        // conflict. It's possible to have nonconflicting alt subsets as in:\n\n        // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n        // from\n        //\n        //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n        //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n        //\n        // In this case, (17,1,[5 $]) indicates there is some next sequence that\n        // would resolve this without conflict to alternative 1. Any other viable\n        // next sequence, however, is associated with a conflict.  We stop\n        // looking for input because no amount of further lookahead will alter\n        // the fact that we should predict alternative 1.  We just can't say for\n        // sure that there is an ambiguity without looking further.\n\n        this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\n        return predictedAlt;\n    }\n\n    computeReachSet(closure, t, fullCtx) {\n        if (this.debug) {\n            console.log(\"in computeReachSet, starting closure: \" + closure);\n        }\n        if( this.mergeCache===null) {\n            this.mergeCache = new DoubleDict();\n        }\n        const intermediate = new ATNConfigSet(fullCtx);\n\n        // Configurations already in a rule stop state indicate reaching the end\n        // of the decision rule (local context) or end of the start rule (full\n        // context). Once reached, these configurations are never updated by a\n        // closure operation, so they are handled separately for the performance\n        // advantage of having a smaller intermediate set when calling closure.\n        //\n        // For full-context reach operations, separate handling is required to\n        // ensure that the alternative matching the longest overall sequence is\n        // chosen when multiple such configurations can match the input.\n\n        let skippedStopStates = null;\n\n        // First figure out where we can reach on input t\n        for (let i=0; i<closure.items.length;i++) {\n            const c = closure.items[i];\n            if(this.debug) {\n                console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n            }\n            if (c.state instanceof RuleStopState) {\n                if (fullCtx || t === Token.EOF) {\n                    if (skippedStopStates===null) {\n                        skippedStopStates = [];\n                    }\n                    skippedStopStates.push(c);\n                    if(this.debug_add) {\n                        console.log(\"added \" + c + \" to skippedStopStates\");\n                    }\n                }\n                continue;\n            }\n            for(let j=0;j<c.state.transitions.length;j++) {\n                const trans = c.state.transitions[j];\n                const target = this.getReachableTarget(trans, t);\n                if (target!==null) {\n                    const cfg = new ATNConfig({state:target}, c);\n                    intermediate.add(cfg, this.mergeCache);\n                    if(this.debug_add) {\n                        console.log(\"added \" + cfg + \" to intermediate\");\n                    }\n                }\n            }\n        }\n        // Now figure out where the reach operation can take us...\n        let reach = null;\n\n        // This block optimizes the reach operation for intermediate sets which\n        // trivially indicate a termination state for the overall\n        // adaptivePredict operation.\n        //\n        // The conditions assume that intermediate\n        // contains all configurations relevant to the reach set, but this\n        // condition is not true when one or more configurations have been\n        // withheld in skippedStopStates, or when the current symbol is EOF.\n        //\n        if (skippedStopStates===null && t!==Token.EOF) {\n            if (intermediate.items.length===1) {\n                // Don't pursue the closure if there is just one state.\n                // It can only have one alternative; just add to result\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            }\n        }\n        // If the reach set could not be trivially determined, perform a closure\n        // operation on the intermediate set to compute its initial value.\n        //\n        if (reach===null) {\n            reach = new ATNConfigSet(fullCtx);\n            const closureBusy = new Set();\n            const treatEofAsEpsilon = t === Token.EOF;\n            for (let k=0; k<intermediate.items.length;k++) {\n                this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n            }\n        }\n        if (t === Token.EOF) {\n            // After consuming EOF no additional input is possible, so we are\n            // only interested in configurations which reached the end of the\n            // decision rule (local context) or end of the start rule (full\n            // context). Update reach to contain only these configurations. This\n            // handles both explicit EOF transitions in the grammar and implicit\n            // EOF transitions following the end of the decision or start rule.\n            //\n            // When reach==intermediate, no closure operation was performed. In\n            // this case, removeAllConfigsNotInRuleStopState needs to check for\n            // reachable rule stop states as well as configurations already in\n            // a rule stop state.\n            //\n            // This is handled before the configurations in skippedStopStates,\n            // because any configurations potentially added from that list are\n            // already guaranteed to meet this condition whether or not it's\n            // required.\n            //\n            reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n        }\n        // If skippedStopStates!==null, then it contains at least one\n        // configuration. For full-context reach operations, these\n        // configurations reached the end of the start rule, in which case we\n        // only add them back to reach if no configuration during the current\n        // closure operation reached such a state. This ensures adaptivePredict\n        // chooses an alternative matching the longest overall sequence when\n        // multiple alternatives are viable.\n        //\n        if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {\n            for (let l=0; l<skippedStopStates.length;l++) {\n                reach.add(skippedStopStates[l], this.mergeCache);\n            }\n        }\n        if (reach.items.length===0) {\n            return null;\n        } else {\n            return reach;\n        }\n    }\n\n    /**\n     * Return a configuration set containing only the configurations from\n     * {@code configs} which are in a {@link RuleStopState}. If all\n     * configurations in {@code configs} are already in a rule stop state, this\n     * method simply returns {@code configs}.\n     *\n     * <p>When {@code lookToEndOfRule} is true, this method uses\n     * {@link ATN//nextTokens} for each configuration in {@code configs} which is\n     * not already in a rule stop state to see if a rule stop state is reachable\n     * from the configuration via epsilon-only transitions.</p>\n     *\n     * @param configs the configuration set to update\n     * @param lookToEndOfRule when true, this method checks for rule stop states\n     * reachable by epsilon-only transitions from each configuration in\n     * {@code configs}.\n     *\n     * @return {@code configs} if all configurations in {@code configs} are in a\n     * rule stop state, otherwise return a new configuration set containing only\n     * the configurations from {@code configs} which are in a rule stop state\n     */\n    removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return configs;\n        }\n        const result = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length;i++) {\n            const config = configs.items[i];\n            if (config.state instanceof RuleStopState) {\n                result.add(config, this.mergeCache);\n                continue;\n            }\n            if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n                const nextTokens = this.atn.nextTokens(config.state);\n                if (nextTokens.contains(Token.EPSILON)) {\n                    const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n                    result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);\n                }\n            }\n        }\n        return result;\n    }\n\n    computeStartState(p, ctx, fullCtx) {\n        // always at least the implicit call to start rule\n        const initialContext = predictionContextFromRuleContext(this.atn, ctx);\n        const configs = new ATNConfigSet(fullCtx);\n        for(let i=0;i<p.transitions.length;i++) {\n            const target = p.transitions[i].target;\n            const c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);\n            const closureBusy = new Set();\n            this.closure(c, configs, closureBusy, true, fullCtx, false);\n        }\n        return configs;\n    }\n\n    /**\n     * This method transforms the start state computed by\n     * {@link //computeStartState} to the special start state used by a\n     * precedence DFA for a particular precedence value. The transformation\n     * process applies the following changes to the start state's configuration\n     * set.\n     *\n     * <ol>\n     * <li>Evaluate the precedence predicates for each configuration using\n     * {@link SemanticContext//evalPrecedence}.</li>\n     * <li>Remove all configurations which predict an alternative greater than\n     * 1, for which another configuration that predicts alternative 1 is in the\n     * same ATN state with the same prediction context. This transformation is\n     * valid for the following reasons:\n     * <ul>\n     * <li>The closure block cannot contain any epsilon transitions which bypass\n     * the body of the closure, so all states reachable via alternative 1 are\n     * part of the precedence alternatives of the transformed left-recursive\n     * rule.</li>\n     * <li>The \"primary\" portion of a left recursive rule cannot contain an\n     * epsilon transition, so the only way an alternative other than 1 can exist\n     * in a state that is also reachable via alternative 1 is by nesting calls\n     * to the left-recursive rule, with the outer calls not being at the\n     * preferred precedence level.</li>\n     * </ul>\n     * </li>\n     * </ol>\n     *\n     * <p>\n     * The prediction context must be considered by this filter to address\n     * situations like the following.\n     * </p>\n     * <code>\n     * <pre>\n     * grammar TA;\n     * prog: statement* EOF;\n     * statement: letterA | statement letterA 'b' ;\n     * letterA: 'a';\n     * </pre>\n     * </code>\n     * <p>\n     * If the above grammar, the ATN state immediately before the token\n     * reference {@code 'a'} in {@code letterA} is reachable from the left edge\n     * of both the primary and closure blocks of the left-recursive rule\n     * {@code statement}. The prediction context associated with each of these\n     * configurations distinguishes between them, and prevents the alternative\n     * which stepped out to {@code prog} (and then back in to {@code statement}\n     * from being eliminated by the filter.\n     * </p>\n     *\n     * @param configs The configuration set computed by\n     * {@link //computeStartState} as the start state for the DFA.\n     * @return The transformed configuration set representing the start state\n     * for a precedence DFA at a particular precedence level (determined by\n     * calling {@link Parser//getPrecedence})\n     */\n    applyPrecedenceFilter(configs) {\n        let config;\n        const statesFromAlt1 = [];\n        const configSet = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            // handle alt 1 first\n            if (config.alt !== 1) {\n                continue;\n            }\n            const updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n            if (updatedContext===null) {\n                // the configuration was eliminated\n                continue;\n            }\n            statesFromAlt1[config.state.stateNumber] = config.context;\n            if (updatedContext !== config.semanticContext) {\n                configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);\n            } else {\n                configSet.add(config, this.mergeCache);\n            }\n        }\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            if (config.alt === 1) {\n                // already handled\n                continue;\n            }\n            // In the future, this elimination step could be updated to also\n            // filter the prediction context for alternatives predicting alt>1\n            // (basically a graph subtraction algorithm).\n            if (!config.precedenceFilterSuppressed) {\n                const context = statesFromAlt1[config.state.stateNumber] || null;\n                if (context!==null && context.equals(config.context)) {\n                    // eliminated\n                    continue;\n                }\n            }\n            configSet.add(config, this.mergeCache);\n        }\n        return configSet;\n    }\n\n    getReachableTarget(trans, ttype) {\n        if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n            return trans.target;\n        } else {\n            return null;\n        }\n    }\n\n    getPredsForAmbigAlts(ambigAlts, configs, nalts) {\n        // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n        // altToPred starts as an array of all null contexts. The entry at index i\n        // corresponds to alternative i. altToPred[i] may have one of three values:\n        //   1. null: no ATNConfig c is found such that c.alt==i\n        //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n        //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n        //      alt i has at least one unpredicated config.\n        //   3. Non-NONE Semantic Context: There exists at least one, and for all\n        //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n        //\n        // From this, it is clear that NONE||anything==NONE.\n        //\n        let altToPred = [];\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if(ambigAlts.contains( c.alt )) {\n                altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n            }\n        }\n        let nPredAlts = 0;\n        for (let i =1;i< nalts+1;i++) {\n            const pred = altToPred[i] || null;\n            if (pred===null) {\n                altToPred[i] = SemanticContext.NONE;\n            } else if (pred !== SemanticContext.NONE) {\n                nPredAlts += 1;\n            }\n        }\n        // nonambig alts are null in altToPred\n        if (nPredAlts===0) {\n            altToPred = null;\n        }\n        if (this.debug) {\n            console.log(\"getPredsForAmbigAlts result \" + Utils.arrayToString(altToPred));\n        }\n        return altToPred;\n    }\n\n    getPredicatePredictions(ambigAlts, altToPred) {\n        const pairs = [];\n        let containsPredicate = false;\n        for (let i=1; i<altToPred.length;i++) {\n            const pred = altToPred[i];\n            // unpredicated is indicated by SemanticContext.NONE\n            if( ambigAlts!==null && ambigAlts.contains( i )) {\n                pairs.push(new PredPrediction(pred, i));\n            }\n            if (pred !== SemanticContext.NONE) {\n                containsPredicate = true;\n            }\n        }\n        if (! containsPredicate) {\n            return null;\n        }\n        return pairs;\n    }\n\n    /**\n     * This method is used to improve the localization of error messages by\n     * choosing an alternative rather than throwing a\n     * {@link NoViableAltException} in particular prediction scenarios where the\n     * {@link //ERROR} state was reached during ATN simulation.\n     *\n     * <p>\n     * The default implementation of this method uses the following\n     * algorithm to identify an ATN configuration which successfully parsed the\n     * decision entry rule. Choosing such an alternative ensures that the\n     * {@link ParserRuleContext} returned by the calling rule will be complete\n     * and valid, and the syntax error will be reported later at a more\n     * localized location.</p>\n     *\n     * <ul>\n     * <li>If a syntactically valid path or paths reach the end of the decision rule and\n     * they are semantically valid if predicated, return the min associated alt.</li>\n     * <li>Else, if a semantically invalid but syntactically valid path exist\n     * or paths exist, return the minimum associated alt.\n     * </li>\n     * <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n     * </ul>\n     *\n     * <p>\n     * In some scenarios, the algorithm described above could predict an\n     * alternative which will result in a {@link FailedPredicateException} in\n     * the parser. Specifically, this could occur if the <em>only</em> configuration\n     * capable of successfully parsing to the end of the decision rule is\n     * blocked by a semantic predicate. By choosing this alternative within\n     * {@link //adaptivePredict} instead of throwing a\n     * {@link NoViableAltException}, the resulting\n     * {@link FailedPredicateException} in the parser will identify the specific\n     * predicate which is preventing the parser from successfully parsing the\n     * decision rule, which helps developers identify and correct logic errors\n     * in semantic predicates.\n     * </p>\n     *\n     * @param configs The ATN configurations which were valid immediately before\n     * the {@link //ERROR} state was reached\n     * @param outerContext The is the \\gamma_0 initial parser context from the paper\n     * or the parser stack at the instant before prediction commences.\n     *\n     * @return The value to return from {@link //adaptivePredict}, or\n     * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n     * identified and {@link //adaptivePredict} should report an error instead\n     */\n    getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {\n        const cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n        const semValidConfigs = cfgs[0];\n        const semInvalidConfigs = cfgs[1];\n        let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n        if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists\n            return alt;\n        }\n        // Is there a syntactically valid path with a failed pred?\n        if (semInvalidConfigs.items.length>0) {\n            alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n            if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists\n                return alt;\n            }\n        }\n        return ATN.INVALID_ALT_NUMBER;\n    }\n\n    getAltThatFinishedDecisionEntryRule(configs) {\n        const alts = [];\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {\n                if(alts.indexOf(c.alt)<0) {\n                    alts.push(c.alt);\n                }\n            }\n        }\n        if (alts.length===0) {\n            return ATN.INVALID_ALT_NUMBER;\n        } else {\n            return Math.min.apply(null, alts);\n        }\n    }\n\n    /**\n     * Walk the list of configurations and split them according to\n     * those that have preds evaluating to true/false.  If no pred, assume\n     * true pred and include in succeeded set.  Returns Pair of sets.\n     *\n     * Create a new set so as not to alter the incoming parameter.\n     *\n     * Assumption: the input stream has been restored to the starting point\n     * prediction, which is where predicates need to evaluate.*/\n    splitAccordingToSemanticValidity( configs, outerContext) {\n        const succeeded = new ATNConfigSet(configs.fullCtx);\n        const failed = new ATNConfigSet(configs.fullCtx);\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.semanticContext !== SemanticContext.NONE) {\n                const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n                if (predicateEvaluationResult) {\n                    succeeded.add(c);\n                } else {\n                    failed.add(c);\n                }\n            } else {\n                succeeded.add(c);\n            }\n        }\n        return [succeeded, failed];\n    }\n\n    /**\n     * Look through a list of predicate/alt pairs, returning alts for the\n     * pairs that win. A {@code NONE} predicate indicates an alt containing an\n     * unpredicated config which behaves as \"always true.\" If !complete\n     * then we stop at the first predicate that evaluates to true. This\n     * includes pairs with null predicates.\n     */\n    evalSemanticContext(predPredictions, outerContext, complete) {\n        const predictions = new BitSet();\n        for(let i=0;i<predPredictions.length;i++) {\n            const pair = predPredictions[i];\n            if (pair.pred === SemanticContext.NONE) {\n                predictions.add(pair.alt);\n                if (! complete) {\n                    break;\n                }\n                continue;\n            }\n            const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n            if (this.debug || this.dfa_debug) {\n                console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n            }\n            if (predicateEvaluationResult) {\n                if (this.debug || this.dfa_debug) {\n                    console.log(\"PREDICT \" + pair.alt);\n                }\n                predictions.add(pair.alt);\n                if (! complete) {\n                    break;\n                }\n            }\n        }\n        return predictions;\n    }\n\n// TODO: If we are doing predicates, there is no point in pursuing\n//     closure operations if we reach a DFA state that uniquely predicts\n//     alternative. We will not be caching that DFA state and it is a\n//     waste to pursue the closure. Might have to advance when we do\n//     ambig detection thought :(\n//\n    closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n        const initialDepth = 0;\n        this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,\n                                 fullCtx, initialDepth, treatEofAsEpsilon);\n    }\n\n    closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        if (this.debug || this.debug_closure) {\n            console.log(\"closure(\" + config.toString(this.parser,true) + \")\");\n            // console.log(\"configs(\" + configs.toString() + \")\");\n            if(config.reachesIntoOuterContext>50) {\n                throw \"problem\";\n            }\n        }\n        if (config.state instanceof RuleStopState) {\n            // We hit rule end. If we have context info, use it\n            // run thru all possible stack tops in ctx\n            if (! config.context.isEmpty()) {\n                for (let i =0; i<config.context.length; i++) {\n                    if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n                        if (fullCtx) {\n                            configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);\n                            continue;\n                        } else {\n                            // we have no context info, just chase follow links (if greedy)\n                            if (this.debug) {\n                                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                            }\n                            this.closure_(config, configs, closureBusy, collectPredicates,\n                                     fullCtx, depth, treatEofAsEpsilon);\n                        }\n                        continue;\n                    }\n                    const returnState = this.atn.states[config.context.getReturnState(i)];\n                    const newContext = config.context.getParent(i); // \"pop\" return state\n                    const parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};\n                    const c = new ATNConfig(parms, null);\n                    // While we have context to pop back from, we may have\n                    // gotten that context AFTER having falling off a rule.\n                    // Make sure we track that we are now out of context.\n                    c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n                    this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);\n                }\n                return;\n            } else if( fullCtx) {\n                // reached end of start rule\n                configs.add(config, this.mergeCache);\n                return;\n            } else {\n                // else if we have no context info, just chase follow links (if greedy)\n                if (this.debug) {\n                    console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                }\n            }\n        }\n        this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n    }\n\n    // Do the actual work of walking epsilon edges//\n    closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        const p = config.state;\n        // optimization\n        if (! p.epsilonOnlyTransitions) {\n            configs.add(config, this.mergeCache);\n            // make sure to not return here, because EOF transitions can act as\n            // both epsilon transitions and non-epsilon transitions.\n        }\n        for(let i = 0;i<p.transitions.length; i++) {\n            if(i === 0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config))\n                continue;\n\n            const t = p.transitions[i];\n            const continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n            const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n            if (c!==null) {\n                let newDepth = depth;\n                if ( config.state instanceof RuleStopState) {\n                    // target fell off end of rule; mark resulting c as having dipped into outer context\n                    // We can't get here if incoming config was rule stop and we had context\n                    // track how far we dip into outer context.  Might\n                    // come in handy and we avoid evaluating context dependent\n                    // preds if this is > 0.\n                    if (this._dfa !== null && this._dfa.precedenceDfa) {\n                        if (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n                            c.precedenceFilterSuppressed = true;\n                        }\n                    }\n\n                    c.reachesIntoOuterContext += 1;\n                    if (closureBusy.add(c)!==c) {\n                        // avoid infinite recursion for right-recursive rules\n                        continue;\n                    }\n                    configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n                    newDepth -= 1;\n                    if (this.debug) {\n                        console.log(\"dips into outer ctx: \" + c);\n                    }\n                } else {\n                    if (!t.isEpsilon && closureBusy.add(c)!==c){\n                        // avoid infinite recursion for EOF* and EOF+\n                        continue;\n                    }\n                    if (t instanceof RuleTransition) {\n                        // latch when newDepth goes negative - once we step out of the entry context we can't return\n                        if (newDepth >= 0) {\n                            newDepth += 1;\n                        }\n                    }\n                }\n                this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);\n            }\n        }\n    }\n\n    canDropLoopEntryEdgeInLeftRecursiveRule(config) {\n        // return False\n        const p = config.state;\n        // First check to see if we are in StarLoopEntryState generated during\n        // left-recursion elimination. For efficiency, also check if\n        // the context has an empty stack case. If so, it would mean\n        // global FOLLOW so we can't perform optimization\n        // Are we the special loop entry/exit state? or SLL wildcard\n        if(p.stateType !== ATNState.STAR_LOOP_ENTRY)\n            return false;\n        if(p.stateType !== ATNState.STAR_LOOP_ENTRY || !p.isPrecedenceDecision ||\n               config.context.isEmpty() || config.context.hasEmptyPath())\n            return false;\n\n        // Require all return states to return back to the same rule that p is in.\n        const numCtxs = config.context.length;\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnState = this.atn.states[config.context.getReturnState(i)];\n            if (returnState.ruleIndex !== p.ruleIndex)\n                return false;\n        }\n\n        const decisionStartState = p.transitions[0].target;\n        const blockEndStateNum = decisionStartState.endState.stateNumber;\n        const blockEndState = this.atn.states[blockEndStateNum];\n\n        // Verify that the top of each stack context leads to loop entry/exit\n        // state through epsilon edges and w/o leaving rule.\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnStateNumber = config.context.getReturnState(i);\n            const returnState = this.atn.states[returnStateNumber];\n            // all states must have single outgoing epsilon edge\n            if (returnState.transitions.length !== 1 || !returnState.transitions[0].isEpsilon)\n                return false;\n\n            // Look for prefix op case like 'not expr', (' type ')' expr\n            const returnStateTarget = returnState.transitions[0].target;\n            if ( returnState.stateType === ATNState.BLOCK_END && returnStateTarget === p )\n                continue;\n\n            // Look for 'expr op expr' or case where expr's return state is block end\n            // of (...)* internal block; the block end points to loop back\n            // which points to p but we don't need to check that\n            if ( returnState === blockEndState )\n                continue;\n\n            // Look for ternary expr ? expr : expr. The return state points at block end,\n            // which points at loop entry state\n            if ( returnStateTarget === blockEndState )\n                continue;\n\n            // Look for complex prefix 'between expr and expr' case where 2nd expr's\n            // return state points at block end state of (...)* internal block\n            if (returnStateTarget.stateType === ATNState.BLOCK_END && returnStateTarget.transitions.length === 1\n                    && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target === p)\n                continue;\n\n            // anything else ain't conforming\n            return false;\n        }\n        return true;\n    }\n\n    getRuleName(index) {\n        if (this.parser!==null && index>=0) {\n            return this.parser.ruleNames[index];\n        } else {\n            return \"<rule \" + index + \">\";\n        }\n    }\n\n    getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n        switch(t.serializationType) {\n        case Transition.RULE:\n            return this.ruleTransition(config, t);\n        case Transition.PRECEDENCE:\n            return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.PREDICATE:\n            return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.ACTION:\n            return this.actionTransition(config, t);\n        case Transition.EPSILON:\n            return new ATNConfig({state:t.target}, config);\n        case Transition.ATOM:\n        case Transition.RANGE:\n        case Transition.SET:\n            // EOF transitions act like epsilon transitions after the first EOF\n            // transition is traversed\n            if (treatEofAsEpsilon) {\n                if (t.matches(Token.EOF, 0, 1)) {\n                    return new ATNConfig({state: t.target}, config);\n                }\n            }\n            return null;\n        default:\n            return null;\n        }\n    }\n\n    actionTransition(config, t) {\n        if (this.debug) {\n            const index = t.actionIndex === -1 ? 65535 : t.actionIndex;\n            console.log(\"ACTION edge \" + t.ruleIndex + \":\" + index);\n        }\n        return new ATNConfig({state:t.target}, config);\n    }\n\n    precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" +\n                    pt.precedence + \">=_p, ctx dependent=true\");\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && inContext) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    predTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex +\n                    \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    ruleTransition(config, t) {\n        if (this.debug) {\n            console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n        }\n        const returnState = t.followState;\n        const newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n        return new ATNConfig({state:t.target, context:newContext}, config );\n    }\n\n    getConflictingAlts(configs) {\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.getAlts(altsets);\n    }\n\n    /**\n     * Sam pointed out a problem with the previous definition, v3, of\n     * ambiguous states. If we have another state associated with conflicting\n     * alternatives, we should keep going. For example, the following grammar\n     *\n     * s : (ID | ID ID?) ';' ;\n     *\n     * When the ATN simulation reaches the state before ';', it has a DFA\n     * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n     * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n     * because alternative to has another way to continue, via [6|2|[]].\n     * The key is that we have a single state that has config's only associated\n     * with a single alternative, 2, and crucially the state transitions\n     * among the configurations are all non-epsilon transitions. That means\n     * we don't consider any conflicts that include alternative 2. So, we\n     * ignore the conflict between alts 1 and 2. We ignore a set of\n     * conflicting alts when there is an intersection with an alternative\n     * associated with a single alt state in the state&rarr;config-list map.\n     *\n     * It's also the case that we might have two conflicting configurations but\n     * also a 3rd nonconflicting configuration for a different alternative:\n     * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n     *\n     * a : A | A | A B ;\n     *\n     * After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not\n     * stop working on this state. In the previous example, we're concerned\n     * with states associated with the conflicting alternatives. Here alt\n     * 3 is not associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, I don't declare the state done. We\n     * ignore a set of conflicting alts when we have an alternative\n     * that we still need to pursue\n     */\n    getConflictingAltsOrUniqueAlt(configs) {\n        let conflictingAlts = null;\n        if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {\n            conflictingAlts = new BitSet();\n            conflictingAlts.add(configs.uniqueAlt);\n        } else {\n            conflictingAlts = configs.conflictingAlts;\n        }\n        return conflictingAlts;\n    }\n\n    getTokenName(t) {\n        if (t===Token.EOF) {\n            return \"EOF\";\n        }\n        if( this.parser!==null && this.parser.literalNames!==null) {\n            if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {\n                console.log(\"\" + t + \" ttype out of range: \" + this.parser.literalNames);\n                console.log(\"\" + this.parser.getInputStream().getTokens());\n            } else {\n                const name = this.parser.literalNames[t] || this.parser.symbolicNames[t];\n                return name + \"<\" + t + \">\";\n            }\n        }\n        return \"\" + t;\n    }\n\n    getLookaheadName(input) {\n        return this.getTokenName(input.LA(1));\n    }\n\n    /**\n     * Used for debugging in adaptivePredict around execATN but I cut\n     * it out for clarity now that alg. works well. We can leave this\n     * \"dead\" code for a bit\n     */\n    dumpDeadEndConfigs(nvae) {\n        console.log(\"dead end configs: \");\n        const decs = nvae.getDeadEndConfigs();\n        for(let i=0; i<decs.length; i++) {\n            const c = decs[i];\n            let trans = \"no edges\";\n            if (c.state.transitions.length>0) {\n                const t = c.state.transitions[0];\n                if (t instanceof AtomTransition) {\n                    trans = \"Atom \"+ this.getTokenName(t.label);\n                } else if (t instanceof SetTransition) {\n                    const neg = (t instanceof NotSetTransition);\n                    trans = (neg ? \"~\" : \"\") + \"Set \" + t.set;\n                }\n            }\n            console.error(c.toString(this.parser, true) + \":\" + trans);\n        }\n    }\n\n    noViableAlt(input, outerContext, configs, startIndex) {\n        return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n    }\n\n    getUniqueAlt(configs) {\n        let alt = ATN.INVALID_ALT_NUMBER;\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (alt === ATN.INVALID_ALT_NUMBER) {\n                alt = c.alt // found first alt\n            } else if( c.alt!==alt) {\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return alt;\n    }\n\n    /**\n     * Add an edge to the DFA, if possible. This method calls\n     * {@link //addDFAState} to ensure the {@code to} state is present in the\n     * DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n     * range of edges that can be represented in the DFA tables, this method\n     * returns without adding the edge to the DFA.\n     *\n     * <p>If {@code to} is {@code null}, this method returns {@code null}.\n     * Otherwise, this method returns the {@link DFAState} returned by calling\n     * {@link //addDFAState} for the {@code to} state.</p>\n     *\n     * @param dfa The DFA\n     * @param from_ The source state for the edge\n     * @param t The input symbol\n     * @param to The target state for the edge\n     *\n     * @return If {@code to} is {@code null}, this method returns {@code null};\n     * otherwise this method returns the result of calling {@link //addDFAState}\n     * on {@code to}\n     */\n    addDFAEdge(dfa, from_, t, to) {\n        if( this.debug) {\n            console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + this.getTokenName(t));\n        }\n        if (to===null) {\n            return null;\n        }\n        to = this.addDFAState(dfa, to); // used existing if possible not incoming\n        if (from_===null || t < -1 || t > this.atn.maxTokenType) {\n            return to;\n        }\n        if (from_.edges===null) {\n            from_.edges = [];\n        }\n        from_.edges[t+1] = to; // connect\n\n        if (this.debug) {\n            const literalNames = this.parser===null ? null : this.parser.literalNames;\n            const symbolicNames = this.parser===null ? null : this.parser.symbolicNames;\n            console.log(\"DFA=\\n\" + dfa.toString(literalNames, symbolicNames));\n        }\n        return to;\n    }\n\n    /**\n     * Add state {@code D} to the DFA if it is not already present, and return\n     * the actual instance stored in the DFA. If a state equivalent to {@code D}\n     * is already in the DFA, the existing state is returned. Otherwise this\n     * method returns {@code D} after adding it to the DFA.\n     *\n     * <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n     * does not change the DFA.</p>\n     *\n     * @param dfa The dfa\n     * @param D The DFA state to add\n     * @return The state stored in the DFA. This will be either the existing\n     * state if {@code D} is already in the DFA, or {@code D} itself if the\n     * state was not already present\n     */\n    addDFAState(dfa, D) {\n        if (D === ATNSimulator.ERROR) {\n            return D;\n        }\n        const existing = dfa.states.get(D);\n        if(existing!==null) {\n            return existing;\n        }\n        D.stateNumber = dfa.states.length;\n        if (! D.configs.readOnly) {\n            D.configs.optimizeConfigs(this);\n            D.configs.setReadonly(true);\n        }\n        dfa.states.add(D);\n        if (this.debug) {\n            console.log(\"adding new DFA state: \" + D);\n        }\n        return D;\n    }\n\n    reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n        }\n    }\n\n    reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n        }\n    }\n\n    // If context sensitive parsing, we know it's ambiguity not conflict//\n    reportAmbiguity(dfa, D, startIndex, stopIndex,\n                                   exact, ambigAlts, configs ) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n        }\n    }\n}\n\nmodule.exports = ParserATNSimulator;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Map, BitSet, AltDict, hashStuff} = require('./../Utils');\nconst ATN = require('./ATN');\nconst {RuleStopState} = require('./ATNState');\nconst {ATNConfigSet} = require('./ATNConfigSet');\nconst {ATNConfig} = require('./ATNConfig');\nconst {SemanticContext} = require('./SemanticContext');\n\n/**\n * This enumeration defines the prediction modes available in ANTLR 4 along with\n * utility methods for analyzing configuration sets for conflicts and/or\n * ambiguities.\n */\nconst PredictionMode = {\n    /**\n     * The SLL(*) prediction mode. This prediction mode ignores the current\n     * parser context when making predictions. This is the fastest prediction\n     * mode, and provides correct results for many grammars. This prediction\n     * mode is more powerful than the prediction mode provided by ANTLR 3, but\n     * may result in syntax errors for grammar and input combinations which are\n     * not SLL.\n     *\n     * <p>\n     * When using this prediction mode, the parser will either return a correct\n     * parse tree (i.e. the same parse tree that would be returned with the\n     * {@link //LL} prediction mode), or it will report a syntax error. If a\n     * syntax error is encountered when using the {@link //SLL} prediction mode,\n     * it may be due to either an actual syntax error in the input or indicate\n     * that the particular combination of grammar and input requires the more\n     * powerful {@link //LL} prediction abilities to complete successfully.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    SLL: 0,\n\n    /**\n     * The LL(*) prediction mode. This prediction mode allows the current parser\n     * context to be used for resolving SLL conflicts that occur during\n     * prediction. This is the fastest prediction mode that guarantees correct\n     * parse results for all combinations of grammars with syntactically correct\n     * inputs.\n     *\n     * <p>\n     * When using this prediction mode, the parser will make correct decisions\n     * for all syntactically-correct grammar and input combinations. However, in\n     * cases where the grammar is truly ambiguous this prediction mode might not\n     * report a precise answer for <em>exactly which</em> alternatives are\n     * ambiguous.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL: 1,\n\n    /**\n     *\n     * The LL(*) prediction mode with exact ambiguity detection. In addition to\n     * the correctness guarantees provided by the {@link //LL} prediction mode,\n     * this prediction mode instructs the prediction algorithm to determine the\n     * complete and exact set of ambiguous alternatives for every ambiguous\n     * decision encountered while parsing.\n     *\n     * <p>\n     * This prediction mode may be used for diagnosing ambiguities during\n     * grammar development. Due to the performance overhead of calculating sets\n     * of ambiguous alternatives, this prediction mode should be avoided when\n     * the exact results are not necessary.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL_EXACT_AMBIG_DETECTION: 2,\n\n    /**\n     *\n     * Computes the SLL prediction termination condition.\n     *\n     * <p>\n     * This method computes the SLL prediction termination condition for both of\n     * the following cases.</p>\n     *\n     * <ul>\n     * <li>The usual SLL+LL fallback upon SLL conflict</li>\n     * <li>Pure SLL without LL fallback</li>\n     * </ul>\n     *\n     * <p><strong>COMBINED SLL+LL PARSING</strong></p>\n     *\n     * <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n     * ensured regardless of how the termination condition is computed by this\n     * method. Due to the substantially higher cost of LL prediction, the\n     * prediction should only fall back to LL when the additional lookahead\n     * cannot lead to a unique SLL prediction.</p>\n     *\n     * <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n     * conflicting subsets should fall back to full LL, even if the\n     * configuration sets don't resolve to the same alternative (e.g.\n     * {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n     * configuration, SLL could continue with the hopes that more lookahead will\n     * resolve via one of those non-conflicting configurations.</p>\n     *\n     * <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n     * stops when it sees only conflicting configuration subsets. In contrast,\n     * full LL keeps going when there is uncertainty.</p>\n     *\n     * <p><strong>HEURISTIC</strong></p>\n     *\n     * <p>As a heuristic, we stop prediction when we see any conflicting subset\n     * unless we see a state that only has one alternative associated with it.\n     * The single-alt-state thing lets prediction continue upon rules like\n     * (otherwise, it would admit defeat too soon):</p>\n     *\n     * <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n     *\n     * <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n     * DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n     * {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n     * processing this node because alternative to has another way to continue,\n     * via {@code [6|2|[]]}.</p>\n     *\n     * <p>It also let's us continue for this rule:</p>\n     *\n     * <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n     *\n     * <p>After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not stop\n     * working on this state. In the previous example, we're concerned with\n     * states associated with the conflicting alternatives. Here alt 3 is not\n     * associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, don't declare the state done.</p>\n     *\n     * <p><strong>PURE SLL PARSING</strong></p>\n     *\n     * <p>To handle pure SLL parsing, all we have to do is make sure that we\n     * combine stack contexts for configurations that differ only by semantic\n     * predicate. From there, we can do the usual SLL termination heuristic.</p>\n     *\n     * <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n     *\n     * <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n     * states because they need to create the DFA cache that works in all\n     * semantic situations. In contrast, full LL evaluates predicates collected\n     * during start state computation so it can ignore predicates thereafter.\n     * This means that SLL termination detection can totally ignore semantic\n     * predicates.</p>\n     *\n     * <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n     * semantic predicate contexts so we might see two configurations like the\n     * following.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n     *\n     * <p>Before testing these configurations against others, we have to merge\n     * {@code x} and {@code x'} (without modifying the existing configurations).\n     * For example, we test {@code (x+x')==x''} when looking for conflicts in\n     * the following configurations.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n     *\n     * <p>If the configuration set has predicates (as indicated by\n     * {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n     * the configurations to strip out all of the predicates so that a standard\n     * {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n     */\n    hasSLLConflictTerminatingPrediction: function( mode, configs) {\n        // Configs in rule stop states indicate reaching the end of the decision\n        // rule (local context) or end of start rule (full context). If all\n        // configs meet this condition, then none of the configurations is able\n        // to match additional input so we terminate prediction.\n        //\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return true;\n        }\n        // pure SLL mode parsing\n        if (mode === PredictionMode.SLL) {\n            // Don't bother with combining configs from different semantic\n            // contexts if we can fail over to full LL; costs more time\n            // since we'll often fail over anyway.\n            if (configs.hasSemanticContext) {\n                // dup configs, tossing out semantic predicates\n                const dup = new ATNConfigSet();\n                for(let i=0;i<configs.items.length;i++) {\n                    let c = configs.items[i];\n                    c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);\n                    dup.add(c);\n                }\n                configs = dup;\n            }\n            // now we have combined contexts for configs with dissimilar preds\n        }\n        // pure SLL or combined SLL+LL mode parsing\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n    },\n\n    /**\n     * Checks if any configuration in {@code configs} is in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if any configuration in {@code configs} is in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    hasConfigInRuleStopState: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (c.state instanceof RuleStopState) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    /**\n     * Checks if all configurations in {@code configs} are in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if all configurations in {@code configs} are in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    allConfigsInRuleStopStates: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (!(c.state instanceof RuleStopState)) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n    /**\n     *\n     * Full LL prediction termination.\n     *\n     * <p>Can we stop looking ahead during ATN simulation or is there some\n     * uncertainty as to which alternative we will ultimately pick, after\n     * consuming more input? Even if there are partial conflicts, we might know\n     * that everything is going to resolve to the same minimum alternative. That\n     * means we can stop since no more lookahead will change that fact. On the\n     * other hand, there might be multiple conflicts that resolve to different\n     * minimums. That means we need more look ahead to decide which of those\n     * alternatives we should predict.</p>\n     *\n     * <p>The basic idea is to split the set of configurations {@code C}, into\n     * conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n     * non-conflicting configurations. Two configurations conflict if they have\n     * identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n     * but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n     * and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n     *\n     * <p>Reduce these configuration subsets to the set of possible alternatives.\n     * You can compute the alternative subsets in one pass as follows:</p>\n     *\n     * <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n     * {@code C} holding {@code s} and {@code ctx} fixed.</p>\n     *\n     * <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     *\n     * <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n     *\n     * <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n     * {@code s} and {@code ctx}.</p>\n     *\n     * <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n     * the union of these alternative subsets is a singleton, then no amount of\n     * more lookahead will help us. We will always pick that alternative. If,\n     * however, there is more than one alternative, then we are uncertain which\n     * alternative to predict and must continue looking for resolution. We may\n     * or may not discover an ambiguity in the future, even if there are no\n     * conflicting subsets this round.</p>\n     *\n     * <p>The biggest sin is to terminate early because it means we've made a\n     * decision but were uncertain as to the eventual outcome. We haven't used\n     * enough lookahead. On the other hand, announcing a conflict too late is no\n     * big deal; you will still have the conflict. It's just inefficient. It\n     * might even look until the end of file.</p>\n     *\n     * <p>No special consideration for semantic predicates is required because\n     * predicates are evaluated on-the-fly for full LL prediction, ensuring that\n     * no configuration contains a semantic context during the termination\n     * check.</p>\n     *\n     * <p><strong>CONFLICTING CONFIGS</strong></p>\n     *\n     * <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n     * when {@code i!=j} but {@code x=x'}. Because we merge all\n     * {@code (s, i, _)} configurations together, that means that there are at\n     * most {@code n} configurations associated with state {@code s} for\n     * {@code n} possible alternatives in the decision. The merged stacks\n     * complicate the comparison of configuration contexts {@code x} and\n     * {@code x'}. Sam checks to see if one is a subset of the other by calling\n     * merge and checking to see if the merged result is either {@code x} or\n     * {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n     * is the superset, then {@code i} is the only possible prediction since the\n     * others resolve to {@code min(i)} as well. However, if {@code x} is\n     * associated with {@code j>i} then at least one stack configuration for\n     * {@code j} is not in conflict with alternative {@code i}. The algorithm\n     * should keep going, looking for more lookahead due to the uncertainty.</p>\n     *\n     * <p>For simplicity, I'm doing a equality check between {@code x} and\n     * {@code x'} that lets the algorithm continue to consume lookahead longer\n     * than necessary. The reason I like the equality is of course the\n     * simplicity but also because that is the test you need to detect the\n     * alternatives that are actually in conflict.</p>\n     *\n     * <p><strong>CONTINUE/STOP RULE</strong></p>\n     *\n     * <p>Continue if union of resolved alternative sets from non-conflicting and\n     * conflicting alternative subsets has more than one alternative. We are\n     * uncertain about which alternative to predict.</p>\n     *\n     * <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n     * alternatives are still in the running for the amount of input we've\n     * consumed at this point. The conflicting sets let us to strip away\n     * configurations that won't lead to more states because we resolve\n     * conflicts to the configuration with a minimum alternate for the\n     * conflicting set.</p>\n     *\n     * <p><strong>CASES</strong></p>\n     *\n     * <ul>\n     *\n     * <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n     *\n     * <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n     * {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n     * {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1,3}} =&gt; continue\n     * </li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n     * {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1}} =&gt; stop and predict 1</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n     * ambiguity {@code {1,2}}</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n     * {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {2}} = {@code {1,2}} =&gt; continue</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n     * {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {3}} = {@code {1,3}} =&gt; continue</li>\n     *\n     * </ul>\n     *\n     * <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n     *\n     * <p>If all states report the same conflicting set of alternatives, then we\n     * know we have the exact ambiguity set.</p>\n     *\n     * <p><code>|A_<em>i</em>|&gt;1</code> and\n     * <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n     *\n     * <p>In other words, we continue examining lookahead until all {@code A_i}\n     * have more than one alternative and all {@code A_i} are the same. If\n     * {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n     * because the resolved set is {@code {1}}. To determine what the real\n     * ambiguity is, we have to know whether the ambiguity is between one and\n     * two or one and three so we keep going. We can only stop prediction when\n     * we need exact ambiguity detection when the sets look like\n     * {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n     */\n    resolvesToJustOneViableAlt: function(altsets) {\n        return PredictionMode.getSingleViableAlt(altsets);\n    },\n\n    /**\n     * Determines if every alternative subset in {@code altsets} contains more\n     * than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every {@link BitSet} in {@code altsets} has\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    allSubsetsConflict: function(altsets) {\n        return ! PredictionMode.hasNonConflictingAltSet(altsets);\n    },\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * exactly one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n     */\n    hasNonConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * more than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    hasConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length>1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if every alternative subset in {@code altsets} is equivalent.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every member of {@code altsets} is equal to the\n     * others, otherwise {@code false}\n     */\n    allSubsetsEqual: function(altsets) {\n        let first = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (first === null) {\n                first = alts;\n            } else if (alts!==first) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n\n    /**\n     * Returns the unique alternative predicted by all alternative subsets in\n     * {@code altsets}. If no such alternative exists, this method returns\n     * {@link ATN//INVALID_ALT_NUMBER}.\n     *\n     * @param altsets a collection of alternative subsets\n     */\n    getUniqueAlt: function(altsets) {\n        const all = PredictionMode.getAlts(altsets);\n        if (all.length===1) {\n            return all.minValue();\n        } else {\n            return ATN.INVALID_ALT_NUMBER;\n        }\n    },\n\n    /**\n     * Gets the complete set of represented alternatives for a collection of\n     * alternative subsets. This method returns the union of each {@link BitSet}\n     * in {@code altsets}.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return the set of represented alternatives in {@code altsets}\n     */\n    getAlts: function(altsets) {\n        const all = new BitSet();\n        altsets.map( function(alts) { all.or(alts); });\n        return all;\n    },\n\n    /**\n     * This function gets the conflicting alt subsets from a configuration set.\n     * For each configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     */\n    getConflictingAltSubsets: function(configs) {\n        const configToAlts = new Map();\n        configToAlts.hashFunction = function(cfg) { hashStuff(cfg.state.stateNumber, cfg.context); };\n        configToAlts.equalsFunction = function(c1, c2) { return c1.state.stateNumber === c2.state.stateNumber && c1.context.equals(c2.context);};\n        configs.items.map(function(cfg) {\n            let alts = configToAlts.get(cfg);\n            if (alts === null) {\n                alts = new BitSet();\n                configToAlts.put(cfg, alts);\n            }\n            alts.add(cfg.alt);\n        });\n        return configToAlts.getValues();\n    },\n\n    /**\n     * Get a map from state to alt subset from a configuration set. For each\n     * configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n     * </pre>\n     */\n    getStateToAltMap: function(configs) {\n        const m = new AltDict();\n        configs.items.map(function(c) {\n            let alts = m.get(c.state);\n            if (alts === null) {\n                alts = new BitSet();\n                m.put(c.state, alts);\n            }\n            alts.add(c.alt);\n        });\n        return m;\n    },\n\n    hasStateAssociatedWithOneAlt: function(configs) {\n        const values = PredictionMode.getStateToAltMap(configs).values();\n        for(let i=0;i<values.length;i++) {\n            if (values[i].length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    getSingleViableAlt: function(altsets) {\n        let result = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            const minAlt = alts.minValue();\n            if(result===null) {\n                result = minAlt;\n            } else if(result!==minAlt) { // more than 1 viable alt\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return result;\n    }\n};\n\nmodule.exports = PredictionMode;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst { Set, Hash, equalArrays } = require('./../Utils');\n\n/**\n * A tree structure used to record the semantic context in which\n * an ATN configuration is valid.  It's either a single predicate,\n * a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n *\n * <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n * {@link SemanticContext} within the scope of this outer class.</p>\n */\nclass SemanticContext {\n\n\thashCode() {\n\t\tconst hash = new Hash();\n\t\tthis.updateHashCode(hash);\n\t\treturn hash.finish();\n\t}\n\n\t/**\n\t * For context independent predicates, we evaluate them without a local\n\t * context (i.e., null context). That way, we can evaluate them without\n\t * having to create proper rule-specific context during prediction (as\n\t * opposed to the parser, which creates them naturally). In a practical\n\t * sense, this avoids a cast exception from RuleContext to myruleContext.\n\t *\n\t * <p>For context dependent predicates, we must pass in a local context so that\n\t * references such as $arg evaluate properly as _localctx.arg. We only\n\t * capture context dependent predicates in the context in which we begin\n\t * prediction, so we passed in the outer context here in case of context\n\t * dependent predicate evaluation.</p>\n\t */\n\tevaluate(parser, outerContext) {}\n\n\t/**\n\t * Evaluate the precedence predicates for the context and reduce the result.\n\t *\n\t * @param parser The parser instance.\n\t * @param outerContext The current parser context object.\n\t * @return The simplified semantic context after precedence predicates are\n\t * evaluated, which will be one of the following values.\n\t * <ul>\n\t * <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code null}: if the predicate simplifies to {@code false} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code this}: if the semantic context is not changed as a result of\n\t * precedence predicate evaluation.</li>\n\t * <li>A non-{@code null} {@link SemanticContext}: the new simplified\n\t * semantic context after precedence predicates are evaluated.</li>\n\t * </ul>\n\t */\n\tevalPrecedence(parser, outerContext) {\n\t\treturn this;\n\t}\n\n\tstatic andContext(a, b) {\n\t\tif (a === null || a === SemanticContext.NONE) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null || b === SemanticContext.NONE) {\n\t\t\treturn a;\n\t\t}\n\t\tconst result = new AND(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n\n\tstatic orContext(a, b) {\n\t\tif (a === null) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null) {\n\t\t\treturn a;\n\t\t}\n\t\tif (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tconst result = new OR(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n}\n\n\nclass Predicate extends SemanticContext {\n\n\tconstructor(ruleIndex, predIndex, isCtxDependent) {\n\t\tsuper();\n\t\tthis.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n\t\tthis.predIndex = predIndex === undefined ? -1 : predIndex;\n\t\tthis.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n\t}\n\n\tevaluate(parser, outerContext) {\n\t\tconst localctx = this.isCtxDependent ? outerContext : null;\n\t\treturn parser.sempred(localctx, this.ruleIndex, this.predIndex);\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof Predicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.ruleIndex === other.ruleIndex &&\n\t\t\t\t\tthis.predIndex === other.predIndex &&\n\t\t\t\t\tthis.isCtxDependent === other.isCtxDependent;\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n\t}\n}\n\n/**\n * The default {@link SemanticContext}, which is semantically equivalent to\n * a predicate of the form {@code {true}?}\n */\nSemanticContext.NONE = new Predicate();\n\n\nclass PrecedencePredicate extends SemanticContext {\n\n\tconstructor(precedence) {\n\t\tsuper();\n\t\tthis.precedence = precedence === undefined ? 0 : precedence;\n\t}\n\n\tevaluate(parser, outerContext) {\n\t\treturn parser.precpred(outerContext, this.precedence);\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tif (parser.precpred(outerContext, this.precedence)) {\n\t\t\treturn SemanticContext.NONE;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tcompareTo(other) {\n\t\treturn this.precedence - other.precedence;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.precedence);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof PrecedencePredicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.precedence === other.precedence;\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn \"{\" + this.precedence + \">=prec}?\";\n\t}\n\n\tstatic filterPrecedencePredicates(set) {\n\t\tconst result = [];\n\t\tset.values().map( function(context) {\n\t\t\tif (context instanceof PrecedencePredicate) {\n\t\t\t\tresult.push(context);\n\t\t\t}\n\t\t});\n\t\treturn result;\n\t}\n}\n\nclass AND extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever none of the contained contexts\n\t * is false\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new Set();\n\t\tif (a instanceof AND) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof AND) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\t\tconst precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the lowest precedence\n\t\t\tlet reduced = null;\n\t\t\tprecedencePredicates.map( function(p) {\n\t\t\t\tif(reduced===null || p.precedence<reduced.precedence) {\n\t\t\t\t\treduced = p;\n\t\t\t\t}\n\t\t\t});\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = Array.from(operands.values());\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof AND)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn equalArrays(this.opnds, other.opnds);\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"AND\");\n\t}\n\n\t/**\n\t * {@inheritDoc}\n\t *\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (!this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === null) {\n\t\t\t\t// The AND context is false if any element is false\n\t\t\t\treturn null;\n\t\t\t} else if (evaluated !== SemanticContext.NONE) {\n\t\t\t\t// Reduce the result by skipping true elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were true, so the AND context is true\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tlet result = null;\n\t\toperands.map(function(o) {\n\t\t\tresult = result === null ? o : SemanticContext.andContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tconst s = this.opnds.map(o => o.toString());\n\t\treturn (s.length > 3 ? s.slice(3) : s).join(\"&&\");\n\t}\n}\n\n\nclass OR extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever at least one of the contained\n\t * contexts is true\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new Set();\n\t\tif (a instanceof OR) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof OR) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\n\t\tconst precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the highest precedence\n\t\t\tconst s = precedencePredicates.sort(function(a, b) {\n\t\t\t\treturn a.compareTo(b);\n\t\t\t});\n\t\t\tconst reduced = s[s.length-1];\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = Array.from(operands.values());\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof OR)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn equalArrays(this.opnds, other.opnds);\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"OR\");\n\t}\n\n\t/**\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === SemanticContext.NONE) {\n\t\t\t\t// The OR context is true if any element is true\n\t\t\t\treturn SemanticContext.NONE;\n\t\t\t} else if (evaluated !== null) {\n\t\t\t\t// Reduce the result by skipping false elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were false, so the OR context is false\n\t\t\treturn null;\n\t\t}\n\t\tconst result = null;\n\t\toperands.map(function(o) {\n\t\t\treturn result === null ? o : SemanticContext.orContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tconst s = this.opnds.map(o => o.toString());\n\t\treturn (s.length > 3 ? s.slice(3) : s).join(\"||\");\n\t}\n}\n\nmodule.exports = {\n\tSemanticContext,\n\tPrecedencePredicate,\n\tPredicate\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst {IntervalSet} = require('./../IntervalSet');\nconst {Predicate, PrecedencePredicate} = require('./SemanticContext');\n\n/**\n * An ATN transition between any two ATN states.  Subclasses define\n * atom, set, epsilon, action, predicate, rule transitions.\n *\n * <p>This is a one way link.  It emanates from a state (usually via a list of\n * transitions) and has a target state.</p>\n *\n * <p>Since we never have to change the ATN transitions once we construct it,\n * we can fix these transitions as specific classes. The DFA transitions\n * on the other hand need to update the labels as it adds transitions to\n * the states. We'll use the term Edge for the DFA to distinguish them from\n * ATN transitions.</p>\n */\nclass Transition {\n    constructor(target) {\n        // The target of this transition.\n        if (target===undefined || target===null) {\n            throw \"target cannot be null.\";\n        }\n        this.target = target;\n        // Are we epsilon, action, sempred?\n        this.isEpsilon = false;\n        this.label = null;\n    }\n}\n\n// constants for serialization\n\nTransition.EPSILON = 1;\nTransition.RANGE = 2;\nTransition.RULE = 3;\n// e.g., {isType(input.LT(1))}?\nTransition.PREDICATE = 4;\nTransition.ATOM = 5;\nTransition.ACTION = 6;\n// ~(A|B) or ~atom, wildcard, which convert to next 2\nTransition.SET = 7;\nTransition.NOT_SET = 8;\nTransition.WILDCARD = 9;\nTransition.PRECEDENCE = 10;\n\nTransition.serializationNames = [\n            \"INVALID\",\n            \"EPSILON\",\n            \"RANGE\",\n            \"RULE\",\n            \"PREDICATE\",\n            \"ATOM\",\n            \"ACTION\",\n            \"SET\",\n            \"NOT_SET\",\n            \"WILDCARD\",\n            \"PRECEDENCE\"\n        ];\n\nTransition.serializationTypes = {\n        EpsilonTransition: Transition.EPSILON,\n        RangeTransition: Transition.RANGE,\n        RuleTransition: Transition.RULE,\n        PredicateTransition: Transition.PREDICATE,\n        AtomTransition: Transition.ATOM,\n        ActionTransition: Transition.ACTION,\n        SetTransition: Transition.SET,\n        NotSetTransition: Transition.NOT_SET,\n        WildcardTransition: Transition.WILDCARD,\n        PrecedencePredicateTransition: Transition.PRECEDENCE\n    };\n\n\n// TODO: make all transitions sets? no, should remove set edges\n\nclass AtomTransition extends Transition {\n    constructor(target, label) {\n        super(target);\n        // The token type or character value; or, signifies special label.\n        this.label_ = label;\n        this.label = this.makeLabel();\n        this.serializationType = Transition.ATOM;\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addOne(this.label_);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label_ === symbol;\n    }\n\n    toString() {\n        return this.label_;\n    }\n}\n\n\nclass RuleTransition extends Transition {\n    constructor(ruleStart, ruleIndex, precedence, followState) {\n        super(ruleStart);\n        // ptr to the rule definition object for this rule ref\n        this.ruleIndex = ruleIndex;\n        this.precedence = precedence;\n        // what node to begin computations following ref to rule\n        this.followState = followState;\n        this.serializationType = Transition.RULE;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n}\n\nclass EpsilonTransition extends Transition {\n    constructor(target, outermostPrecedenceReturn) {\n        super(target);\n        this.serializationType = Transition.EPSILON;\n        this.isEpsilon = true;\n        this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"epsilon\";\n    }\n}\n\n\nclass RangeTransition extends Transition {\n    constructor(target, start, stop) {\n        super(target);\n        this.serializationType = Transition.RANGE;\n        this.start = start;\n        this.stop = stop;\n        this.label = this.makeLabel();\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addRange(this.start, this.stop);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= this.start && symbol <= this.stop;\n    }\n\n    toString() {\n        return \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n    }\n}\n\n\nclass AbstractPredicateTransition extends Transition {\n    constructor(target) {\n        super(target);\n    }\n}\n\nclass PredicateTransition extends AbstractPredicateTransition {\n    constructor(target, ruleIndex, predIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.PREDICATE;\n        this.ruleIndex = ruleIndex;\n        this.predIndex = predIndex;\n        this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n    }\n\n    toString() {\n        return \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n    }\n}\n\n\nclass ActionTransition extends Transition {\n    constructor(target, ruleIndex, actionIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.ACTION;\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex===undefined ? -1 : actionIndex;\n        this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n    }\n}\n\n\n// A transition containing a set of values.\nclass SetTransition extends Transition {\n    constructor(target, set) {\n        super(target);\n        this.serializationType = Transition.SET;\n        if (set !==undefined && set !==null) {\n            this.label = set;\n        } else {\n            this.label = new IntervalSet();\n            this.label.addOne(Token.INVALID_TYPE);\n        }\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label.contains(symbol);\n    }\n\n    toString() {\n        return this.label.toString();\n    }\n}\n\nclass NotSetTransition extends SetTransition {\n    constructor(target, set) {\n        super(target, set);\n        this.serializationType = Transition.NOT_SET;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&\n                !super.matches(symbol, minVocabSymbol, maxVocabSymbol);\n    }\n\n    toString() {\n        return '~' + super.toString();\n    }\n}\n\nclass WildcardTransition extends Transition {\n    constructor(target) {\n        super(target);\n        this.serializationType = Transition.WILDCARD;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n    }\n\n    toString() {\n        return \".\";\n    }\n}\n\nclass PrecedencePredicateTransition extends AbstractPredicateTransition {\n    constructor(target, precedence) {\n        super(target);\n        this.serializationType = Transition.PRECEDENCE;\n        this.precedence = precedence;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new PrecedencePredicate(this.precedence);\n    }\n\n    toString() {\n        return this.precedence + \" >= _p\";\n    }\n}\n\nmodule.exports = {\n    Transition,\n    AtomTransition,\n    SetTransition,\n    NotSetTransition,\n    RuleTransition,\n    ActionTransition,\n    EpsilonTransition,\n    RangeTransition,\n    WildcardTransition,\n    PredicateTransition,\n    PrecedencePredicateTransition,\n    AbstractPredicateTransition\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.ATN = require('./ATN');\nexports.ATNDeserializer = require('./ATNDeserializer');\nexports.LexerATNSimulator = require('./LexerATNSimulator');\nexports.ParserATNSimulator = require('./ParserATNSimulator');\nexports.PredictionMode = require('./PredictionMode');\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Set} = require(\"../Utils\");\nconst {DFAState} = require('./DFAState');\nconst {StarLoopEntryState} = require('../atn/ATNState');\nconst {ATNConfigSet} = require('./../atn/ATNConfigSet');\nconst {DFASerializer} = require('./DFASerializer');\nconst {LexerDFASerializer} = require('./DFASerializer');\n\nclass DFA {\n\tconstructor(atnStartState, decision) {\n\t\tif (decision === undefined) {\n\t\t\tdecision = 0;\n\t\t}\n\t\t/**\n\t\t * From which ATN state did we create this DFA?\n\t\t */\n\t\tthis.atnStartState = atnStartState;\n\t\tthis.decision = decision;\n\t\t/**\n\t\t * A set of all DFA states. Use {@link Map} so we can get old state back\n\t\t * ({@link Set} only allows you to see if it's there).\n\t\t */\n\t\tthis._states = new Set();\n\t\tthis.s0 = null;\n\t\t/**\n\t\t * {@code true} if this DFA is for a precedence decision; otherwise,\n\t\t * {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n\t\t * {@link //setPrecedenceDfa}\n\t\t */\n\t\tthis.precedenceDfa = false;\n\t\tif (atnStartState instanceof StarLoopEntryState)\n\t\t{\n\t\t\tif (atnStartState.isPrecedenceDecision) {\n\t\t\t\tthis.precedenceDfa = true;\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Get the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @return The start state corresponding to the specified precedence, or\n\t * {@code null} if no start state exists for the specified precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tgetPrecedenceStartState(precedence) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\t// s0.edges is never null for a precedence DFA\n\t\tif (precedence < 0 || precedence >= this.s0.edges.length) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.s0.edges[precedence] || null;\n\t}\n\n\t/**\n\t * Set the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @param startState The start state corresponding to the specified\n\t * precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tsetPrecedenceStartState(precedence, startState) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\tif (precedence < 0) {\n\t\t\treturn;\n\t\t}\n\n\t\t/**\n\t\t * synchronization on s0 here is ok. when the DFA is turned into a\n\t\t * precedence DFA, s0 will be initialized once and not updated again\n\t\t * s0.edges is never null for a precedence DFA\n\t\t */\n\t\tthis.s0.edges[precedence] = startState;\n\t}\n\n\t/**\n\t * Sets whether this is a precedence DFA. If the specified value differs\n\t * from the current DFA configuration, the following actions are taken;\n\t * otherwise no changes are made to the current DFA.\n\t *\n\t * <ul>\n\t * <li>The {@link //states} map is cleared</li>\n\t * <li>If {@code precedenceDfa} is {@code false}, the initial state\n\t * {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n\t * {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n\t * store the start states for individual precedence values.</li>\n\t * <li>The {@link //precedenceDfa} field is updated</li>\n\t * </ul>\n\t *\n\t * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n\t * {@code false}\n\t */\n\tsetPrecedenceDfa(precedenceDfa) {\n\t\tif (this.precedenceDfa!==precedenceDfa) {\n\t\t\tthis._states = new Set();\n\t\t\tif (precedenceDfa) {\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t} else {\n\t\t\t\tthis.s0 = null;\n\t\t\t}\n\t\t\tthis.precedenceDfa = precedenceDfa;\n\t\t}\n\t}\n\n\t/**\n\t * Return a list of all states in this DFA, ordered by state number.\n\t */\n\tsortedStates() {\n\t\tconst list = this._states.values();\n\t\treturn list.sort(function(a, b) {\n\t\t\treturn a.stateNumber - b.stateNumber;\n\t\t});\n\t}\n\n\ttoString(literalNames, symbolicNames) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new DFASerializer(this, literalNames, symbolicNames);\n\t\treturn serializer.toString();\n\t}\n\n\ttoLexerString() {\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new LexerDFASerializer(this);\n\t\treturn serializer.toString();\n\t}\n\n\tget states(){\n\t\treturn this._states;\n\t}\n}\n\n\nmodule.exports = DFA;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nconst Utils = require('./../Utils');\n\n/**\n * A DFA walker that knows how to dump them to serialized strings.\n */\nclass DFASerializer {\n    constructor(dfa, literalNames, symbolicNames) {\n        this.dfa = dfa;\n        this.literalNames = literalNames || [];\n        this.symbolicNames = symbolicNames || [];\n    }\n\n    toString() {\n       if(this.dfa.s0 === null) {\n           return null;\n       }\n       let buf = \"\";\n       const states = this.dfa.sortedStates();\n       for(let i=0; i<states.length; i++) {\n           const s = states[i];\n           if(s.edges!==null) {\n                const n = s.edges.length;\n                for(let j=0;j<n;j++) {\n                    const t = s.edges[j] || null;\n                    if(t!==null && t.stateNumber !== 0x7FFFFFFF) {\n                        buf = buf.concat(this.getStateString(s));\n                        buf = buf.concat(\"-\");\n                        buf = buf.concat(this.getEdgeLabel(j));\n                        buf = buf.concat(\"->\");\n                        buf = buf.concat(this.getStateString(t));\n                        buf = buf.concat('\\n');\n                    }\n                }\n           }\n       }\n       return buf.length===0 ? null : buf;\n    }\n\n    getEdgeLabel(i) {\n        if (i===0) {\n            return \"EOF\";\n        } else if(this.literalNames !==null || this.symbolicNames!==null) {\n            return this.literalNames[i-1] || this.symbolicNames[i-1];\n        } else {\n            return String.fromCharCode(i-1);\n        }\n    }\n\n    getStateString(s) {\n        const baseStateStr = ( s.isAcceptState ? \":\" : \"\") + \"s\" + s.stateNumber + ( s.requiresFullContext ? \"^\" : \"\");\n        if(s.isAcceptState) {\n            if (s.predicates !== null) {\n                return baseStateStr + \"=>\" + Utils.arrayToString(s.predicates);\n            } else {\n                return baseStateStr + \"=>\" + s.prediction.toString();\n            }\n        } else {\n            return baseStateStr;\n        }\n    }\n}\n\nclass LexerDFASerializer extends DFASerializer {\n    constructor(dfa) {\n        super(dfa, null);\n    }\n\n    getEdgeLabel(i) {\n        return \"'\" + String.fromCharCode(i) + \"'\";\n    }\n}\n\nmodule.exports = { DFASerializer , LexerDFASerializer };\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {ATNConfigSet} = require('./../atn/ATNConfigSet');\nconst {Hash, Set} = require('./../Utils');\n\n/**\n * Map a predicate to a predicted alternative.\n */\nclass PredPrediction {\n\tconstructor(pred, alt) {\n\t\tthis.alt = alt;\n\t\tthis.pred = pred;\n\t}\n\n\ttoString() {\n\t\treturn \"(\" + this.pred + \", \" + this.alt + \")\";\n\t}\n}\n\n/**\n * A DFA state represents a set of possible ATN configurations.\n * As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n * to keep track of all possible states the ATN can be in after\n * reading each input symbol. That is to say, after reading\n * input a1a2..an, the DFA is in a state that represents the\n * subset T of the states of the ATN that are reachable from the\n * ATN's start state along some path labeled a1a2..an.\"\n * In conventional NFA&rarr;DFA conversion, therefore, the subset T\n * would be a bitset representing the set of states the\n * ATN could be in. We need to track the alt predicted by each\n * state as well, however. More importantly, we need to maintain\n * a stack of states, tracking the closure operations as they\n * jump from rule to rule, emulating rule invocations (method calls).\n * I have to add a stack to simulate the proper lookahead sequences for\n * the underlying LL grammar from which the ATN was derived.\n *\n * <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n * is both a state (ala normal conversion) and a RuleContext describing\n * the chain of rules (if any) followed to arrive at that state.</p>\n *\n * <p>A DFA state may have multiple references to a particular state,\n * but with different ATN contexts (with same or different alts)\n * meaning that state was reached via a different set of rule invocations.</p>\n */\nclass DFAState {\n\tconstructor(stateNumber, configs) {\n\t\tif (stateNumber === null) {\n\t\t\tstateNumber = -1;\n\t\t}\n\t\tif (configs === null) {\n\t\t\tconfigs = new ATNConfigSet();\n\t\t}\n\t\tthis.stateNumber = stateNumber;\n\t\tthis.configs = configs;\n\t\t/**\n\t\t * {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n\t\t * {@link Token//EOF} maps to {@code edges[0]}.\n\t\t */\n\t\tthis.edges = null;\n\t\tthis.isAcceptState = false;\n\t\t/**\n\t\t * if accept state, what ttype do we match or alt do we predict?\n\t\t * This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link//predicates}\n\t\t * {@code !=null} or {@link //requiresFullContext}.\n\t\t */\n\t\tthis.prediction = 0;\n\t\tthis.lexerActionExecutor = null;\n\t\t/**\n\t\t * Indicates that this state was created during SLL prediction that\n\t\t * discovered a conflict between the configurations in the state. Future\n\t\t * {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n\t\t * full context prediction if this field is true.\n\t\t */\n\t\tthis.requiresFullContext = false;\n\t\t/**\n\t\t * During SLL parsing, this is a list of predicates associated with the\n\t\t * ATN configurations of the DFA state. When we have predicates,\n\t\t * {@link //requiresFullContext} is {@code false} since full context\n\t\t * prediction evaluates predicates\n\t\t * on-the-fly. If this is not null, then {@link //prediction} is\n\t\t * {@link ATN//INVALID_ALT_NUMBER}.\n\t\t *\n\t\t * <p>We only use these for non-{@link //requiresFullContext} but\n\t\t * conflicting states. That\n\t\t * means we know from the context (it's $ or we don't dip into outer\n\t\t * context) that it's an ambiguity not a conflict.</p>\n\t\t *\n\t\t * <p>This list is computed by {@link\n\t\t * ParserATNSimulator//predicateDFAState}.</p>\n\t\t */\n\t\tthis.predicates = null;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get the set of all alts mentioned by all ATN configurations in this\n\t * DFA state.\n\t */\n\tgetAltSet() {\n\t\tconst alts = new Set();\n\t\tif (this.configs !== null) {\n\t\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\t\tconst c = this.configs[i];\n\t\t\t\talts.add(c.alt);\n\t\t\t}\n\t\t}\n\t\tif (alts.length === 0) {\n\t\t\treturn null;\n\t\t} else {\n\t\t\treturn alts;\n\t\t}\n\t}\n\n\t/**\n\t * Two {@link DFAState} instances are equal if their ATN configuration sets\n\t * are the same. This method is used to see if a state already exists.\n\t *\n\t * <p>Because the number of alternatives and number of ATN configurations are\n\t * finite, there is a finite number of DFA states that can be processed.\n\t * This is necessary to show that the algorithm terminates.</p>\n\t *\n\t * <p>Cannot test the DFA state numbers here because in\n\t * {@link ParserATNSimulator//addDFAState} we need to know if any other state\n\t * exists that has this exact set of ATN configurations. The\n\t * {@link //stateNumber} is irrelevant.</p>\n\t */\n\tequals(other) {\n\t\t// compare set of ATN configurations in this set with other\n\t\treturn this === other ||\n\t\t\t\t(other instanceof DFAState &&\n\t\t\t\t\tthis.configs.equals(other.configs));\n\t}\n\n\ttoString() {\n\t\tlet s = \"\" + this.stateNumber + \":\" + this.configs;\n\t\tif(this.isAcceptState) {\n\t\t\ts = s + \"=>\";\n\t\t\tif (this.predicates !== null)\n\t\t\t\ts = s + this.predicates;\n\t\t\telse\n\t\t\t\ts = s + this.prediction;\n\t\t}\n\t\treturn s;\n\t}\n\n\thashCode() {\n\t\tconst hash = new Hash();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n}\n\nmodule.exports = { DFAState, PredPrediction };\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.DFA = require('./DFA');\nexports.DFASerializer = require('./DFASerializer').DFASerializer;\nexports.LexerDFASerializer = require('./DFASerializer').LexerDFASerializer;\nexports.PredPrediction = require('./DFAState').PredPrediction;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {BitSet} = require('./../Utils');\nconst {ErrorListener} = require('./ErrorListener')\nconst {Interval} = require('./../IntervalSet')\n\n\n/**\n * This implementation of {@link ANTLRErrorListener} can be used to identify\n *  certain potential correctness and performance problems in grammars. \"Reports\"\n *  are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n *  message.\n *\n *  <ul>\n *  <li><b>Ambiguities</b>: These are cases where more than one path through the\n *  grammar can match the input.</li>\n *  <li><b>Weak context sensitivity</b>: These are cases where full-context\n *  prediction resolved an SLL conflict to a unique alternative which equaled the\n *  minimum alternative of the SLL conflict.</li>\n *  <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n *  full-context prediction resolved an SLL conflict to a unique alternative,\n *  <em>and</em> the minimum alternative of the SLL conflict was found to not be\n *  a truly viable alternative. Two-stage parsing cannot be used for inputs where\n *  this situation occurs.</li>\n *  </ul>\n */\nclass DiagnosticErrorListener extends ErrorListener {\n\tconstructor(exactOnly) {\n\t\tsuper();\n\t\texactOnly = exactOnly || true;\n\t\t// whether all ambiguities or only exact ambiguities are reported.\n\t\tthis.exactOnly = exactOnly;\n\t}\n\n\treportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n\t\tif (this.exactOnly && !exact) {\n\t\t\treturn;\n\t\t}\n\t\tconst msg = \"reportAmbiguity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\": ambigAlts=\" +\n\t\t\tthis.getConflictingAlts(ambigAlts, configs) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\t\tconst msg = \"reportAttemptingFullContext d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\t\tconst msg = \"reportContextSensitivity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\tgetDecisionDescription(recognizer, dfa) {\n\t\tconst decision = dfa.decision\n\t\tconst ruleIndex = dfa.atnStartState.ruleIndex\n\n\t\tconst ruleNames = recognizer.ruleNames\n\t\tif (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\tconst ruleName = ruleNames[ruleIndex] || null\n\t\tif (ruleName === null || ruleName.length === 0) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\treturn `${decision} (${ruleName})`;\n\t}\n\n\t/**\n\t * Computes the set of conflicting or ambiguous alternatives from a\n\t * configuration set, if that information was not already provided by the\n\t * parser.\n\t *\n\t * @param reportedAlts The set of conflicting or ambiguous alternatives, as\n\t * reported by the parser.\n\t * @param configs The conflicting or ambiguous configuration set.\n\t * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n\t * returns the set of alternatives represented in {@code configs}.\n     */\n\tgetConflictingAlts(reportedAlts, configs) {\n\t\tif (reportedAlts !== null) {\n\t\t\treturn reportedAlts;\n\t\t}\n\t\tconst result = new BitSet()\n\t\tfor (let i = 0; i < configs.items.length; i++) {\n\t\t\tresult.add(configs.items[i].alt);\n\t\t}\n\t\treturn `{${result.values().join(\", \")}}`;\n\t}\n}\n\nmodule.exports = DiagnosticErrorListener\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Provides an empty default implementation of {@link ANTLRErrorListener}. The\n * default implementation of each method does nothing, but can be overridden as\n * necessary.\n */\nclass ErrorListener {\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    }\n}\n\n/**\n * {@inheritDoc}\n *\n * <p>\n * This implementation prints messages to {@link System//err} containing the\n * values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n * the following format.</p>\n *\n * <pre>\n * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n * </pre>\n *\n */\nclass ConsoleErrorListener extends ErrorListener {\n    constructor() {\n        super();\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        console.error(\"line \" + line + \":\" + column + \" \" + msg);\n    }\n}\n\n\n/**\n * Provides a default instance of {@link ConsoleErrorListener}.\n */\nConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n\nclass ProxyErrorListener extends ErrorListener {\n    constructor(delegates) {\n        super();\n        if (delegates===null) {\n            throw \"delegates\";\n        }\n        this.delegates = delegates;\n        return this;\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        this.delegates.map(d => d.syntaxError(recognizer, offendingSymbol, line, column, msg, e));\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n        this.delegates.map(d => d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs));\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n        this.delegates.map(d => d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs));\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n        this.delegates.map(d => d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs));\n    }\n}\n\nmodule.exports = {ErrorListener, ConsoleErrorListener, ProxyErrorListener}\n\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token')\nconst {NoViableAltException, InputMismatchException, FailedPredicateException, ParseCancellationException} = require('./Errors')\nconst {ATNState} = require('./../atn/ATNState')\nconst {Interval, IntervalSet} = require('./../IntervalSet')\n\nclass ErrorStrategy {\n\n    reset(recognizer) {\n    }\n\n    recoverInline(recognizer) {\n    }\n\n    recover(recognizer, e) {\n    }\n\n    sync(recognizer) {\n    }\n\n    inErrorRecoveryMode(recognizer) {\n    }\n\n    reportError(recognizer) {\n    }\n}\n\n\n/**\n * This is the default implementation of {@link ANTLRErrorStrategy} used for\n * error reporting and recovery in ANTLR parsers.\n*/\nclass DefaultErrorStrategy extends ErrorStrategy {\n    constructor() {\n        super();\n        /**\n         * Indicates whether the error strategy is currently \"recovering from an\n         * error\". This is used to suppress reporting multiple error messages while\n         * attempting to recover from a detected syntax error.\n         *\n         * @see //inErrorRecoveryMode\n         */\n        this.errorRecoveryMode = false;\n\n        /**\n         * The index into the input stream where the last error occurred.\n         * This is used to prevent infinite loops where an error is found\n         * but no token is consumed during recovery...another error is found,\n         * ad nauseum. This is a failsafe mechanism to guarantee that at least\n         * one token/tree node is consumed for two errors.\n         */\n        this.lastErrorIndex = -1;\n        this.lastErrorStates = null;\n        this.nextTokensContext = null;\n        this.nextTokenState = 0;\n    }\n\n    /**\n     * <p>The default implementation simply calls {@link //endErrorCondition} to\n     * ensure that the handler is not in error recovery mode.</p>\n    */\n    reset(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * This method is called to enter error recovery mode when a recognition\n     * exception is reported.\n     *\n     * @param recognizer the parser instance\n    */\n    beginErrorCondition(recognizer) {\n        this.errorRecoveryMode = true;\n    }\n\n    inErrorRecoveryMode(recognizer) {\n        return this.errorRecoveryMode;\n    }\n\n    /**\n     * This method is called to leave error recovery mode after recovering from\n     * a recognition exception.\n     * @param recognizer\n     */\n    endErrorCondition(recognizer) {\n        this.errorRecoveryMode = false;\n        this.lastErrorStates = null;\n        this.lastErrorIndex = -1;\n    }\n\n    /**\n     * {@inheritDoc}\n     * <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n     */\n    reportMatch(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * <p>The default implementation returns immediately if the handler is already\n     * in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n     * and dispatches the reporting task based on the runtime type of {@code e}\n     * according to the following table.</p>\n     *\n     * <ul>\n     * <li>{@link NoViableAltException}: Dispatches the call to\n     * {@link //reportNoViableAlternative}</li>\n     * <li>{@link InputMismatchException}: Dispatches the call to\n     * {@link //reportInputMismatch}</li>\n     * <li>{@link FailedPredicateException}: Dispatches the call to\n     * {@link //reportFailedPredicate}</li>\n     * <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n     * the exception</li>\n     * </ul>\n     */\n    reportError(recognizer, e) {\n       // if we've already reported an error and have not matched a token\n       // yet successfully, don't report any errors.\n        if(this.inErrorRecoveryMode(recognizer)) {\n            return; // don't report spurious errors\n        }\n        this.beginErrorCondition(recognizer);\n        if ( e instanceof NoViableAltException ) {\n            this.reportNoViableAlternative(recognizer, e);\n        } else if ( e instanceof InputMismatchException ) {\n            this.reportInputMismatch(recognizer, e);\n        } else if ( e instanceof FailedPredicateException ) {\n            this.reportFailedPredicate(recognizer, e);\n        } else {\n            console.log(\"unknown recognition error type: \" + e.constructor.name);\n            console.log(e.stack);\n            recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n        }\n    }\n\n    /**\n     *\n     * {@inheritDoc}\n     *\n     * <p>The default implementation resynchronizes the parser by consuming tokens\n     * until we find one in the resynchronization set--loosely the set of tokens\n     * that can follow the current rule.</p>\n     *\n     */\n    recover(recognizer, e) {\n        if (this.lastErrorIndex===recognizer.getInputStream().index &&\n            this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {\n            // uh oh, another error at same token index and previously-visited\n            // state in ATN; must be a case where LT(1) is in the recovery\n            // token set so nothing got consumed. Consume a single token\n            // at least to prevent an infinite loop; this is a failsafe.\n            recognizer.consume();\n        }\n        this.lastErrorIndex = recognizer._input.index;\n        if (this.lastErrorStates === null) {\n            this.lastErrorStates = [];\n        }\n        this.lastErrorStates.push(recognizer.state);\n        const followSet = this.getErrorRecoverySet(recognizer)\n        this.consumeUntil(recognizer, followSet);\n    }\n\n    /**\n     * The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n     * that the current lookahead symbol is consistent with what were expecting\n     * at this point in the ATN. You can call this anytime but ANTLR only\n     * generates code to check before subrules/loops and each iteration.\n     *\n     * <p>Implements Jim Idle's magic sync mechanism in closures and optional\n     * subrules. E.g.,</p>\n     *\n     * <pre>\n     * a : sync ( stuff sync )* ;\n     * sync : {consume to what can follow sync} ;\n     * </pre>\n     *\n     * At the start of a sub rule upon error, {@link //sync} performs single\n     * token deletion, if possible. If it can't do that, it bails on the current\n     * rule and uses the default error recovery, which consumes until the\n     * resynchronization set of the current rule.\n     *\n     * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n     * with an empty alternative), then the expected set includes what follows\n     * the subrule.</p>\n     *\n     * <p>During loop iteration, it consumes until it sees a token that can start a\n     * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n     * stay in the loop as long as possible.</p>\n     *\n     * <p><strong>ORIGINS</strong></p>\n     *\n     * <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n     * A single mismatch token or missing token would force the parser to bail\n     * out of the entire rules surrounding the loop. So, for rule</p>\n     *\n     * <pre>\n     * classDef : 'class' ID '{' member* '}'\n     * </pre>\n     *\n     * input with an extra token between members would force the parser to\n     * consume until it found the next class definition rather than the next\n     * member definition of the current class.\n     *\n     * <p>This functionality cost a little bit of effort because the parser has to\n     * compare token set at the start of the loop and at each iteration. If for\n     * some reason speed is suffering for you, you can turn off this\n     * functionality by simply overriding this method as a blank { }.</p>\n     *\n     */\n    sync(recognizer) {\n        // If already recovering, don't try to sync\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        const s = recognizer._interp.atn.states[recognizer.state];\n        const la = recognizer.getTokenStream().LA(1);\n        // try cheaper subset first; might get lucky. seems to shave a wee bit off\n        const nextTokens = recognizer.atn.nextTokens(s);\n        if(nextTokens.contains(la)) {\n            this.nextTokensContext = null;\n            this.nextTokenState = ATNState.INVALID_STATE_NUMBER;\n            return;\n        } else if (nextTokens.contains(Token.EPSILON)) {\n            if(this.nextTokensContext === null) {\n                // It's possible the next token won't match information tracked\n                // by sync is restricted for performance.\n                this.nextTokensContext = recognizer._ctx;\n                this.nextTokensState = recognizer._stateNumber;\n            }\n            return;\n        }\n        switch (s.stateType) {\n        case ATNState.BLOCK_START:\n        case ATNState.STAR_BLOCK_START:\n        case ATNState.PLUS_BLOCK_START:\n        case ATNState.STAR_LOOP_ENTRY:\n           // report error and recover if possible\n            if( this.singleTokenDeletion(recognizer) !== null) {\n                return;\n            } else {\n                throw new InputMismatchException(recognizer);\n            }\n        case ATNState.PLUS_LOOP_BACK:\n        case ATNState.STAR_LOOP_BACK:\n            this.reportUnwantedToken(recognizer);\n            const expecting = new IntervalSet()\n            expecting.addSet(recognizer.getExpectedTokens());\n            const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer))\n            this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n            break;\n        default:\n            // do nothing if we can't identify the exact kind of ATN state\n        }\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link NoViableAltException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportNoViableAlternative(recognizer, e) {\n        const tokens = recognizer.getTokenStream()\n        let input\n        if(tokens !== null) {\n            if (e.startToken.type===Token.EOF) {\n                input = \"<EOF>\";\n            } else {\n                input = tokens.getText(new Interval(e.startToken.tokenIndex, e.offendingToken.tokenIndex));\n            }\n        } else {\n            input = \"<unknown input>\";\n        }\n        const msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is an\n     * {@link InputMismatchException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportInputMismatch(recognizer, e) {\n        const msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) +\n            \" expecting \" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link FailedPredicateException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportFailedPredicate(recognizer, e) {\n        const ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex]\n        const msg = \"rule \" + ruleName + \" \" + e.message\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the removal\n     * of a token from the input stream. At the time this method is called, the\n     * erroneous symbol is current {@code LT(1)} symbol and has not yet been\n     * removed from the input stream. When this method returns,\n     * {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenDeletion} identifies\n     * single-token deletion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     *\n     */\n    reportUnwantedToken(recognizer) {\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const tokenName = this.getTokenErrorDisplay(t)\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"extraneous input \" + tokenName + \" expecting \" +\n            expecting.toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the\n     * insertion of a missing token into the input stream. At the time this\n     * method is called, the missing token has not yet been inserted. When this\n     * method returns, {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenInsertion} identifies\n     * single-token insertion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     */\n    reportMissingToken(recognizer) {\n        if ( this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"missing \" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n            \" at \" + this.getTokenErrorDisplay(t)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * <p>The default implementation attempts to recover from the mismatched input\n     * by using single token insertion and deletion as described below. If the\n     * recovery attempt fails, this method throws an\n     * {@link InputMismatchException}.</p>\n     *\n     * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n     *\n     * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n     * right token, however, then assume {@code LA(1)} is some extra spurious\n     * token and delete it. Then consume and return the next token (which was\n     * the {@code LA(2)} token) as the successful result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n     * //singleTokenDeletion}.</p>\n     *\n     * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n     *\n     * <p>If current token (at {@code LA(1)}) is consistent with what could come\n     * after the expected {@code LA(1)} token, then assume the token is missing\n     * and use the parser's {@link TokenFactory} to create it on the fly. The\n     * \"insertion\" is performed by returning the created token as the successful\n     * result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n     * //singleTokenInsertion}.</p>\n     *\n     * <p><strong>EXAMPLE</strong></p>\n     *\n     * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n     * the parser returns from the nested call to {@code expr}, it will have\n     * call chain:</p>\n     *\n     * <pre>\n     * stat &rarr; expr &rarr; atom\n     * </pre>\n     *\n     * and it will be trying to match the {@code ')'} at this point in the\n     * derivation:\n     *\n     * <pre>\n     * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n     * ^\n     * </pre>\n     *\n     * The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n     * call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n     * is in the set of tokens that can follow the {@code ')'} token reference\n     * in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n     */\n    recoverInline(recognizer) {\n        // SINGLE TOKEN DELETION\n        const matchedSymbol = this.singleTokenDeletion(recognizer)\n        if (matchedSymbol !== null) {\n            // we have deleted the extra token.\n            // now, move past ttype token as if all were ok\n            recognizer.consume();\n            return matchedSymbol;\n        }\n        // SINGLE TOKEN INSERTION\n        if (this.singleTokenInsertion(recognizer)) {\n            return this.getMissingSymbol(recognizer);\n        }\n        // even that didn't work; must throw the exception\n        throw new InputMismatchException(recognizer);\n    }\n\n    /**\n     * This method implements the single-token insertion inline error recovery\n     * strategy. It is called by {@link //recoverInline} if the single-token\n     * deletion strategy fails to recover from the mismatched input. If this\n     * method returns {@code true}, {@code recognizer} will be in error recovery\n     * mode.\n     *\n     * <p>This method determines whether or not single-token insertion is viable by\n     * checking if the {@code LA(1)} input symbol could be successfully matched\n     * if it were instead the {@code LA(2)} symbol. If this method returns\n     * {@code true}, the caller is responsible for creating and inserting a\n     * token with the correct type to produce this behavior.</p>\n     *\n     * @param recognizer the parser instance\n     * @return {@code true} if single-token insertion is a viable recovery\n     * strategy for the current mismatched input, otherwise {@code false}\n     */\n    singleTokenInsertion(recognizer) {\n        const currentSymbolType = recognizer.getTokenStream().LA(1)\n        // if current token is consistent with what could come after current\n        // ATN state, then we know we're missing a token; error recovery\n        // is free to conjure up and insert the missing token\n        const atn = recognizer._interp.atn\n        const currentState = atn.states[recognizer.state]\n        const next = currentState.transitions[0].target\n        const expectingAtLL2 = atn.nextTokens(next, recognizer._ctx)\n        if (expectingAtLL2.contains(currentSymbolType) ){\n            this.reportMissingToken(recognizer);\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n    /**\n     * This method implements the single-token deletion inline error recovery\n     * strategy. It is called by {@link //recoverInline} to attempt to recover\n     * from mismatched input. If this method returns null, the parser and error\n     * handler state will not have changed. If this method returns non-null,\n     * {@code recognizer} will <em>not</em> be in error recovery mode since the\n     * returned token was a successful match.\n     *\n     * <p>If the single-token deletion is successful, this method calls\n     * {@link //reportUnwantedToken} to report the error, followed by\n     * {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n     * before returning {@link //reportMatch} is called to signal a successful\n     * match.</p>\n     *\n     * @param recognizer the parser instance\n     * @return the successfully matched {@link Token} instance if single-token\n     * deletion successfully recovers from the mismatched input, otherwise\n     * {@code null}\n     */\n    singleTokenDeletion(recognizer) {\n        const nextTokenType = recognizer.getTokenStream().LA(2)\n        const expecting = this.getExpectedTokens(recognizer)\n        if (expecting.contains(nextTokenType)) {\n            this.reportUnwantedToken(recognizer);\n            // print(\"recoverFromMismatchedToken deleting \" \\\n            // + str(recognizer.getTokenStream().LT(1)) \\\n            // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n            // + \" is what we want\", file=sys.stderr)\n            recognizer.consume(); // simply delete extra token\n            // we want to return the token we're actually matching\n            const matchedSymbol = recognizer.getCurrentToken()\n            this.reportMatch(recognizer); // we know current token is correct\n            return matchedSymbol;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Conjure up a missing token during error recovery.\n     *\n     * The recognizer attempts to recover from single missing\n     * symbols. But, actions might refer to that missing symbol.\n     * For example, x=ID {f($x);}. The action clearly assumes\n     * that there has been an identifier matched previously and that\n     * $x points at that token. If that token is missing, but\n     * the next token in the stream is what we want we assume that\n     * this token is missing and we keep going. Because we\n     * have to return some token to replace the missing token,\n     * we have to conjure one up. This method gives the user control\n     * over the tokens returned for missing tokens. Mostly,\n     * you will want to create something special for identifier\n     * tokens. For literals such as '{' and ',', the default\n     * action in the parser or tree parser works. It simply creates\n     * a CommonToken of the appropriate type. The text will be the token.\n     * If you change what tokens must be created by the lexer,\n     * override this method to create the appropriate tokens.\n     *\n     */\n    getMissingSymbol(recognizer) {\n        const currentSymbol = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const expectedTokenType = expecting.first() // get any element\n        let tokenText\n        if (expectedTokenType===Token.EOF) {\n            tokenText = \"<missing EOF>\";\n        } else {\n            tokenText = \"<missing \" + recognizer.literalNames[expectedTokenType] + \">\";\n        }\n        let current = currentSymbol\n        const lookback = recognizer.getTokenStream().LT(-1)\n        if (current.type===Token.EOF && lookback !== null) {\n            current = lookback;\n        }\n        return recognizer.getTokenFactory().create(current.source,\n            expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,\n            -1, -1, current.line, current.column);\n    }\n\n    getExpectedTokens(recognizer) {\n        return recognizer.getExpectedTokens();\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out. Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     */\n    getTokenErrorDisplay(t) {\n        if (t === null) {\n            return \"<no token>\";\n        }\n        let s = t.text\n        if (s === null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        return this.escapeWSAndQuote(s);\n    }\n\n    escapeWSAndQuote(s) {\n        s = s.replace(/\\n/g,\"\\\\n\");\n        s = s.replace(/\\r/g,\"\\\\r\");\n        s = s.replace(/\\t/g,\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    /**\n     * Compute the error recovery set for the current rule. During\n     * rule invocation, the parser pushes the set of tokens that can\n     * follow that rule reference on the stack; this amounts to\n     * computing FIRST of what follows the rule reference in the\n     * enclosing rule. See LinearApproximator.FIRST().\n     * This local follow set only includes tokens\n     * from within the rule; i.e., the FIRST computation done by\n     * ANTLR stops at the end of a rule.\n     *\n     * EXAMPLE\n     *\n     * When you find a \"no viable alt exception\", the input is not\n     * consistent with any of the alternatives for rule r. The best\n     * thing to do is to consume tokens until you see something that\n     * can legally follow a call to r//or* any rule that called r.\n     * You don't want the exact set of viable next tokens because the\n     * input might just be missing a token--you might consume the\n     * rest of the input looking for one of the missing tokens.\n     *\n     * Consider grammar:\n     *\n     * a : '[' b ']'\n     * | '(' b ')'\n     * ;\n     * b : c '^' INT ;\n     * c : ID\n     * | INT\n     * ;\n     *\n     * At each rule invocation, the set of tokens that could follow\n     * that rule is pushed on a stack. Here are the various\n     * context-sensitive follow sets:\n     *\n     * FOLLOW(b1_in_a) = FIRST(']') = ']'\n     * FOLLOW(b2_in_a) = FIRST(')') = ')'\n     * FOLLOW(c_in_b) = FIRST('^') = '^'\n     *\n     * Upon erroneous input \"[]\", the call chain is\n     *\n     * a -> b -> c\n     *\n     * and, hence, the follow context stack is:\n     *\n     * depth follow set start of rule execution\n     * 0 <EOF> a (from main())\n     * 1 ']' b\n     * 2 '^' c\n     *\n     * Notice that ')' is not included, because b would have to have\n     * been called from a different context in rule a for ')' to be\n     * included.\n     *\n     * For error recovery, we cannot consider FOLLOW(c)\n     * (context-sensitive or otherwise). We need the combined set of\n     * all context-sensitive FOLLOW sets--the set of all tokens that\n     * could follow any reference in the call chain. We need to\n     * resync to one of those tokens. Note that FOLLOW(c)='^' and if\n     * we resync'd to that token, we'd consume until EOF. We need to\n     * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n     * In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n     * not consume anything. After printing an error, rule c would\n     * return normally. Rule b would not find the required '^' though.\n     * At this point, it gets a mismatched token error and throws an\n     * exception (since LA(1) is not in the viable following token\n     * set). The rule exception handler tries to recover, but finds\n     * the same recovery set and doesn't consume anything. Rule b\n     * exits normally returning to rule a. Now it finds the ']' (and\n     * with the successful match exits errorRecovery mode).\n     *\n     * So, you can see that the parser walks up the call chain looking\n     * for the token that was a member of the recovery set.\n     *\n     * Errors are not generated in errorRecovery mode.\n     *\n     * ANTLR's error recovery mechanism is based upon original ideas:\n     *\n     * \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n     *\n     * and\n     *\n     * \"A note on error recovery in recursive descent parsers\":\n     * http://portal.acm.org/citation.cfm?id=947902.947905\n     *\n     * Later, Josef Grosch had some good ideas:\n     *\n     * \"Efficient and Comfortable Error Recovery in Recursive Descent\n     * Parsers\":\n     * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n     *\n     * Like Grosch I implement context-sensitive FOLLOW sets that are combined\n     * at run-time upon error to avoid overhead during parsing.\n     */\n    getErrorRecoverySet(recognizer) {\n        const atn = recognizer._interp.atn\n        let ctx = recognizer._ctx\n        const recoverSet = new IntervalSet()\n        while (ctx !== null && ctx.invokingState>=0) {\n            // compute what follows who invoked us\n            const invokingState = atn.states[ctx.invokingState]\n            const rt = invokingState.transitions[0]\n            const follow = atn.nextTokens(rt.followState)\n            recoverSet.addSet(follow);\n            ctx = ctx.parentCtx;\n        }\n        recoverSet.removeOne(Token.EPSILON);\n        return recoverSet;\n    }\n\n// Consume tokens until one matches the given token set.//\n    consumeUntil(recognizer, set) {\n        let ttype = recognizer.getTokenStream().LA(1)\n        while( ttype !== Token.EOF && !set.contains(ttype)) {\n            recognizer.consume();\n            ttype = recognizer.getTokenStream().LA(1);\n        }\n    }\n}\n\n\n/**\n * This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n * by immediately canceling the parse operation with a\n * {@link ParseCancellationException}. The implementation ensures that the\n * {@link ParserRuleContext//exception} field is set for all parse tree nodes\n * that were not completed prior to encountering the error.\n *\n * <p>\n * This error strategy is useful in the following scenarios.</p>\n *\n * <ul>\n * <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n * stage of two-stage parsing to immediately terminate if an error is\n * encountered, and immediately fall back to the second stage. In addition to\n * avoiding wasted work by attempting to recover from errors here, the empty\n * implementation of {@link BailErrorStrategy//sync} improves the performance of\n * the first stage.</li>\n * <li><strong>Silent validation:</strong> When syntax errors are not being\n * reported or logged, and the parse result is simply ignored if errors occur,\n * the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n * when the result will be ignored either way.</li>\n * </ul>\n *\n * <p>\n * {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n *\n * @see Parser//setErrorHandler(ANTLRErrorStrategy)\n * */\nclass BailErrorStrategy extends DefaultErrorStrategy {\n    constructor() {\n        super();\n    }\n\n    /**\n     * Instead of recovering from exception {@code e}, re-throw it wrapped\n     * in a {@link ParseCancellationException} so it is not caught by the\n     * rule function catches. Use {@link Exception//getCause()} to get the\n     * original {@link RecognitionException}.\n     */\n    recover(recognizer, e) {\n        let context = recognizer._ctx\n        while (context !== null) {\n            context.exception = e;\n            context = context.parentCtx;\n        }\n        throw new ParseCancellationException(e);\n    }\n\n    /**\n     * Make sure we don't attempt to recover inline; if the parser\n     * successfully recovers, it won't throw an exception.\n     */\n    recoverInline(recognizer) {\n        this.recover(recognizer, new InputMismatchException(recognizer));\n    }\n\n// Make sure we don't attempt to recover from problems in subrules.//\n    sync(recognizer) {\n        // pass\n    }\n}\n\n\nmodule.exports = {BailErrorStrategy, DefaultErrorStrategy};\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n *  3 kinds of errors: prediction errors, failed predicate errors, and\n *  mismatched input errors. In each case, the parser knows where it is\n *  in the input, where it is in the ATN, the rule invocation stack,\n *  and what kind of problem occurred.\n */\n\nconst {PredicateTransition} = require('./../atn/Transition');\nconst {Interval} = require('../IntervalSet').Interval;\n\nclass RecognitionException extends Error {\n    constructor(params) {\n        super(params.message);\n        if (!!Error.captureStackTrace) {\n            Error.captureStackTrace(this, RecognitionException);\n        } else {\n            var stack = new Error().stack;\n        }\n        this.message = params.message;\n        this.recognizer = params.recognizer;\n        this.input = params.input;\n        this.ctx = params.ctx;\n        /**\n         * The current {@link Token} when an error occurred. Since not all streams\n         * support accessing symbols by index, we have to track the {@link Token}\n         * instance itself\n        */\n        this.offendingToken = null;\n        /**\n         * Get the ATN state number the parser was in at the time the error\n         * occurred. For {@link NoViableAltException} and\n         * {@link LexerNoViableAltException} exceptions, this is the\n         * {@link DecisionState} number. For others, it is the state whose outgoing\n         * edge we couldn't match.\n         */\n        this.offendingState = -1;\n        if (this.recognizer!==null) {\n            this.offendingState = this.recognizer.state;\n        }\n    }\n\n    /**\n     * Gets the set of input symbols which could potentially follow the\n     * previously matched symbol at the time this exception was thrown.\n     *\n     * <p>If the set of expected tokens is not known and could not be computed,\n     * this method returns {@code null}.</p>\n     *\n     * @return The set of token types that could potentially follow the current\n     * state in the ATN, or {@code null} if the information is not available.\n     */\n    getExpectedTokens() {\n        if (this.recognizer!==null) {\n            return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n        } else {\n            return null;\n        }\n    }\n\n    // <p>If the state number is not known, this method returns -1.</p>\n    toString() {\n        return this.message;\n    }\n}\n\nclass LexerNoViableAltException extends RecognitionException {\n    constructor(lexer, input, startIndex, deadEndConfigs) {\n        super({message: \"\", recognizer: lexer, input: input, ctx: null});\n        this.startIndex = startIndex;\n        this.deadEndConfigs = deadEndConfigs;\n    }\n\n    toString() {\n        let symbol = \"\";\n        if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n            symbol = this.input.getText(new Interval(this.startIndex,this.startIndex));\n        }\n        return \"LexerNoViableAltException\" + symbol;\n    }\n}\n\n\n/**\n * Indicates that the parser could not decide which of two or more paths\n * to take based upon the remaining input. It tracks the starting token\n * of the offending input and also knows where the parser was\n * in the various paths when the error. Reported by reportNoViableAlternative()\n */\nclass NoViableAltException extends RecognitionException {\n    constructor(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n        ctx = ctx || recognizer._ctx;\n        offendingToken = offendingToken || recognizer.getCurrentToken();\n        startToken = startToken || recognizer.getCurrentToken();\n        input = input || recognizer.getInputStream();\n        super({message: \"\", recognizer: recognizer, input: input, ctx: ctx});\n        // Which configurations did we try at input.index() that couldn't match\n        // input.LT(1)?//\n        this.deadEndConfigs = deadEndConfigs;\n        // The token object at the start index; the input stream might\n        // not be buffering tokens so get a reference to it. (At the\n        // time the error occurred, of course the stream needs to keep a\n        // buffer all of the tokens but later we might not have access to those.)\n        this.startToken = startToken;\n        this.offendingToken = offendingToken;\n    }\n}\n\n/**\n * This signifies any kind of mismatched input exceptions such as\n * when the current input does not match the expected token.\n*/\nclass InputMismatchException extends RecognitionException {\n    constructor(recognizer) {\n        super({message: \"\", recognizer: recognizer, input: recognizer.getInputStream(), ctx: recognizer._ctx});\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n\nfunction formatMessage(predicate, message) {\n    if (message !==null) {\n        return message;\n    } else {\n        return \"failed predicate: {\" + predicate + \"}?\";\n    }\n}\n\n/**\n * A semantic predicate failed during validation. Validation of predicates\n * occurs when normally parsing the alternative just like matching a token.\n * Disambiguating predicate evaluation occurs when we test a predicate during\n * prediction.\n*/\nclass FailedPredicateException extends RecognitionException {\n    constructor(recognizer, predicate, message) {\n        super({\n            message: formatMessage(predicate, message || null), recognizer: recognizer,\n            input: recognizer.getInputStream(), ctx: recognizer._ctx\n        });\n        const s = recognizer._interp.atn.states[recognizer.state]\n        const trans = s.transitions[0]\n        if (trans instanceof PredicateTransition) {\n            this.ruleIndex = trans.ruleIndex;\n            this.predicateIndex = trans.predIndex;\n        } else {\n            this.ruleIndex = 0;\n            this.predicateIndex = 0;\n        }\n        this.predicate = predicate;\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n\n\nclass ParseCancellationException extends Error{\n    constructor() {\n        super()\n        Error.captureStackTrace(this, ParseCancellationException);\n    }\n}\n\nmodule.exports = {\n    RecognitionException,\n    NoViableAltException,\n    LexerNoViableAltException,\n    InputMismatchException,\n    FailedPredicateException,\n    ParseCancellationException\n};\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nmodule.exports.RecognitionException = require('./Errors').RecognitionException;\nmodule.exports.NoViableAltException = require('./Errors').NoViableAltException;\nmodule.exports.LexerNoViableAltException = require('./Errors').LexerNoViableAltException;\nmodule.exports.InputMismatchException = require('./Errors').InputMismatchException;\nmodule.exports.FailedPredicateException = require('./Errors').FailedPredicateException;\nmodule.exports.DiagnosticErrorListener = require('./DiagnosticErrorListener');\nmodule.exports.BailErrorStrategy = require('./ErrorStrategy').BailErrorStrategy;\nmodule.exports.DefaultErrorStrategy = require('./ErrorStrategy').DefaultErrorStrategy;\nmodule.exports.ErrorListener = require('./ErrorListener').ErrorListener;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexports.atn = require('./atn/index');\nexports.codepointat = require('./polyfills/codepointat');\nexports.dfa = require('./dfa/index');\nexports.fromcodepoint = require('./polyfills/fromcodepoint');\nexports.tree = require('./tree/index');\nexports.error = require('./error/index');\nexports.Token = require('./Token').Token;\nexports.CharStreams = require('./CharStreams');\nexports.CommonToken = require('./Token').CommonToken;\nexports.InputStream = require('./InputStream');\nexports.FileStream = require('./FileStream');\nexports.CommonTokenStream = require('./CommonTokenStream');\nexports.Lexer = require('./Lexer');\nexports.Parser = require('./Parser');\nvar pc = require('./PredictionContext');\nexports.PredictionContextCache = pc.PredictionContextCache;\nexports.ParserRuleContext = require('./ParserRuleContext');\nexports.Interval = require('./IntervalSet').Interval;\nexports.IntervalSet = require('./IntervalSet').IntervalSet;\nexports.Utils = require('./Utils');\nexports.LL1Analyzer = require('./LL1Analyzer').LL1Analyzer;\n","/*! https://mths.be/codepointat v0.2.0 by @mathias */\nif (!String.prototype.codePointAt) {\n\t(function() {\n\t\t'use strict'; // needed to support `apply`/`call` with `undefined`/`null`\n\t\tvar defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\tlet result;\n\t\t\ttry {\n\t\t\t\tconst object = {};\n\t\t\t\tconst $defineProperty = Object.defineProperty;\n\t\t\t\tresult = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {\n\t\t\t}\n\t\t\treturn result;\n\t\t}());\n\t\tconst codePointAt = function(position) {\n\t\t\tif (this == null) {\n\t\t\t\tthrow TypeError();\n\t\t\t}\n\t\t\tconst string = String(this);\n\t\t\tconst size = string.length;\n\t\t\t// `ToInteger`\n\t\t\tlet index = position ? Number(position) : 0;\n\t\t\tif (index !== index) { // better `isNaN`\n\t\t\t\tindex = 0;\n\t\t\t}\n\t\t\t// Account for out-of-bounds indices:\n\t\t\tif (index < 0 || index >= size) {\n\t\t\t\treturn undefined;\n\t\t\t}\n\t\t\t// Get the first code unit\n\t\t\tconst first = string.charCodeAt(index);\n\t\t\tlet second;\n\t\t\tif ( // check if its the start of a surrogate pair\n\t\t\t\tfirst >= 0xD800 && first <= 0xDBFF && // high surrogate\n\t\t\t\tsize > index + 1 // there is a next code unit\n\t\t\t) {\n\t\t\t\tsecond = string.charCodeAt(index + 1);\n\t\t\t\tif (second >= 0xDC00 && second <= 0xDFFF) { // low surrogate\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\treturn (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn first;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String.prototype, 'codePointAt', {\n\t\t\t\t'value': codePointAt,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.prototype.codePointAt = codePointAt;\n\t\t}\n\t}());\n}\n","/*! https://mths.be/fromcodepoint v0.2.1 by @mathias */\nif (!String.fromCodePoint) {\n\t(function() {\n\t\tconst defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\tlet result;\n\t\t\ttry {\n\t\t\t\tconst object = {};\n\t\t\t\tconst $defineProperty = Object.defineProperty;\n\t\t\t\tresult = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {}\n\t\t\treturn result;\n\t\t}());\n\t\tconst stringFromCharCode = String.fromCharCode;\n\t\tconst floor = Math.floor;\n\t\tconst fromCodePoint = function(_) {\n\t\t\tconst MAX_SIZE = 0x4000;\n\t\t\tconst codeUnits = [];\n\t\t\tlet highSurrogate;\n\t\t\tlet lowSurrogate;\n\t\t\tlet index = -1;\n\t\t\tconst length = arguments.length;\n\t\t\tif (!length) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\tlet result = '';\n\t\t\twhile (++index < length) {\n\t\t\t\tlet codePoint = Number(arguments[index]);\n\t\t\t\tif (\n\t\t\t\t\t!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`\n\t\t\t\t\tcodePoint < 0 || // not a valid Unicode code point\n\t\t\t\t\tcodePoint > 0x10FFFF || // not a valid Unicode code point\n\t\t\t\t\tfloor(codePoint) !== codePoint // not an integer\n\t\t\t\t) {\n\t\t\t\t\tthrow RangeError('Invalid code point: ' + codePoint);\n\t\t\t\t}\n\t\t\t\tif (codePoint <= 0xFFFF) { // BMP code point\n\t\t\t\t\tcodeUnits.push(codePoint);\n\t\t\t\t} else { // Astral code point; split in surrogate halves\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\tcodePoint -= 0x10000;\n\t\t\t\t\thighSurrogate = (codePoint >> 10) + 0xD800;\n\t\t\t\t\tlowSurrogate = (codePoint % 0x400) + 0xDC00;\n\t\t\t\t\tcodeUnits.push(highSurrogate, lowSurrogate);\n\t\t\t\t}\n\t\t\t\tif (index + 1 === length || codeUnits.length > MAX_SIZE) {\n\t\t\t\t\tresult += stringFromCharCode.apply(null, codeUnits);\n\t\t\t\t\tcodeUnits.length = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String, 'fromCodePoint', {\n\t\t\t\t'value': fromCodePoint,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.fromCodePoint = fromCodePoint;\n\t\t}\n\t}());\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./../Token');\nconst {Interval} = require('./../IntervalSet');\nconst INVALID_INTERVAL = new Interval(-1, -2);\n\n/**\n * The basic notion of a tree has a parent, a payload, and a list of children.\n * It is the most abstract interface for all the trees used by ANTLR.\n */\nclass Tree {}\n\nclass SyntaxTree extends Tree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ParseTree extends SyntaxTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass RuleNode extends ParseTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n\n\tgetRuleContext(){\n\t\tthrow new Error(\"missing interface implementation\")\n\t}\n}\n\nclass TerminalNode extends ParseTree {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ErrorNode extends TerminalNode {\n\tconstructor() {\n\t\tsuper();\n\t}\n}\n\nclass ParseTreeVisitor {\n\tvisit(ctx) {\n\t\t if (Array.isArray(ctx)) {\n\t\t\treturn ctx.map(function(child) {\n\t\t\t\treturn child.accept(this);\n\t\t\t}, this);\n\t\t} else {\n\t\t\treturn ctx.accept(this);\n\t\t}\n\t}\n\n\tvisitChildren(ctx) {\n\t\tif (ctx.children) {\n\t\t\treturn this.visit(ctx.children);\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tvisitTerminal(node) {\n\t}\n\n\tvisitErrorNode(node) {\n\t}\n}\n\nclass ParseTreeListener {\n\tvisitTerminal(node) {\n\t}\n\n\tvisitErrorNode(node) {\n\t}\n\n\tenterEveryRule(node) {\n\t}\n\n\texitEveryRule(node) {\n\t}\n}\n\nclass TerminalNodeImpl extends TerminalNode {\n\tconstructor(symbol) {\n\t\tsuper();\n\t\tthis.parentCtx = null;\n\t\tthis.symbol = symbol;\n\t}\n\n\tgetChild(i) {\n\t\treturn null;\n\t}\n\n\tgetSymbol() {\n\t\treturn this.symbol;\n\t}\n\n\tgetParent() {\n\t\treturn this.parentCtx;\n\t}\n\n\tgetPayload() {\n\t\treturn this.symbol;\n\t}\n\n\tgetSourceInterval() {\n\t\tif (this.symbol === null) {\n\t\t\treturn INVALID_INTERVAL;\n\t\t}\n\t\tconst tokenIndex = this.symbol.tokenIndex;\n\t\treturn new Interval(tokenIndex, tokenIndex);\n\t}\n\n\tgetChildCount() {\n\t\treturn 0;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitTerminal(this);\n\t}\n\n\tgetText() {\n\t\treturn this.symbol.text;\n\t}\n\n\ttoString() {\n\t\tif (this.symbol.type === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else {\n\t\t\treturn this.symbol.text;\n\t\t}\n\t}\n}\n\n\n/**\n * Represents a token that was consumed during resynchronization\n * rather than during a valid match operation. For example,\n * we will create this kind of a node during single token insertion\n * and deletion as well as during \"consume until error recovery set\"\n * upon no viable alternative exceptions.\n */\nclass ErrorNodeImpl extends TerminalNodeImpl {\n\tconstructor(token) {\n\t\tsuper(token);\n\t}\n\n\tisErrorNode() {\n\t\treturn true;\n\t}\n\n\taccept(visitor) {\n\t\treturn visitor.visitErrorNode(this);\n\t}\n}\n\nclass ParseTreeWalker {\n\n\t/**\n\t * Performs a walk on the given parse tree starting at the root and going down recursively\n\t * with depth-first search. On each node, {@link ParseTreeWalker//enterRule} is called before\n\t * recursively walking down into child nodes, then\n\t * {@link ParseTreeWalker//exitRule} is called after the recursive call to wind up.\n\t * @param listener The listener used by the walker to process grammar rules\n\t * @param t The parse tree to be walked on\n\t */\n\twalk(listener, t) {\n\t\tconst errorNode = t instanceof ErrorNode ||\n\t\t\t\t(t.isErrorNode !== undefined && t.isErrorNode());\n\t\tif (errorNode) {\n\t\t\tlistener.visitErrorNode(t);\n\t\t} else if (t instanceof TerminalNode) {\n\t\t\tlistener.visitTerminal(t);\n\t\t} else {\n\t\t\tthis.enterRule(listener, t);\n\t\t\tfor (let i = 0; i < t.getChildCount(); i++) {\n\t\t\t\tconst child = t.getChild(i);\n\t\t\t\tthis.walk(listener, child);\n\t\t\t}\n\t\t\tthis.exitRule(listener, t);\n\t\t}\n\t}\n\n\t/**\n\t * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener//enterEveryRule}\n\t * then by triggering the event specific to the given parse tree node\n\t * @param listener The listener responding to the trigger events\n\t * @param r The grammar rule containing the rule context\n\t */\n\tenterRule(listener, r) {\n\t\tconst ctx = r.getRuleContext();\n\t\tlistener.enterEveryRule(ctx);\n\t\tctx.enterRule(listener);\n\t}\n\n\t/**\n\t * Exits a grammar rule by first triggering the event specific to the given parse tree node\n\t * then by triggering the generic event {@link ParseTreeListener//exitEveryRule}\n\t * @param listener The listener responding to the trigger events\n\t * @param r The grammar rule containing the rule context\n\t */\n\texitRule(listener, r) {\n\t\tconst ctx = r.getRuleContext();\n\t\tctx.exitRule(listener);\n\t\tlistener.exitEveryRule(ctx);\n\t}\n}\n\nParseTreeWalker.DEFAULT = new ParseTreeWalker();\n\nmodule.exports = {\n\tRuleNode,\n\tErrorNode,\n\tTerminalNode,\n\tErrorNodeImpl,\n\tTerminalNodeImpl,\n\tParseTreeListener,\n\tParseTreeVisitor,\n\tParseTreeWalker,\n\tINVALID_INTERVAL\n}\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Utils = require('./../Utils');\nconst {Token} = require('./../Token');\nconst {ErrorNode, TerminalNode, RuleNode} = require('./Tree');\n\n/** A set of utility routines useful for all kinds of ANTLR trees. */\nconst Trees = {\n    /**\n     * Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n     *  node payloads to get the text for the nodes.  Detect\n     *  parse trees and extract data appropriately.\n     */\n    toStringTree: function(tree, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        let s = Trees.getNodeText(tree, ruleNames);\n        s = Utils.escapeWhitespace(s, false);\n        const c = tree.getChildCount();\n        if(c===0) {\n            return s;\n        }\n        let res = \"(\" + s + ' ';\n        if(c>0) {\n            s = Trees.toStringTree(tree.getChild(0), ruleNames);\n            res = res.concat(s);\n        }\n        for(let i=1;i<c;i++) {\n            s = Trees.toStringTree(tree.getChild(i), ruleNames);\n            res = res.concat(' ' + s);\n        }\n        res = res.concat(\")\");\n        return res;\n    },\n\n    getNodeText: function(t, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        if(ruleNames!==null) {\n            if (t instanceof RuleNode) {\n                const context = t.getRuleContext()\n                const altNumber = context.getAltNumber();\n                // use const value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n                if ( altNumber != 0 ) {\n                    return ruleNames[t.ruleIndex]+\":\"+altNumber;\n                }\n                return ruleNames[t.ruleIndex];\n            } else if ( t instanceof ErrorNode) {\n                return t.toString();\n            } else if(t instanceof TerminalNode) {\n                if(t.symbol!==null) {\n                    return t.symbol.text;\n                }\n            }\n        }\n        // no recog for rule names\n        const payload = t.getPayload();\n        if (payload instanceof Token ) {\n            return payload.text;\n        }\n        return t.getPayload().toString();\n    },\n\n    /**\n     * Return ordered list of all children of this node\n     */\n    getChildren: function(t) {\n        const list = [];\n        for(let i=0;i<t.getChildCount();i++) {\n            list.push(t.getChild(i));\n        }\n        return list;\n    },\n\n    /**\n     * Return a list of all ancestors of this node.  The first node of\n     * list is the root and the last is the parent of this node.\n     */\n    getAncestors: function(t) {\n        let ancestors = [];\n        t = t.getParent();\n        while(t!==null) {\n            ancestors = [t].concat(ancestors);\n            t = t.getParent();\n        }\n        return ancestors;\n    },\n\n    findAllTokenNodes: function(t, ttype) {\n        return Trees.findAllNodes(t, ttype, true);\n    },\n\n    findAllRuleNodes: function(t, ruleIndex) {\n        return Trees.findAllNodes(t, ruleIndex, false);\n    },\n\n    findAllNodes: function(t, index, findTokens) {\n        const nodes = [];\n        Trees._findAllNodes(t, index, findTokens, nodes);\n        return nodes;\n    },\n\n    _findAllNodes: function(t, index, findTokens, nodes) {\n        // check this node (the root) first\n        if(findTokens && (t instanceof TerminalNode)) {\n            if(t.symbol.type===index) {\n                nodes.push(t);\n            }\n        } else if(!findTokens && (t instanceof RuleNode)) {\n            if(t.ruleIndex===index) {\n                nodes.push(t);\n            }\n        }\n        // check children\n        for(let i=0;i<t.getChildCount();i++) {\n            Trees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n        }\n    },\n\n    descendants: function(t) {\n        let nodes = [t];\n        for(let i=0;i<t.getChildCount();i++) {\n            nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n        }\n        return nodes;\n    }\n}\n\nmodule.exports = Trees;\n","/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst Tree = require('./Tree');\nconst Trees = require('./Trees');\nmodule.exports = {...Tree, Trees}\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","export class TerraformProg {\r\n  constructor(file) {\r\n    this.errors = [];\r\n    this.warnings = [];\r\n    this.imports = [];\r\n    this.alreadyImported = [];\r\n    this.files = [];\r\n    this.fileName = file;\r\n  }\r\n\r\n  toStringType(terraform_type) {\r\n    let str = `\\n ${terraform_type} : \\n`;\r\n    for (const key in this[terraform_type]) {\r\n      const node_type = this[terraform_type][key];\r\n      str += `    ${key}: ${node_type}\\n`;\r\n    }\r\n    return str;\r\n  }\r\n\r\n  toString() {\r\n    let str = 'prog: \\n';\r\n    console.log('DEBUG: ', `${this.files}\\n\\n`);\r\n    for (const st in this.files) {\r\n      str += st.toString();\r\n    }\r\n    return str;\r\n  }\r\n}\r\n","export class TerraformFile {\r\n  constructor() {\r\n    this.terraform_directive = [];\r\n\r\n    this.variable_directive = [];\r\n\r\n    this.output_directive = [];\r\n\r\n    this.resource_directive = [];\r\n\r\n    this.data_directive = [];\r\n\r\n    this.provider_directive = [];\r\n\r\n    this.module_directive = [];\r\n    this.modules_source = [];\r\n\r\n    this.field = [];\r\n    this.complex_field = [];\r\n    this.complex_field_object = [];\r\n    this.is_complex_field = false;\r\n    this.name = {};\r\n    this.type = {};\r\n    this.object = {};\r\n\r\n    this.errors = [];\r\n    this.warnings = [];\r\n  }\r\n}\r\n\r\nexport function newTerraformFile(input, source) {\r\n\r\n}\r\n","export class TerraformNode {\r\n  constructor(source) {\r\n    // this.source = source;\r\n    // this.source.terraform = this;\r\n  }\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class TerraformField extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.value = input;\r\n  }\r\n\r\n  toString() {\r\n    return `${this.value}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for field');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newTerraformField(input, source) {\r\n  let res;\r\n  if (TerraformField.isValid(input, source)) {\r\n    res = new TerraformField(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","// type checks for all known types\n//\n// note that:\n//\n// - check by duck-typing on a property like `isUnit`, instead of checking instanceof.\n//   instanceof cannot be used because that would not allow to pass data from\n//   one instance of math.js to another since each has it's own instance of Unit.\n// - check the `isUnit` property via the constructor, so there will be no\n//   matches for \"fake\" instances like plain objects with a property `isUnit`.\n//   That is important for security reasons.\n// - It must not be possible to override the type checks used internally,\n//   for security reasons, so these functions are not exposed in the expression\n//   parser.\nexport function isNumber(x) {\n  return typeof x === 'number';\n}\nexport function isBigNumber(x) {\n  if (!x || typeof x !== 'object' || typeof x.constructor !== 'function') {\n    return false;\n  }\n\n  if (x.isBigNumber === true && typeof x.constructor.prototype === 'object' && x.constructor.prototype.isBigNumber === true) {\n    return true;\n  }\n\n  if (typeof x.constructor.isDecimal === 'function' && x.constructor.isDecimal(x) === true) {\n    return true;\n  }\n\n  return false;\n}\nexport function isComplex(x) {\n  return x && typeof x === 'object' && Object.getPrototypeOf(x).isComplex === true || false;\n}\nexport function isFraction(x) {\n  return x && typeof x === 'object' && Object.getPrototypeOf(x).isFraction === true || false;\n}\nexport function isUnit(x) {\n  return x && x.constructor.prototype.isUnit === true || false;\n}\nexport function isString(x) {\n  return typeof x === 'string';\n}\nexport var isArray = Array.isArray;\nexport function isMatrix(x) {\n  return x && x.constructor.prototype.isMatrix === true || false;\n}\n/**\n * Test whether a value is a collection: an Array or Matrix\n * @param {*} x\n * @returns {boolean} isCollection\n */\n\nexport function isCollection(x) {\n  return Array.isArray(x) || isMatrix(x);\n}\nexport function isDenseMatrix(x) {\n  return x && x.isDenseMatrix && x.constructor.prototype.isMatrix === true || false;\n}\nexport function isSparseMatrix(x) {\n  return x && x.isSparseMatrix && x.constructor.prototype.isMatrix === true || false;\n}\nexport function isRange(x) {\n  return x && x.constructor.prototype.isRange === true || false;\n}\nexport function isIndex(x) {\n  return x && x.constructor.prototype.isIndex === true || false;\n}\nexport function isBoolean(x) {\n  return typeof x === 'boolean';\n}\nexport function isResultSet(x) {\n  return x && x.constructor.prototype.isResultSet === true || false;\n}\nexport function isHelp(x) {\n  return x && x.constructor.prototype.isHelp === true || false;\n}\nexport function isFunction(x) {\n  return typeof x === 'function';\n}\nexport function isDate(x) {\n  return x instanceof Date;\n}\nexport function isRegExp(x) {\n  return x instanceof RegExp;\n}\nexport function isObject(x) {\n  return !!(x && typeof x === 'object' && x.constructor === Object && !isComplex(x) && !isFraction(x));\n}\nexport function isNull(x) {\n  return x === null;\n}\nexport function isUndefined(x) {\n  return x === undefined;\n}\nexport function isAccessorNode(x) {\n  return x && x.isAccessorNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isArrayNode(x) {\n  return x && x.isArrayNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isAssignmentNode(x) {\n  return x && x.isAssignmentNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isBlockNode(x) {\n  return x && x.isBlockNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isConditionalNode(x) {\n  return x && x.isConditionalNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isConstantNode(x) {\n  return x && x.isConstantNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isFunctionAssignmentNode(x) {\n  return x && x.isFunctionAssignmentNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isFunctionNode(x) {\n  return x && x.isFunctionNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isIndexNode(x) {\n  return x && x.isIndexNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isNode(x) {\n  return x && x.isNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isObjectNode(x) {\n  return x && x.isObjectNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isOperatorNode(x) {\n  return x && x.isOperatorNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isParenthesisNode(x) {\n  return x && x.isParenthesisNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isRangeNode(x) {\n  return x && x.isRangeNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isSymbolNode(x) {\n  return x && x.isSymbolNode === true && x.constructor.prototype.isNode === true || false;\n}\nexport function isChain(x) {\n  return x && x.constructor.prototype.isChain === true || false;\n}\nexport function typeOf(x) {\n  var t = typeof x;\n\n  if (t === 'object') {\n    // JavaScript types\n    if (x === null) return 'null';\n    if (Array.isArray(x)) return 'Array';\n    if (x instanceof Date) return 'Date';\n    if (x instanceof RegExp) return 'RegExp'; // math.js types\n\n    if (isBigNumber(x)) return 'BigNumber';\n    if (isComplex(x)) return 'Complex';\n    if (isFraction(x)) return 'Fraction';\n    if (isMatrix(x)) return 'Matrix';\n    if (isUnit(x)) return 'Unit';\n    if (isIndex(x)) return 'Index';\n    if (isRange(x)) return 'Range';\n    if (isResultSet(x)) return 'ResultSet';\n    if (isNode(x)) return x.type;\n    if (isChain(x)) return 'Chain';\n    if (isHelp(x)) return 'Help';\n    return 'Object';\n  }\n\n  if (t === 'function') return 'Function';\n  return t; // can be 'string', 'number', 'boolean', ...\n}","import { isArray } from 'mathjs';\r\nimport { TerraformNode } from './terraform_node.js';\r\n\r\nexport class TerraformComplexField extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.name = input.name;\r\n    this.objects = input.objects;\r\n  }\r\n\r\n  toString() {\r\n    let str = `${this.name} {\\n`;\r\n    this.objects.forEach((object) => {\r\n      str += `    ${object}\\n`;\r\n    });\r\n    str += '  }';\r\n    return str;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.name) !== 'string' || !isArray(input.objects) || input == '') {\r\n      source.errors.push('Incorrect input for field');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newTerraformComplexField(input, source) {\r\n  let res;\r\n  if (TerraformComplexField.isValid(input, source)) {\r\n    res = new TerraformComplexField(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class TerraformObject extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.value = [];\r\n    input.field.forEach((e) => {\r\n      this.value.push(e.value);\r\n    });\r\n    input.complex_field.forEach((e) => {\r\n      this.value.push(e);\r\n    });\r\n  }\r\n\r\n  toString() {\r\n    let str = '';\r\n    if (this.value.length > 0) {\r\n      for (let i = 0; i < this.value.length - 1; i++) {\r\n        str += `  ${this.value[i]}\\n`;\r\n      }\r\n      str += `  ${this.value[this.value.length - 1]}`;\r\n    }\r\n    return str;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (!Array.isArray(input.field) || !Array.isArray(input.complex_field) || input == []) {\r\n      source.errors.push('Incorrect input for object');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newTerraformObject(input, source) {\r\n  let res;\r\n  if (TerraformObject.isValid(input, source)) {\r\n    res = new TerraformObject(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class TerraformName extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.value = input;\r\n  }\r\n\r\n  toString() {\r\n    return `${this.value}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for name');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newTerraformName(input, source) {\r\n  let res;\r\n  if (TerraformName.isValid(input, source)) {\r\n    res = new TerraformName(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class TerraformType extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.value = input;\r\n  }\r\n\r\n  toString() {\r\n    return `${this.value}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for Type');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newTerraformType(input, source) {\r\n  let res;\r\n  if (TerraformType.isValid(input, source)) {\r\n    res = new TerraformType(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class ModuleDirective extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.fileName = '';\r\n    this.type = 'module';\r\n    this.moduleSource = input.source;\r\n    this.name = input.name;\r\n    this.objects = (input.objects.value) ? input.objects : '';\r\n    this.variablesName = (input.names.variables) ? input.names.variables : [];\r\n    this.variablesObject = [];\r\n    this.datasName = (input.names.datas) ? input.names.datas : [];\r\n    this.datasObject = [];\r\n    this.resourcesName = (input.names.resources) ? input.names.resources : [];\r\n    this.resourcesObject = [];\r\n    this.modulesName = (input.names.modules) ? input.names.modules : [];\r\n    this.modulesObject = [];\r\n    this.attributes = [];\r\n  }\r\n\r\n  toString() {\r\n    if (this.objects == '') { return `module \"${this.name}\" {\\n  ${this.moduleSource}\\n}`; }\r\n    return `module \"${this.name}\" {\\n  ${this.moduleSource}\\n${this.objects}\\n}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.objects) !== 'object' || typeof (input.name) !== 'string' || typeof (input.names) !== 'object' || input == '') {\r\n      source.errors.push('Incorrect input for module');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newModuleDirective(input, source) {\r\n  let res;\r\n  if (ModuleDirective.isValid(input, source)) {\r\n    res = new ModuleDirective(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformComplexField } from \"../../model/complex_field.js\";\r\n\r\nexport function get_names(objects, isModule) {\r\n  const variables = [];\r\n  const resources = [];\r\n  const datas = [];\r\n  const modules = [];\r\n\r\n  objects.forEach((e) => {\r\n    if (e instanceof TerraformComplexField) {\r\n      const result = get_names(e.objects);\r\n      result.variables.forEach((variable) => {\r\n        variables.push(variable);\r\n      });\r\n      result.resources.forEach((resource) => {\r\n        resources.push(resource);\r\n      });\r\n      result.datas.forEach((data) => {\r\n        datas.push(data);\r\n      });\r\n      result.modules.forEach((module) => {\r\n        modules.push(module);\r\n      });\r\n    } else {\r\n      let variableName = '';\r\n      let resource = '';\r\n      let data = '';\r\n      let module = '';\r\n      const values = e.split('=');\r\n      if (values[1] != undefined) {\r\n        const variableValue = values[1].split('.');\r\n        variableName = get_variable_name(values);\r\n        if (variableName.length == 0) {\r\n          resource = get_resource_name(values, variableValue);\r\n        }\r\n        if (resource.length == 0) {\r\n          data = get_data_name(values, variableValue);\r\n        }\r\n        if (data.length == 0) {\r\n          module = get_module_name(values, variableValue);\r\n        }\r\n        if (variableName != '') {\r\n          let find = false;\r\n          variableName.forEach((variable) => {\r\n            variables.forEach((v) => {\r\n              if (v.var == variable.var && v.name == variable.name) { find = true; }\r\n            });\r\n            if (!find) { variables.push(variable); } else { find = false; }\r\n          });\r\n        }\r\n        if (resource != '' && !resources.includes(resource)) {\r\n          if (Array.isArray(resource)) {\r\n            resource.forEach((r) => {\r\n              resources.push(r);\r\n            });\r\n          } else {\r\n            resources.push(resource);\r\n          }\r\n        }\r\n        if (data != '' && !datas.includes(data)) {\r\n          datas.push(data);\r\n        }\r\n        if (isModule && module != '' && !modules.includes(module)) {\r\n          modules.push(module);\r\n        }\r\n      }\r\n    }\r\n  });\r\n\r\n  return {\r\n    variables, resources, datas, modules,\r\n  };\r\n}\r\n\r\nexport function get_objects(array, result, isModule) {\r\n  array.forEach((rd) => {\r\n    get_items(rd.variablesName, result.variables).forEach((e) => {\r\n      rd.variablesObject.push(e);\r\n    });\r\n\r\n    compare_array_differences(rd.variablesName, rd.variablesObject, rd.fileName).forEach((e) => {\r\n      result.errors.push(e);\r\n    });\r\n\r\n    get_items(rd.resourcesName, result.resources).forEach((e) => {\r\n      rd.resourcesObject.push(e);\r\n    });\r\n\r\n    compare_array_differences(rd.resourcesName, rd.resourcesObject, rd.fileName).forEach((e) => {\r\n      result.errors.push(e);\r\n    });\r\n\r\n    get_items(rd.datasName, result.datas).forEach((e) => {\r\n      rd.datasObject.push(e);\r\n    });\r\n\r\n    compare_array_differences(rd.datasName, rd.datasObject, rd.fileName).forEach((e) => {\r\n      result.errors.push(e);\r\n    });\r\n\r\n    if (isModule) {\r\n      get_items(rd.modulesName, result.modules).forEach((e) => {\r\n        rd.modulesObject.push(e);\r\n      });\r\n\r\n      compare_array_differences(rd.modulesName, rd.modulesObject, rd.fileName).forEach((e) => {\r\n        result.errors.push(e);\r\n      });\r\n    }\r\n  });\r\n\r\n  return result;\r\n}\r\n\r\nfunction get_items(arrayNames, items) {\r\n  const arrayObjects = [];\r\n  if (arrayNames.length > 0) {\r\n    arrayNames.forEach((rv) => {\r\n      items.forEach((v) => {\r\n        if (rv.type == v.type && rv.name == v.name) {\r\n          arrayObjects.push({ name: rv.var, value: v });\r\n        } else if (!rv.type && rv.name == v.name) {\r\n          arrayObjects.push({ name: rv.var, value: v });\r\n        }\r\n      });\r\n    });\r\n  }\r\n  return arrayObjects;\r\n}\r\n\r\nfunction compare_array_differences(arrayNames, arrayObjects, fileName) {\r\n  const errors = [];\r\n  if (arrayNames.length != arrayObjects.length) {\r\n    let find = false;\r\n    let error;\r\n    arrayNames.forEach((rn) => {\r\n      arrayObjects.forEach((ro) => {\r\n        if (ro.type && rn.type == ro.type && rn.name == ro.name) {\r\n          find = true;\r\n        } else if (!ro.type && rn.name == ro.name) {\r\n          find = true;\r\n        }\r\n      });\r\n      if (!find) {\r\n        if (rn.type) {\r\n          error = `TERRAFORM ERROR in file : ${fileName} object type ${rn.type} : ${rn.name} unknow`;\r\n        } else {\r\n          error = `TERRAFORM ERROR in file : ${fileName} variable ${rn.name} unknow`;\r\n        }\r\n        errors.push(error);\r\n      }\r\n    });\r\n  }\r\n  return errors;\r\n}\r\n\r\nfunction get_variable_name(values) {\r\n  const variableName = [];\r\n  let variableValue;\r\n  let value = '';\r\n  values.forEach((v) => {\r\n    variableValue = v.split('.');\r\n    if (variableValue[0] == 'var') {\r\n      value = { var: values[0], name: variableValue[1] };\r\n      if (!variableName.includes(value)) variableName.push(value);\r\n    } else if (variableValue[0].substring(3) == 'var') {\r\n      if (variableValue[1][variableValue.length - 1] != '\"') {\r\n        value = { var: values[0].split('{')[0], name: variableValue[1].split('}')[0] };\r\n        if (!variableName.includes(value)) variableName.push(value);\r\n      } else {\r\n        value = { var: values[0].split('{')[0], name: variableValue[1].slice(0, -2) };\r\n        if (!variableName.includes(value)) variableName.push(value);\r\n      }\r\n    } else if (variableValue[0].substring(0, 5) == '<<EOF' && variableValue[0].slice(-3) == 'var') {\r\n      const script = variableValue[1].split('\\r');\r\n      value = { var: values[0], name: script[0].slice(0, -2) };\r\n      if (!variableName.includes(value)) variableName.push(value);\r\n    }\r\n  });\r\n  return variableName;\r\n}\r\n\r\nfunction get_resource_name(values, variableValue) {\r\n  let resource = '';\r\n  if (variableValue[0].substring(0, 3) == '\"${' && variableValue.length === 3) {\r\n    resource = { var: values[0], type: variableValue[0].substring(3), name: variableValue[1] };\r\n  } else if (variableValue[0].substring(0, 1) == '[' && variableValue.length >= 2) {\r\n    const array = values[1].split(',');\r\n    resource = [];\r\n    for (let i = 0; i < array.length; i++) {\r\n      const explode = array[i].split('.');\r\n      if (i == 0) {\r\n        if (explode[0].substring(0, 4) == '[\"${') {\r\n          resource.push({ var: values[0], type: explode[0].substring(4), name: explode[1] });\r\n        }\r\n      } else if (explode[0].substring(0, 3) == '\"${') {\r\n        resource.push({ var: values[0], type: explode[0].substring(3), name: explode[1] });\r\n      }\r\n    }\r\n  }\r\n  return resource;\r\n}\r\n\r\nfunction get_data_name(values, variableValue) {\r\n  let data = '';\r\n  if (variableValue[0] == 'data') {\r\n    data = { var: values[0], type: variableValue[1], name: variableValue[2] };\r\n  } else if (variableValue[0].substring(0, 3) == '\"${' && variableValue[0].substring(3, 7) == 'data') {\r\n    data = { var: values[0], type: variableValue[1], name: variableValue[2] };\r\n  }\r\n  return data;\r\n}\r\n\r\nfunction get_module_name(values, variableValue) {\r\n  let module = '';\r\n  if (variableValue[0] == 'module') {\r\n    module = { var: values[0], name: variableValue[1] };\r\n  } else if (variableValue[0].substring(0, 3) == '\"${' && variableValue[0].substring(3, 7) == 'module') {\r\n    module = { var: values[0], name: variableValue[1] };\r\n  }\r\n  return module;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class ModuleSource extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.value = input;\r\n  }\r\n\r\n  toString() {\r\n    return `${this.value}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for source');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newModuleSource(input, source) {\r\n  let res;\r\n  if (ModuleSource.isValid(input, source)) {\r\n    res = new ModuleSource(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class TerraformDirective extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.fileName = '';\r\n    this.objects = input.objects;\r\n  }\r\n\r\n  toString() {\r\n    return `  ${this.name}  {\\n${this.objects}\\n  }`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.objects) !== 'object' || input == '') {\r\n      source.errors.push('Incorrect input for Terraform');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newTerraformDirective(input, source) {\r\n  let res;\r\n  if (TerraformDirective.isValid(input, source)) {\r\n    res = new TerraformDirective(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class DataDirective extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.fileName = '';\r\n    this.name = input.name;\r\n    this.type = input.type;\r\n    this.objects = input.objects;\r\n  }\r\n\r\n  toString() {\r\n    return `data \"${this.type}\" \"${this.name}\" {\\n${this.objects}\\n}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.objects) !== 'object' || typeof (input.name) !== 'string' || typeof (input.name) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for data');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newDataDirective(input, source) {\r\n  let res;\r\n  if (DataDirective.isValid(input, source)) {\r\n    res = new DataDirective(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class ResourceDirective extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.fileName = '';\r\n    this.type = input.type;\r\n    this.name = input.name;\r\n    this.variablesName = input.names.variables;\r\n    this.variablesObject = [];\r\n    this.resourcesName = input.names.resources;\r\n    this.resourcesObject = [];\r\n    this.datasName = input.names.datas;\r\n    this.datasObject = [];\r\n    this.objects = input.objects;\r\n    this.representation = '';\r\n  }\r\n\r\n  toString() {\r\n    return `resource \"${this.type}\" \"${this.name}\" {\\n${this.objects}\\n}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.objects) !== 'object' || typeof (input.name) !== 'string' || typeof (input.type) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for ressource');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newResourceDirective(input, source) {\r\n  let res;\r\n  if (ResourceDirective.isValid(input, source)) {\r\n    res = new ResourceDirective(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class OutputDirective extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.fileName = '';\r\n    this.name = input.name;\r\n    this.objects = input.objects;\r\n    this.variablesName = input.names.variables;\r\n    this.variablesObject = [];\r\n    this.resourcesName = input.names.resources;\r\n    this.resourcesObject = [];\r\n    this.datasName = input.names.datas;\r\n    this.datasObject = [];\r\n  }\r\n\r\n  toString() {\r\n    return `output \"${this.name}\" {\\n${this.objects}\\n}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.objects) !== 'object' || typeof (input.name) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for Output');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newOutputDirective(input, source) {\r\n  let res;\r\n  if (OutputDirective.isValid(input, source)) {\r\n    res = new OutputDirective(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class VariableDirective extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.fileName = '';\r\n    this.name = input.name;\r\n    this.objects = input.objects;\r\n  }\r\n\r\n  toString() {\r\n    return `variable \"${this.name}\" {\\n${this.objects}\\n}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.objects) !== 'object' || typeof (input.name) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for Variable');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newVariableDirective(input, source) {\r\n  let res;\r\n  if (VariableDirective.isValid(input, source)) {\r\n    res = new VariableDirective(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","import { TerraformNode } from './terraform_node.js';\r\n\r\nexport class ProviderDirective extends TerraformNode {\r\n  constructor(input, source) {\r\n    super(source);\r\n    this.fileName = '';\r\n    this.name = input.name;\r\n    this.objects = input.objects;\r\n  }\r\n\r\n  toString() {\r\n    return `provider \"${this.name}\" {\\n${this.objects}\\n}`;\r\n  }\r\n\r\n  static isValid(input, source) {\r\n    if (typeof (input.objects) !== 'object' || typeof (input.name) !== 'string' || input == '') {\r\n      source.errors.push('Incorrect input for provider');\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n}\r\n\r\nexport function newProviderDirective(input, source) {\r\n  let res;\r\n  if (ProviderDirective.isValid(input, source)) {\r\n    res = new ProviderDirective(input, source);\r\n  } else {\r\n    res = {};\r\n  }\r\n  return res;\r\n}\r\n","// Generated from terraformParser.g4 by ANTLR 4.9.3\r\n// jshint ignore: start\r\nimport antlr4 from 'antlr4';\r\n\r\nimport file from './file.js';\r\nimport field from './field.js';\r\nimport complex_field from './complex_field.js';\r\nimport object from './object.js';\r\nimport name from './name.js';\r\nimport provider_type from './provider_type.js';\r\n\r\nimport module_directive from './module_directive.js';\r\nimport module_source from './module_source.js';\r\nimport terraform_directive from './terraform_directive.js';\r\nimport data_directive from './data_directive.js';\r\nimport resource_directive from './resource_directive.js';\r\nimport output_directive from './output_directive.js';\r\nimport variable_directive from './variable_directive.js';\r\nimport provider_directive from './provider_directive.js';\r\n\r\n// This class defines a complete listener for a parse tree produced by terraformParser.\r\nexport default class terraformParserListener extends antlr4.tree.ParseTreeListener {\r\n  constructor(prog) {\r\n    super();\r\n    this.prog = prog;\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#file.\r\n  enterFile(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#file.\r\n  exitFile(ctx) {\r\n    file.exit_file({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#directive.\r\n  enterDirective(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#directive.\r\n  exitDirective(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#dataDirective.\r\n  enterDataDirective(ctx) {\r\n    data_directive.enter_data_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#dataDirective.\r\n  exitDataDirective(ctx) {\r\n    data_directive.exit_data_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#moduleDirective.\r\n  enterModuleDirective(ctx) {\r\n    module_directive.enter_module_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#moduleDirective.\r\n  exitModuleDirective(ctx) {\r\n    module_directive.exit_module_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#moduleSource.\r\n  enterModuleSource(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#moduleSource.\r\n  exitModuleSource(ctx) {\r\n    module_source.exit_module_source({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#providerDirective.\r\n  enterProviderDirective(ctx) {\r\n    provider_directive.enter_provider_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#providerDirective.\r\n  exitProviderDirective(ctx) {\r\n    provider_directive.exit_provider_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#terraformDirective.\r\n  enterTerraformDirective(ctx) {\r\n    terraform_directive.enter_terraform_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#terraformDirective.\r\n  exitTerraformDirective(ctx) {\r\n    terraform_directive.exit_terraform_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#resourceDirective.\r\n  enterResourceDirective(ctx) {\r\n    resource_directive.enter_resource_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#resourceDirective.\r\n  exitResourceDirective(ctx) {\r\n    resource_directive.exit_resource_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#variableDirective.\r\n  enterVariableDirective(ctx) {\r\n    variable_directive.enter_variable_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#variableDirective.\r\n  exitVariableDirective(ctx) {\r\n    variable_directive.exit_variable_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#outputDirective.\r\n  enterOutputDirective(ctx) {\r\n    output_directive.enter_output_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#outputDirective.\r\n  exitOutputDirective(ctx) {\r\n    output_directive.exit_output_directive({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#name.\r\n  enterName(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#name.\r\n  exitName(ctx) {\r\n    name.exit_name({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#resourceType.\r\n  enterProviderType(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#resourceType.\r\n  exitProviderType(ctx) {\r\n    provider_type.exit_provider_type({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#type.\r\n  enterType(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#type.\r\n  exitType(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#object.\r\n  enterObject(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#object.\r\n  exitObject(ctx) {\r\n    object.exit_object({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#field.\r\n  enterField(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#field.1\r\n  exitField(ctx) {\r\n    field.exit_field({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#complexField.\r\n  enterComplexField(ctx) {\r\n    complex_field.enter_complex_field({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#complexField.\r\n  exitComplexField(ctx) {\r\n    complex_field.exit_complex_field({ ctx: { ctx, errors: this.prog.errors }, prog: this.prog });\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#validation.\r\n  enterValidation(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#validation.\r\n  exitValidation(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#condition.\r\n  enterCondition(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#condition.\r\n  exitCondition(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#expression.\r\n  enterExpression(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#expression.\r\n  exitExpression(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#functionCall.\r\n  enterFunctionCall(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#functionCall.\r\n  exitFunctionCall(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#complexExpression.\r\n  enterComplexExpression(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#complexExpression.\r\n  exitComplexExpression(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#array.\r\n  enterArray(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#array.\r\n  exitArray(ctx) {\r\n  }\r\n\r\n  // Enter a parse tree produced by terraformParser#index.\r\n  enterIndex(ctx) {\r\n  }\r\n\r\n  // Exit a parse tree produced by terraformParser#index.\r\n  exitIndex(ctx) {\r\n  }\r\n}\r\n","import { newDataDirective } from '../model/data_directive.js';\r\n\r\nexport default {\r\n  enter_data_directive(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_data_directive(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const name = (prog.name) ? prog.name.value : '';\r\n    const type = (prog.name) ? prog.type.value : '';\r\n    const objects = (prog.object) ? prog.object : '';\r\n\r\n    parsed_rule.prog.current_file.data_directive.push(newDataDirective({ name, type, objects }, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newModuleDirective } from '../model/module_directive.js';\r\nimport { get_names } from '../parser/compiler/get_links_between_objects.js';\r\n\r\nexport default {\r\n  enter_module_directive(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_module_directive(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const name = (prog.name) ? prog.name.value : '';\r\n    const objects = (prog.object) ? prog.object : '';\r\n    const source = (prog.modules_source[prog.modules_source.length - 1]) ? prog.modules_source[prog.modules_source.length - 1] : '';\r\n    const names = (objects.value) ? get_names(objects.value, true) : [];\r\n\r\n    parsed_rule.prog.current_file.module_directive.push(newModuleDirective({\r\n      name, objects, source, names,\r\n    }, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newModuleSource } from '../model/module_source.js';\r\n\r\nexport default {\r\n  enter_module_source(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_module_source(parsed_rule) {\r\n    const source = (parsed_rule.ctx.ctx.getText()) ? parsed_rule.ctx.ctx.getText() : '';\r\n    parsed_rule.prog.current_file.modules_source.push(newModuleSource(source, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newProviderDirective } from '../model/provider_directive.js';\r\n\r\nexport default {\r\n  enter_provider_directive(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_provider_directive(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const name = (prog.name) ? prog.name.value : '';\r\n    const objects = (prog.object) ? prog.object : '';\r\n\r\n    parsed_rule.prog.current_file.provider_directive.push(newProviderDirective({ name, objects }, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newTerraformDirective } from '../model/terraform_directive.js';\r\n\r\nexport default {\r\n  enter_terraform_directive(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_terraform_directive(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const objects = (prog.object && prog.object != '') ? prog.object : '';\r\n\r\n    parsed_rule.prog.current_file.terraform_directive.push(newTerraformDirective(objects, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newResourceDirective } from '../model/resource_directive.js';\r\nimport { get_names } from '../parser/compiler/get_links_between_objects.js';\r\n\r\nexport default {\r\n  enter_resource_directive(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_resource_directive(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const type = (prog.type) ? prog.type.value : '';\r\n    const name = (prog.name) ? prog.name.value : '';\r\n    const objects = (prog.object && prog.object != '') ? prog.object : '';\r\n    const names = get_names(objects.value);\r\n\r\n    parsed_rule.prog.current_file.resource_directive.push(newResourceDirective({\r\n      type, name, objects, names,\r\n    }, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newVariableDirective } from '../model/variable_directive.js';\r\n\r\nexport default {\r\n  enter_variable_directive(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_variable_directive(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const name = (prog.name) ? prog.name.value : '';\r\n    const objects = (prog.object && prog.object != '') ? prog.object : '';\r\n\r\n    parsed_rule.prog.current_file.variable_directive.push(newVariableDirective({ name, objects }, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newOutputDirective } from '../model/output_directive.js';\r\nimport { get_names } from '../parser/compiler/get_links_between_objects.js';\r\n\r\nexport default {\r\n  enter_output_directive(parsed_rule) {\r\n    parsed_rule.prog.current_file.field = [];\r\n  },\r\n\r\n  exit_output_directive(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const name = (prog.name) ? prog.name.value : '';\r\n    const objects = (prog.object && prog.object != '') ? prog.object : '';\r\n    const names = get_names(objects.value);\r\n\r\n    parsed_rule.prog.current_file.output_directive.push(newOutputDirective({ name, objects, names }, parsed_rule.ctx));\r\n  },\r\n};\r\n","import { newTerraformName } from '../model/name.js';\r\n\r\nexport default {\r\n  exit_name(parsed_rule) {\r\n    const name = (parsed_rule.ctx.ctx) ? parsed_rule.ctx.ctx.getText().replaceAll('\"', '') : '';\r\n    parsed_rule.prog.current_file.name = newTerraformName(name, parsed_rule.ctx);\r\n  },\r\n};\r\n","import { newTerraformType } from '../model/provider_type.js';\r\n\r\nexport default {\r\n  exit_provider_type(parsed_rule) {\r\n    const type = (parsed_rule.ctx.ctx.getText()) ? parsed_rule.ctx.ctx.getText().replaceAll('\"', '') : '';\r\n    parsed_rule.prog.current_file.type = newTerraformType(type, parsed_rule.ctx);\r\n  },\r\n};\r\n","import { newTerraformObject } from '../model/object.js';\r\n\r\nexport default {\r\n  exit_object(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const field = (prog.field != []) ? prog.field : [];\r\n    const complex_field = (prog.complex_field != []) ? prog.complex_field : [];\r\n    parsed_rule.prog.current_file.object = newTerraformObject({ field, complex_field }, parsed_rule.ctx);\r\n  },\r\n};\r\n","import { newTerraformField } from '../model/field.js';\r\n\r\nexport default {\r\n  exit_field(parsed_rule) {\r\n    const { is_complex_field } = parsed_rule.prog.current_file;\r\n    if (is_complex_field == false) {\r\n      const field = (parsed_rule.ctx.ctx.getText()) ? parsed_rule.ctx.ctx.getText() : '';\r\n      parsed_rule.prog.current_file.field.push(newTerraformField(field, parsed_rule.ctx));\r\n    } else {\r\n      const field = (parsed_rule.ctx.ctx.getText()) ? parsed_rule.ctx.ctx.getText() : '';\r\n      parsed_rule.prog.current_file.complex_field_object.push(field);\r\n    }\r\n  },\r\n};\r\n","import { newTerraformComplexField } from '../model/complex_field.js';\r\n\r\nexport default {\r\n  enter_complex_field(parsed_rule) {\r\n    parsed_rule.prog.current_file.is_complex_field = true;\r\n    parsed_rule.prog.current_file.complex_field_object = [];\r\n  },\r\n\r\n  exit_complex_field(parsed_rule) {\r\n    const prog = parsed_rule.prog.current_file;\r\n    const name = (parsed_rule.ctx.ctx.getText()) ? parsed_rule.ctx.ctx.getText().split('{')[0] : '';\r\n    const objects = (prog.complex_field_object != []) ? prog.complex_field_object : [];\r\n    parsed_rule.prog.current_file.complex_field.push(newTerraformComplexField({ name, objects }, parsed_rule.ctx));\r\n    parsed_rule.prog.current_file.is_complex_field = false;\r\n  },\r\n};\r\n","// Generated from terraformParser.g4 by ANTLR 4.9.3\r\n// jshint ignore: start\r\nimport antlr4 from 'antlr4';\r\nimport terraformParserListener from '../../listener/terraformListener.js';\r\n\r\nconst serializedATN = ['\\u0003\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786',\r\n  '\\u5964\\u0003*\\u010e\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\\u0004',\r\n  '\\t\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006\\u0004\\u0007\\t\\u0007',\r\n  '\\u0004\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b\\t\\u000b\\u0004\\f\\t\\f',\r\n  '\\u0004\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0004\\u000f\\t\\u000f\\u0004\\u0010\\t\\u0010',\r\n  '\\u0004\\u0011\\t\\u0011\\u0004\\u0012\\t\\u0012\\u0004\\u0013\\t\\u0013\\u0004\\u0014',\r\n  '\\t\\u0014\\u0004\\u0015\\t\\u0015\\u0004\\u0016\\t\\u0016\\u0004\\u0017\\t\\u0017',\r\n  '\\u0004\\u0018\\t\\u0018\\u0003\\u0002\\u0006\\u00022\\n\\u0002\\r\\u0002\\u000e',\r\n  '\\u00023\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003',\r\n  '\\u0003\\u0003\\u0003\\u0003\\u0005\\u0003=\\n\\u0003\\u0003\\u0004\\u0003\\u0004',\r\n  '\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0006\\u0004D\\n\\u0004\\r\\u0004\\u000e',\r\n  '\\u0004E\\u0003\\u0004\\u0003\\u0004\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005',\r\n  '\\u0003\\u0005\\u0003\\u0005\\u0006\\u0005O\\n\\u0005\\r\\u0005\\u000e\\u0005P\\u0003',\r\n  '\\u0005\\u0003\\u0005\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003',\r\n  '\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003',\r\n  '\\b\\u0003\\b\\u0003\\b\\u0006\\bb\\n\\b\\r\\b\\u000e\\bc\\u0003\\b\\u0003\\b\\u0003\\t',\r\n  '\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\n\\u0003\\n\\u0003',\r\n  '\\n\\u0003\\n\\u0006\\ns\\n\\n\\r\\n\\u000e\\nt\\u0003\\n\\u0003\\n\\u0003\\u000b\\u0003',\r\n  '\\u000b\\u0003\\u000b\\u0003\\u000b\\u0006\\u000b}\\n\\u000b\\r\\u000b\\u000e\\u000b',\r\n  '~\\u0003\\u000b\\u0003\\u000b\\u0003\\f\\u0003\\f\\u0003\\r\\u0003\\r\\u0003\\u000e',\r\n  '\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e',\r\n  '\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e',\r\n  '\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0005\\u000e\\u0098\\n',\r\n  '\\u000e\\u0003\\u000f\\u0003\\u000f\\u0006\\u000f\\u009c\\n\\u000f\\r\\u000f\\u000e',\r\n  '\\u000f\\u009d\\u0003\\u0010\\u0003\\u0010\\u0003\\u0010\\u0003\\u0010\\u0003\\u0011',\r\n  '\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\\u0003\\u0012\\u0003\\u0012',\r\n  '\\u0003\\u0012\\u0003\\u0012\\u0006\\u0012\\u00ad\\n\\u0012\\r\\u0012\\u000e\\u0012',\r\n  '\\u00ae\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003',\r\n  '\\u0013\\u0003\\u0013\\u0003\\u0013\\u0003\\u0013\\u0003\\u0013\\u0005\\u0013\\u00bb',\r\n  '\\n\\u0013\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014',\r\n  '\\u0003\\u0014\\u0005\\u0014\\u00c3\\n\\u0014\\u0003\\u0015\\u0003\\u0015\\u0003',\r\n  '\\u0015\\u0003\\u0015\\u0003\\u0015\\u0007\\u0015\\u00ca\\n\\u0015\\f\\u0015\\u000e',\r\n  '\\u0015\\u00cd\\u000b\\u0015\\u0003\\u0015\\u0005\\u0015\\u00d0\\n\\u0015\\u0003',\r\n  '\\u0015\\u0003\\u0015\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003',\r\n  '\\u0016\\u0003\\u0016\\u0006\\u0016\\u00da\\n\\u0016\\r\\u0016\\u000e\\u0016\\u00db',\r\n  '\\u0006\\u0016\\u00de\\n\\u0016\\r\\u0016\\u000e\\u0016\\u00df\\u0003\\u0016\\u0003',\r\n  '\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0005\\u0016\\u00e8',\r\n  '\\n\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016',\r\n  '\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016\\u0003\\u0016',\r\n  '\\u0007\\u0016\\u00f5\\n\\u0016\\f\\u0016\\u000e\\u0016\\u00f8\\u000b\\u0016\\u0003',\r\n  '\\u0017\\u0003\\u0017\\u0003\\u0017\\u0003\\u0017\\u0003\\u0017\\u0003\\u0017\\u0007',\r\n  '\\u0017\\u0100\\n\\u0017\\f\\u0017\\u000e\\u0017\\u0103\\u000b\\u0017\\u0003\\u0017',\r\n  '\\u0005\\u0017\\u0106\\n\\u0017\\u0003\\u0017\\u0003\\u0017\\u0005\\u0017\\u010a',\r\n  '\\n\\u0017\\u0003\\u0018\\u0003\\u0018\\u0003\\u0018\\u0002\\u0003*\\u0019\\u0002',\r\n  '\\u0004\\u0006\\b\\n\\f\\u000e\\u0010\\u0012\\u0014\\u0016\\u0018\\u001a\\u001c\\u001e',\r\n  ' \"$&(*,.\\u0002\\u0003\\u0004\\u0002\\u001a\\u001a  \\u0002\\u0122\\u00021\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0004<\\u0003\\u0002\\u0002\\u0002\\u0006>\\u0003\\u0002',\r\n  '\\u0002\\u0002\\bI\\u0003\\u0002\\u0002\\u0002\\nT\\u0003\\u0002\\u0002\\u0002\\f',\r\n  'X\\u0003\\u0002\\u0002\\u0002\\u000e^\\u0003\\u0002\\u0002\\u0002\\u0010g\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0012n\\u0003\\u0002\\u0002\\u0002\\u0014x\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0016\\u0082\\u0003\\u0002\\u0002\\u0002\\u0018\\u0084\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u001a\\u0097\\u0003\\u0002\\u0002\\u0002\\u001c\\u009b\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u001e\\u009f\\u0003\\u0002\\u0002\\u0002 \\u00a3\\u0003\\u0002',\r\n  '\\u0002\\u0002\"\\u00a8\\u0003\\u0002\\u0002\\u0002$\\u00ba\\u0003\\u0002\\u0002',\r\n  '\\u0002&\\u00c2\\u0003\\u0002\\u0002\\u0002(\\u00c4\\u0003\\u0002\\u0002\\u0002',\r\n  '*\\u00e7\\u0003\\u0002\\u0002\\u0002,\\u0109\\u0003\\u0002\\u0002\\u0002.\\u010b',\r\n  '\\u0003\\u0002\\u0002\\u000202\\u0005\\u0004\\u0003\\u000210\\u0003\\u0002\\u0002',\r\n  '\\u000223\\u0003\\u0002\\u0002\\u000231\\u0003\\u0002\\u0002\\u000234\\u0003\\u0002',\r\n  '\\u0002\\u00024\\u0003\\u0003\\u0002\\u0002\\u00025=\\u0005\\f\\u0007\\u00026=',\r\n  '\\u0005\\u000e\\b\\u00027=\\u0005\\u0010\\t\\u00028=\\u0005\\u0012\\n\\u00029=\\u0005',\r\n  '\\u0014\\u000b\\u0002:=\\u0005\\b\\u0005\\u0002;=\\u0005\\u0006\\u0004\\u0002<',\r\n  '5\\u0003\\u0002\\u0002\\u0002<6\\u0003\\u0002\\u0002\\u0002<7\\u0003\\u0002\\u0002',\r\n  '\\u0002<8\\u0003\\u0002\\u0002\\u0002<9\\u0003\\u0002\\u0002\\u0002<:\\u0003\\u0002',\r\n  '\\u0002\\u0002<;\\u0003\\u0002\\u0002\\u0002=\\u0005\\u0003\\u0002\\u0002\\u0002',\r\n  '>?\\u0007\\u0004\\u0002\\u0002?@\\u0005\\u0018\\r\\u0002@A\\u0005\\u0016\\f\\u0002',\r\n  'AC\\u0007\\u0010\\u0002\\u0002BD\\u0005\\u001c\\u000f\\u0002CB\\u0003\\u0002\\u0002',\r\n  '\\u0002DE\\u0003\\u0002\\u0002\\u0002EC\\u0003\\u0002\\u0002\\u0002EF\\u0003\\u0002',\r\n  '\\u0002\\u0002FG\\u0003\\u0002\\u0002\\u0002GH\\u0007\\u0011\\u0002\\u0002H\\u0007',\r\n  '\\u0003\\u0002\\u0002\\u0002IJ\\u0007\\u0003\\u0002\\u0002JK\\u0005\\u0016\\f\\u0002',\r\n  'KN\\u0007\\u0010\\u0002\\u0002LO\\u0005\\n\\u0006\\u0002MO\\u0005\\u001c\\u000f',\r\n  '\\u0002NL\\u0003\\u0002\\u0002\\u0002NM\\u0003\\u0002\\u0002\\u0002OP\\u0003\\u0002',\r\n  '\\u0002\\u0002PN\\u0003\\u0002\\u0002\\u0002PQ\\u0003\\u0002\\u0002\\u0002QR\\u0003',\r\n  '\\u0002\\u0002\\u0002RS\\u0007\\u0011\\u0002\\u0002S\\t\\u0003\\u0002\\u0002\\u0002',\r\n  'TU\\u0007\\u0005\\u0002\\u0002UV\\u0007\\u0012\\u0002\\u0002VW\\u0007\\u001f\\u0002',\r\n  '\\u0002W\\u000b\\u0003\\u0002\\u0002\\u0002XY\\u0007\\u0006\\u0002\\u0002YZ\\u0005',\r\n  '\\u0016\\f\\u0002Z[\\u0007\\u0010\\u0002\\u0002[\\\\\\u0005\\u001c\\u000f\\u0002',\r\n  '\\\\]\\u0007\\u0011\\u0002\\u0002]\\r\\u0003\\u0002\\u0002\\u0002^_\\u0007\\u0007',\r\n  '\\u0002\\u0002_a\\u0007\\u0010\\u0002\\u0002`b\\u0005\\u001c\\u000f\\u0002a`\\u0003',\r\n  '\\u0002\\u0002\\u0002bc\\u0003\\u0002\\u0002\\u0002ca\\u0003\\u0002\\u0002\\u0002',\r\n  'cd\\u0003\\u0002\\u0002\\u0002de\\u0003\\u0002\\u0002\\u0002ef\\u0007\\u0011\\u0002',\r\n  '\\u0002f\\u000f\\u0003\\u0002\\u0002\\u0002gh\\u0007\\b\\u0002\\u0002hi\\u0005',\r\n  '\\u0018\\r\\u0002ij\\u0005\\u0016\\f\\u0002jk\\u0007\\u0010\\u0002\\u0002kl\\u0005',\r\n  '\\u001c\\u000f\\u0002lm\\u0007\\u0011\\u0002\\u0002m\\u0011\\u0003\\u0002\\u0002',\r\n  '\\u0002no\\u0007\\t\\u0002\\u0002op\\u0005\\u0016\\f\\u0002pr\\u0007\\u0010\\u0002',\r\n  '\\u0002qs\\u0005\\u001c\\u000f\\u0002rq\\u0003\\u0002\\u0002\\u0002st\\u0003\\u0002',\r\n  '\\u0002\\u0002tr\\u0003\\u0002\\u0002\\u0002tu\\u0003\\u0002\\u0002\\u0002uv\\u0003',\r\n  '\\u0002\\u0002\\u0002vw\\u0007\\u0011\\u0002\\u0002w\\u0013\\u0003\\u0002\\u0002',\r\n  '\\u0002xy\\u0007\\n\\u0002\\u0002yz\\u0005\\u0016\\f\\u0002z|\\u0007\\u0010\\u0002',\r\n  '\\u0002{}\\u0005\\u001c\\u000f\\u0002|{\\u0003\\u0002\\u0002\\u0002}~\\u0003\\u0002',\r\n  '\\u0002\\u0002~|\\u0003\\u0002\\u0002\\u0002~\\u007f\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u007f\\u0080\\u0003\\u0002\\u0002\\u0002\\u0080\\u0081\\u0007\\u0011\\u0002\\u0002',\r\n  '\\u0081\\u0015\\u0003\\u0002\\u0002\\u0002\\u0082\\u0083\\u0007\\u001f\\u0002\\u0002',\r\n  '\\u0083\\u0017\\u0003\\u0002\\u0002\\u0002\\u0084\\u0085\\u0007\\u001f\\u0002\\u0002',\r\n  '\\u0085\\u0019\\u0003\\u0002\\u0002\\u0002\\u0086\\u0098\\u0007\\u001d\\u0002\\u0002',\r\n  '\\u0087\\u0098\\u0007\\u000b\\u0002\\u0002\\u0088\\u0089\\u0007\\u000b\\u0002\\u0002',\r\n  '\\u0089\\u008a\\u0007\\u0013\\u0002\\u0002\\u008a\\u008b\\u0005\\u001a\\u000e\\u0002',\r\n  '\\u008b\\u008c\\u0007\\u0014\\u0002\\u0002\\u008c\\u0098\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u008d\\u008e\\u0007\\f\\u0002\\u0002\\u008e\\u008f\\u0007\\u0013\\u0002\\u0002',\r\n  '\\u008f\\u0090\\u0005\\u001a\\u000e\\u0002\\u0090\\u0091\\u0007\\u0014\\u0002\\u0002',\r\n  '\\u0091\\u0098\\u0003\\u0002\\u0002\\u0002\\u0092\\u0093\\u0007\\r\\u0002\\u0002',\r\n  '\\u0093\\u0094\\u0007\\u0013\\u0002\\u0002\\u0094\\u0095\\u0005\\u001c\\u000f\\u0002',\r\n  '\\u0095\\u0096\\u0007\\u0014\\u0002\\u0002\\u0096\\u0098\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0097\\u0086\\u0003\\u0002\\u0002\\u0002\\u0097\\u0087\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0097\\u0088\\u0003\\u0002\\u0002\\u0002\\u0097\\u008d\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0097\\u0092\\u0003\\u0002\\u0002\\u0002\\u0098\\u001b\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0099\\u009c\\u0005 \\u0011\\u0002\\u009a\\u009c\\u0005\\u001e\\u0010\\u0002',\r\n  '\\u009b\\u0099\\u0003\\u0002\\u0002\\u0002\\u009b\\u009a\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u009c\\u009d\\u0003\\u0002\\u0002\\u0002\\u009d\\u009b\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u009d\\u009e\\u0003\\u0002\\u0002\\u0002\\u009e\\u001d\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u009f\\u00a0\\u0007\\u001e\\u0002\\u0002\\u00a0\\u00a1\\u0007\\u0012\\u0002\\u0002',\r\n  '\\u00a1\\u00a2\\u0005&\\u0014\\u0002\\u00a2\\u001f\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00a3\\u00a4\\u0007\\u001e\\u0002\\u0002\\u00a4\\u00a5\\u0007\\u0010\\u0002\\u0002',\r\n  '\\u00a5\\u00a6\\u0005\\u001c\\u000f\\u0002\\u00a6\\u00a7\\u0007\\u0011\\u0002\\u0002',\r\n  '\\u00a7!\\u0003\\u0002\\u0002\\u0002\\u00a8\\u00a9\\u0007\\u0010\\u0002\\u0002',\r\n  '\\u00a9\\u00aa\\u0007\\u000e\\u0002\\u0002\\u00aa\\u00ac\\u0007\\u0012\\u0002\\u0002',\r\n  '\\u00ab\\u00ad\\u0005$\\u0013\\u0002\\u00ac\\u00ab\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00ad\\u00ae\\u0003\\u0002\\u0002\\u0002\\u00ae\\u00ac\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00ae\\u00af\\u0003\\u0002\\u0002\\u0002\\u00af\\u00b0\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00b0\\u00b1\\u0007\\u000f\\u0002\\u0002\\u00b1\\u00b2\\u0007\\u0012\\u0002\\u0002',\r\n  '\\u00b2\\u00b3\\u0007\\u001f\\u0002\\u0002\\u00b3\\u00b4\\u0007\\u0011\\u0002\\u0002',\r\n  '\\u00b4#\\u0003\\u0002\\u0002\\u0002\\u00b5\\u00bb\\u0007\\u001f\\u0002\\u0002',\r\n  '\\u00b6\\u00bb\\u0007 \\u0002\\u0002\\u00b7\\u00bb\\u0007\\u001c\\u0002\\u0002',\r\n  '\\u00b8\\u00bb\\u0007\\u001b\\u0002\\u0002\\u00b9\\u00bb\\u0005(\\u0015\\u0002',\r\n  '\\u00ba\\u00b5\\u0003\\u0002\\u0002\\u0002\\u00ba\\u00b6\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00ba\\u00b7\\u0003\\u0002\\u0002\\u0002\\u00ba\\u00b8\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00ba\\u00b9\\u0003\\u0002\\u0002\\u0002\\u00bb%\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00bc\\u00c3\\u0007 \\u0002\\u0002\\u00bd\\u00c3\\u0007\\u001c\\u0002\\u0002',\r\n  '\\u00be\\u00c3\\u0005,\\u0017\\u0002\\u00bf\\u00c3\\u0005*\\u0016\\u0002\\u00c0',\r\n  '\\u00c3\\u0007\\u001f\\u0002\\u0002\\u00c1\\u00c3\\u0005\\u001a\\u000e\\u0002\\u00c2',\r\n  '\\u00bc\\u0003\\u0002\\u0002\\u0002\\u00c2\\u00bd\\u0003\\u0002\\u0002\\u0002\\u00c2',\r\n  '\\u00be\\u0003\\u0002\\u0002\\u0002\\u00c2\\u00bf\\u0003\\u0002\\u0002\\u0002\\u00c2',\r\n  '\\u00c0\\u0003\\u0002\\u0002\\u0002\\u00c2\\u00c1\\u0003\\u0002\\u0002\\u0002\\u00c3',\r\n  \"\\'\\u0003\\u0002\\u0002\\u0002\\u00c4\\u00c5\\u0007\\u001e\\u0002\\u0002\\u00c5\",\r\n  '\\u00c6\\u0007\\u0013\\u0002\\u0002\\u00c6\\u00cb\\u0005&\\u0014\\u0002\\u00c7',\r\n  '\\u00c8\\u0007\\u0017\\u0002\\u0002\\u00c8\\u00ca\\u0005&\\u0014\\u0002\\u00c9',\r\n  '\\u00c7\\u0003\\u0002\\u0002\\u0002\\u00ca\\u00cd\\u0003\\u0002\\u0002\\u0002\\u00cb',\r\n  '\\u00c9\\u0003\\u0002\\u0002\\u0002\\u00cb\\u00cc\\u0003\\u0002\\u0002\\u0002\\u00cc',\r\n  '\\u00cf\\u0003\\u0002\\u0002\\u0002\\u00cd\\u00cb\\u0003\\u0002\\u0002\\u0002\\u00ce',\r\n  '\\u00d0\\u0007\\u0017\\u0002\\u0002\\u00cf\\u00ce\\u0003\\u0002\\u0002\\u0002\\u00cf',\r\n  '\\u00d0\\u0003\\u0002\\u0002\\u0002\\u00d0\\u00d1\\u0003\\u0002\\u0002\\u0002\\u00d1',\r\n  '\\u00d2\\u0007\\u0014\\u0002\\u0002\\u00d2)\\u0003\\u0002\\u0002\\u0002\\u00d3',\r\n  '\\u00d4\\b\\u0016\\u0001\\u0002\\u00d4\\u00e8\\u0007\\u001e\\u0002\\u0002\\u00d5',\r\n  '\\u00dd\\u0007%\\u0002\\u0002\\u00d6\\u00de\\u0007&\\u0002\\u0002\\u00d7\\u00de',\r\n  \"\\u0007)\\u0002\\u0002\\u00d8\\u00da\\u0007\\'\\u0002\\u0002\\u00d9\\u00d8\\u0003\",\r\n  '\\u0002\\u0002\\u0002\\u00da\\u00db\\u0003\\u0002\\u0002\\u0002\\u00db\\u00d9\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00db\\u00dc\\u0003\\u0002\\u0002\\u0002\\u00dc\\u00de\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00dd\\u00d6\\u0003\\u0002\\u0002\\u0002\\u00dd\\u00d7\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00dd\\u00d9\\u0003\\u0002\\u0002\\u0002\\u00de\\u00df\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00df\\u00dd\\u0003\\u0002\\u0002\\u0002\\u00df\\u00e0\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00e0\\u00e1\\u0003\\u0002\\u0002\\u0002\\u00e1\\u00e8\\u0007',\r\n  '*\\u0002\\u0002\\u00e2\\u00e3\\u0007\\u001f\\u0002\\u0002\\u00e3\\u00e4\\u0005',\r\n  '*\\u0016\\u0002\\u00e4\\u00e5\\u0007\\u001f\\u0002\\u0002\\u00e5\\u00e8\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00e6\\u00e8\\u0005(\\u0015\\u0002\\u00e7\\u00d3\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00e7\\u00d5\\u0003\\u0002\\u0002\\u0002\\u00e7\\u00e2\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00e7\\u00e6\\u0003\\u0002\\u0002\\u0002\\u00e8\\u00f6\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00e9\\u00ea\\f\\b\\u0002\\u0002\\u00ea\\u00eb\\u0007\\u0018',\r\n  '\\u0002\\u0002\\u00eb\\u00f5\\u0005*\\u0016\\t\\u00ec\\u00ed\\f\\u0007\\u0002\\u0002',\r\n  '\\u00ed\\u00ee\\u0007\\u0015\\u0002\\u0002\\u00ee\\u00ef\\u0005.\\u0018\\u0002',\r\n  '\\u00ef\\u00f0\\u0007\\u0016\\u0002\\u0002\\u00f0\\u00f5\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00f1\\u00f2\\f\\u0006\\u0002\\u0002\\u00f2\\u00f3\\u0007\\u0018\\u0002\\u0002',\r\n  '\\u00f3\\u00f5\\u0005.\\u0018\\u0002\\u00f4\\u00e9\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00f4\\u00ec\\u0003\\u0002\\u0002\\u0002\\u00f4\\u00f1\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00f5\\u00f8\\u0003\\u0002\\u0002\\u0002\\u00f6\\u00f4\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00f6\\u00f7\\u0003\\u0002\\u0002\\u0002\\u00f7+\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00f8\\u00f6\\u0003\\u0002\\u0002\\u0002\\u00f9\\u00fa\\u0007\\u0015\\u0002\\u0002',\r\n  '\\u00fa\\u010a\\u0007\\u0016\\u0002\\u0002\\u00fb\\u00fc\\u0007\\u0015\\u0002\\u0002',\r\n  '\\u00fc\\u0101\\u0005&\\u0014\\u0002\\u00fd\\u00fe\\u0007\\u0017\\u0002\\u0002',\r\n  '\\u00fe\\u0100\\u0005&\\u0014\\u0002\\u00ff\\u00fd\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0100\\u0103\\u0003\\u0002\\u0002\\u0002\\u0101\\u00ff\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0101\\u0102\\u0003\\u0002\\u0002\\u0002\\u0102\\u0105\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0103\\u0101\\u0003\\u0002\\u0002\\u0002\\u0104\\u0106\\u0007\\u0017\\u0002\\u0002',\r\n  '\\u0105\\u0104\\u0003\\u0002\\u0002\\u0002\\u0105\\u0106\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0106\\u0107\\u0003\\u0002\\u0002\\u0002\\u0107\\u0108\\u0007\\u0016\\u0002\\u0002',\r\n  '\\u0108\\u010a\\u0003\\u0002\\u0002\\u0002\\u0109\\u00f9\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0109\\u00fb\\u0003\\u0002\\u0002\\u0002\\u010a-\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u010b\\u010c\\t\\u0002\\u0002\\u0002\\u010c/\\u0003\\u0002\\u0002\\u0002\\u001b',\r\n  '3<ENPct~\\u0097\\u009b\\u009d\\u00ae\\u00ba\\u00c2\\u00cb\\u00cf\\u00db\\u00dd',\r\n  '\\u00df\\u00e7\\u00f4\\u00f6\\u0101\\u0105\\u0109'].join('');\r\n\r\nconst atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\r\n\r\nconst decisionsToDFA = atn.decisionToState.map((ds, index) => new antlr4.dfa.DFA(ds, index));\r\n\r\nconst sharedContextCache = new antlr4.PredictionContextCache();\r\n\r\nexport default class terraformParser extends antlr4.Parser {\r\n  static grammarFileName = 'terraformParser.g4';\r\n\r\n  static literalNames = [null, \"'module'\", \"'data'\", \"'source'\", \"'provider'\",\r\n    \"'terraform'\", \"'resource'\", \"'variable'\", \"'output'\",\r\n    \"'list'\", \"'map'\", \"'object'\", \"'condition'\",\r\n    \"'error_message'\", \"'{'\", \"'}'\", \"'='\", \"'('\",\r\n    \"')'\", \"'['\", \"']'\", \"','\", \"'.'\", \"'-'\", \"'*'\",\r\n    null, null, null, null, null, null, null, null,\r\n    null, null, \"'<<EOF'\", null, null, null, null,\r\n    \"'EOF'\"];\r\n\r\n  static symbolicNames = [null, 'MODULE', 'DATA', 'SOURCE', 'PROVIDER',\r\n    'TERRAFORM', 'RESOURCE', 'VARIABLE', 'OUTPUT',\r\n    'LIST', 'MAP', 'OBJECT', 'CONDITION', 'ERROR',\r\n    'AO', 'AF', 'EQUAL', 'PO', 'PF', 'CO', 'CF',\r\n    'VIRG', 'POINT', 'TIRET', 'MULT', 'BOOLEANOP',\r\n    'BOOLEAN', 'TYPE', 'IDENTIFIER', 'STRING',\r\n    'NUMBER', 'COMMENT', 'LINE_COMMENT', 'HAS_COMMENT',\r\n    'WS', 'OPEN', 'IDENTIFIERS', 'WSS', 'NUMBERS',\r\n    'AUTRE', 'CLOSE'];\r\n\r\n  static ruleNames = ['file', 'directive', 'dataDirective', 'moduleDirective',\r\n    'moduleSource', 'providerDirective', 'terraformDirective',\r\n    'resourceDirective', 'variableDirective', 'outputDirective',\r\n    'name', 'providerType', 'type', 'object', 'field',\r\n    'complexField', 'validation', 'condition', 'expression',\r\n    'functionCall', 'complexExpression', 'array', 'index'];\r\n\r\n  constructor(input) {\r\n    super(input);\r\n    this._interp = new antlr4.atn.ParserATNSimulator(this, atn, decisionsToDFA, sharedContextCache);\r\n    this.ruleNames = terraformParser.ruleNames;\r\n    this.literalNames = terraformParser.literalNames;\r\n    this.symbolicNames = terraformParser.symbolicNames;\r\n  }\r\n\r\n  get atn() {\r\n    return atn;\r\n  }\r\n\r\n  sempred(localctx, ruleIndex, predIndex) {\r\n    \tswitch (ruleIndex) {\r\n    \tcase 20:\r\n    \t    \t\treturn this.complexExpression_sempred(localctx, predIndex);\r\n      default:\r\n        throw `No predicate with index:${ruleIndex}`;\r\n    }\r\n  }\r\n\r\n  complexExpression_sempred(localctx, predIndex) {\r\n    \tswitch (predIndex) {\r\n    \t\tcase 0:\r\n    \t\t\treturn this.precpred(this._ctx, 6);\r\n    \t\tcase 1:\r\n    \t\t\treturn this.precpred(this._ctx, 5);\r\n    \t\tcase 2:\r\n    \t\t\treturn this.precpred(this._ctx, 4);\r\n    \t\tdefault:\r\n    \t\t\tthrow `No predicate with index:${predIndex}`;\r\n    \t}\r\n  }\r\n\r\n  file() {\r\n\t    const localctx = new FileContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 0, terraformParser.RULE_file);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 47;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        do {\r\n\t            this.state = 46;\r\n\t            this.directive();\r\n\t            this.state = 49;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t        } while ((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << terraformParser.MODULE) | (1 << terraformParser.DATA) | (1 << terraformParser.PROVIDER) | (1 << terraformParser.TERRAFORM) | (1 << terraformParser.RESOURCE) | (1 << terraformParser.VARIABLE) | (1 << terraformParser.OUTPUT))) !== 0));\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  directive() {\r\n\t    const localctx = new DirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 2, terraformParser.RULE_directive);\r\n\t    try {\r\n\t        this.state = 58;\r\n\t        this._errHandler.sync(this);\r\n\t        switch (this._input.LA(1)) {\r\n\t        case terraformParser.PROVIDER:\r\n\t            this.enterOuterAlt(localctx, 1);\r\n\t            this.state = 51;\r\n\t            this.providerDirective();\r\n\t            break;\r\n\t        case terraformParser.TERRAFORM:\r\n\t            this.enterOuterAlt(localctx, 2);\r\n\t            this.state = 52;\r\n\t            this.terraformDirective();\r\n\t            break;\r\n\t        case terraformParser.RESOURCE:\r\n\t            this.enterOuterAlt(localctx, 3);\r\n\t            this.state = 53;\r\n\t            this.resourceDirective();\r\n\t            break;\r\n\t        case terraformParser.VARIABLE:\r\n\t            this.enterOuterAlt(localctx, 4);\r\n\t            this.state = 54;\r\n\t            this.variableDirective();\r\n\t            break;\r\n\t        case terraformParser.OUTPUT:\r\n\t            this.enterOuterAlt(localctx, 5);\r\n\t            this.state = 55;\r\n\t            this.outputDirective();\r\n\t            break;\r\n\t        case terraformParser.MODULE:\r\n\t            this.enterOuterAlt(localctx, 6);\r\n\t            this.state = 56;\r\n\t            this.moduleDirective();\r\n\t            break;\r\n\t        case terraformParser.DATA:\r\n\t            this.enterOuterAlt(localctx, 7);\r\n\t            this.state = 57;\r\n\t            this.dataDirective();\r\n\t            break;\r\n\t        default:\r\n\t            throw new antlr4.error.NoViableAltException(this);\r\n\t        }\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  dataDirective() {\r\n\t    const localctx = new DataDirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 4, terraformParser.RULE_dataDirective);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 60;\r\n\t        this.match(terraformParser.DATA);\r\n\t        this.state = 61;\r\n\t        this.providerType();\r\n\t        this.state = 62;\r\n\t        this.name();\r\n\t        this.state = 63;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 65;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        do {\r\n\t            this.state = 64;\r\n\t            this.object();\r\n\t            this.state = 67;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t        } while (_la === terraformParser.IDENTIFIER);\r\n\t        this.state = 69;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  moduleDirective() {\r\n\t    const localctx = new ModuleDirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 6, terraformParser.RULE_moduleDirective);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 71;\r\n\t        this.match(terraformParser.MODULE);\r\n\t        this.state = 72;\r\n\t        this.name();\r\n\t        this.state = 73;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 76;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        do {\r\n\t            this.state = 76;\r\n\t            this._errHandler.sync(this);\r\n\t            switch (this._input.LA(1)) {\r\n\t            case terraformParser.SOURCE:\r\n\t                this.state = 74;\r\n\t                this.moduleSource();\r\n\t                break;\r\n\t            case terraformParser.IDENTIFIER:\r\n\t                this.state = 75;\r\n\t                this.object();\r\n\t                break;\r\n\t            default:\r\n\t                throw new antlr4.error.NoViableAltException(this);\r\n\t            }\r\n\t            this.state = 78;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t        } while (_la === terraformParser.SOURCE || _la === terraformParser.IDENTIFIER);\r\n\t        this.state = 80;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  moduleSource() {\r\n\t    const localctx = new ModuleSourceContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 8, terraformParser.RULE_moduleSource);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 82;\r\n\t        this.match(terraformParser.SOURCE);\r\n\t        this.state = 83;\r\n\t        this.match(terraformParser.EQUAL);\r\n\t        this.state = 84;\r\n\t        this.match(terraformParser.STRING);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  providerDirective() {\r\n\t    const localctx = new ProviderDirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 10, terraformParser.RULE_providerDirective);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 86;\r\n\t        this.match(terraformParser.PROVIDER);\r\n\t        this.state = 87;\r\n\t        this.name();\r\n\t        this.state = 88;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 89;\r\n\t        this.object();\r\n\t        this.state = 90;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  terraformDirective() {\r\n\t    const localctx = new TerraformDirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 12, terraformParser.RULE_terraformDirective);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 92;\r\n\t        this.match(terraformParser.TERRAFORM);\r\n\t        this.state = 93;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 95;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        do {\r\n\t            this.state = 94;\r\n\t            this.object();\r\n\t            this.state = 97;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t        } while (_la === terraformParser.IDENTIFIER);\r\n\t        this.state = 99;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  resourceDirective() {\r\n\t    const localctx = new ResourceDirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 14, terraformParser.RULE_resourceDirective);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 101;\r\n\t        this.match(terraformParser.RESOURCE);\r\n\t        this.state = 102;\r\n\t        this.providerType();\r\n\t        this.state = 103;\r\n\t        this.name();\r\n\t        this.state = 104;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 105;\r\n\t        this.object();\r\n\t        this.state = 106;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  variableDirective() {\r\n\t    const localctx = new VariableDirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 16, terraformParser.RULE_variableDirective);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 108;\r\n\t        this.match(terraformParser.VARIABLE);\r\n\t        this.state = 109;\r\n\t        this.name();\r\n\t        this.state = 110;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 112;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        do {\r\n\t            this.state = 111;\r\n\t            this.object();\r\n\t            this.state = 114;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t        } while (_la === terraformParser.IDENTIFIER);\r\n\t        this.state = 116;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  outputDirective() {\r\n\t    const localctx = new OutputDirectiveContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 18, terraformParser.RULE_outputDirective);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 118;\r\n\t        this.match(terraformParser.OUTPUT);\r\n\t        this.state = 119;\r\n\t        this.name();\r\n\t        this.state = 120;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 122;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        do {\r\n\t            this.state = 121;\r\n\t            this.object();\r\n\t            this.state = 124;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t        } while (_la === terraformParser.IDENTIFIER);\r\n\t        this.state = 126;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  name() {\r\n\t    const localctx = new NameContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 20, terraformParser.RULE_name);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 128;\r\n\t        this.match(terraformParser.STRING);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  providerType() {\r\n\t    const localctx = new ProviderTypeContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 22, terraformParser.RULE_providerType);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 130;\r\n\t        this.match(terraformParser.STRING);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  type() {\r\n\t    const localctx = new TypeContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 24, terraformParser.RULE_type);\r\n\t    try {\r\n\t        this.state = 149;\r\n\t        this._errHandler.sync(this);\r\n\t        const la_ = this._interp.adaptivePredict(this._input, 8, this._ctx);\r\n\t        switch (la_) {\r\n\t        case 1:\r\n\t            this.enterOuterAlt(localctx, 1);\r\n\t            this.state = 132;\r\n\t            this.match(terraformParser.TYPE);\r\n\t            break;\r\n\r\n\t        case 2:\r\n\t            this.enterOuterAlt(localctx, 2);\r\n\t            this.state = 133;\r\n\t            this.match(terraformParser.LIST);\r\n\t            break;\r\n\r\n\t        case 3:\r\n\t            this.enterOuterAlt(localctx, 3);\r\n\t            this.state = 134;\r\n\t            this.match(terraformParser.LIST);\r\n\t            this.state = 135;\r\n\t            this.match(terraformParser.PO);\r\n\t            this.state = 136;\r\n\t            this.type();\r\n\t            this.state = 137;\r\n\t            this.match(terraformParser.PF);\r\n\t            break;\r\n\r\n\t        case 4:\r\n\t            this.enterOuterAlt(localctx, 4);\r\n\t            this.state = 139;\r\n\t            this.match(terraformParser.MAP);\r\n\t            this.state = 140;\r\n\t            this.match(terraformParser.PO);\r\n\t            this.state = 141;\r\n\t            this.type();\r\n\t            this.state = 142;\r\n\t            this.match(terraformParser.PF);\r\n\t            break;\r\n\r\n\t        case 5:\r\n\t            this.enterOuterAlt(localctx, 5);\r\n\t            this.state = 144;\r\n\t            this.match(terraformParser.OBJECT);\r\n\t            this.state = 145;\r\n\t            this.match(terraformParser.PO);\r\n\t            this.state = 146;\r\n\t            this.object();\r\n\t            this.state = 147;\r\n\t            this.match(terraformParser.PF);\r\n\t            break;\r\n\t        }\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  object() {\r\n\t    const localctx = new ObjectContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 26, terraformParser.RULE_object);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 153;\r\n\t        this._errHandler.sync(this);\r\n\t        let _alt = 1;\r\n\t        do {\r\n\t        \tswitch (_alt) {\r\n\t        \tcase 1:\r\n\t        \t\tthis.state = 153;\r\n\t        \t\tthis._errHandler.sync(this);\r\n\t        \t\tvar la_ = this._interp.adaptivePredict(this._input, 9, this._ctx);\r\n\t        \t\tswitch (la_) {\r\n\t        \t\tcase 1:\r\n\t        \t\t    this.state = 151;\r\n\t        \t\t    this.complexField();\r\n\t        \t\t    break;\r\n\r\n\t        \t\tcase 2:\r\n\t        \t\t    this.state = 152;\r\n\t        \t\t    this.field();\r\n\t        \t\t    break;\r\n\t        \t\t}\r\n\t        \t\tbreak;\r\n\t        \tdefault:\r\n\t        \t\tthrow new antlr4.error.NoViableAltException(this);\r\n\t        \t}\r\n\t        \tthis.state = 155;\r\n\t        \tthis._errHandler.sync(this);\r\n\t        \t_alt = this._interp.adaptivePredict(this._input, 10, this._ctx);\r\n\t        } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  field() {\r\n\t    const localctx = new FieldContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 28, terraformParser.RULE_field);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 157;\r\n\t        this.match(terraformParser.IDENTIFIER);\r\n\t        this.state = 158;\r\n\t        this.match(terraformParser.EQUAL);\r\n\t        this.state = 159;\r\n\t        this.expression();\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  complexField() {\r\n\t    const localctx = new ComplexFieldContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 30, terraformParser.RULE_complexField);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 161;\r\n\t        this.match(terraformParser.IDENTIFIER);\r\n\t        this.state = 162;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 163;\r\n\t        this.object();\r\n\t        this.state = 164;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  validation() {\r\n\t    const localctx = new ValidationContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 32, terraformParser.RULE_validation);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 166;\r\n\t        this.match(terraformParser.AO);\r\n\t        this.state = 167;\r\n\t        this.match(terraformParser.CONDITION);\r\n\t        this.state = 168;\r\n\t        this.match(terraformParser.EQUAL);\r\n\t        this.state = 170;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        do {\r\n\t            this.state = 169;\r\n\t            this.condition();\r\n\t            this.state = 172;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t        } while ((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << terraformParser.BOOLEANOP) | (1 << terraformParser.BOOLEAN) | (1 << terraformParser.IDENTIFIER) | (1 << terraformParser.STRING) | (1 << terraformParser.NUMBER))) !== 0));\r\n\t        this.state = 174;\r\n\t        this.match(terraformParser.ERROR);\r\n\t        this.state = 175;\r\n\t        this.match(terraformParser.EQUAL);\r\n\t        this.state = 176;\r\n\t        this.match(terraformParser.STRING);\r\n\t        this.state = 177;\r\n\t        this.match(terraformParser.AF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  condition() {\r\n\t    const localctx = new ConditionContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 34, terraformParser.RULE_condition);\r\n\t    try {\r\n\t        this.state = 184;\r\n\t        this._errHandler.sync(this);\r\n\t        switch (this._input.LA(1)) {\r\n\t        case terraformParser.STRING:\r\n\t            this.enterOuterAlt(localctx, 1);\r\n\t            this.state = 179;\r\n\t            this.match(terraformParser.STRING);\r\n\t            break;\r\n\t        case terraformParser.NUMBER:\r\n\t            this.enterOuterAlt(localctx, 2);\r\n\t            this.state = 180;\r\n\t            this.match(terraformParser.NUMBER);\r\n\t            break;\r\n\t        case terraformParser.BOOLEAN:\r\n\t            this.enterOuterAlt(localctx, 3);\r\n\t            this.state = 181;\r\n\t            this.match(terraformParser.BOOLEAN);\r\n\t            break;\r\n\t        case terraformParser.BOOLEANOP:\r\n\t            this.enterOuterAlt(localctx, 4);\r\n\t            this.state = 182;\r\n\t            this.match(terraformParser.BOOLEANOP);\r\n\t            break;\r\n\t        case terraformParser.IDENTIFIER:\r\n\t            this.enterOuterAlt(localctx, 5);\r\n\t            this.state = 183;\r\n\t            this.functionCall();\r\n\t            break;\r\n\t        default:\r\n\t            throw new antlr4.error.NoViableAltException(this);\r\n\t        }\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  expression() {\r\n\t    const localctx = new ExpressionContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 36, terraformParser.RULE_expression);\r\n\t    try {\r\n\t        this.state = 192;\r\n\t        this._errHandler.sync(this);\r\n\t        const la_ = this._interp.adaptivePredict(this._input, 13, this._ctx);\r\n\t        switch (la_) {\r\n\t        case 1:\r\n\t            this.enterOuterAlt(localctx, 1);\r\n\t            this.state = 186;\r\n\t            this.match(terraformParser.NUMBER);\r\n\t            break;\r\n\r\n\t        case 2:\r\n\t            this.enterOuterAlt(localctx, 2);\r\n\t            this.state = 187;\r\n\t            this.match(terraformParser.BOOLEAN);\r\n\t            break;\r\n\r\n\t        case 3:\r\n\t            this.enterOuterAlt(localctx, 3);\r\n\t            this.state = 188;\r\n\t            this.array();\r\n\t            break;\r\n\r\n\t        case 4:\r\n\t            this.enterOuterAlt(localctx, 4);\r\n\t            this.state = 189;\r\n\t            this.complexExpression(0);\r\n\t            break;\r\n\r\n\t        case 5:\r\n\t            this.enterOuterAlt(localctx, 5);\r\n\t            this.state = 190;\r\n\t            this.match(terraformParser.STRING);\r\n\t            break;\r\n\r\n\t        case 6:\r\n\t            this.enterOuterAlt(localctx, 6);\r\n\t            this.state = 191;\r\n\t            this.type();\r\n\t            break;\r\n\t        }\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  functionCall() {\r\n\t    const localctx = new FunctionCallContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 38, terraformParser.RULE_functionCall);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 194;\r\n\t        this.match(terraformParser.IDENTIFIER);\r\n\t        this.state = 195;\r\n\t        this.match(terraformParser.PO);\r\n\t        this.state = 196;\r\n\t        this.expression();\r\n\t        this.state = 201;\r\n\t        this._errHandler.sync(this);\r\n\t        let _alt = this._interp.adaptivePredict(this._input, 14, this._ctx);\r\n\t        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {\r\n\t            if (_alt === 1) {\r\n\t                this.state = 197;\r\n\t                this.match(terraformParser.VIRG);\r\n\t                this.state = 198;\r\n\t                this.expression();\r\n\t            }\r\n\t            this.state = 203;\r\n\t            this._errHandler.sync(this);\r\n\t            _alt = this._interp.adaptivePredict(this._input, 14, this._ctx);\r\n\t        }\r\n\r\n\t        this.state = 205;\r\n\t        this._errHandler.sync(this);\r\n\t        _la = this._input.LA(1);\r\n\t        if (_la === terraformParser.VIRG) {\r\n\t            this.state = 204;\r\n\t            this.match(terraformParser.VIRG);\r\n\t        }\r\n\r\n\t        this.state = 207;\r\n\t        this.match(terraformParser.PF);\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  complexExpression(_p) {\r\n    if (_p === undefined) {\r\n\t\t    _p = 0;\r\n    }\r\n\t    const _parentctx = this._ctx;\r\n\t    const _parentState = this.state;\r\n\t    let localctx = new ComplexExpressionContext(this, this._ctx, _parentState);\r\n\t    let _prevctx = localctx;\r\n\t    const _startState = 40;\r\n\t    this.enterRecursionRule(localctx, 40, terraformParser.RULE_complexExpression, _p);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 229;\r\n\t        this._errHandler.sync(this);\r\n\t        var la_ = this._interp.adaptivePredict(this._input, 19, this._ctx);\r\n\t        switch (la_) {\r\n\t        case 1:\r\n\t            this.state = 210;\r\n\t            this.match(terraformParser.IDENTIFIER);\r\n\t            break;\r\n\r\n\t        case 2:\r\n\t            this.state = 211;\r\n\t            this.match(terraformParser.OPEN);\r\n\t            this.state = 219;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t            do {\r\n\t                this.state = 219;\r\n\t                this._errHandler.sync(this);\r\n\t                switch (this._input.LA(1)) {\r\n\t                case terraformParser.IDENTIFIERS:\r\n\t                    this.state = 212;\r\n\t                    this.match(terraformParser.IDENTIFIERS);\r\n\t                    break;\r\n\t                case terraformParser.AUTRE:\r\n\t                    this.state = 213;\r\n\t                    this.match(terraformParser.AUTRE);\r\n\t                    break;\r\n\t                case terraformParser.WSS:\r\n\t                    this.state = 215;\r\n\t                    this._errHandler.sync(this);\r\n\t                    var _alt = 1;\r\n\t                    do {\r\n\t                    \tswitch (_alt) {\r\n\t                    \tcase 1:\r\n\t                    \t\tthis.state = 214;\r\n\t                    \t\tthis.match(terraformParser.WSS);\r\n\t                    \t\tbreak;\r\n\t                    \tdefault:\r\n\t                    \t\tthrow new antlr4.error.NoViableAltException(this);\r\n\t                    \t}\r\n\t                    \tthis.state = 217;\r\n\t                    \tthis._errHandler.sync(this);\r\n\t                    \t_alt = this._interp.adaptivePredict(this._input, 16, this._ctx);\r\n\t                    } while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER);\r\n\t                    break;\r\n\t                default:\r\n\t                    throw new antlr4.error.NoViableAltException(this);\r\n\t                }\r\n\t                this.state = 221;\r\n\t                this._errHandler.sync(this);\r\n\t                _la = this._input.LA(1);\r\n\t            } while (((((_la - 36)) & ~0x1f) == 0 && ((1 << (_la - 36)) & ((1 << (terraformParser.IDENTIFIERS - 36)) | (1 << (terraformParser.WSS - 36)) | (1 << (terraformParser.AUTRE - 36)))) !== 0));\r\n\t            this.state = 223;\r\n\t            this.match(terraformParser.CLOSE);\r\n\t            break;\r\n\r\n\t        case 3:\r\n\t            this.state = 224;\r\n\t            this.match(terraformParser.STRING);\r\n\t            this.state = 225;\r\n\t            this.complexExpression(0);\r\n\t            this.state = 226;\r\n\t            this.match(terraformParser.STRING);\r\n\t            break;\r\n\r\n\t        case 4:\r\n\t            this.state = 228;\r\n\t            this.functionCall();\r\n\t            break;\r\n\t        }\r\n\t        this._ctx.stop = this._input.LT(-1);\r\n\t        this.state = 244;\r\n\t        this._errHandler.sync(this);\r\n\t        var _alt = this._interp.adaptivePredict(this._input, 21, this._ctx);\r\n\t        while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {\r\n\t            if (_alt === 1) {\r\n\t                if (this._parseListeners !== null) {\r\n\t                    this.triggerExitRuleEvent();\r\n\t                }\r\n\t                _prevctx = localctx;\r\n\t                this.state = 242;\r\n\t                this._errHandler.sync(this);\r\n\t                var la_ = this._interp.adaptivePredict(this._input, 20, this._ctx);\r\n\t                switch (la_) {\r\n\t                case 1:\r\n\t                    localctx = new ComplexExpressionContext(this, _parentctx, _parentState);\r\n\t                    this.pushNewRecursionContext(localctx, _startState, terraformParser.RULE_complexExpression);\r\n\t                    this.state = 231;\r\n\t                    if (!(this.precpred(this._ctx, 6))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, 'this.precpred(this._ctx, 6)');\r\n\t                    }\r\n\t                    this.state = 232;\r\n\t                    this.match(terraformParser.POINT);\r\n\t                    this.state = 233;\r\n\t                    this.complexExpression(7);\r\n\t                    break;\r\n\r\n\t                case 2:\r\n\t                    localctx = new ComplexExpressionContext(this, _parentctx, _parentState);\r\n\t                    this.pushNewRecursionContext(localctx, _startState, terraformParser.RULE_complexExpression);\r\n\t                    this.state = 234;\r\n\t                    if (!(this.precpred(this._ctx, 5))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, 'this.precpred(this._ctx, 5)');\r\n\t                    }\r\n\t                    this.state = 235;\r\n\t                    this.match(terraformParser.CO);\r\n\t                    this.state = 236;\r\n\t                    this.index();\r\n\t                    this.state = 237;\r\n\t                    this.match(terraformParser.CF);\r\n\t                    break;\r\n\r\n\t                case 3:\r\n\t                    localctx = new ComplexExpressionContext(this, _parentctx, _parentState);\r\n\t                    this.pushNewRecursionContext(localctx, _startState, terraformParser.RULE_complexExpression);\r\n\t                    this.state = 239;\r\n\t                    if (!(this.precpred(this._ctx, 4))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, 'this.precpred(this._ctx, 4)');\r\n\t                    }\r\n\t                    this.state = 240;\r\n\t                    this.match(terraformParser.POINT);\r\n\t                    this.state = 241;\r\n\t                    this.index();\r\n\t                    break;\r\n\t                }\r\n\t            }\r\n\t            this.state = 246;\r\n\t            this._errHandler.sync(this);\r\n\t            _alt = this._interp.adaptivePredict(this._input, 21, this._ctx);\r\n\t        }\r\n\t    } catch (error) {\r\n\t        if (error instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = error;\r\n\t\t        this._errHandler.reportError(this, error);\r\n\t\t        this._errHandler.recover(this, error);\r\n\t\t    } else {\r\n\t\t    \tthrow error;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.unrollRecursionContexts(_parentctx);\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  array() {\r\n\t    const localctx = new ArrayContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 42, terraformParser.RULE_array);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.state = 263;\r\n\t        this._errHandler.sync(this);\r\n\t        const la_ = this._interp.adaptivePredict(this._input, 24, this._ctx);\r\n\t        switch (la_) {\r\n\t        case 1:\r\n\t            this.enterOuterAlt(localctx, 1);\r\n\t            this.state = 247;\r\n\t            this.match(terraformParser.CO);\r\n\t            this.state = 248;\r\n\t            this.match(terraformParser.CF);\r\n\t            break;\r\n\r\n\t        case 2:\r\n\t            this.enterOuterAlt(localctx, 2);\r\n\t            this.state = 249;\r\n\t            this.match(terraformParser.CO);\r\n\t            this.state = 250;\r\n\t            this.expression();\r\n\t            this.state = 255;\r\n\t            this._errHandler.sync(this);\r\n\t            var _alt = this._interp.adaptivePredict(this._input, 22, this._ctx);\r\n\t            while (_alt != 2 && _alt != antlr4.atn.ATN.INVALID_ALT_NUMBER) {\r\n\t                if (_alt === 1) {\r\n\t                    this.state = 251;\r\n\t                    this.match(terraformParser.VIRG);\r\n\t                    this.state = 252;\r\n\t                    this.expression();\r\n\t                }\r\n\t                this.state = 257;\r\n\t                this._errHandler.sync(this);\r\n\t                _alt = this._interp.adaptivePredict(this._input, 22, this._ctx);\r\n\t            }\r\n\r\n\t            this.state = 259;\r\n\t            this._errHandler.sync(this);\r\n\t            _la = this._input.LA(1);\r\n\t            if (_la === terraformParser.VIRG) {\r\n\t                this.state = 258;\r\n\t                this.match(terraformParser.VIRG);\r\n\t            }\r\n\r\n\t            this.state = 261;\r\n\t            this.match(terraformParser.CF);\r\n\t            break;\r\n\t        }\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n\r\n  index() {\r\n\t    const localctx = new IndexContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 44, terraformParser.RULE_index);\r\n\t    let _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 265;\r\n\t        _la = this._input.LA(1);\r\n\t        if (!(_la === terraformParser.MULT || _la === terraformParser.NUMBER)) {\r\n\t        this._errHandler.recoverInline(this);\r\n\t        } else {\r\n\t        \tthis._errHandler.reportMatch(this);\r\n\t            this.consume();\r\n\t        }\r\n\t    } catch (re) {\r\n\t    \tif (re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n  }\r\n}\r\n\r\nterraformParser.EOF = antlr4.Token.EOF;\r\nterraformParser.MODULE = 1;\r\nterraformParser.DATA = 2;\r\nterraformParser.SOURCE = 3;\r\nterraformParser.PROVIDER = 4;\r\nterraformParser.TERRAFORM = 5;\r\nterraformParser.RESOURCE = 6;\r\nterraformParser.VARIABLE = 7;\r\nterraformParser.OUTPUT = 8;\r\nterraformParser.LIST = 9;\r\nterraformParser.MAP = 10;\r\nterraformParser.OBJECT = 11;\r\nterraformParser.CONDITION = 12;\r\nterraformParser.ERROR = 13;\r\nterraformParser.AO = 14;\r\nterraformParser.AF = 15;\r\nterraformParser.EQUAL = 16;\r\nterraformParser.PO = 17;\r\nterraformParser.PF = 18;\r\nterraformParser.CO = 19;\r\nterraformParser.CF = 20;\r\nterraformParser.VIRG = 21;\r\nterraformParser.POINT = 22;\r\nterraformParser.TIRET = 23;\r\nterraformParser.MULT = 24;\r\nterraformParser.BOOLEANOP = 25;\r\nterraformParser.BOOLEAN = 26;\r\nterraformParser.TYPE = 27;\r\nterraformParser.IDENTIFIER = 28;\r\nterraformParser.STRING = 29;\r\nterraformParser.NUMBER = 30;\r\nterraformParser.COMMENT = 31;\r\nterraformParser.LINE_COMMENT = 32;\r\nterraformParser.HAS_COMMENT = 33;\r\nterraformParser.WS = 34;\r\nterraformParser.OPEN = 35;\r\nterraformParser.IDENTIFIERS = 36;\r\nterraformParser.WSS = 37;\r\nterraformParser.NUMBERS = 38;\r\nterraformParser.AUTRE = 39;\r\nterraformParser.CLOSE = 40;\r\n\r\nterraformParser.RULE_file = 0;\r\nterraformParser.RULE_directive = 1;\r\nterraformParser.RULE_dataDirective = 2;\r\nterraformParser.RULE_moduleDirective = 3;\r\nterraformParser.RULE_moduleSource = 4;\r\nterraformParser.RULE_providerDirective = 5;\r\nterraformParser.RULE_terraformDirective = 6;\r\nterraformParser.RULE_resourceDirective = 7;\r\nterraformParser.RULE_variableDirective = 8;\r\nterraformParser.RULE_outputDirective = 9;\r\nterraformParser.RULE_name = 10;\r\nterraformParser.RULE_providerType = 11;\r\nterraformParser.RULE_type = 12;\r\nterraformParser.RULE_object = 13;\r\nterraformParser.RULE_field = 14;\r\nterraformParser.RULE_complexField = 15;\r\nterraformParser.RULE_validation = 16;\r\nterraformParser.RULE_condition = 17;\r\nterraformParser.RULE_expression = 18;\r\nterraformParser.RULE_functionCall = 19;\r\nterraformParser.RULE_complexExpression = 20;\r\nterraformParser.RULE_array = 21;\r\nterraformParser.RULE_index = 22;\r\n\r\nclass FileContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_file;\r\n  }\r\n\r\n  directive = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(DirectiveContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(DirectiveContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterFile(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitFile(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass DirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_directive;\r\n  }\r\n\r\n  providerDirective() {\r\n\t    return this.getTypedRuleContext(ProviderDirectiveContext, 0);\r\n  }\r\n\r\n  terraformDirective() {\r\n\t    return this.getTypedRuleContext(TerraformDirectiveContext, 0);\r\n  }\r\n\r\n  resourceDirective() {\r\n\t    return this.getTypedRuleContext(ResourceDirectiveContext, 0);\r\n  }\r\n\r\n  variableDirective() {\r\n\t    return this.getTypedRuleContext(VariableDirectiveContext, 0);\r\n  }\r\n\r\n  outputDirective() {\r\n\t    return this.getTypedRuleContext(OutputDirectiveContext, 0);\r\n  }\r\n\r\n  moduleDirective() {\r\n\t    return this.getTypedRuleContext(ModuleDirectiveContext, 0);\r\n  }\r\n\r\n  dataDirective() {\r\n\t    return this.getTypedRuleContext(DataDirectiveContext, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass DataDirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_dataDirective;\r\n  }\r\n\r\n  DATA() {\r\n\t    return this.getToken(terraformParser.DATA, 0);\r\n  }\r\n\r\n  providerType() {\r\n\t    return this.getTypedRuleContext(ProviderTypeContext, 0);\r\n  }\r\n\r\n  name() {\r\n\t    return this.getTypedRuleContext(NameContext, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  object = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ObjectContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ObjectContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterDataDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitDataDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ModuleDirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_moduleDirective;\r\n  }\r\n\r\n  MODULE() {\r\n\t    return this.getToken(terraformParser.MODULE, 0);\r\n  }\r\n\r\n  name() {\r\n\t    return this.getTypedRuleContext(NameContext, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  moduleSource = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ModuleSourceContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ModuleSourceContext, i);\r\n  };\r\n\r\n  object = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ObjectContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ObjectContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterModuleDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitModuleDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ModuleSourceContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_moduleSource;\r\n  }\r\n\r\n  SOURCE() {\r\n\t    return this.getToken(terraformParser.SOURCE, 0);\r\n  }\r\n\r\n  EQUAL() {\r\n\t    return this.getToken(terraformParser.EQUAL, 0);\r\n  }\r\n\r\n  STRING() {\r\n\t    return this.getToken(terraformParser.STRING, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterModuleSource(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitModuleSource(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ProviderDirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_providerDirective;\r\n  }\r\n\r\n  PROVIDER() {\r\n\t    return this.getToken(terraformParser.PROVIDER, 0);\r\n  }\r\n\r\n  name() {\r\n\t    return this.getTypedRuleContext(NameContext, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  object() {\r\n\t    return this.getTypedRuleContext(ObjectContext, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterProviderDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitProviderDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass TerraformDirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_terraformDirective;\r\n  }\r\n\r\n  TERRAFORM() {\r\n\t    return this.getToken(terraformParser.TERRAFORM, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  object = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ObjectContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ObjectContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterTerraformDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitTerraformDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ResourceDirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_resourceDirective;\r\n  }\r\n\r\n  RESOURCE() {\r\n\t    return this.getToken(terraformParser.RESOURCE, 0);\r\n  }\r\n\r\n  providerType() {\r\n\t    return this.getTypedRuleContext(ProviderTypeContext, 0);\r\n  }\r\n\r\n  name() {\r\n\t    return this.getTypedRuleContext(NameContext, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  object() {\r\n\t    return this.getTypedRuleContext(ObjectContext, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterResourceDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitResourceDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass VariableDirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_variableDirective;\r\n  }\r\n\r\n  VARIABLE() {\r\n\t    return this.getToken(terraformParser.VARIABLE, 0);\r\n  }\r\n\r\n  name() {\r\n\t    return this.getTypedRuleContext(NameContext, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  object = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ObjectContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ObjectContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterVariableDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitVariableDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass OutputDirectiveContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_outputDirective;\r\n  }\r\n\r\n  OUTPUT() {\r\n\t    return this.getToken(terraformParser.OUTPUT, 0);\r\n  }\r\n\r\n  name() {\r\n\t    return this.getTypedRuleContext(NameContext, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  object = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ObjectContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ObjectContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterOutputDirective(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitOutputDirective(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass NameContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_name;\r\n  }\r\n\r\n  STRING() {\r\n\t    return this.getToken(terraformParser.STRING, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterName(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitName(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ProviderTypeContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_providerType;\r\n  }\r\n\r\n  STRING() {\r\n\t    return this.getToken(terraformParser.STRING, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterProviderType(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitProviderType(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass TypeContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_type;\r\n  }\r\n\r\n  TYPE() {\r\n\t    return this.getToken(terraformParser.TYPE, 0);\r\n  }\r\n\r\n  LIST() {\r\n\t    return this.getToken(terraformParser.LIST, 0);\r\n  }\r\n\r\n  PO() {\r\n\t    return this.getToken(terraformParser.PO, 0);\r\n  }\r\n\r\n  type() {\r\n\t    return this.getTypedRuleContext(TypeContext, 0);\r\n  }\r\n\r\n  PF() {\r\n\t    return this.getToken(terraformParser.PF, 0);\r\n  }\r\n\r\n  MAP() {\r\n\t    return this.getToken(terraformParser.MAP, 0);\r\n  }\r\n\r\n  OBJECT() {\r\n\t    return this.getToken(terraformParser.OBJECT, 0);\r\n  }\r\n\r\n  object() {\r\n\t    return this.getTypedRuleContext(ObjectContext, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterType(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitType(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ObjectContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_object;\r\n  }\r\n\r\n  complexField = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ComplexFieldContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ComplexFieldContext, i);\r\n  };\r\n\r\n  field = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(FieldContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(FieldContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterObject(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitObject(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass FieldContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_field;\r\n  }\r\n\r\n  IDENTIFIER() {\r\n\t    return this.getToken(terraformParser.IDENTIFIER, 0);\r\n  }\r\n\r\n  EQUAL() {\r\n\t    return this.getToken(terraformParser.EQUAL, 0);\r\n  }\r\n\r\n  expression() {\r\n\t    return this.getTypedRuleContext(ExpressionContext, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterField(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitField(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ComplexFieldContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_complexField;\r\n  }\r\n\r\n  IDENTIFIER() {\r\n\t    return this.getToken(terraformParser.IDENTIFIER, 0);\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  object() {\r\n\t    return this.getTypedRuleContext(ObjectContext, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterComplexField(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitComplexField(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ValidationContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_validation;\r\n  }\r\n\r\n  AO() {\r\n\t    return this.getToken(terraformParser.AO, 0);\r\n  }\r\n\r\n  CONDITION() {\r\n\t    return this.getToken(terraformParser.CONDITION, 0);\r\n  }\r\n\r\n  EQUAL = function (i) {\r\n    if (i === undefined) {\r\n      i = null;\r\n    }\r\n\t    if (i === null) {\r\n\t        return this.getTokens(terraformParser.EQUAL);\r\n\t    }\r\n\t        return this.getToken(terraformParser.EQUAL, i);\r\n  };\r\n\r\n  ERROR() {\r\n\t    return this.getToken(terraformParser.ERROR, 0);\r\n  }\r\n\r\n  STRING() {\r\n\t    return this.getToken(terraformParser.STRING, 0);\r\n  }\r\n\r\n  AF() {\r\n\t    return this.getToken(terraformParser.AF, 0);\r\n  }\r\n\r\n  condition = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ConditionContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ConditionContext, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterValidation(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitValidation(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ConditionContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_condition;\r\n  }\r\n\r\n  STRING() {\r\n\t    return this.getToken(terraformParser.STRING, 0);\r\n  }\r\n\r\n  NUMBER() {\r\n\t    return this.getToken(terraformParser.NUMBER, 0);\r\n  }\r\n\r\n  BOOLEAN() {\r\n\t    return this.getToken(terraformParser.BOOLEAN, 0);\r\n  }\r\n\r\n  BOOLEANOP() {\r\n\t    return this.getToken(terraformParser.BOOLEANOP, 0);\r\n  }\r\n\r\n  functionCall() {\r\n\t    return this.getTypedRuleContext(FunctionCallContext, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterCondition(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitCondition(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ExpressionContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_expression;\r\n  }\r\n\r\n  NUMBER() {\r\n\t    return this.getToken(terraformParser.NUMBER, 0);\r\n  }\r\n\r\n  BOOLEAN() {\r\n\t    return this.getToken(terraformParser.BOOLEAN, 0);\r\n  }\r\n\r\n  array() {\r\n\t    return this.getTypedRuleContext(ArrayContext, 0);\r\n  }\r\n\r\n  complexExpression() {\r\n\t    return this.getTypedRuleContext(ComplexExpressionContext, 0);\r\n  }\r\n\r\n  STRING() {\r\n\t    return this.getToken(terraformParser.STRING, 0);\r\n  }\r\n\r\n  type() {\r\n\t    return this.getTypedRuleContext(TypeContext, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterExpression(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitExpression(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass FunctionCallContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_functionCall;\r\n  }\r\n\r\n  IDENTIFIER() {\r\n\t    return this.getToken(terraformParser.IDENTIFIER, 0);\r\n  }\r\n\r\n  PO() {\r\n\t    return this.getToken(terraformParser.PO, 0);\r\n  }\r\n\r\n  expression = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ExpressionContext, i);\r\n  };\r\n\r\n  PF() {\r\n\t    return this.getToken(terraformParser.PF, 0);\r\n  }\r\n\r\n  VIRG = function (i) {\r\n    if (i === undefined) {\r\n      i = null;\r\n    }\r\n\t    if (i === null) {\r\n\t        return this.getTokens(terraformParser.VIRG);\r\n\t    }\r\n\t        return this.getToken(terraformParser.VIRG, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterFunctionCall(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitFunctionCall(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ComplexExpressionContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_complexExpression;\r\n  }\r\n\r\n  IDENTIFIER() {\r\n\t    return this.getToken(terraformParser.IDENTIFIER, 0);\r\n  }\r\n\r\n  OPEN() {\r\n\t    return this.getToken(terraformParser.OPEN, 0);\r\n  }\r\n\r\n  CLOSE() {\r\n\t    return this.getToken(terraformParser.CLOSE, 0);\r\n  }\r\n\r\n  IDENTIFIERS = function (i) {\r\n    if (i === undefined) {\r\n      i = null;\r\n    }\r\n\t    if (i === null) {\r\n\t        return this.getTokens(terraformParser.IDENTIFIERS);\r\n\t    }\r\n\t        return this.getToken(terraformParser.IDENTIFIERS, i);\r\n  };\r\n\r\n  AUTRE = function (i) {\r\n    if (i === undefined) {\r\n      i = null;\r\n    }\r\n\t    if (i === null) {\r\n\t        return this.getTokens(terraformParser.AUTRE);\r\n\t    }\r\n\t        return this.getToken(terraformParser.AUTRE, i);\r\n  };\r\n\r\n  WSS = function (i) {\r\n    if (i === undefined) {\r\n      i = null;\r\n    }\r\n\t    if (i === null) {\r\n\t        return this.getTokens(terraformParser.WSS);\r\n\t    }\r\n\t        return this.getToken(terraformParser.WSS, i);\r\n  };\r\n\r\n  STRING = function (i) {\r\n    if (i === undefined) {\r\n      i = null;\r\n    }\r\n\t    if (i === null) {\r\n\t        return this.getTokens(terraformParser.STRING);\r\n\t    }\r\n\t        return this.getToken(terraformParser.STRING, i);\r\n  };\r\n\r\n  complexExpression = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ComplexExpressionContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ComplexExpressionContext, i);\r\n  };\r\n\r\n  functionCall() {\r\n\t    return this.getTypedRuleContext(FunctionCallContext, 0);\r\n  }\r\n\r\n  POINT() {\r\n\t    return this.getToken(terraformParser.POINT, 0);\r\n  }\r\n\r\n  CO() {\r\n\t    return this.getToken(terraformParser.CO, 0);\r\n  }\r\n\r\n  index() {\r\n\t    return this.getTypedRuleContext(IndexContext, 0);\r\n  }\r\n\r\n  CF() {\r\n\t    return this.getToken(terraformParser.CF, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterComplexExpression(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitComplexExpression(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass ArrayContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_array;\r\n  }\r\n\r\n  CO() {\r\n\t    return this.getToken(terraformParser.CO, 0);\r\n  }\r\n\r\n  CF() {\r\n\t    return this.getToken(terraformParser.CF, 0);\r\n  }\r\n\r\n  expression = function (i) {\r\n\t    if (i === undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if (i === null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    }\r\n\t        return this.getTypedRuleContext(ExpressionContext, i);\r\n  };\r\n\r\n  VIRG = function (i) {\r\n    if (i === undefined) {\r\n      i = null;\r\n    }\r\n\t    if (i === null) {\r\n\t        return this.getTokens(terraformParser.VIRG);\r\n\t    }\r\n\t        return this.getToken(terraformParser.VIRG, i);\r\n  };\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterArray(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitArray(this);\r\n    }\r\n  }\r\n}\r\n\r\nclass IndexContext extends antlr4.ParserRuleContext {\r\n  constructor(parser, parent, invokingState) {\r\n    if (parent === undefined) {\r\n      parent = null;\r\n    }\r\n    if (invokingState === undefined || invokingState === null) {\r\n      invokingState = -1;\r\n    }\r\n    super(parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = terraformParser.RULE_index;\r\n  }\r\n\r\n  NUMBER() {\r\n\t    return this.getToken(terraformParser.NUMBER, 0);\r\n  }\r\n\r\n  MULT() {\r\n\t    return this.getToken(terraformParser.MULT, 0);\r\n  }\r\n\r\n  enterRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.enterIndex(this);\r\n    }\r\n  }\r\n\r\n  exitRule(listener) {\r\n\t    if (listener instanceof terraformParserListener) {\r\n\t        listener.exitIndex(this);\r\n    }\r\n  }\r\n}\r\n\r\nterraformParser.FileContext = FileContext;\r\nterraformParser.DirectiveContext = DirectiveContext;\r\nterraformParser.DataDirectiveContext = DataDirectiveContext;\r\nterraformParser.ModuleDirectiveContext = ModuleDirectiveContext;\r\nterraformParser.ModuleSourceContext = ModuleSourceContext;\r\nterraformParser.ProviderDirectiveContext = ProviderDirectiveContext;\r\nterraformParser.TerraformDirectiveContext = TerraformDirectiveContext;\r\nterraformParser.ResourceDirectiveContext = ResourceDirectiveContext;\r\nterraformParser.VariableDirectiveContext = VariableDirectiveContext;\r\nterraformParser.OutputDirectiveContext = OutputDirectiveContext;\r\nterraformParser.NameContext = NameContext;\r\nterraformParser.ProviderTypeContext = ProviderTypeContext;\r\nterraformParser.TypeContext = TypeContext;\r\nterraformParser.ObjectContext = ObjectContext;\r\nterraformParser.FieldContext = FieldContext;\r\nterraformParser.ComplexFieldContext = ComplexFieldContext;\r\nterraformParser.ValidationContext = ValidationContext;\r\nterraformParser.ConditionContext = ConditionContext;\r\nterraformParser.ExpressionContext = ExpressionContext;\r\nterraformParser.FunctionCallContext = FunctionCallContext;\r\nterraformParser.ComplexExpressionContext = ComplexExpressionContext;\r\nterraformParser.ArrayContext = ArrayContext;\r\nterraformParser.IndexContext = IndexContext;\r\n","// Generated from terraformLexer.g4 by ANTLR 4.9.3\r\n// jshint ignore: start\r\nimport antlr4 from 'antlr4';\r\n\r\nconst serializedATN = ['\\u0003\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786',\r\n  '\\u5964\\u0002*\\u01a4\\b\\u0001\\b\\u0001\\u0004\\u0002\\t\\u0002\\u0004\\u0003',\r\n  '\\t\\u0003\\u0004\\u0004\\t\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006',\r\n  '\\u0004\\u0007\\t\\u0007\\u0004\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b',\r\n  '\\t\\u000b\\u0004\\f\\t\\f\\u0004\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0004\\u000f\\t\\u000f',\r\n  '\\u0004\\u0010\\t\\u0010\\u0004\\u0011\\t\\u0011\\u0004\\u0012\\t\\u0012\\u0004\\u0013',\r\n  '\\t\\u0013\\u0004\\u0014\\t\\u0014\\u0004\\u0015\\t\\u0015\\u0004\\u0016\\t\\u0016',\r\n  '\\u0004\\u0017\\t\\u0017\\u0004\\u0018\\t\\u0018\\u0004\\u0019\\t\\u0019\\u0004\\u001a',\r\n  '\\t\\u001a\\u0004\\u001b\\t\\u001b\\u0004\\u001c\\t\\u001c\\u0004\\u001d\\t\\u001d',\r\n  '\\u0004\\u001e\\t\\u001e\\u0004\\u001f\\t\\u001f\\u0004 \\t \\u0004!\\t!\\u0004\"',\r\n  \"\\t\\\"\\u0004#\\t#\\u0004$\\t$\\u0004%\\t%\\u0004&\\t&\\u0004\\'\\t\\'\\u0004(\\t(\\u0004\",\r\n  ')\\t)\\u0004*\\t*\\u0004+\\t+\\u0004,\\t,\\u0004-\\t-\\u0004.\\t.\\u0004/\\t/\\u0004',\r\n  '0\\t0\\u00041\\t1\\u0003\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003',\r\n  '\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003',\r\n  '\\u0003\\u0003\\u0003\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003',\r\n  '\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003',\r\n  '\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003',\r\n  '\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003',\r\n  '\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0007\\u0003\\u0007\\u0003',\r\n  '\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003',\r\n  '\\u0007\\u0003\\b\\u0003\\b\\u0003\\b\\u0003\\b\\u0003\\b\\u0003\\b\\u0003\\b\\u0003',\r\n  '\\b\\u0003\\b\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003',\r\n  '\\n\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\u000b\\u0003\\u000b\\u0003\\u000b',\r\n  '\\u0003\\u000b\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f',\r\n  '\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0003',\r\n  '\\r\\u0003\\r\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e',\r\n  '\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e',\r\n  '\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000f\\u0003\\u000f\\u0003\\u0010',\r\n  '\\u0003\\u0010\\u0003\\u0011\\u0003\\u0011\\u0003\\u0012\\u0003\\u0012\\u0003\\u0013',\r\n  '\\u0003\\u0013\\u0003\\u0014\\u0003\\u0014\\u0003\\u0015\\u0003\\u0015\\u0003\\u0016',\r\n  '\\u0003\\u0016\\u0003\\u0017\\u0003\\u0017\\u0003\\u0018\\u0003\\u0018\\u0003\\u0019',\r\n  '\\u0003\\u0019\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a',\r\n  '\\u0003\\u001a\\u0003\\u001a\\u0005\\u001a\\u00e9\\n\\u001a\\u0003\\u001b\\u0003',\r\n  '\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003',\r\n  '\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003',\r\n  '\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003',\r\n  '\\u001b\\u0003\\u001b\\u0003\\u001b\\u0005\\u001b\\u0101\\n\\u001b\\u0003\\u001c',\r\n  '\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c',\r\n  '\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c',\r\n  '\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c',\r\n  '\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c',\r\n  '\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c',\r\n  '\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c',\r\n  '\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0005\\u001c\\u012c\\n',\r\n  '\\u001c\\u0003\\u001d\\u0003\\u001d\\u0007\\u001d\\u0130\\n\\u001d\\f\\u001d\\u000e',\r\n  '\\u001d\\u0133\\u000b\\u001d\\u0003\\u001e\\u0003\\u001e\\u0005\\u001e\\u0137\\n',\r\n  '\\u001e\\u0003\\u001f\\u0003\\u001f\\u0003\\u001f\\u0003\\u001f\\u0005\\u001f\\u013d',\r\n  '\\n\\u001f\\u0003 \\u0003 \\u0003 \\u0007 \\u0142\\n \\f \\u000e \\u0145\\u000b',\r\n  ' \\u0003 \\u0003 \\u0003!\\u0003!\\u0003!\\u0005!\\u014c\\n!\\u0003\"\\u0003\"',\r\n  '\\u0003\"\\u0003\"\\u0003\"\\u0003\"\\u0003#\\u0003#\\u0003$\\u0003$\\u0003%',\r\n  '\\u0003%\\u0003%\\u0007%\\u015b\\n%\\f%\\u000e%\\u015e\\u000b%\\u0005%\\u0160\\n',\r\n  '%\\u0003&\\u0003&\\u0003&\\u0003&\\u0007&\\u0166\\n&\\f&\\u000e&\\u0169\\u000b',\r\n  \"&\\u0003&\\u0003&\\u0003&\\u0003&\\u0003&\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\",\r\n  \"\\u0007\\'\\u0174\\n\\'\\f\\'\\u000e\\'\\u0177\\u000b\\'\\u0003\\'\\u0003\\'\\u0003(\",\r\n  '\\u0003(\\u0007(\\u017d\\n(\\f(\\u000e(\\u0180\\u000b(\\u0003(\\u0003(\\u0003)',\r\n  '\\u0006)\\u0185\\n)\\r)\\u000e)\\u0186\\u0003)\\u0003)\\u0003*\\u0003*\\u0003*',\r\n  '\\u0003*\\u0003*\\u0003*\\u0003*\\u0003*\\u0003+\\u0003+\\u0003,\\u0003,\\u0003',\r\n  '-\\u0003-\\u0003.\\u0003.\\u0003/\\u0003/\\u00030\\u00030\\u00031\\u00031\\u0003',\r\n  '1\\u00031\\u00031\\u00031\\u0003\\u0167\\u00022\\u0004\\u0003\\u0006\\u0004\\b',\r\n  '\\u0005\\n\\u0006\\f\\u0007\\u000e\\b\\u0010\\t\\u0012\\n\\u0014\\u000b\\u0016\\f\\u0018',\r\n  '\\r\\u001a\\u000e\\u001c\\u000f\\u001e\\u0010 \\u0011\"\\u0012$\\u0013&\\u0014',\r\n  '(\\u0015*\\u0016,\\u0017.\\u00180\\u00192\\u001a4\\u001b6\\u001c8\\u001d:\\u001e',\r\n  \"<\\u0002>\\u0002@\\u001fB\\u0002D\\u0002F\\u0002H\\u0002J L!N\\\"P#R$T%V&X\\'\",\r\n  'Z\\u0002\\\\\\u0002^(`)b*\\u0004\\u0002\\u0003\\u0011\\u0006\\u0002((>>@@~~\\u0004',\r\n  '\\u0002--11\\u0003\\u00022;\\u0007\\u0002&&00C\\\\aac|\\u0004\\u0002\\u0002\\u0081',\r\n  '\\ud802\\udc01\\u0003\\u0002\\ud802\\udc01\\u0003\\u0002\\udc02\\ue001\\n\\u0002',\r\n  '$$11^^ddhhppttvv\\u0005\\u00022;CHch\\u0005\\u0002\\u0002!$$^^\\u0003\\u0002',\r\n  '3;\\u0004\\u0002\\f\\f\\u000f\\u000f\\u0005\\u0002\\u000b\\f\\u000f\\u000f\"\"\\u0003',\r\n  '\\u0002c|\\b\\u0002#&/1??aa}}\\u007f\\u007f\\u0002\\u01b5\\u0002\\u0004\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0002\\u0006\\u0003\\u0002\\u0002\\u0002\\u0002\\b\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0002\\n\\u0003\\u0002\\u0002\\u0002\\u0002\\f\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0002\\u000e\\u0003\\u0002\\u0002\\u0002\\u0002\\u0010\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0002\\u0012\\u0003\\u0002\\u0002\\u0002\\u0002\\u0014\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0002\\u0016\\u0003\\u0002\\u0002\\u0002\\u0002\\u0018\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0002\\u001a\\u0003\\u0002\\u0002\\u0002\\u0002\\u001c\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0002\\u001e\\u0003\\u0002\\u0002\\u0002\\u0002 \\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0002\"\\u0003\\u0002\\u0002\\u0002\\u0002$\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0002&\\u0003\\u0002\\u0002\\u0002\\u0002(\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0002*\\u0003\\u0002\\u0002\\u0002\\u0002,\\u0003\\u0002\\u0002\\u0002\\u0002',\r\n  '.\\u0003\\u0002\\u0002\\u0002\\u00020\\u0003\\u0002\\u0002\\u0002\\u00022\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00024\\u0003\\u0002\\u0002\\u0002\\u00026\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u00028\\u0003\\u0002\\u0002\\u0002\\u0002:\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0002@\\u0003\\u0002\\u0002\\u0002\\u0002J\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0002L\\u0003\\u0002\\u0002\\u0002\\u0002N\\u0003\\u0002\\u0002\\u0002\\u0002',\r\n  'P\\u0003\\u0002\\u0002\\u0002\\u0002R\\u0003\\u0002\\u0002\\u0002\\u0002T\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0003V\\u0003\\u0002\\u0002\\u0002\\u0003X\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0003^\\u0003\\u0002\\u0002\\u0002\\u0003`\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0003b\\u0003\\u0002\\u0002\\u0002\\u0004d\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0006k\\u0003\\u0002\\u0002\\u0002\\bp\\u0003\\u0002\\u0002\\u0002\\nw\\u0003',\r\n  '\\u0002\\u0002\\u0002\\f\\u0080\\u0003\\u0002\\u0002\\u0002\\u000e\\u008a\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0010\\u0093\\u0003\\u0002\\u0002\\u0002\\u0012\\u009c\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0014\\u00a3\\u0003\\u0002\\u0002\\u0002\\u0016\\u00a8\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0018\\u00ac\\u0003\\u0002\\u0002\\u0002\\u001a\\u00b3\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u001c\\u00bd\\u0003\\u0002\\u0002\\u0002\\u001e\\u00cb\\u0003',\r\n  '\\u0002\\u0002\\u0002 \\u00cd\\u0003\\u0002\\u0002\\u0002\"\\u00cf\\u0003\\u0002',\r\n  '\\u0002\\u0002$\\u00d1\\u0003\\u0002\\u0002\\u0002&\\u00d3\\u0003\\u0002\\u0002',\r\n  '\\u0002(\\u00d5\\u0003\\u0002\\u0002\\u0002*\\u00d7\\u0003\\u0002\\u0002\\u0002',\r\n  ',\\u00d9\\u0003\\u0002\\u0002\\u0002.\\u00db\\u0003\\u0002\\u0002\\u00020\\u00dd',\r\n  '\\u0003\\u0002\\u0002\\u00022\\u00df\\u0003\\u0002\\u0002\\u00024\\u00e8\\u0003',\r\n  '\\u0002\\u0002\\u00026\\u0100\\u0003\\u0002\\u0002\\u00028\\u012b\\u0003\\u0002',\r\n  '\\u0002\\u0002:\\u012d\\u0003\\u0002\\u0002\\u0002<\\u0136\\u0003\\u0002\\u0002',\r\n  '\\u0002>\\u013c\\u0003\\u0002\\u0002\\u0002@\\u013e\\u0003\\u0002\\u0002\\u0002',\r\n  'B\\u0148\\u0003\\u0002\\u0002\\u0002D\\u014d\\u0003\\u0002\\u0002\\u0002F\\u0153',\r\n  '\\u0003\\u0002\\u0002\\u0002H\\u0155\\u0003\\u0002\\u0002\\u0002J\\u015f\\u0003',\r\n  '\\u0002\\u0002\\u0002L\\u0161\\u0003\\u0002\\u0002\\u0002N\\u016f\\u0003\\u0002',\r\n  '\\u0002\\u0002P\\u017a\\u0003\\u0002\\u0002\\u0002R\\u0184\\u0003\\u0002\\u0002',\r\n  '\\u0002T\\u018a\\u0003\\u0002\\u0002\\u0002V\\u0192\\u0003\\u0002\\u0002\\u0002',\r\n  'X\\u0194\\u0003\\u0002\\u0002\\u0002Z\\u0196\\u0003\\u0002\\u0002\\u0002\\\\\\u0198',\r\n  '\\u0003\\u0002\\u0002\\u0002^\\u019a\\u0003\\u0002\\u0002\\u0002`\\u019c\\u0003',\r\n  '\\u0002\\u0002\\u0002b\\u019e\\u0003\\u0002\\u0002\\u0002de\\u0007o\\u0002\\u0002',\r\n  'ef\\u0007q\\u0002\\u0002fg\\u0007f\\u0002\\u0002gh\\u0007w\\u0002\\u0002hi\\u0007',\r\n  'n\\u0002\\u0002ij\\u0007g\\u0002\\u0002j\\u0005\\u0003\\u0002\\u0002\\u0002kl',\r\n  '\\u0007f\\u0002\\u0002lm\\u0007c\\u0002\\u0002mn\\u0007v\\u0002\\u0002no\\u0007',\r\n  'c\\u0002\\u0002o\\u0007\\u0003\\u0002\\u0002\\u0002pq\\u0007u\\u0002\\u0002qr',\r\n  '\\u0007q\\u0002\\u0002rs\\u0007w\\u0002\\u0002st\\u0007t\\u0002\\u0002tu\\u0007',\r\n  'e\\u0002\\u0002uv\\u0007g\\u0002\\u0002v\\t\\u0003\\u0002\\u0002\\u0002wx\\u0007',\r\n  'r\\u0002\\u0002xy\\u0007t\\u0002\\u0002yz\\u0007q\\u0002\\u0002z{\\u0007x\\u0002',\r\n  '\\u0002{|\\u0007k\\u0002\\u0002|}\\u0007f\\u0002\\u0002}~\\u0007g\\u0002\\u0002',\r\n  '~\\u007f\\u0007t\\u0002\\u0002\\u007f\\u000b\\u0003\\u0002\\u0002\\u0002\\u0080',\r\n  '\\u0081\\u0007v\\u0002\\u0002\\u0081\\u0082\\u0007g\\u0002\\u0002\\u0082\\u0083',\r\n  '\\u0007t\\u0002\\u0002\\u0083\\u0084\\u0007t\\u0002\\u0002\\u0084\\u0085\\u0007',\r\n  'c\\u0002\\u0002\\u0085\\u0086\\u0007h\\u0002\\u0002\\u0086\\u0087\\u0007q\\u0002',\r\n  '\\u0002\\u0087\\u0088\\u0007t\\u0002\\u0002\\u0088\\u0089\\u0007o\\u0002\\u0002',\r\n  '\\u0089\\r\\u0003\\u0002\\u0002\\u0002\\u008a\\u008b\\u0007t\\u0002\\u0002\\u008b',\r\n  '\\u008c\\u0007g\\u0002\\u0002\\u008c\\u008d\\u0007u\\u0002\\u0002\\u008d\\u008e',\r\n  '\\u0007q\\u0002\\u0002\\u008e\\u008f\\u0007w\\u0002\\u0002\\u008f\\u0090\\u0007',\r\n  't\\u0002\\u0002\\u0090\\u0091\\u0007e\\u0002\\u0002\\u0091\\u0092\\u0007g\\u0002',\r\n  '\\u0002\\u0092\\u000f\\u0003\\u0002\\u0002\\u0002\\u0093\\u0094\\u0007x\\u0002',\r\n  '\\u0002\\u0094\\u0095\\u0007c\\u0002\\u0002\\u0095\\u0096\\u0007t\\u0002\\u0002',\r\n  '\\u0096\\u0097\\u0007k\\u0002\\u0002\\u0097\\u0098\\u0007c\\u0002\\u0002\\u0098',\r\n  '\\u0099\\u0007d\\u0002\\u0002\\u0099\\u009a\\u0007n\\u0002\\u0002\\u009a\\u009b',\r\n  '\\u0007g\\u0002\\u0002\\u009b\\u0011\\u0003\\u0002\\u0002\\u0002\\u009c\\u009d',\r\n  '\\u0007q\\u0002\\u0002\\u009d\\u009e\\u0007w\\u0002\\u0002\\u009e\\u009f\\u0007',\r\n  'v\\u0002\\u0002\\u009f\\u00a0\\u0007r\\u0002\\u0002\\u00a0\\u00a1\\u0007w\\u0002',\r\n  '\\u0002\\u00a1\\u00a2\\u0007v\\u0002\\u0002\\u00a2\\u0013\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u00a3\\u00a4\\u0007n\\u0002\\u0002\\u00a4\\u00a5\\u0007k\\u0002\\u0002',\r\n  '\\u00a5\\u00a6\\u0007u\\u0002\\u0002\\u00a6\\u00a7\\u0007v\\u0002\\u0002\\u00a7',\r\n  '\\u0015\\u0003\\u0002\\u0002\\u0002\\u00a8\\u00a9\\u0007o\\u0002\\u0002\\u00a9',\r\n  '\\u00aa\\u0007c\\u0002\\u0002\\u00aa\\u00ab\\u0007r\\u0002\\u0002\\u00ab\\u0017',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u00ac\\u00ad\\u0007q\\u0002\\u0002\\u00ad\\u00ae',\r\n  '\\u0007d\\u0002\\u0002\\u00ae\\u00af\\u0007l\\u0002\\u0002\\u00af\\u00b0\\u0007',\r\n  'g\\u0002\\u0002\\u00b0\\u00b1\\u0007e\\u0002\\u0002\\u00b1\\u00b2\\u0007v\\u0002',\r\n  '\\u0002\\u00b2\\u0019\\u0003\\u0002\\u0002\\u0002\\u00b3\\u00b4\\u0007e\\u0002',\r\n  '\\u0002\\u00b4\\u00b5\\u0007q\\u0002\\u0002\\u00b5\\u00b6\\u0007p\\u0002\\u0002',\r\n  '\\u00b6\\u00b7\\u0007f\\u0002\\u0002\\u00b7\\u00b8\\u0007k\\u0002\\u0002\\u00b8',\r\n  '\\u00b9\\u0007v\\u0002\\u0002\\u00b9\\u00ba\\u0007k\\u0002\\u0002\\u00ba\\u00bb',\r\n  '\\u0007q\\u0002\\u0002\\u00bb\\u00bc\\u0007p\\u0002\\u0002\\u00bc\\u001b\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00bd\\u00be\\u0007g\\u0002\\u0002\\u00be\\u00bf\\u0007',\r\n  't\\u0002\\u0002\\u00bf\\u00c0\\u0007t\\u0002\\u0002\\u00c0\\u00c1\\u0007q\\u0002',\r\n  '\\u0002\\u00c1\\u00c2\\u0007t\\u0002\\u0002\\u00c2\\u00c3\\u0007a\\u0002\\u0002',\r\n  '\\u00c3\\u00c4\\u0007o\\u0002\\u0002\\u00c4\\u00c5\\u0007g\\u0002\\u0002\\u00c5',\r\n  '\\u00c6\\u0007u\\u0002\\u0002\\u00c6\\u00c7\\u0007u\\u0002\\u0002\\u00c7\\u00c8',\r\n  '\\u0007c\\u0002\\u0002\\u00c8\\u00c9\\u0007i\\u0002\\u0002\\u00c9\\u00ca\\u0007',\r\n  'g\\u0002\\u0002\\u00ca\\u001d\\u0003\\u0002\\u0002\\u0002\\u00cb\\u00cc\\u0007',\r\n  '}\\u0002\\u0002\\u00cc\\u001f\\u0003\\u0002\\u0002\\u0002\\u00cd\\u00ce\\u0007',\r\n  '\\u007f\\u0002\\u0002\\u00ce!\\u0003\\u0002\\u0002\\u0002\\u00cf\\u00d0\\u0007',\r\n  '?\\u0002\\u0002\\u00d0#\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00d2\\u0007*\\u0002',\r\n  '\\u0002\\u00d2%\\u0003\\u0002\\u0002\\u0002\\u00d3\\u00d4\\u0007+\\u0002\\u0002',\r\n  \"\\u00d4\\'\\u0003\\u0002\\u0002\\u0002\\u00d5\\u00d6\\u0007]\\u0002\\u0002\\u00d6\",\r\n  ')\\u0003\\u0002\\u0002\\u0002\\u00d7\\u00d8\\u0007_\\u0002\\u0002\\u00d8+\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u00d9\\u00da\\u0007.\\u0002\\u0002\\u00da-\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u00db\\u00dc\\u00070\\u0002\\u0002\\u00dc/\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u00dd\\u00de\\u0007/\\u0002\\u0002\\u00de1\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u00df\\u00e0\\u0007,\\u0002\\u0002\\u00e03\\u0003\\u0002\\u0002\\u0002\\u00e1',\r\n  '\\u00e9\\t\\u0002\\u0002\\u0002\\u00e2\\u00e9\\u0005\"\\u0011\\u0002\\u00e3\\u00e4',\r\n  '\\u0007?\\u0002\\u0002\\u00e4\\u00e9\\u0007?\\u0002\\u0002\\u00e5\\u00e9\\u0005',\r\n  '2\\u0019\\u0002\\u00e6\\u00e9\\u00050\\u0018\\u0002\\u00e7\\u00e9\\t\\u0003\\u0002',\r\n  '\\u0002\\u00e8\\u00e1\\u0003\\u0002\\u0002\\u0002\\u00e8\\u00e2\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u00e8\\u00e3\\u0003\\u0002\\u0002\\u0002\\u00e8\\u00e5\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u00e8\\u00e6\\u0003\\u0002\\u0002\\u0002\\u00e8\\u00e7\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u00e95\\u0003\\u0002\\u0002\\u0002\\u00ea\\u00eb\\u0007v\\u0002\\u0002',\r\n  '\\u00eb\\u00ec\\u0007t\\u0002\\u0002\\u00ec\\u00ed\\u0007w\\u0002\\u0002\\u00ed',\r\n  '\\u0101\\u0007g\\u0002\\u0002\\u00ee\\u00ef\\u0007$\\u0002\\u0002\\u00ef\\u00f0',\r\n  '\\u0007v\\u0002\\u0002\\u00f0\\u00f1\\u0007t\\u0002\\u0002\\u00f1\\u00f2\\u0007',\r\n  'w\\u0002\\u0002\\u00f2\\u00f3\\u0007g\\u0002\\u0002\\u00f3\\u0101\\u0007$\\u0002',\r\n  '\\u0002\\u00f4\\u00f5\\u0007h\\u0002\\u0002\\u00f5\\u00f6\\u0007c\\u0002\\u0002',\r\n  '\\u00f6\\u00f7\\u0007n\\u0002\\u0002\\u00f7\\u00f8\\u0007u\\u0002\\u0002\\u00f8',\r\n  '\\u0101\\u0007g\\u0002\\u0002\\u00f9\\u00fa\\u0007$\\u0002\\u0002\\u00fa\\u00fb',\r\n  '\\u0007h\\u0002\\u0002\\u00fb\\u00fc\\u0007c\\u0002\\u0002\\u00fc\\u00fd\\u0007',\r\n  'n\\u0002\\u0002\\u00fd\\u00fe\\u0007u\\u0002\\u0002\\u00fe\\u00ff\\u0007g\\u0002',\r\n  '\\u0002\\u00ff\\u0101\\u0007$\\u0002\\u0002\\u0100\\u00ea\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0100\\u00ee\\u0003\\u0002\\u0002\\u0002\\u0100\\u00f4\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0100\\u00f9\\u0003\\u0002\\u0002\\u0002\\u01017\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0102\\u0103\\u0007u\\u0002\\u0002\\u0103\\u0104\\u0007v\\u0002\\u0002',\r\n  '\\u0104\\u0105\\u0007t\\u0002\\u0002\\u0105\\u0106\\u0007k\\u0002\\u0002\\u0106',\r\n  '\\u0107\\u0007p\\u0002\\u0002\\u0107\\u012c\\u0007i\\u0002\\u0002\\u0108\\u0109',\r\n  '\\u0007$\\u0002\\u0002\\u0109\\u010a\\u0007u\\u0002\\u0002\\u010a\\u010b\\u0007',\r\n  'v\\u0002\\u0002\\u010b\\u010c\\u0007t\\u0002\\u0002\\u010c\\u010d\\u0007k\\u0002',\r\n  '\\u0002\\u010d\\u010e\\u0007p\\u0002\\u0002\\u010e\\u010f\\u0007i\\u0002\\u0002',\r\n  '\\u010f\\u012c\\u0007$\\u0002\\u0002\\u0110\\u0111\\u0007p\\u0002\\u0002\\u0111',\r\n  '\\u0112\\u0007w\\u0002\\u0002\\u0112\\u0113\\u0007o\\u0002\\u0002\\u0113\\u0114',\r\n  '\\u0007d\\u0002\\u0002\\u0114\\u0115\\u0007g\\u0002\\u0002\\u0115\\u012c\\u0007',\r\n  't\\u0002\\u0002\\u0116\\u0117\\u0007$\\u0002\\u0002\\u0117\\u0118\\u0007p\\u0002',\r\n  '\\u0002\\u0118\\u0119\\u0007w\\u0002\\u0002\\u0119\\u011a\\u0007o\\u0002\\u0002',\r\n  '\\u011a\\u011b\\u0007d\\u0002\\u0002\\u011b\\u011c\\u0007g\\u0002\\u0002\\u011c',\r\n  '\\u011d\\u0007t\\u0002\\u0002\\u011d\\u012c\\u0007$\\u0002\\u0002\\u011e\\u011f',\r\n  '\\u0007d\\u0002\\u0002\\u011f\\u0120\\u0007q\\u0002\\u0002\\u0120\\u0121\\u0007',\r\n  'q\\u0002\\u0002\\u0121\\u012c\\u0007n\\u0002\\u0002\\u0122\\u0123\\u0007$\\u0002',\r\n  '\\u0002\\u0123\\u0124\\u0007d\\u0002\\u0002\\u0124\\u0125\\u0007q\\u0002\\u0002',\r\n  '\\u0125\\u0126\\u0007q\\u0002\\u0002\\u0126\\u0127\\u0007n\\u0002\\u0002\\u0127',\r\n  '\\u012c\\u0007$\\u0002\\u0002\\u0128\\u0129\\u0007c\\u0002\\u0002\\u0129\\u012a',\r\n  '\\u0007p\\u0002\\u0002\\u012a\\u012c\\u0007{\\u0002\\u0002\\u012b\\u0102\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u012b\\u0108\\u0003\\u0002\\u0002\\u0002\\u012b\\u0110\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u012b\\u0116\\u0003\\u0002\\u0002\\u0002\\u012b\\u011e\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u012b\\u0122\\u0003\\u0002\\u0002\\u0002\\u012b\\u0128\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u012c9\\u0003\\u0002\\u0002\\u0002\\u012d\\u0131\\u0005',\r\n  '>\\u001f\\u0002\\u012e\\u0130\\u0005<\\u001e\\u0002\\u012f\\u012e\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0130\\u0133\\u0003\\u0002\\u0002\\u0002\\u0131\\u012f\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0131\\u0132\\u0003\\u0002\\u0002\\u0002\\u0132;\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0133\\u0131\\u0003\\u0002\\u0002\\u0002\\u0134\\u0137\\u0005>',\r\n  '\\u001f\\u0002\\u0135\\u0137\\t\\u0004\\u0002\\u0002\\u0136\\u0134\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0136\\u0135\\u0003\\u0002\\u0002\\u0002\\u0137=\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0138\\u013d\\t\\u0005\\u0002\\u0002\\u0139\\u013d\\n\\u0006\\u0002',\r\n  '\\u0002\\u013a\\u013b\\t\\u0007\\u0002\\u0002\\u013b\\u013d\\t\\b\\u0002\\u0002\\u013c',\r\n  '\\u0138\\u0003\\u0002\\u0002\\u0002\\u013c\\u0139\\u0003\\u0002\\u0002\\u0002\\u013c',\r\n  '\\u013a\\u0003\\u0002\\u0002\\u0002\\u013d?\\u0003\\u0002\\u0002\\u0002\\u013e',\r\n  '\\u0143\\u0007$\\u0002\\u0002\\u013f\\u0142\\u0005B!\\u0002\\u0140\\u0142\\u0005',\r\n  'H$\\u0002\\u0141\\u013f\\u0003\\u0002\\u0002\\u0002\\u0141\\u0140\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0142\\u0145\\u0003\\u0002\\u0002\\u0002\\u0143\\u0141\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0143\\u0144\\u0003\\u0002\\u0002\\u0002\\u0144\\u0146\\u0003\\u0002',\r\n  '\\u0002\\u0002\\u0145\\u0143\\u0003\\u0002\\u0002\\u0002\\u0146\\u0147\\u0007$',\r\n  '\\u0002\\u0002\\u0147A\\u0003\\u0002\\u0002\\u0002\\u0148\\u014b\\u0007^\\u0002',\r\n  '\\u0002\\u0149\\u014c\\t\\t\\u0002\\u0002\\u014a\\u014c\\u0005D\"\\u0002\\u014b',\r\n  '\\u0149\\u0003\\u0002\\u0002\\u0002\\u014b\\u014a\\u0003\\u0002\\u0002\\u0002\\u014c',\r\n  'C\\u0003\\u0002\\u0002\\u0002\\u014d\\u014e\\u0007w\\u0002\\u0002\\u014e\\u014f',\r\n  '\\u0005F#\\u0002\\u014f\\u0150\\u0005F#\\u0002\\u0150\\u0151\\u0005F#\\u0002\\u0151',\r\n  '\\u0152\\u0005F#\\u0002\\u0152E\\u0003\\u0002\\u0002\\u0002\\u0153\\u0154\\t\\n',\r\n  '\\u0002\\u0002\\u0154G\\u0003\\u0002\\u0002\\u0002\\u0155\\u0156\\n\\u000b\\u0002',\r\n  '\\u0002\\u0156I\\u0003\\u0002\\u0002\\u0002\\u0157\\u0160\\u00072\\u0002\\u0002',\r\n  '\\u0158\\u015c\\t\\f\\u0002\\u0002\\u0159\\u015b\\t\\u0004\\u0002\\u0002\\u015a\\u0159',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u015b\\u015e\\u0003\\u0002\\u0002\\u0002\\u015c\\u015a',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u015c\\u015d\\u0003\\u0002\\u0002\\u0002\\u015d\\u0160',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u015e\\u015c\\u0003\\u0002\\u0002\\u0002\\u015f\\u0157',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u015f\\u0158\\u0003\\u0002\\u0002\\u0002\\u0160K',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u0161\\u0162\\u00071\\u0002\\u0002\\u0162\\u0163',\r\n  '\\u0007,\\u0002\\u0002\\u0163\\u0167\\u0003\\u0002\\u0002\\u0002\\u0164\\u0166',\r\n  '\\u000b\\u0002\\u0002\\u0002\\u0165\\u0164\\u0003\\u0002\\u0002\\u0002\\u0166\\u0169',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u0167\\u0168\\u0003\\u0002\\u0002\\u0002\\u0167\\u0165',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u0168\\u016a\\u0003\\u0002\\u0002\\u0002\\u0169\\u0167',\r\n  '\\u0003\\u0002\\u0002\\u0002\\u016a\\u016b\\u0007,\\u0002\\u0002\\u016b\\u016c',\r\n  '\\u00071\\u0002\\u0002\\u016c\\u016d\\u0003\\u0002\\u0002\\u0002\\u016d\\u016e',\r\n  '\\b&\\u0002\\u0002\\u016eM\\u0003\\u0002\\u0002\\u0002\\u016f\\u0170\\u00071\\u0002',\r\n  '\\u0002\\u0170\\u0171\\u00071\\u0002\\u0002\\u0171\\u0175\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0172\\u0174\\n\\r\\u0002\\u0002\\u0173\\u0172\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0174\\u0177\\u0003\\u0002\\u0002\\u0002\\u0175\\u0173\\u0003\\u0002\\u0002\\u0002',\r\n  '\\u0175\\u0176\\u0003\\u0002\\u0002\\u0002\\u0176\\u0178\\u0003\\u0002\\u0002\\u0002',\r\n  \"\\u0177\\u0175\\u0003\\u0002\\u0002\\u0002\\u0178\\u0179\\b\\'\\u0002\\u0002\\u0179\",\r\n  'O\\u0003\\u0002\\u0002\\u0002\\u017a\\u017e\\u0007%\\u0002\\u0002\\u017b\\u017d',\r\n  '\\n\\r\\u0002\\u0002\\u017c\\u017b\\u0003\\u0002\\u0002\\u0002\\u017d\\u0180\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u017e\\u017c\\u0003\\u0002\\u0002\\u0002\\u017e\\u017f\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u017f\\u0181\\u0003\\u0002\\u0002\\u0002\\u0180\\u017e\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0181\\u0182\\b(\\u0002\\u0002\\u0182Q\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0183\\u0185\\t\\u000e\\u0002\\u0002\\u0184\\u0183\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0185\\u0186\\u0003\\u0002\\u0002\\u0002\\u0186\\u0184\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0186\\u0187\\u0003\\u0002\\u0002\\u0002\\u0187\\u0188\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0188\\u0189\\b)\\u0002\\u0002\\u0189S\\u0003\\u0002\\u0002\\u0002\\u018a',\r\n  '\\u018b\\u0007>\\u0002\\u0002\\u018b\\u018c\\u0007>\\u0002\\u0002\\u018c\\u018d',\r\n  '\\u0007G\\u0002\\u0002\\u018d\\u018e\\u0007Q\\u0002\\u0002\\u018e\\u018f\\u0007',\r\n  'H\\u0002\\u0002\\u018f\\u0190\\u0003\\u0002\\u0002\\u0002\\u0190\\u0191\\b*\\u0003',\r\n  '\\u0002\\u0191U\\u0003\\u0002\\u0002\\u0002\\u0192\\u0193\\t\\u000f\\u0002\\u0002',\r\n  '\\u0193W\\u0003\\u0002\\u0002\\u0002\\u0194\\u0195\\u0005R)\\u0002\\u0195Y\\u0003',\r\n  '\\u0002\\u0002\\u0002\\u0196\\u0197\\u0005F#\\u0002\\u0197[\\u0003\\u0002\\u0002',\r\n  '\\u0002\\u0198\\u0199\\u0005H$\\u0002\\u0199]\\u0003\\u0002\\u0002\\u0002\\u019a',\r\n  '\\u019b\\u0005J%\\u0002\\u019b_\\u0003\\u0002\\u0002\\u0002\\u019c\\u019d\\t\\u0010',\r\n  '\\u0002\\u0002\\u019da\\u0003\\u0002\\u0002\\u0002\\u019e\\u019f\\u0007G\\u0002',\r\n  '\\u0002\\u019f\\u01a0\\u0007Q\\u0002\\u0002\\u01a0\\u01a1\\u0007H\\u0002\\u0002',\r\n  '\\u01a1\\u01a2\\u0003\\u0002\\u0002\\u0002\\u01a2\\u01a3\\b1\\u0004\\u0002\\u01a3',\r\n  'c\\u0003\\u0002\\u0002\\u0002\\u0013\\u0002\\u0003\\u00e8\\u0100\\u012b\\u0131',\r\n  '\\u0136\\u013c\\u0141\\u0143\\u014b\\u015c\\u015f\\u0167\\u0175\\u017e\\u0186\\u0005',\r\n  '\\u0002\\u0003\\u0002\\u0007\\u0003\\u0002\\u0006\\u0002\\u0002'].join('');\r\n\r\nconst atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\r\n\r\nconst decisionsToDFA = atn.decisionToState.map((ds, index) => new antlr4.dfa.DFA(ds, index));\r\n\r\nexport default class terraformLexer extends antlr4.Lexer {\r\n  static grammarFileName = 'terraformLexer.g4';\r\n\r\n  static channelNames = ['DEFAULT_TOKEN_CHANNEL', 'HIDDEN'];\r\n\r\n  static modeNames = ['DEFAULT_MODE', 'SCRIPT'];\r\n\r\n  static literalNames = [null, \"'module'\", \"'data'\", \"'source'\", \"'provider'\",\r\n    \"'terraform'\", \"'resource'\", \"'variable'\", \"'output'\",\r\n    \"'list'\", \"'map'\", \"'object'\", \"'condition'\", \"'error_message'\",\r\n    \"'{'\", \"'}'\", \"'='\", \"'('\", \"')'\", \"'['\", \"']'\",\r\n    \"','\", \"'.'\", \"'-'\", \"'*'\", null, null, null, null,\r\n    null, null, null, null, null, null, \"'<<EOF'\",\r\n    null, null, null, null, \"'EOF'\"];\r\n\r\n  static symbolicNames = [null, 'MODULE', 'DATA', 'SOURCE', 'PROVIDER',\r\n    'TERRAFORM', 'RESOURCE', 'VARIABLE', 'OUTPUT',\r\n    'LIST', 'MAP', 'OBJECT', 'CONDITION', 'ERROR',\r\n    'AO', 'AF', 'EQUAL', 'PO', 'PF', 'CO', 'CF', 'VIRG',\r\n    'POINT', 'TIRET', 'MULT', 'BOOLEANOP', 'BOOLEAN',\r\n    'TYPE', 'IDENTIFIER', 'STRING', 'NUMBER', 'COMMENT',\r\n    'LINE_COMMENT', 'HAS_COMMENT', 'WS', 'OPEN', 'IDENTIFIERS',\r\n    'WSS', 'NUMBERS', 'AUTRE', 'CLOSE'];\r\n\r\n  static ruleNames = ['MODULE', 'DATA', 'SOURCE', 'PROVIDER', 'TERRAFORM',\r\n    'RESOURCE', 'VARIABLE', 'OUTPUT', 'LIST', 'MAP', 'OBJECT',\r\n    'CONDITION', 'ERROR', 'AO', 'AF', 'EQUAL', 'PO', 'PF',\r\n    'CO', 'CF', 'VIRG', 'POINT', 'TIRET', 'MULT', 'BOOLEANOP',\r\n    'BOOLEAN', 'TYPE', 'IDENTIFIER', 'LetterOrDigit',\r\n    'Letter', 'STRING', 'ESC', 'UNICODE', 'HEX', 'SAFECODEPOINT',\r\n    'NUMBER', 'COMMENT', 'LINE_COMMENT', 'HAS_COMMENT',\r\n    'WS', 'OPEN', 'IDENTIFIERS', 'WSS', 'HEXS', 'SAFECODEPOINTS',\r\n    'NUMBERS', 'AUTRE', 'CLOSE'];\r\n\r\n  constructor(input) {\r\n    super(input);\r\n    this._interp = new antlr4.atn.LexerATNSimulator(this, atn, decisionsToDFA, new antlr4.PredictionContextCache());\r\n  }\r\n\r\n  get atn() {\r\n    return atn;\r\n  }\r\n}\r\n\r\nterraformLexer.EOF = antlr4.Token.EOF;\r\nterraformLexer.MODULE = 1;\r\nterraformLexer.DATA = 2;\r\nterraformLexer.SOURCE = 3;\r\nterraformLexer.PROVIDER = 4;\r\nterraformLexer.TERRAFORM = 5;\r\nterraformLexer.RESOURCE = 6;\r\nterraformLexer.VARIABLE = 7;\r\nterraformLexer.OUTPUT = 8;\r\nterraformLexer.LIST = 9;\r\nterraformLexer.MAP = 10;\r\nterraformLexer.OBJECT = 11;\r\nterraformLexer.CONDITION = 12;\r\nterraformLexer.ERROR = 13;\r\nterraformLexer.AO = 14;\r\nterraformLexer.AF = 15;\r\nterraformLexer.EQUAL = 16;\r\nterraformLexer.PO = 17;\r\nterraformLexer.PF = 18;\r\nterraformLexer.CO = 19;\r\nterraformLexer.CF = 20;\r\nterraformLexer.VIRG = 21;\r\nterraformLexer.POINT = 22;\r\nterraformLexer.TIRET = 23;\r\nterraformLexer.MULT = 24;\r\nterraformLexer.BOOLEANOP = 25;\r\nterraformLexer.BOOLEAN = 26;\r\nterraformLexer.TYPE = 27;\r\nterraformLexer.IDENTIFIER = 28;\r\nterraformLexer.STRING = 29;\r\nterraformLexer.NUMBER = 30;\r\nterraformLexer.COMMENT = 31;\r\nterraformLexer.LINE_COMMENT = 32;\r\nterraformLexer.HAS_COMMENT = 33;\r\nterraformLexer.WS = 34;\r\nterraformLexer.OPEN = 35;\r\nterraformLexer.IDENTIFIERS = 36;\r\nterraformLexer.WSS = 37;\r\nterraformLexer.NUMBERS = 38;\r\nterraformLexer.AUTRE = 39;\r\nterraformLexer.CLOSE = 40;\r\n\r\nterraformLexer.SCRIPT = 1;\r\n","import { parse } from './parse_file.js';\r\nimport { get_objects } from './get_links_between_objects.js';\r\n\r\nexport function parse_directories(filesPath) {\r\n  let result = parse_directory(filesPath);\r\n  for (let i = 0; i < result.modules.length; i++) {\r\n    const source = result.modules[i].moduleSource.value.split('=');\r\n    let path = source[1];\r\n    path = path.replaceAll('\"', '');\r\n    const filesPathExplode = filesPath.split('/');\r\n    let modulePath = '';\r\n    for (let i = 0; i < filesPathExplode.length - 1; i++) {\r\n      modulePath += `${filesPathExplode[i]}/`;\r\n    }\r\n    if (path.includes('..')) { result = parse_directory(path.replace('..', modulePath), result, result.modules[i].name); } else if (path.includes('.')) { result = parse_directory(path.replace('.', modulePath), result, result.modules[i].name); } else { result = parse_directory(modulePath + path, result, result.modules[i].name); }\r\n  }\r\n  result = get_all_objects(result);\r\n\r\n  return result;\r\n}\r\n\r\nfunction get_all_objects(result) {\r\n  result = get_objects(result.resources, result);\r\n  result = get_objects(result.modules, result, true);\r\n  result = get_objects(result.outputs, result);\r\n\r\n  return result;\r\n}\r\n\r\nexport function get_module_attribute(result, module) {\r\n  result.forEach((v) => {\r\n    if (v.moduleName) {\r\n      if (module.name == v.moduleName) {\r\n        module.attributes.push(v);\r\n      }\r\n    }\r\n  });\r\n}\r\n\r\nfunction parse_directory(filePath, result, moduleName) {\r\n  let value;\r\n  if (result) { value = result; } else {\r\n    value = {\r\n      provider: [],\r\n      resources: [],\r\n      outputs: [],\r\n      variables: [],\r\n      modules: [],\r\n      datas: [],\r\n      terraform: [],\r\n      errors: [],\r\n    };\r\n  }\r\n\r\n  // var stats = fs.statSync(filePath);\r\n  // var files;\r\n  const res = [];\r\n\r\n  // if(stats.isDirectory()) {\r\n  //     files = fs.readdirSync(filePath);\r\n  //     files.forEach(e => {\r\n  //         res.push(parse(filePath + '/' + e, 'UTF-8'))\r\n  //     })\r\n  // } else {\r\n  //     res.push(parse(filePath, 'UTF-8'))\r\n  // }\r\n  res.push(parse(filePath, 'UTF-8'));\r\n\r\n  res.forEach((r) => {\r\n    r.files.forEach((st) => {\r\n      st.provider_directive.forEach((v) => {\r\n        v.fileName = r.fileName;\r\n        if (moduleName) v.moduleName = moduleName;\r\n        value.provider.push(v);\r\n      });\r\n      st.resource_directive.forEach((v) => {\r\n        v.fileName = r.fileName;\r\n        if (moduleName) v.moduleName = moduleName;\r\n        value.resources.push(v);\r\n      });\r\n      st.output_directive.forEach((v) => {\r\n        v.fileName = r.fileName;\r\n        if (moduleName) v.moduleName = moduleName;\r\n        value.outputs.push(v);\r\n      });\r\n      st.variable_directive.forEach((v) => {\r\n        v.fileName = r.fileName;\r\n        if (moduleName) v.moduleName = moduleName;\r\n        value.variables.push(v);\r\n      });\r\n      st.data_directive.forEach((v) => {\r\n        v.fileName = r.fileName;\r\n        if (moduleName) v.moduleName = moduleName;\r\n        value.datas.push(v);\r\n      });\r\n      st.module_directive.forEach((v) => {\r\n        v.fileName = r.fileName;\r\n        if (moduleName) v.moduleName = moduleName;\r\n        value.modules.push(v);\r\n      });\r\n      st.terraform_directive.forEach((v) => {\r\n        v.fileName = r.fileName;\r\n        if (moduleName) v.moduleName = moduleName;\r\n        value.terraform.push(v);\r\n      });\r\n    });\r\n    r.errors.forEach((e) => {\r\n      value.errors.push(e);\r\n    });\r\n  });\r\n  return value;\r\n}\r\n","import { TerraformProg } from '../../model/prog.js';\r\nimport parse_file from './prog_init.js';\r\n\r\nexport function parse(src) {\r\n  // let filePath = src.split(\"/\")\r\n  // let fileName = filePath[filePath.length - 1]\r\n  const prog = new TerraformProg(src);\r\n  parse_file(src, '', '', null, prog);\r\n  return prog;\r\n}\r\n","import { TerraformFile } from '../../model/file.js';\r\nimport { parse as parse_terraform } from '../grammar_parsing/index.js';\r\nimport hclListener from '../../listener/terraformListener.js';\r\n\r\nexport default function parse_file(file, namespace_uri, namespace_prefix, parent_file, prog) {\r\n  let src_data; let res; let\r\n    listener;\r\n  if (typeof (file) === 'string') {\r\n    // if (file.slice(0, 4) == 'http') {\r\n    //     try {\r\n    //         src_data = request('GET', file).getBody().toString()\r\n    //     } catch (error) {\r\n    //         prog.errors.push(new Error(\"File error\", 0, `Can not read file ${file}`))\r\n    //         return null\r\n    //     }\r\n    // } else {\r\n    //     try {\r\n    //         src_data = fs.readFileSync(file, 'utf8')\r\n    //     } catch (error) {\r\n    //         prog.errors.push(new Error(\"File error\", 0, `Can not read file ${file}`))\r\n    //         return null\r\n    //     }\r\n\r\n    // }\r\n    src_data = file;\r\n    const current_file = new TerraformFile();\r\n    // current_file.origin_file = file\r\n    current_file.ns_uri = (namespace_uri) || '';\r\n    current_file.ns_prefix = (namespace_prefix) || '';\r\n\r\n    prog.current_parent_file = parent_file;\r\n    prog.current_file = current_file;\r\n    listener = new hclListener(prog);\r\n    res = parse_terraform({\r\n      src_data, listener, prog, file,\r\n    });\r\n    prog.files.push(current_file);\r\n    prog.alreadyImported.push(file);\r\n  }\r\n  return res;\r\n}\r\n","import antlr4 from 'antlr4';\r\nimport hclParser from './terraformParser.js';\r\nimport hclLexer from './terraformLexer.js';\r\n\r\nexport function parse(src) {\r\n  const input = src.src_data\r\n  const chars = new antlr4.InputStream(input);\r\n  const lexer = new hclLexer(chars);\r\n  const tokens = new antlr4.CommonTokenStream(lexer);\r\n  const parser = new hclParser(tokens);\r\n  parser.buildParseTrees = true;\r\n  const tree = parser.file();\r\n  antlr4.tree.ParseTreeWalker.DEFAULT.walk(src.listener, tree);\r\n  return src.listener;\r\n}\r\n","import { parse_directories, get_module_attribute } from '../../parser/compiler/parse_directory.js';\r\n\r\nonmessage = function(event) {\r\n\tconst datas = getDatas(event.data)\r\n\tpostMessage(datas);\r\n}\r\n\r\nexport default function getDatas(filesPath) {\r\n  const result = parse_directories(filesPath);\r\n\r\n  if (result.provider.length > 0) {\r\n    // const schema = verify_schema(result.provider[0].name);\r\n    // if (!schema.valid) console.log(schema.errors);\r\n    // else {\r\n    //   if (schema.metadatas.provider.required && result.provider.length == 0) {\r\n    //     result.errors.push('Provider required');\r\n    //   }\r\n    //   if (result.provider[0].constructor.name != schema.metadatas.provider.providerType) {\r\n    //     result.errors.push(`TERRAFORM ERROR in file : ${result.provider.fileName} wrong type for provider`);\r\n    //   }\r\n    //   result.provider[0].orderResources = (schema.metadatas.provider.orderResources) ? schema.metadatas.provider.orderResources : [];\r\n    //   analyse_resources(result.resources, schema.metadatas.provider.resources).forEach((e) => {\r\n    //     result.errors.push(e);\r\n    //   });\r\n    // }\r\n\r\n    result.modules.forEach((module) => {\r\n      get_module_attribute(result.variables, module);\r\n      get_module_attribute(result.provider, module);\r\n      get_module_attribute(result.resources, module);\r\n      get_module_attribute(result.outputs, module);\r\n      get_module_attribute(result.datas, module);\r\n      get_module_attribute(result.terraform, module);\r\n    });\r\n\r\n    // if (schema.valid) {\r\n    //   analyse_modules(result.modules, schema.metadatas.provider.modules).forEach((e) => {\r\n    //     result.errors.push(e);\r\n    //   });\r\n    // }\r\n\r\n    if (result.errors.length != 0) {\r\n      console.log('\\n#################### ERRORS ####################');\r\n      result.errors.forEach((e) => console.log(e));\r\n    }\r\n  } else {\r\n    result.errors.push('Provider required');\r\n  }\r\n\r\n  return result;\r\n}\r\n"],"names":["Token","Lexer","Interval","module","exports","constructor","tokenSource","super","this","tokens","index","fetchedEOF","mark","release","marker","reset","seek","lazyInit","adjustSeekIndex","get","consume","skipEofCheck","length","LA","EOF","sync","i","n","fetch","t","nextToken","tokenIndex","push","type","getTokens","start","stop","types","undefined","subset","contains","LT","LB","k","setup","setTokenSource","nextTokenOnChannel","channel","token","previousTokenOnChannel","getHiddenTokensToRight","nextOnChannel","DEFAULT_TOKEN_CHANNEL","from_","to","filterForChannel","getHiddenTokensToLeft","prevOnChannel","left","right","hidden","getSourceName","getText","interval","fill","s","text","InputStream","fs","CharStreams","fromString","str","fromBlob","blob","encoding","onLoad","onError","reader","window","FileReader","onload","e","is","target","result","onerror","readAsText","fromBuffer","buffer","toString","fromPath","path","callback","readFile","err","data","fromPathSync","readFileSync","CommonToken","CommonTokenFactory","copyText","create","source","line","column","createThin","DEFAULT","BufferedTokenStream","lexer","DEFAULT_CHANNEL","getNumberOfOnChannelTokens","fileName","decodeToUnicodeCodePoints","name","strdata","_index","codePoint","codePointAt","Array","codeUnit","charCodeAt","_size","offset","pos","Math","min","String","fromCodePoint","slice","size","clone","item","IntervalSet","intervals","readOnly","first","v","INVALID_TYPE","addOne","addInterval","addRange","l","h","toAdd","existing","splice","max","reduce","addSet","other","forEach","current","next","complement","toRemove","removeRange","removeOne","x","value","replace","literalNames","symbolicNames","elemsAreChar","toTokenString","toCharString","toIndexString","names","fromCharCode","join","j","elementName","EPSILON","map","acc","val","Set","BitSet","ATNConfig","RuleStopState","RuleTransition","NotSetTransition","WildcardTransition","AbstractPredicateTransition","predictionContextFromRuleContext","PredictionContext","SingletonPredictionContext","LL1Analyzer","atn","getDecisionLookahead","count","transitions","look","alt","lookBusy","seeThruPreds","_LOOK","transition","EMPTY","HIT_PRED","LOOK","stopState","ctx","r","lookContext","calledRuleStack","addEOF","c","state","context","add","isEmpty","removed","ruleIndex","remove","returnState","states","getReturnState","getParent","newContext","followState","stateNumber","isEpsilon","MIN_USER_TOKEN_TYPE","maxTokenType","set","label","Recognizer","RecognitionException","LexerNoViableAltException","input","_input","_factory","_tokenFactorySourcePair","_interp","_token","_tokenStartCharIndex","_tokenStartLine","_tokenStartColumn","_hitEOF","_channel","_type","_modeStack","_mode","DEFAULT_MODE","_text","tokenStartMarker","emitEOF","continueOuter","ttype","SKIP","match","console","log","stack","notifyListeners","recover","MORE","emit","skip","more","mode","m","pushMode","debug","popMode","pop","emitToken","getCharIndex","cpos","lpos","eof","getAllTokens","msg","getErrorDisplay","getErrorListenerDispatch","syntaxError","d","getErrorDisplayForChar","getCharErrorDisplay","re","inputStream","sourceName","HIDDEN","HIDDEN_CHANNEL","MIN_CHAR_VALUE","MAX_CHAR_VALUE","ParseTreeListener","TerminalNode","ErrorNode","DefaultErrorStrategy","ATNDeserializer","ATNDeserializationOptions","TraceListener","parser","enterEveryRule","ruleNames","visitTerminal","node","symbol","_ctx","exitEveryRule","Parser","_errHandler","_precedenceStack","buildParseTrees","_tracer","_parseListeners","_syntaxErrors","setInputStream","setTrace","getCurrentToken","reportMatch","recoverInline","addErrorNode","matchWildcard","_buildParseTrees","getParseListeners","addParseListener","listener","removeParseListener","idx","indexOf","removeParseListeners","triggerEnterRuleEvent","enterRule","triggerExitRuleEvent","reverse","exitRule","getTokenFactory","setTokenFactory","factory","getATNWithBypassAlts","serializedAtn","getSerializedATN","bypassAltsAtnCache","deserializationOptions","generateRuleBypassTransitions","deserialize","compileParseTreePattern","pattern","patternRuleIndex","getTokenStream","ParseTreePatternMatcher","compile","getInputStream","setTokenStream","notifyErrorListeners","offendingToken","o","hasListener","inErrorRecoveryMode","addTokenNode","invokingState","isErrorNode","visitErrorNode","addContextToParseTree","parentCtx","addChild","localctx","enterOuterAlt","altNum","setAltNumber","removeLastChild","getPrecedence","enterRecursionRule","precedence","pushNewRecursionContext","previous","unrollRecursionContexts","retCtx","parseListeners","getInvokingContext","precpred","inContext","isExpectedToken","following","nextTokens","rt","getExpectedTokens","getExpectedTokensWithinCurrentRule","getRuleIndex","ruleName","getRuleIndexMap","getRuleInvocationStack","p","getDFAStrings","decisionToDFA","dumpDFA","seenOne","dfa","printer","println","decision","print","trace","RuleContext","Tree","INVALID_INTERVAL","TerminalNodeImpl","ErrorNodeImpl","ParserRuleContext","parent","invokingStateNumber","children","exception","copyFrom","child","badToken","getChild","getToken","getTypedRuleContext","ctxType","getTypedRuleContexts","contexts","getChildCount","getSourceInterval","Hash","Map","equalArrays","cachedHashCode","hasEmptyPath","EMPTY_RETURN_STATE","hashCode","updateHashCode","hash","update","globalNodeCount","id","finish","equals","up","static","EmptyPredictionContext","ArrayPredictionContext","parents","returnStates","merge","a","b","rootIsWildcard","mergeCache","rootMerge","payloads","mergeRoot","spc","singleParent","apc","a_","mergeSingletons","mergedReturnStates","mergedParents","a_parent","b_parent","payload","ax_ax","M","uniqueParents","containsKey","put","q","combineCommonParents","mergeArrays","PredictionContextCache","cache","outerContext","getCachedPredictionContext","contextCache","visited","changed","updated","ConsoleErrorListener","ProxyErrorListener","_listeners","INSTANCE","_stateNumber","checkVersion","toolVersion","addErrorListener","removeErrorListeners","getLiteralNames","Object","getPrototypeOf","getSymbolicNames","getTokenNames","tokenNames","getTokenTypeMap","tokenTypeMapCache","ruleIndexMapCache","getTokenType","tokenName","getErrorHeader","getOffendingToken","getTokenErrorDisplay","sempred","actionIndex","RuleNode","Trees","depth","getRuleContext","getPayload","getAltNumber","altNumber","accept","visitor","visitChildren","toStringTree","recog","ri","getTokenSource","EMPTY_SOURCE","txt","valueToString","arrayToString","isArray","standardEqualsFunction","standardHashCodeFunction","prototype","seed","round","random","pow","key","h1b","k1","remainder","bytes","h1","c1","c2","or","bits","keys","values","minValue","apply","hashFunction","equalsFunction","hashKey","entries","entry","oldValue","concat","getKeys","getValues","arguments","AltDict","DoubleDict","defaultMapCtor","cacheMap","hashStuff","escapeWhitespace","escapeSpaces","titleCase","charAt","toUpperCase","substr","ATN","grammarType","decisionToState","ruleToStartState","ruleToStopState","modeNameToStartState","ruleToTokenType","lexerActions","modeToStartState","nextTokensInContext","nextTokensNoContext","nextTokenWithinRule","addState","removeState","defineDecisionState","getDecisionState","expected","INVALID_ALT_NUMBER","DecisionState","SemanticContext","checkParams","params","isCfg","semanticContext","reachesIntoOuterContext","props","precedenceFilterSuppressed","config","checkContext","NONE","hashCodeForConfigSet","equalsForConfigSet","LexerATNConfig","lexerActionExecutor","passedThroughNonGreedyDecision","checkNonGreedyDecision","nonGreedy","Utils","hashATNConfig","equalATNConfigs","ATNConfigSet","fullCtx","configLookup","configs","uniqueAlt","conflictingAlts","hasSemanticContext","dipsIntoOuterContext","merged","getStates","getPredicates","preds","optimizeConfigs","interpreter","getCachedContext","addAll","coll","containsFast","clear","setReadonly","items","OrderedATNConfigSet","verifyATN","defaultOptions","ATNType","ATNState","BasicState","BlockStartState","BlockEndState","LoopEndState","RuleStartState","TokensStartState","PlusLoopbackState","StarLoopbackState","StarLoopEntryState","PlusBlockStartState","StarBlockStartState","BasicBlockStartState","Transition","AtomTransition","SetTransition","RangeTransition","ActionTransition","EpsilonTransition","PredicateTransition","PrecedencePredicateTransition","LexerActionType","LexerSkipAction","LexerChannelAction","LexerCustomAction","LexerMoreAction","LexerTypeAction","LexerPushModeAction","LexerPopModeAction","LexerModeAction","ADDED_UNICODE_SMP","SUPPORTED_UUIDS","initArray","tmp","byteToHex","bth","createByteToHex","options","stateFactories","actionFactories","isFeatureSupported","feature","actualUuid","idx1","checkUUID","readATN","readStates","readRules","readModes","sets","readSets","readInt","bind","uuid","readInt32","readEdges","readDecisions","readLexerActions","markPrecedenceDecisions","PARSER","temp","split","version","readUUID","pair","loopBackStateNumbers","endStateNumbers","nstates","stype","stateFactory","LOOP_END","loopBackStateNumber","endStateNumber","loopBackState","endState","numNonGreedyStates","numPrecedenceStates","isPrecedenceRule","nrules","LEXER","tokenType","nmodes","readUnicode","iset","i1","i2","trans","nedges","src","trg","arg1","arg2","arg3","edgeFactory","addTransition","outermostPrecedenceReturn","startState","ndecisions","decState","actionType","data1","data2","lexerActionFactory","generateRuleBypassTransition","bypassStart","bypassStop","excludeTransition","stateIsEndStateFor","matchState","maybeLoopEndState","epsilonOnlyTransitions","isPrecedenceDecision","checkCondition","condition","message","readLong","bb","int","RANGE","RULE","PREDICATE","PRECEDENCE","ATOM","ACTION","SET","NOT_SET","WILDCARD","sf","BASIC","RULE_START","BLOCK_START","PLUS_BLOCK_START","STAR_BLOCK_START","TOKEN_START","RULE_STOP","BLOCK_END","STAR_LOOP_BACK","STAR_LOOP_ENTRY","PLUS_LOOP_BACK","af","CHANNEL","CUSTOM","MODE","POP_MODE","PUSH_MODE","TYPE","DFAState","ATNSimulator","sharedContextCache","ERROR","INVALID_STATE_NUMBER","stateType","isNonGreedyExitState","serializationNames","LexerActionExecutor","resetSimState","sim","dfaState","SimState","LexerATNSimulator","startIndex","prevAccept","copyState","simulator","match_calls","s0","matchATN","execATN","old_mode","s0_closure","computeStartState","suppressEdge","addDFAState","predict","toLexerString","ds0","isAcceptState","captureSimState","getExistingTargetState","computeTargetState","failOrAccept","edges","MIN_DFA_EDGE","MAX_DFA_EDGE","reach","getReachableConfigSet","addDFAEdge","prediction","closure","skipAlt","cfg","currentAltReachedAcceptState","getTokenName","getReachableTarget","fixOffsetBeforeMatch","treatEofAsEpsilon","charPos","execute","matches","initialContext","speculative","getEpsilonTarget","serializationType","predIndex","evaluatePredicate","append","savedcolumn","savedLine","settings","tk","cfgs","proposed","firstConfigWithRuleStopState","newState","getDFA","tt","dfa_debug","LexerAction","action","isPositionDependent","LexerIndexedCustomAction","updatedLexerActions","requiresSeek","stopIndex","lexerAction","numActions","PredPrediction","PredictionMode","NoViableAltException","predictionMode","LL","_startIndex","_outerContext","_dfa","debug_closure","debug_add","debug_list_atn_decisions","retry_debug","adaptivePredict","getLookaheadName","precedenceDfa","getPrecedenceStartState","atnStartState","applyPrecedenceFilter","setPrecedenceStartState","previousD","D","noViableAlt","getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule","requiresFullContext","SLL","predicates","conflictIndex","evalSemanticContext","reportAttemptingFullContext","execATNWithFullContext","alts","reportAmbiguity","computeReachSet","predictedAlt","getUniqueAlt","altSubSets","getConflictingAltSubsets","allSubsetsConflict","getConflictingAlts","hasSLLConflictTerminatingPrediction","predicateDFAState","decisionState","nalts","altsToCollectPredsFrom","getConflictingAltsOrUniqueAlt","altToPred","getPredsForAmbigAlts","getPredicatePredictions","foundExactAmbig","resolvesToJustOneViableAlt","LL_EXACT_AMBIG_DETECTION","allSubsetsEqual","getSingleViableAlt","reportContextSensitivity","intermediate","skippedStopStates","closureBusy","removeAllConfigsNotInRuleStopState","hasConfigInRuleStopState","lookToEndOfRule","allConfigsInRuleStopStates","endOfRuleState","statesFromAlt1","configSet","updatedContext","evalPrecedence","ambigAlts","orContext","nPredAlts","pred","pairs","containsPredicate","splitAccordingToSemanticValidity","semValidConfigs","semInvalidConfigs","getAltThatFinishedDecisionEntryRule","succeeded","failed","evaluate","predPredictions","complete","predictions","predicateEvaluationResult","collectPredicates","closureCheckingStopState","getRuleName","closure_","parms","canDropLoopEntryEdgeInLeftRecursiveRule","continueCollecting","newDepth","numCtxs","blockEndStateNum","blockEndState","returnStateNumber","returnStateTarget","ruleTransition","precedenceTransition","predTransition","actionTransition","pt","currentPosition","predSucceeds","getPredicate","newSemCtx","andContext","isCtxDependent","altsets","getAlts","dumpDeadEndConfigs","nvae","decs","getDeadEndConfigs","error","exact","dup","hasConflictingAltSet","hasStateAssociatedWithOneAlt","hasNonConflictingAltSet","all","configToAlts","getStateToAltMap","minAlt","AND","opnds","OR","Predicate","PrecedencePredicate","compareTo","operands","precedencePredicates","filterPrecedencePredicates","reduced","from","differs","evaluated","sort","serializationTypes","minVocabSymbol","maxVocabSymbol","label_","makeLabel","ruleStart","ParserATNSimulator","DFASerializer","LexerDFASerializer","_states","precedenceState","setPrecedenceDfa","sortedStates","buf","getStateString","getEdgeLabel","baseStateStr","getAltSet","DFA","ErrorListener","exactOnly","recognizer","getDecisionDescription","reportedAlts","offendingSymbol","delegates","InputMismatchException","FailedPredicateException","ParseCancellationException","reportError","errorRecoveryMode","lastErrorIndex","lastErrorStates","nextTokensContext","nextTokenState","endErrorCondition","beginErrorCondition","reportNoViableAlternative","reportInputMismatch","reportFailedPredicate","getMessage","followSet","getErrorRecoverySet","consumeUntil","la","nextTokensState","singleTokenDeletion","reportUnwantedToken","expecting","whatFollowsLoopIterationOrRule","startToken","escapeWSAndQuote","reportMissingToken","matchedSymbol","singleTokenInsertion","getMissingSymbol","currentSymbolType","nextTokenType","currentSymbol","expectedTokenType","tokenText","lookback","recoverSet","follow","BailErrorStrategy","Error","captureStackTrace","offendingState","formatMessage","predicate","deadEndConfigs","predicateIndex","tree","CommonTokenStream","pc","defineProperty","object","$defineProperty","position","TypeError","string","Number","second","stringFromCharCode","floor","_","MAX_SIZE","codeUnits","highSurrogate","lowSurrogate","isFinite","RangeError","ParseTree","getSymbol","ParseTreeWalker","walk","ParseTreeVisitor","visit","getNodeText","res","getChildren","list","getAncestors","ancestors","findAllTokenNodes","findAllNodes","findAllRuleNodes","findTokens","nodes","_findAllNodes","descendants","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","__webpack_modules__","TerraformProg","file","errors","warnings","imports","alreadyImported","files","terraform_type","node_type","st","TerraformFile","terraform_directive","variable_directive","output_directive","resource_directive","data_directive","provider_directive","module_directive","modules_source","field","complex_field","complex_field_object","is_complex_field","TerraformNode","TerraformField","TerraformComplexField","objects","TerraformObject","TerraformName","TerraformType","ModuleDirective","moduleSource","variablesName","variables","variablesObject","datasName","datas","datasObject","resourcesName","resources","resourcesObject","modulesName","modules","modulesObject","attributes","get_names","isModule","variable","resource","variableName","variableValue","var","includes","substring","script","get_variable_name","array","explode","get_resource_name","get_data_name","get_module_name","find","get_objects","rd","get_items","compare_array_differences","arrayNames","arrayObjects","rv","rn","ro","ModuleSource","TerraformDirective","DataDirective","ResourceDirective","representation","OutputDirective","VariableDirective","ProviderDirective","terraformParserListener","prog","current_file","parsed_rule","isValid","newModuleDirective","newModuleSource","replaceAll","antlr4","serializedATN","decisionsToDFA","ds","terraformParser","complexExpression_sempred","FileContext","RULE_file","_la","directive","MODULE","DATA","PROVIDER","TERRAFORM","RESOURCE","VARIABLE","OUTPUT","DirectiveContext","RULE_directive","providerDirective","terraformDirective","resourceDirective","variableDirective","outputDirective","moduleDirective","dataDirective","DataDirectiveContext","RULE_dataDirective","providerType","AO","IDENTIFIER","AF","ModuleDirectiveContext","RULE_moduleDirective","SOURCE","ModuleSourceContext","RULE_moduleSource","EQUAL","STRING","ProviderDirectiveContext","RULE_providerDirective","TerraformDirectiveContext","RULE_terraformDirective","ResourceDirectiveContext","RULE_resourceDirective","VariableDirectiveContext","RULE_variableDirective","OutputDirectiveContext","RULE_outputDirective","NameContext","RULE_name","ProviderTypeContext","RULE_providerType","TypeContext","RULE_type","LIST","PO","PF","MAP","OBJECT","ObjectContext","RULE_object","_alt","complexField","FieldContext","RULE_field","expression","ComplexFieldContext","RULE_complexField","ValidationContext","RULE_validation","CONDITION","BOOLEANOP","BOOLEAN","NUMBER","ConditionContext","RULE_condition","functionCall","ExpressionContext","RULE_expression","complexExpression","FunctionCallContext","RULE_functionCall","VIRG","_p","_parentctx","_parentState","ComplexExpressionContext","RULE_complexExpression","OPEN","IDENTIFIERS","AUTRE","WSS","CLOSE","POINT","CO","CF","ArrayContext","RULE_array","IndexContext","RULE_index","MULT","TIRET","COMMENT","LINE_COMMENT","HAS_COMMENT","WS","NUMBERS","enterFile","exitFile","enterDirective","exitDirective","enterDataDirective","exitDataDirective","enterModuleDirective","exitModuleDirective","enterModuleSource","exitModuleSource","enterProviderDirective","exitProviderDirective","enterTerraformDirective","exitTerraformDirective","enterResourceDirective","exitResourceDirective","enterVariableDirective","exitVariableDirective","enterOutputDirective","exitOutputDirective","enterName","exitName","enterProviderType","exitProviderType","enterType","exitType","enterObject","exitObject","enterField","exitField","enterComplexField","exitComplexField","enterValidation","exitValidation","enterCondition","exitCondition","enterExpression","exitExpression","enterFunctionCall","exitFunctionCall","enterComplexExpression","exitComplexExpression","enterArray","exitArray","enterIndex","exitIndex","terraformLexer","get_module_attribute","moduleName","parse_directory","filePath","provider","outputs","terraform","namespace_uri","namespace_prefix","parent_file","src_data","ns_uri","ns_prefix","current_parent_file","chars","hclLexer","hclParser","parse_terraform","hclListener","parse_file","SCRIPT","onmessage","event","filesPath","filesPathExplode","modulePath","get_all_objects","parse_directories","postMessage"],"sourceRoot":""}